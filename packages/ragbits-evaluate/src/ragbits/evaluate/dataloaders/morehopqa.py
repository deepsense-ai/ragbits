import json
from collections.abc import Iterable

from ragbits.core.sources.base import Source
from ragbits.evaluate.dataloaders.base import DataLoader
from ragbits.evaluate.pipelines.morehopqa import MoreHopQAData


class MoreHopQADataLoader(DataLoader[MoreHopQAData]):
    """
    MoreHopQA benchmark evaluation data loader.

    The source should point to a local/remote file exported from the
    Hugging Face dataset. Rows are expected to contain at least:
    - "_id" (str) - the unique identifier
    - "question" (str) - the question
    - "answer" (str) - the correct answer
    """

    def __init__(
        self,
        source: Source,
        *,
        split: str = "data",
        id_key: str = "_id",
        question_key: str = "question",
        answer_key: str = "answer",
        start_idx: int | None = None,
        end_idx: int | None = None,
    ) -> None:
        """
        Initialize the MoreHopQA data loader.

        Args:
            source: The source to load the data from.
            split: The split to load the data from (file name generated by the source helper).
            id_key: Column name for the task ID.
            question_key: Column name for the question.
            answer_key: Column name for the answer.
            start_idx: The starting index for the examples to load. If None, starts from 0.
            end_idx: The ending index for the examples to load. If None, loads all examples.
        """
        required = {id_key, question_key, answer_key}
        super().__init__(source=source, split=split, required_keys=required)
        self.id_key = id_key
        self.question_key = question_key
        self.answer_key = answer_key
        self.start_idx = start_idx
        self.end_idx = end_idx

    async def load(self) -> Iterable[MoreHopQAData]:
        """
        Load the data from a JSON array file.

        Returns:
            The loaded evaluation data.
        """
        data_path = await self.source.fetch()
        with open(data_path, encoding="utf-8") as f:
            dataset = json.load(f)

        # Ensure it's a list
        if not isinstance(dataset, list):
            raise ValueError(f"Expected JSON array, got {type(dataset).__name__}")

        return await self.map(dataset)

    async def map(self, dataset: Iterable[dict]) -> Iterable[MoreHopQAData]:
        """
        Map the dataset to the MoreHopQA evaluation data schema.

        Args:
            dataset: The dataset to map.

        Returns:
            The MoreHopQA evaluation data rows.
        """
        # Apply slicing if start_idx or end_idx is specified
        start = self.start_idx if self.start_idx is not None else 0
        dataset_list = list(dataset)
        end = self.end_idx if self.end_idx is not None else len(dataset_list)
        dataset = dataset_list[start:end]

        result = []
        for idx, row in enumerate(dataset):
            task_id = str(idx)
            question = str(row.get(self.question_key, ""))
            answer = str(row.get(self.answer_key, ""))

            result.append(
                MoreHopQAData(
                    task_id=task_id,
                    question=question,
                    answer=answer,
                )
            )

        return result
