{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Ragbits docs","text":""},{"location":"#main-header","title":"\ud83d\udc30 Ragbits","text":"<p> Building blocks for rapid development of GenAI applications. </p>"},{"location":"#features","title":"Features","text":""},{"location":"#build-reliable-scalable-genai-apps","title":"\ud83d\udd28 Build Reliable &amp; Scalable GenAI Apps","text":"<ul> <li>Swap LLMs anytime \u2013 Switch between 100+ LLMs via LiteLLM or run local models).</li> <li>Type-safe LLM calls \u2013 Use Python generics to enforce strict type safety in model interactions.</li> <li>Bring your own vector store \u2013 Connect to Qdrant, PgVector, and more with built-in support.</li> <li>Developer tools included \u2013 Manage vector stores, query pipelines, and test prompts from your terminal.</li> <li>Modular installation \u2013 Install only what you need, reducing dependencies and improving performance.</li> </ul>"},{"location":"#fast-flexible-rag-processing","title":"\ud83d\udcda Fast &amp; Flexible RAG Processing","text":"<ul> <li>Ingest 20+ formats \u2013 Process PDFs, HTML, spreadsheets, presentations, and more. Process data using Docling, Unstructured or create a custom parser.</li> <li>Handle complex data \u2013 Extract tables, images, and structured content with built-in VLMs support.</li> <li>Connect to any data source \u2013 Use prebuilt connectors for S3, GCS, Azure, or implement your own.</li> <li>Scale ingestion \u2013 Process large datasets quickly with Ray-based parallel processing.</li> </ul>"},{"location":"#build-multi-agent-workflows-with-ease","title":"\ud83e\udd16 Build Multi-Agent Workflows with Ease","text":"<ul> <li>Multi-agent coordination \u2013 Create teams of specialized agents with role-based collaboration using A2A protocol for interoperability.</li> <li>Real-time data integration \u2013 Leverage Model Context Protocol (MCP) for live web access, database queries, and API integrations.</li> <li>Conversation state management \u2013 Maintain context across interactions with automatic history tracking.</li> </ul>"},{"location":"#deploy-monitor-with-confidence","title":"\ud83d\ude80 Deploy &amp; Monitor with Confidence","text":"<ul> <li>Real-time observability \u2013 Track performance with OpenTelemetry and CLI insights.</li> <li>Built-in testing \u2013 Validate prompts with promptfoo before deployment.</li> <li>Auto-optimization \u2013 Continuously evaluate and refine model performance.</li> <li>Chat UI \u2013 Deploy chatbot interface with API, persistance and user feedback.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>To get started quickly, you can install with:</p> pipuv <pre><code>pip install ragbits\n</code></pre> <pre><code>uv add ragbits\n</code></pre> <p>This is a starter bundle of packages, containing:</p> <ul> <li><code>ragbits-core</code> - fundamental tools for working with prompts, LLMs and vector databases.</li> <li><code>ragbits-agents</code> - abstractions for building agentic systems.</li> <li><code>ragbits-document-search</code> - retrieval and ingestion piplines for knowledge bases.</li> <li><code>ragbits-evaluate</code> - unified evaluation framework for Ragbits components.</li> <li><code>ragbits-guardrails</code> - utilities for ensuring the safety and relevance of responses.</li> <li><code>ragbits-chat</code> - full-stack infrastructure for building conversational AI applications.</li> <li><code>ragbits-cli</code> - <code>ragbits</code> shell command for interacting with Ragbits components.</li> </ul> <p>Alternatively, you can use individual components of the stack by installing their respective packages.</p>"},{"location":"#quickstart","title":"Quickstart","text":""},{"location":"#basics","title":"Basics","text":"<p>To define a prompt and run LLM:</p> <pre><code>import asyncio\nfrom pydantic import BaseModel\nfrom ragbits.core.llms import LiteLLM\nfrom ragbits.core.prompt import Prompt\n\nclass QuestionAnswerPromptInput(BaseModel):\n    question: str\n\nclass QuestionAnswerPrompt(Prompt[QuestionAnswerPromptInput, str]):\n    system_prompt = \"\"\"\n    You are a question answering agent. Answer the question to the best of your ability.\n    \"\"\"\n    user_prompt = \"\"\"\n    Question: {{ question }}\n    \"\"\"\n\nllm = LiteLLM(model_name=\"gpt-4.1-nano\")\n\nasync def main() -&gt; None:\n    prompt = QuestionAnswerPrompt(QuestionAnswerPromptInput(question=\"What are high memory and low memory on linux?\"))\n    response = await llm.generate(prompt)\n    print(response)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"#document-search","title":"Document Search","text":"<p>To build and query a simple vector store index:</p> <pre><code>import asyncio\nfrom ragbits.core.embeddings import LiteLLMEmbedder\nfrom ragbits.core.vector_stores import InMemoryVectorStore\nfrom ragbits.document_search import DocumentSearch\n\nembedder = LiteLLMEmbedder(model_name=\"text-embedding-3-small\")\nvector_store = InMemoryVectorStore(embedder=embedder)\ndocument_search = DocumentSearch(vector_store=vector_store)\n\nasync def run() -&gt; None:\n    await document_search.ingest(\"web://https://arxiv.org/pdf/1706.03762\")\n    result = await document_search.search(\"What are the key findings presented in this paper?\")\n    print(result)\n\nif __name__ == \"__main__\":\n    asyncio.run(run())\n</code></pre>"},{"location":"#retrieval-augmented-generation","title":"Retrieval-Augmented Generation","text":"<p>To build a simple RAG pipeline:</p> <pre><code>import asyncio\nfrom collections.abc import Iterable\nfrom pydantic import BaseModel\nfrom ragbits.core.embeddings import LiteLLMEmbedder\nfrom ragbits.core.llms import LiteLLM\nfrom ragbits.core.prompt import Prompt\nfrom ragbits.core.vector_stores import InMemoryVectorStore\nfrom ragbits.document_search import DocumentSearch\nfrom ragbits.document_search.documents.element import Element\n\nclass QuestionAnswerPromptInput(BaseModel):\n    question: str\n    context: Iterable[Element]\n\nclass QuestionAnswerPrompt(Prompt[QuestionAnswerPromptInput, str]):\n    system_prompt = \"\"\"\n    You are a question answering agent. Answer the question that will be provided using context.\n    If in the given context there is not enough information refuse to answer.\n    \"\"\"\n    user_prompt = \"\"\"\n    Question: {{ question }}\n    Context: {% for chunk in context %}{{ chunk.text_representation }}{%- endfor %}\n    \"\"\"\n\nllm = LiteLLM(model_name=\"gpt-4.1-nano\")\nembedder = LiteLLMEmbedder(model_name=\"text-embedding-3-small\")\nvector_store = InMemoryVectorStore(embedder=embedder)\ndocument_search = DocumentSearch(vector_store=vector_store)\n\nasync def run() -&gt; None:\n    question = \"What are the key findings presented in this paper?\"\n\n    await document_search.ingest(\"web://https://arxiv.org/pdf/1706.03762\")\n    chunks = await document_search.search(question)\n\n    prompt = QuestionAnswerPrompt(QuestionAnswerPromptInput(question=question, context=chunks))\n    response = await llm.generate(prompt)\n    print(response)\n\nif __name__ == \"__main__\":\n    asyncio.run(run())\n</code></pre>"},{"location":"#agentic-rag","title":"Agentic RAG","text":"<p>To build an agentic RAG pipeline:</p> <pre><code>import asyncio\nfrom ragbits.agents import Agent\nfrom ragbits.core.embeddings import LiteLLMEmbedder\nfrom ragbits.core.llms import LiteLLM\nfrom ragbits.core.vector_stores import InMemoryVectorStore\nfrom ragbits.document_search import DocumentSearch\n\nembedder = LiteLLMEmbedder(model_name=\"text-embedding-3-small\")\nvector_store = InMemoryVectorStore(embedder=embedder)\ndocument_search = DocumentSearch(vector_store=vector_store)\n\nllm = LiteLLM(model_name=\"gpt-4.1-nano\")\nagent = Agent(llm=llm, tools=[document_search.search])\n\nasync def main() -&gt; None:\n    await document_search.ingest(\"web://https://arxiv.org/pdf/1706.03762\")\n    response = await agent.run(\"What are the key findings presented in this paper?\")\n    print(response.content)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"#chat-ui","title":"Chat UI","text":"<p>To expose your GenAI application through Ragbits API:</p> <pre><code>from collections.abc import AsyncGenerator\nfrom ragbits.agents import Agent, ToolCallResult\nfrom ragbits.chat.api import RagbitsAPI\nfrom ragbits.chat.interface import ChatInterface\nfrom ragbits.chat.interface.types import ChatContext, ChatResponse, LiveUpdateType\nfrom ragbits.core.embeddings import LiteLLMEmbedder\nfrom ragbits.core.llms import LiteLLM, ToolCall\nfrom ragbits.core.prompt import ChatFormat\nfrom ragbits.core.vector_stores import InMemoryVectorStore\nfrom ragbits.document_search import DocumentSearch\n\nembedder = LiteLLMEmbedder(model_name=\"text-embedding-3-small\")\nvector_store = InMemoryVectorStore(embedder=embedder)\ndocument_search = DocumentSearch(vector_store=vector_store)\n\nllm = LiteLLM(model_name=\"gpt-4.1-nano\")\nagent = Agent(llm=llm, tools=[document_search.search])\n\nclass MyChat(ChatInterface):\n    async def setup(self) -&gt; None:\n        await document_search.ingest(\"web://https://arxiv.org/pdf/1706.03762\")\n\n    async def chat(\n        self,\n        message: str,\n        history: ChatFormat,\n        context: ChatContext,\n    ) -&gt; AsyncGenerator[ChatResponse]:\n        async for result in agent.run_streaming(message):\n            match result:\n                case str():\n                    yield self.create_live_update(\n                        update_id=\"1\",\n                        type=LiveUpdateType.START,\n                        label=\"Answering...\",\n                    )\n                    yield self.create_text_response(result)\n                case ToolCall():\n                    yield self.create_live_update(\n                        update_id=\"2\",\n                        type=LiveUpdateType.START,\n                        label=\"Searching...\",\n                    )\n                case ToolCallResult():\n                    yield self.create_live_update(\n                        update_id=\"2\",\n                        type=LiveUpdateType.FINISH,\n                        label=\"Search\",\n                        description=f\"Found {len(result.result)} relevant chunks.\",\n                    )\n\n        yield self.create_live_update(\n            update_id=\"1\",\n            type=LiveUpdateType.FINISH,\n            label=\"Answer\",\n        )\n\nif __name__ == \"__main__\":\n    api = RagbitsAPI(MyChat)\n    api.run()\n</code></pre>"},{"location":"#rapid-development","title":"Rapid development","text":"<p>Create Ragbits projects from templates:</p> <pre><code>uvx create-ragbits-app\n</code></pre> <p>Explore <code>create-ragbits-app</code> repo here. If you have a new idea for a template, feel free to contribute!</p>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Tutorials - Get started with Ragbits in a few minutes</li> <li>How-to - Learn how to use Ragbits in your projects</li> <li>CLI - Learn how to run Ragbits in your terminal</li> <li>API reference - Explore the underlying Ragbits API</li> </ul>"},{"location":"#license","title":"License","text":"<p>Ragbits is licensed under the MIT License.</p>"},{"location":"api_reference/agents/","title":"Agents","text":""},{"location":"api_reference/agents/#ragbits.agents.AgentOptions","title":"ragbits.agents.AgentOptions","text":"<p>               Bases: <code>Options</code>, <code>Generic[LLMClientOptionsT]</code></p> <p>Options for the agent run.</p>"},{"location":"api_reference/agents/#ragbits.agents.AgentOptions.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(extra='allow', arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.AgentOptions.llm_options","title":"llm_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>llm_options: LLMClientOptionsT | None | NotGiven = NOT_GIVEN\n</code></pre> <p>The options for the LLM.</p>"},{"location":"api_reference/agents/#ragbits.agents.AgentOptions.max_turns","title":"max_turns  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>max_turns: int | None | NotGiven = NOT_GIVEN\n</code></pre> <p>The maximum number of turns the agent can take, if NOT_GIVEN, it defaults to 10, if None, agent will run forever</p>"},{"location":"api_reference/agents/#ragbits.agents.AgentOptions.max_total_tokens","title":"max_total_tokens  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>max_total_tokens: int | None | NotGiven = NOT_GIVEN\n</code></pre> <p>The maximum number of tokens the agent can use, if NOT_GIVEN or None, agent will run forever</p>"},{"location":"api_reference/agents/#ragbits.agents.AgentOptions.max_prompt_tokens","title":"max_prompt_tokens  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>max_prompt_tokens: int | None | NotGiven = NOT_GIVEN\n</code></pre> <p>The maximum number of prompt tokens the agent can use, if NOT_GIVEN or None, agent will run forever</p>"},{"location":"api_reference/agents/#ragbits.agents.AgentOptions.max_completion_tokens","title":"max_completion_tokens  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>max_completion_tokens: int | None | NotGiven = NOT_GIVEN\n</code></pre> <p>The maximum number of completion tokens the agent can use, if NOT_GIVEN or None, agent will run forever</p>"},{"location":"api_reference/agents/#ragbits.agents.AgentOptions.dict","title":"dict","text":"<pre><code>dict() -&gt; dict[str, Any]\n</code></pre> <p>Creates a dictionary representation of the Options instance. If a value is None, it will be replaced with a provider-specific not-given sentinel.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>A dictionary representation of the Options instance.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/options.py</code> <pre><code>def dict(self) -&gt; dict[str, Any]:  # type: ignore # mypy complains about overriding BaseModel.dict\n    \"\"\"\n    Creates a dictionary representation of the Options instance.\n    If a value is None, it will be replaced with a provider-specific not-given sentinel.\n\n    Returns:\n        A dictionary representation of the Options instance.\n    \"\"\"\n    options = self.model_dump()\n\n    return {\n        key: self._not_given if value is None or isinstance(value, NotGiven) else value\n        for key, value in options.items()\n    }\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent","title":"ragbits.agents.Agent","text":"<pre><code>Agent(llm: LLM[LLMClientOptionsT], prompt: str | type[Prompt[PromptInputT, PromptOutputT]] | Prompt[PromptInputT, PromptOutputT] | None = None, *, history: ChatFormat | None = None, keep_history: bool = False, tools: list[Callable] | None = None, mcp_servers: list[MCPServer] | None = None, default_options: AgentOptions[LLMClientOptionsT] | None = None)\n</code></pre> <p>               Bases: <code>ConfigurableComponent[AgentOptions[LLMClientOptionsT]]</code>, <code>Generic[LLMClientOptionsT, PromptInputT, PromptOutputT]</code></p> <p>Agent class that orchestrates the LLM and the prompt, and can call tools.</p> <p>Current implementation is highly experimental, and the API is subject to change.</p> <p>Initialize the agent instance.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The LLM to run the agent.</p> <p> TYPE: <code>LLM[LLMClientOptionsT]</code> </p> <code>prompt</code> <p>The prompt for the agent. Can be: - str: A string prompt that will be used as system message when combined with string input,     or as the user message when no input is provided during run(). - type[Prompt]: A structured prompt class that will be instantiated with the input. - Prompt: Already instantiated prompt instance - None: No predefined prompt. The input provided to run() will be used as the complete prompt.</p> <p> TYPE: <code>str | type[Prompt[PromptInputT, PromptOutputT]] | Prompt[PromptInputT, PromptOutputT] | None</code> DEFAULT: <code>None</code> </p> <code>history</code> <p>The history of the agent.</p> <p> TYPE: <code>ChatFormat | None</code> DEFAULT: <code>None</code> </p> <code>keep_history</code> <p>Whether to keep the history of the agent.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>tools</code> <p>The tools available to the agent.</p> <p> TYPE: <code>list[Callable] | None</code> DEFAULT: <code>None</code> </p> <code>mcp_servers</code> <p>The MCP servers available to the agent.</p> <p> TYPE: <code>list[MCPServer] | None</code> DEFAULT: <code>None</code> </p> <code>default_options</code> <p>The default options for the agent run.</p> <p> TYPE: <code>AgentOptions[LLMClientOptionsT] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/_main.py</code> <pre><code>def __init__(\n    self,\n    llm: LLM[LLMClientOptionsT],\n    prompt: str | type[Prompt[PromptInputT, PromptOutputT]] | Prompt[PromptInputT, PromptOutputT] | None = None,\n    *,\n    history: ChatFormat | None = None,\n    keep_history: bool = False,\n    tools: list[Callable] | None = None,\n    mcp_servers: list[MCPServer] | None = None,\n    default_options: AgentOptions[LLMClientOptionsT] | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the agent instance.\n\n    Args:\n        llm: The LLM to run the agent.\n        prompt: The prompt for the agent. Can be:\n            - str: A string prompt that will be used as system message when combined with string input,\n                or as the user message when no input is provided during run().\n            - type[Prompt]: A structured prompt class that will be instantiated with the input.\n            - Prompt: Already instantiated prompt instance\n            - None: No predefined prompt. The input provided to run() will be used as the complete prompt.\n        history: The history of the agent.\n        keep_history: Whether to keep the history of the agent.\n        tools: The tools available to the agent.\n        mcp_servers: The MCP servers available to the agent.\n        default_options: The default options for the agent run.\n    \"\"\"\n    super().__init__(default_options)\n    self.id = uuid.uuid4().hex[:8]\n    self.llm = llm\n    self.prompt = prompt\n    self.tools = [Tool.from_callable(tool) for tool in tools or []]\n    self.mcp_servers = mcp_servers or []\n    self.history = history or []\n    self.keep_history = keep_history\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls: type[AgentOptions] = AgentOptions\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = agents\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'agent'\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id = hex[:8]\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.llm","title":"llm  <code>instance-attribute</code>","text":"<pre><code>llm = llm\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.prompt","title":"prompt  <code>instance-attribute</code>","text":"<pre><code>prompt = prompt\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.tools","title":"tools  <code>instance-attribute</code>","text":"<pre><code>tools = [from_callable(tool) for tool in tools or []]\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.mcp_servers","title":"mcp_servers  <code>instance-attribute</code>","text":"<pre><code>mcp_servers = mcp_servers or []\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.history","title":"history  <code>instance-attribute</code>","text":"<pre><code>history = history or []\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.keep_history","title":"keep_history  <code>instance-attribute</code>","text":"<pre><code>keep_history = keep_history\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.run","title":"run  <code>async</code>","text":"<pre><code>run(input: str | PromptInputT | None = None, options: AgentOptions[LLMClientOptionsT] | None = None, context: AgentRunContext | None = None, tool_choice: ToolChoice | None = None) -&gt; AgentResult[PromptOutputT]\n</code></pre> <p>Run the agent. The method is experimental, inputs and outputs may change in the future.</p> PARAMETER DESCRIPTION <code>input</code> <p>The input for the agent run. Can be: - str: A string input that will be used as user message. - PromptInputT: Structured input for use with structured prompt classes. - None: No input. Only valid when a string prompt was provided during initialization.</p> <p> TYPE: <code>str | PromptInputT | None</code> DEFAULT: <code>None</code> </p> <code>options</code> <p>The options for the agent run.</p> <p> TYPE: <code>AgentOptions[LLMClientOptionsT] | None</code> DEFAULT: <code>None</code> </p> <code>context</code> <p>The context for the agent run.</p> <p> TYPE: <code>AgentRunContext | None</code> DEFAULT: <code>None</code> </p> <code>tool_choice</code> <p>Parameter that allows to control what tool is used at first call. Can be one of: - \"auto\": let model decide if tool call is needed - \"none\": do not call tool - \"required: enforce tool usage (model decides which one) - Callable: one of provided tools</p> <p> TYPE: <code>ToolChoice | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>AgentResult[PromptOutputT]</code> <p>The result of the agent run.</p> RAISES DESCRIPTION <code>AgentToolDuplicateError</code> <p>If the tool names are duplicated.</p> <code>AgentToolNotSupportedError</code> <p>If the selected tool type is not supported.</p> <code>AgentToolNotAvailableError</code> <p>If the selected tool is not available.</p> <code>AgentInvalidPromptInputError</code> <p>If the prompt/input combination is invalid.</p> <code>AgentMaxTurnsExceededError</code> <p>If the maximum number of turns is exceeded.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/_main.py</code> <pre><code>async def run(\n    self,\n    input: str | PromptInputT | None = None,\n    options: AgentOptions[LLMClientOptionsT] | None = None,\n    context: AgentRunContext | None = None,\n    tool_choice: ToolChoice | None = None,\n) -&gt; AgentResult[PromptOutputT]:\n    \"\"\"\n    Run the agent. The method is experimental, inputs and outputs may change in the future.\n\n    Args:\n        input: The input for the agent run. Can be:\n            - str: A string input that will be used as user message.\n            - PromptInputT: Structured input for use with structured prompt classes.\n            - None: No input. Only valid when a string prompt was provided during initialization.\n        options: The options for the agent run.\n        context: The context for the agent run.\n        tool_choice: Parameter that allows to control what tool is used at first call. Can be one of:\n            - \"auto\": let model decide if tool call is needed\n            - \"none\": do not call tool\n            - \"required: enforce tool usage (model decides which one)\n            - Callable: one of provided tools\n\n    Returns:\n        The result of the agent run.\n\n    Raises:\n        AgentToolDuplicateError: If the tool names are duplicated.\n        AgentToolNotSupportedError: If the selected tool type is not supported.\n        AgentToolNotAvailableError: If the selected tool is not available.\n        AgentInvalidPromptInputError: If the prompt/input combination is invalid.\n        AgentMaxTurnsExceededError: If the maximum number of turns is exceeded.\n    \"\"\"\n    if context is None:\n        context = AgentRunContext()\n\n    input = cast(PromptInputT, input)\n    merged_options = (self.default_options | options) if options else self.default_options\n    llm_options = merged_options.llm_options or self.llm.default_options\n\n    prompt_with_history = self._get_prompt_with_history(input)\n    tools_mapping = await self._get_all_tools()\n    tool_calls = []\n\n    turn_count = 0\n    max_turns = merged_options.max_turns\n    max_turns = 10 if max_turns is NOT_GIVEN else max_turns\n    with trace(input=input, options=merged_options) as outputs:\n        while not max_turns or turn_count &lt; max_turns:\n            self._check_token_limits(merged_options, context.usage, prompt_with_history, self.llm)\n            response = cast(\n                LLMResponseWithMetadata[PromptOutputT],\n                await self.llm.generate_with_metadata(\n                    prompt=prompt_with_history,\n                    tools=[tool.to_function_schema() for tool in tools_mapping.values()],\n                    tool_choice=tool_choice if tool_choice and turn_count == 0 else None,\n                    options=self._get_llm_options(llm_options, merged_options, context.usage),\n                ),\n            )\n            context.usage += response.usage or Usage()\n\n            if not response.tool_calls:\n                break\n\n            for tool_call in response.tool_calls:\n                result = await self._execute_tool(tool_call=tool_call, tools_mapping=tools_mapping, context=context)\n                tool_calls.append(result)\n\n                prompt_with_history = prompt_with_history.add_tool_use_message(**result.__dict__)\n\n            turn_count += 1\n        else:\n            raise AgentMaxTurnsExceededError(cast(int, max_turns))\n\n        outputs.result = {\n            \"content\": response.content,\n            \"metadata\": response.metadata,\n            \"tool_calls\": tool_calls or None,\n        }\n\n        prompt_with_history = prompt_with_history.add_assistant_message(response.content)\n\n        if self.keep_history:\n            self.history = prompt_with_history.chat\n\n        return AgentResult(\n            content=response.content,\n            metadata=response.metadata,\n            tool_calls=tool_calls or None,\n            history=prompt_with_history.chat,\n            usage=context.usage,\n        )\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.run_streaming","title":"run_streaming","text":"<pre><code>run_streaming(input: str | PromptInputT | None = None, options: AgentOptions[LLMClientOptionsT] | None = None, context: AgentRunContext | None = None, tool_choice: ToolChoice | None = None) -&gt; AgentResultStreaming\n</code></pre> <p>This method returns an <code>AgentResultStreaming</code> object that can be asynchronously iterated over. After the loop completes, all items are available under the same names as in AgentResult class.</p> PARAMETER DESCRIPTION <code>input</code> <p>The input for the agent run.</p> <p> TYPE: <code>str | PromptInputT | None</code> DEFAULT: <code>None</code> </p> <code>options</code> <p>The options for the agent run.</p> <p> TYPE: <code>AgentOptions[LLMClientOptionsT] | None</code> DEFAULT: <code>None</code> </p> <code>context</code> <p>The context for the agent run.</p> <p> TYPE: <code>AgentRunContext | None</code> DEFAULT: <code>None</code> </p> <code>tool_choice</code> <p>Parameter that allows to control what tool is used at first call. Can be one of: - \"auto\": let model decide if tool call is needed - \"none\": do not call tool - \"required: enforce tool usage (model decides which one) - Callable: one of provided tools</p> <p> TYPE: <code>ToolChoice | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>AgentResultStreaming</code> <p>A <code>StreamingResult</code> object for iteration and collection.</p> RAISES DESCRIPTION <code>AgentToolDuplicateError</code> <p>If the tool names are duplicated.</p> <code>AgentToolNotSupportedError</code> <p>If the selected tool type is not supported.</p> <code>AgentToolNotAvailableError</code> <p>If the selected tool is not available.</p> <code>AgentInvalidPromptInputError</code> <p>If the prompt/input combination is invalid.</p> <code>AgentMaxTurnsExceededError</code> <p>If the maximum number of turns is exceeded.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/_main.py</code> <pre><code>def run_streaming(\n    self,\n    input: str | PromptInputT | None = None,\n    options: AgentOptions[LLMClientOptionsT] | None = None,\n    context: AgentRunContext | None = None,\n    tool_choice: ToolChoice | None = None,\n) -&gt; AgentResultStreaming:\n    \"\"\"\n    This method returns an `AgentResultStreaming` object that can be asynchronously\n    iterated over. After the loop completes, all items are available under the same names as in AgentResult class.\n\n    Args:\n        input: The input for the agent run.\n        options: The options for the agent run.\n        context: The context for the agent run.\n        tool_choice: Parameter that allows to control what tool is used at first call. Can be one of:\n            - \"auto\": let model decide if tool call is needed\n            - \"none\": do not call tool\n            - \"required: enforce tool usage (model decides which one)\n            - Callable: one of provided tools\n\n    Returns:\n        A `StreamingResult` object for iteration and collection.\n\n    Raises:\n        AgentToolDuplicateError: If the tool names are duplicated.\n        AgentToolNotSupportedError: If the selected tool type is not supported.\n        AgentToolNotAvailableError: If the selected tool is not available.\n        AgentInvalidPromptInputError: If the prompt/input combination is invalid.\n        AgentMaxTurnsExceededError: If the maximum number of turns is exceeded.\n    \"\"\"\n    generator = self._stream_internal(input, options, context, tool_choice)\n    return AgentResultStreaming(generator)\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.get_agent_card","title":"get_agent_card  <code>async</code>","text":"<pre><code>get_agent_card(name: str, description: str, version: str = '0.0.0', host: str = '127.0.0.1', port: int = 8000, protocol: str = 'http', default_input_modes: list[str] | None = None, default_output_modes: list[str] | None = None, capabilities: AgentCapabilities | None = None, skills: list[AgentSkill] | None = None) -&gt; AgentCard\n</code></pre> <p>Create an AgentCard that encapsulates metadata about the agent, such as its name, version, description, network location, supported input/output modes, capabilities, and skills.</p> PARAMETER DESCRIPTION <code>name</code> <p>Human-readable name of the agent.</p> <p> TYPE: <code>str</code> </p> <code>description</code> <p>A brief description of the agent.</p> <p> TYPE: <code>str</code> </p> <code>version</code> <p>Version string of the agent. Defaults to \"0.0.0\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'0.0.0'</code> </p> <code>host</code> <p>Hostname or IP where the agent will be served. Defaults to \"0.0.0.0\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'127.0.0.1'</code> </p> <code>port</code> <p>Port number on which the agent listens. Defaults to 8000.</p> <p> TYPE: <code>int</code> DEFAULT: <code>8000</code> </p> <code>protocol</code> <p>URL scheme (e.g. \"http\" or \"https\"). Defaults to \"http\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'http'</code> </p> <code>default_input_modes</code> <p>List of input content modes supported by the agent. Defaults to [\"text\"].</p> <p> TYPE: <code>list[str] | None</code> DEFAULT: <code>None</code> </p> <code>default_output_modes</code> <p>List of output content modes supported. Defaults to [\"text\"].</p> <p> TYPE: <code>list[str] | None</code> DEFAULT: <code>None</code> </p> <code>capabilities</code> <p>Agent capabilities; if None, defaults to empty capabilities.</p> <p> TYPE: <code>AgentCapabilities | None</code> DEFAULT: <code>None</code> </p> <code>skills</code> <p>List of AgentSkill objects representing the agent's skills. If None, attempts to extract skills from the agent's registered tools.</p> <p> TYPE: <code>list[AgentSkill] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>AgentCard</code> <p>An A2A-compliant agent descriptor including URL and capabilities.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/_main.py</code> <pre><code>@requires_dependencies([\"a2a.types\"], \"a2a\")\nasync def get_agent_card(\n    self,\n    name: str,\n    description: str,\n    version: str = \"0.0.0\",\n    host: str = \"127.0.0.1\",\n    port: int = 8000,\n    protocol: str = \"http\",\n    default_input_modes: list[str] | None = None,\n    default_output_modes: list[str] | None = None,\n    capabilities: \"AgentCapabilities | None\" = None,\n    skills: list[\"AgentSkill\"] | None = None,\n) -&gt; \"AgentCard\":\n    \"\"\"\n    Create an AgentCard that encapsulates metadata about the agent,\n    such as its name, version, description, network location, supported input/output modes,\n    capabilities, and skills.\n\n    Args:\n        name: Human-readable name of the agent.\n        description: A brief description of the agent.\n        version: Version string of the agent. Defaults to \"0.0.0\".\n        host: Hostname or IP where the agent will be served. Defaults to \"0.0.0.0\".\n        port: Port number on which the agent listens. Defaults to 8000.\n        protocol: URL scheme (e.g. \"http\" or \"https\"). Defaults to \"http\".\n        default_input_modes: List of input content modes supported by the agent. Defaults to [\"text\"].\n        default_output_modes: List of output content modes supported. Defaults to [\"text\"].\n        capabilities: Agent capabilities; if None, defaults to empty capabilities.\n        skills: List of AgentSkill objects representing the agent's skills.\n            If None, attempts to extract skills from the agent's registered tools.\n\n    Returns:\n        An A2A-compliant agent descriptor including URL and capabilities.\n    \"\"\"\n    return AgentCard(\n        name=name,\n        version=version,\n        description=description,\n        url=f\"{protocol}://{host}:{port}\",\n        defaultInputModes=default_input_modes or [\"text\"],\n        defaultOutputModes=default_output_modes or [\"text\"],\n        skills=skills or await self._extract_agent_skills(),\n        capabilities=capabilities or AgentCapabilities(),\n    )\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.to_pydantic_ai","title":"to_pydantic_ai","text":"<pre><code>to_pydantic_ai() -&gt; Agent\n</code></pre> <p>Convert ragbits agent instance into a <code>pydantic_ai.Agent</code> representation.</p> RETURNS DESCRIPTION <code>PydanticAIAgent</code> <p>The equivalent Pydantic-based agent configuration.</p> <p> TYPE: <code>Agent</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If the <code>prompt</code> is not a string or a <code>Prompt</code> instance.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/_main.py</code> <pre><code>@requires_dependencies(\"pydantic_ai\")\ndef to_pydantic_ai(self) -&gt; \"PydanticAIAgent\":\n    \"\"\"\n    Convert ragbits agent instance into a `pydantic_ai.Agent` representation.\n\n    Returns:\n        PydanticAIAgent: The equivalent Pydantic-based agent configuration.\n\n    Raises:\n        ValueError: If the `prompt` is not a string or a `Prompt` instance.\n    \"\"\"\n    mcp_servers: list[mcp.MCPServerStdio | mcp.MCPServerHTTP] = []\n\n    if not self.prompt:\n        raise ValueError(\"Prompt is required but was None.\")\n\n    if isinstance(self.prompt, str):\n        system_prompt = self.prompt\n    else:\n        if not self.prompt.system_prompt:\n            raise ValueError(\"System prompt is required but was None.\")\n        system_prompt = self.prompt.system_prompt\n\n    for mcp_server in self.mcp_servers:\n        if isinstance(mcp_server, MCPServerStdio):\n            mcp_servers.append(\n                mcp.MCPServerStdio(\n                    command=mcp_server.params.command, args=mcp_server.params.args, env=mcp_server.params.env\n                )\n            )\n        elif isinstance(mcp_server, MCPServerStreamableHttp):\n            timeout = mcp_server.params[\"timeout\"]\n            sse_timeout = mcp_server.params[\"sse_read_timeout\"]\n\n            mcp_servers.append(\n                mcp.MCPServerHTTP(\n                    url=mcp_server.params[\"url\"],\n                    headers=mcp_server.params[\"headers\"],\n                    timeout=timeout.total_seconds() if isinstance(timeout, timedelta) else timeout,\n                    sse_read_timeout=sse_timeout.total_seconds()\n                    if isinstance(sse_timeout, timedelta)\n                    else sse_timeout,\n                )\n            )\n    return PydanticAIAgent(\n        model=self.llm.model_name,\n        system_prompt=system_prompt,\n        tools=[tool.to_pydantic_ai() for tool in self.tools],\n        mcp_servers=mcp_servers,\n    )\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.Agent.from_pydantic_ai","title":"from_pydantic_ai  <code>classmethod</code>","text":"<pre><code>from_pydantic_ai(pydantic_ai_agent: Agent) -&gt; Self\n</code></pre> <p>Construct an agent instance from a <code>pydantic_ai.Agent</code> representation.</p> PARAMETER DESCRIPTION <code>pydantic_ai_agent</code> <p>A Pydantic-based agent configuration.</p> <p> TYPE: <code>Agent</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the agent class initialized from the Pydantic representation.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/_main.py</code> <pre><code>@classmethod\n@requires_dependencies(\"pydantic_ai\")\ndef from_pydantic_ai(cls, pydantic_ai_agent: \"PydanticAIAgent\") -&gt; Self:\n    \"\"\"\n    Construct an agent instance from a `pydantic_ai.Agent` representation.\n\n    Args:\n        pydantic_ai_agent: A Pydantic-based agent configuration.\n\n    Returns:\n        An instance of the agent class initialized from the Pydantic representation.\n    \"\"\"\n    mcp_servers: list[MCPServerStdio | MCPServerStreamableHttp] = []\n    for mcp_server in pydantic_ai_agent._mcp_servers:\n        if isinstance(mcp_server, mcp.MCPServerStdio):\n            mcp_servers.append(\n                MCPServerStdio(\n                    params={\n                        \"command\": mcp_server.command,\n                        \"args\": list(mcp_server.args),\n                        \"env\": mcp_server.env or {},\n                    }\n                )\n            )\n        elif isinstance(mcp_server, mcp.MCPServerHTTP):\n            headers = mcp_server.headers or {}\n\n            mcp_servers.append(\n                MCPServerStreamableHttp(\n                    params={\n                        \"url\": mcp_server.url,\n                        \"headers\": {str(k): str(v) for k, v in headers.items()},\n                        \"sse_read_timeout\": mcp_server.sse_read_timeout,\n                        \"timeout\": mcp_server.timeout,\n                    }\n                )\n            )\n\n    if not pydantic_ai_agent.model:\n        raise ValueError(\"Missing LLM in `pydantic_ai.Agent` instance\")\n    elif isinstance(pydantic_ai_agent.model, str):\n        model_name = pydantic_ai_agent.model\n    else:\n        model_name = pydantic_ai_agent.model.model_name\n\n    return cls(\n        llm=LiteLLM(model_name=model_name),  # type: ignore[arg-type]\n        prompt=\"\\n\".join(pydantic_ai_agent._system_prompts),\n        tools=[tool.function for _, tool in pydantic_ai_agent._function_tools.items()],\n        mcp_servers=cast(list[MCPServer], mcp_servers),\n    )\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.AgentResult","title":"ragbits.agents.AgentResult  <code>dataclass</code>","text":"<pre><code>AgentResult(content: PromptOutputT, metadata: dict, history: ChatFormat, tool_calls: list[ToolCallResult] | None = None, usage: Usage = Field(default_factory=Usage))\n</code></pre> <p>               Bases: <code>Generic[PromptOutputT]</code></p> <p>Result of the agent run.</p>"},{"location":"api_reference/agents/#ragbits.agents.AgentResult.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: PromptOutputT\n</code></pre> <p>The output content of the agent.</p>"},{"location":"api_reference/agents/#ragbits.agents.AgentResult.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: dict\n</code></pre> <p>The additional data returned by the agent.</p>"},{"location":"api_reference/agents/#ragbits.agents.AgentResult.history","title":"history  <code>instance-attribute</code>","text":"<pre><code>history: ChatFormat\n</code></pre> <p>The history of the agent.</p>"},{"location":"api_reference/agents/#ragbits.agents.AgentResult.tool_calls","title":"tool_calls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>tool_calls: list[ToolCallResult] | None = None\n</code></pre> <p>Tool calls run by the agent.</p>"},{"location":"api_reference/agents/#ragbits.agents.AgentResult.usage","title":"usage  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>usage: Usage = Field(default_factory=Usage)\n</code></pre> <p>The token usage of the agent run.</p>"},{"location":"api_reference/agents/#ragbits.agents.AgentResultStreaming","title":"ragbits.agents.AgentResultStreaming","text":"<pre><code>AgentResultStreaming(generator: AsyncGenerator[str | ToolCall | ToolCallResult | SimpleNamespace | BasePrompt | Usage])\n</code></pre> <p>               Bases: <code>AsyncIterator[str | ToolCall | ToolCallResult]</code></p> <p>An async iterator that will collect all yielded items by LLM.generate_streaming(). This object is returned by <code>run_streaming</code>. It can be used in an <code>async for</code> loop to process items as they arrive. After the loop completes, all items are available under the same names as in AgentResult class.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/_main.py</code> <pre><code>def __init__(\n    self, generator: AsyncGenerator[str | ToolCall | ToolCallResult | SimpleNamespace | BasePrompt | Usage]\n):\n    self._generator = generator\n    self.content: str = \"\"\n    self.tool_calls: list[ToolCallResult] | None = None\n    self.metadata: dict = {}\n    self.history: ChatFormat\n    self.usage: Usage = Usage()\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.AgentResultStreaming.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: str = ''\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.AgentResultStreaming.tool_calls","title":"tool_calls  <code>instance-attribute</code>","text":"<pre><code>tool_calls: list[ToolCallResult] | None = None\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.AgentResultStreaming.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: dict = {}\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.AgentResultStreaming.history","title":"history  <code>instance-attribute</code>","text":"<pre><code>history: ChatFormat\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.AgentResultStreaming.usage","title":"usage  <code>instance-attribute</code>","text":"<pre><code>usage: Usage = Usage()\n</code></pre>"},{"location":"api_reference/agents/#ragbits.agents.a2a.server.create_agent_server","title":"ragbits.agents.a2a.server.create_agent_server","text":"<pre><code>create_agent_server(agent: Agent, agent_card: AgentCard, input_model: type[BaseModel]) -&gt; Server\n</code></pre> <p>Create a Uvicorn server instance that serves the specified agent over HTTP.</p> <p>The server's host and port are extracted from the URL in the given agent_card.</p> PARAMETER DESCRIPTION <code>agent</code> <p>The Ragbits Agent instance to serve.</p> <p> TYPE: <code>Agent</code> </p> <code>agent_card</code> <p>Metadata for the agent, including its URL.</p> <p> TYPE: <code>AgentCard</code> </p> <code>input_model</code> <p>A Pydantic model class used to validate incoming request data.</p> <p> TYPE: <code>type[BaseModel]</code> </p> RETURNS DESCRIPTION <code>Server</code> <p>A configured uvicorn.Server instance ready to be started.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the URL in agent_card does not contain a valid hostname or port.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/a2a/server.py</code> <pre><code>def create_agent_server(\n    agent: Agent,\n    agent_card: \"AgentCard\",\n    input_model: type[BaseModel],\n) -&gt; \"uvicorn.Server\":\n    \"\"\"\n    Create a Uvicorn server instance that serves the specified agent over HTTP.\n\n    The server's host and port are extracted from the URL in the given agent_card.\n\n    Args:\n        agent: The Ragbits Agent instance to serve.\n        agent_card: Metadata for the agent, including its URL.\n        input_model: A Pydantic model class used to validate incoming request data.\n\n    Returns:\n        A configured uvicorn.Server instance ready to be started.\n\n    Raises:\n        ValueError: If the URL in agent_card does not contain a valid hostname or port.\n    \"\"\"\n    app = create_agent_app(agent=agent, agent_card=agent_card, input_model=input_model)\n    url = urlparse(agent_card.url)\n\n    if not url.hostname:\n        raise ValueError(f\"Could not parse hostname from URL: {agent_card.url}\")\n    if not url.port:\n        raise ValueError(f\"Could not parse port from URL: {agent_card.url}\")\n\n    config = uvicorn.Config(app=app, host=url.hostname, port=url.port)\n    server = uvicorn.Server(config=config)\n\n    return server\n</code></pre>"},{"location":"api_reference/agents/mcp/","title":"Server","text":""},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServer","title":"ragbits.agents.mcp.server.MCPServer","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for Model Context Protocol servers.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServer.name","title":"name  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>A readable name for the server.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServer.connect","title":"connect  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>connect() -&gt; None\n</code></pre> <p>Connect to the server. For example, this might mean spawning a subprocess or opening a network connection. The server is expected to remain connected until <code>cleanup()</code> is called.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>@abstractmethod\nasync def connect(self) -&gt; None:\n    \"\"\"\n    Connect to the server. For example, this might mean spawning a subprocess or\n    opening a network connection. The server is expected to remain connected until `cleanup()` is called.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServer.cleanup","title":"cleanup  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>cleanup() -&gt; None\n</code></pre> <p>Cleanup the server. For example, this might mean closing a subprocess or closing a network connection.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>@abstractmethod\nasync def cleanup(self) -&gt; None:\n    \"\"\"\n    Cleanup the server. For example, this might mean closing a subprocess or closing a network connection.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServer.list_tools","title":"list_tools  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>list_tools() -&gt; list[Tool]\n</code></pre> <p>List the tools available on the server.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>@abstractmethod\nasync def list_tools(self) -&gt; list[\"MCPTool\"]:\n    \"\"\"\n    List the tools available on the server.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServer.call_tool","title":"call_tool  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>call_tool(tool_name: str, arguments: dict[str, Any] | None) -&gt; CallToolResult\n</code></pre> <p>Invoke a tool on the server.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>@abstractmethod\nasync def call_tool(self, tool_name: str, arguments: dict[str, Any] | None) -&gt; \"CallToolResult\":\n    \"\"\"\n    Invoke a tool on the server.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdioParams","title":"ragbits.agents.mcp.server.MCPServerStdioParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>Mirrors <code>mcp.client.stdio.StdioServerParameters</code>, but lets you pass params without another import.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdioParams.command","title":"command  <code>instance-attribute</code>","text":"<pre><code>command: str\n</code></pre> <p>The executable to run to start the server. For example, <code>python</code> or <code>node</code>.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdioParams.args","title":"args  <code>instance-attribute</code>","text":"<pre><code>args: NotRequired[list[str]]\n</code></pre> <p>Command line args to pass to the <code>command</code> executable. For example, <code>['foo.py']</code> or <code>['server.js', '--port', '8080']</code>.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdioParams.env","title":"env  <code>instance-attribute</code>","text":"<pre><code>env: NotRequired[dict[str, str]]\n</code></pre> <p>The environment variables to set for the server. .</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdioParams.cwd","title":"cwd  <code>instance-attribute</code>","text":"<pre><code>cwd: NotRequired[str | Path]\n</code></pre> <p>The working directory to use when spawning the process.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdioParams.encoding","title":"encoding  <code>instance-attribute</code>","text":"<pre><code>encoding: NotRequired[str]\n</code></pre> <p>The text encoding used when sending/receiving messages to the server. Defaults to <code>utf-8</code>.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdioParams.encoding_error_handler","title":"encoding_error_handler  <code>instance-attribute</code>","text":"<pre><code>encoding_error_handler: NotRequired[Literal['strict', 'ignore', 'replace']]\n</code></pre> <p>The text encoding error handler. Defaults to <code>strict</code>.</p> <p>See https://docs.python.org/3/library/codecs.html#codec-base-classes for explanations of possible values.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdio","title":"ragbits.agents.mcp.server.MCPServerStdio","text":"<pre><code>MCPServerStdio(params: MCPServerStdioParams, cache_tools_list: bool = False, name: str | None = None, client_session_timeout_seconds: float | None = 5)\n</code></pre> <p>               Bases: <code>_MCPServerWithClientSession</code></p> <p>MCP server implementation that uses the stdio transport. See the spec for details.</p> <p>Create a new MCP server based on the stdio transport.</p> PARAMETER DESCRIPTION <code>params</code> <p>The params that configure the server. This includes the command to run to start the server, the args to pass to the command, the environment variables to set for the server, the working directory to use when spawning the process, and the text encoding used when sending/receiving messages to the server.</p> <p> TYPE: <code>MCPServerStdioParams</code> </p> <code>cache_tools_list</code> <p>Whether to cache the tools list. If <code>True</code>, the tools list will be cached and only fetched from the server once. If <code>False</code>, the tools list will be fetched from the server on each call to <code>list_tools()</code>. The cache can be invalidated by calling <code>invalidate_tools_cache()</code>. You should set this to <code>True</code> if you know the server will not change its tools list, because it can drastically improve latency (by avoiding a round-trip to the server every time).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>name</code> <p>A readable name for the server. If not provided, we'll create one from the command.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>client_session_timeout_seconds</code> <p>the read timeout passed to the MCP ClientSession.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>5</code> </p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>def __init__(\n    self,\n    params: MCPServerStdioParams,\n    cache_tools_list: bool = False,\n    name: str | None = None,\n    client_session_timeout_seconds: float | None = 5,\n) -&gt; None:\n    \"\"\"\n    Create a new MCP server based on the stdio transport.\n\n    Args:\n        params: The params that configure the server. This includes the command to run to\n            start the server, the args to pass to the command, the environment variables to\n            set for the server, the working directory to use when spawning the process, and\n            the text encoding used when sending/receiving messages to the server.\n        cache_tools_list: Whether to cache the tools list. If `True`, the tools list will be\n            cached and only fetched from the server once. If `False`, the tools list will be\n            fetched from the server on each call to `list_tools()`. The cache can be\n            invalidated by calling `invalidate_tools_cache()`. You should set this to `True`\n            if you know the server will not change its tools list, because it can drastically\n            improve latency (by avoiding a round-trip to the server every time).\n        name: A readable name for the server. If not provided, we'll create one from the\n            command.\n        client_session_timeout_seconds: the read timeout passed to the MCP ClientSession.\n    \"\"\"\n    super().__init__(cache_tools_list, client_session_timeout_seconds)\n\n    self.params = StdioServerParameters(\n        command=params[\"command\"],\n        args=params.get(\"args\", []),\n        env=params.get(\"env\"),\n        cwd=params.get(\"cwd\"),\n        encoding=params.get(\"encoding\", \"utf-8\"),\n        encoding_error_handler=params.get(\"encoding_error_handler\", \"strict\"),\n    )\n\n    self._name = name or f\"stdio: {self.params.command}\"\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdio.session","title":"session  <code>instance-attribute</code>","text":"<pre><code>session: ClientSession | None = None\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdio.exit_stack","title":"exit_stack  <code>instance-attribute</code>","text":"<pre><code>exit_stack = AsyncExitStack()\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdio.cache_tools_list","title":"cache_tools_list  <code>instance-attribute</code>","text":"<pre><code>cache_tools_list = cache_tools_list\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdio.server_initialize_result","title":"server_initialize_result  <code>instance-attribute</code>","text":"<pre><code>server_initialize_result: InitializeResult | None = None\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdio.client_session_timeout_seconds","title":"client_session_timeout_seconds  <code>instance-attribute</code>","text":"<pre><code>client_session_timeout_seconds = client_session_timeout_seconds\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdio.params","title":"params  <code>instance-attribute</code>","text":"<pre><code>params = StdioServerParameters(command=params['command'], args=get('args', []), env=get('env'), cwd=get('cwd'), encoding=get('encoding', 'utf-8'), encoding_error_handler=get('encoding_error_handler', 'strict'))\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdio.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>A readable name for the server.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdio.connect","title":"connect  <code>async</code>","text":"<pre><code>connect() -&gt; None\n</code></pre> <p>Connect to the server.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>async def connect(self) -&gt; None:\n    \"\"\"\n    Connect to the server.\n    \"\"\"\n    try:\n        transport = await self.exit_stack.enter_async_context(self.create_streams())\n        # streamablehttp_client returns (read, write, get_session_id)\n        # sse_client returns (read, write)\n\n        read, write, *_ = transport\n\n        session = await self.exit_stack.enter_async_context(\n            ClientSession(\n                read,\n                write,\n                timedelta(seconds=self.client_session_timeout_seconds)\n                if self.client_session_timeout_seconds\n                else None,\n            )\n        )\n        server_result = await session.initialize()\n        self.server_initialize_result = server_result\n        self.session = session\n    except Exception as e:\n        logger.error(f\"Error initializing MCP server: {e}\")\n        await self.cleanup()\n        raise\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdio.cleanup","title":"cleanup  <code>async</code>","text":"<pre><code>cleanup() -&gt; None\n</code></pre> <p>Cleanup the server.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>async def cleanup(self) -&gt; None:\n    \"\"\"\n    Cleanup the server.\n    \"\"\"\n    async with self._cleanup_lock:\n        try:\n            await self.exit_stack.aclose()\n        except Exception as e:\n            logger.error(f\"Error cleaning up server: {e}\")\n        finally:\n            self.session = None\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdio.list_tools","title":"list_tools  <code>async</code>","text":"<pre><code>list_tools() -&gt; list[Tool]\n</code></pre> <p>List the tools available on the server.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>async def list_tools(self) -&gt; list[\"MCPTool\"]:\n    \"\"\"\n    List the tools available on the server.\n    \"\"\"\n    if not self.session:\n        raise RuntimeError(\"Server not initialized. Make sure you call `connect()` first.\")\n\n    # Return from cache if caching is enabled, we have tools, and the cache is not dirty\n    if self.cache_tools_list and not self._cache_dirty and self._tools_list:\n        return self._tools_list\n\n    # Reset the cache dirty to False\n    self._cache_dirty = False\n\n    # Fetch the tools from the server\n    self._tools_list = (await self.session.list_tools()).tools\n    return self._tools_list\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdio.call_tool","title":"call_tool  <code>async</code>","text":"<pre><code>call_tool(tool_name: str, arguments: dict[str, Any] | None) -&gt; CallToolResult\n</code></pre> <p>Invoke a tool on the server.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>async def call_tool(self, tool_name: str, arguments: dict[str, Any] | None) -&gt; \"CallToolResult\":\n    \"\"\"\n    Invoke a tool on the server.\n    \"\"\"\n    if not self.session:\n        raise RuntimeError(\"Server not initialized. Make sure you call `connect()` first.\")\n\n    return await self.session.call_tool(tool_name, arguments)\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdio.invalidate_tools_cache","title":"invalidate_tools_cache","text":"<pre><code>invalidate_tools_cache() -&gt; None\n</code></pre> <p>Invalidate the tools cache.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>def invalidate_tools_cache(self) -&gt; None:\n    \"\"\"\n    Invalidate the tools cache.\n    \"\"\"\n    self._cache_dirty = True\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStdio.create_streams","title":"create_streams","text":"<pre><code>create_streams() -&gt; AbstractAsyncContextManager[tuple[MemoryObjectReceiveStream[SessionMessage | Exception], MemoryObjectSendStream[SessionMessage], GetSessionIdCallback | None]]\n</code></pre> <p>Create the streams for the server.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>def create_streams(\n    self,\n) -&gt; AbstractAsyncContextManager[\n    tuple[\n        \"MemoryObjectReceiveStream[SessionMessage | Exception]\",\n        \"MemoryObjectSendStream[SessionMessage]\",\n        \"GetSessionIdCallback | None\",\n    ]\n]:\n    \"\"\"\n    Create the streams for the server.\n    \"\"\"\n    return stdio_client(self.params)\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSseParams","title":"ragbits.agents.mcp.server.MCPServerSseParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>Mirrors the params in<code>mcp.client.sse.sse_client</code>.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSseParams.url","title":"url  <code>instance-attribute</code>","text":"<pre><code>url: str\n</code></pre> <p>The URL of the server.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSseParams.headers","title":"headers  <code>instance-attribute</code>","text":"<pre><code>headers: NotRequired[dict[str, str]]\n</code></pre> <p>The headers to send to the server.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSseParams.timeout","title":"timeout  <code>instance-attribute</code>","text":"<pre><code>timeout: NotRequired[float]\n</code></pre> <p>The timeout for the HTTP request. Defaults to 5 seconds.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSseParams.sse_read_timeout","title":"sse_read_timeout  <code>instance-attribute</code>","text":"<pre><code>sse_read_timeout: NotRequired[float]\n</code></pre> <p>The timeout for the SSE connection, in seconds. Defaults to 5 minutes.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSse","title":"ragbits.agents.mcp.server.MCPServerSse","text":"<pre><code>MCPServerSse(params: MCPServerSseParams, cache_tools_list: bool = False, name: str | None = None, client_session_timeout_seconds: float | None = 5)\n</code></pre> <p>               Bases: <code>_MCPServerWithClientSession</code></p> <p>MCP server implementation that uses the HTTP with SSE transport. See the spec for details.</p> <p>Create a new MCP server based on the HTTP with SSE transport.</p> PARAMETER DESCRIPTION <code>params</code> <p>The params that configure the server. This includes the URL of the server, the headers to send to the server, the timeout for the HTTP request, and the timeout for the SSE connection.</p> <p> TYPE: <code>MCPServerSseParams</code> </p> <code>cache_tools_list</code> <p>Whether to cache the tools list. If <code>True</code>, the tools list will be cached and only fetched from the server once. If <code>False</code>, the tools list will be fetched from the server on each call to <code>list_tools()</code>. The cache can be invalidated by calling <code>invalidate_tools_cache()</code>. You should set this to <code>True</code> if you know the server will not change its tools list, because it can drastically improve latency (by avoiding a round-trip to the server every time).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>name</code> <p>A readable name for the server. If not provided, we'll create one from the URL.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>client_session_timeout_seconds</code> <p>the read timeout passed to the MCP ClientSession.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>5</code> </p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>def __init__(\n    self,\n    params: MCPServerSseParams,\n    cache_tools_list: bool = False,\n    name: str | None = None,\n    client_session_timeout_seconds: float | None = 5,\n) -&gt; None:\n    \"\"\"\n    Create a new MCP server based on the HTTP with SSE transport.\n\n    Args:\n        params: The params that configure the server. This includes the URL of the server,\n            the headers to send to the server, the timeout for the HTTP request, and the\n            timeout for the SSE connection.\n        cache_tools_list: Whether to cache the tools list. If `True`, the tools list will be\n            cached and only fetched from the server once. If `False`, the tools list will be\n            fetched from the server on each call to `list_tools()`. The cache can be\n            invalidated by calling `invalidate_tools_cache()`. You should set this to `True`\n            if you know the server will not change its tools list, because it can drastically\n            improve latency (by avoiding a round-trip to the server every time).\n        name: A readable name for the server. If not provided, we'll create one from the\n            URL.\n        client_session_timeout_seconds: the read timeout passed to the MCP ClientSession.\n    \"\"\"\n    super().__init__(cache_tools_list, client_session_timeout_seconds)\n\n    self.params = params\n    self._name = name or f\"sse: {self.params['url']}\"\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSse.session","title":"session  <code>instance-attribute</code>","text":"<pre><code>session: ClientSession | None = None\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSse.exit_stack","title":"exit_stack  <code>instance-attribute</code>","text":"<pre><code>exit_stack = AsyncExitStack()\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSse.cache_tools_list","title":"cache_tools_list  <code>instance-attribute</code>","text":"<pre><code>cache_tools_list = cache_tools_list\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSse.server_initialize_result","title":"server_initialize_result  <code>instance-attribute</code>","text":"<pre><code>server_initialize_result: InitializeResult | None = None\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSse.client_session_timeout_seconds","title":"client_session_timeout_seconds  <code>instance-attribute</code>","text":"<pre><code>client_session_timeout_seconds = client_session_timeout_seconds\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSse.params","title":"params  <code>instance-attribute</code>","text":"<pre><code>params = params\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSse.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>A readable name for the server.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSse.connect","title":"connect  <code>async</code>","text":"<pre><code>connect() -&gt; None\n</code></pre> <p>Connect to the server.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>async def connect(self) -&gt; None:\n    \"\"\"\n    Connect to the server.\n    \"\"\"\n    try:\n        transport = await self.exit_stack.enter_async_context(self.create_streams())\n        # streamablehttp_client returns (read, write, get_session_id)\n        # sse_client returns (read, write)\n\n        read, write, *_ = transport\n\n        session = await self.exit_stack.enter_async_context(\n            ClientSession(\n                read,\n                write,\n                timedelta(seconds=self.client_session_timeout_seconds)\n                if self.client_session_timeout_seconds\n                else None,\n            )\n        )\n        server_result = await session.initialize()\n        self.server_initialize_result = server_result\n        self.session = session\n    except Exception as e:\n        logger.error(f\"Error initializing MCP server: {e}\")\n        await self.cleanup()\n        raise\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSse.cleanup","title":"cleanup  <code>async</code>","text":"<pre><code>cleanup() -&gt; None\n</code></pre> <p>Cleanup the server.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>async def cleanup(self) -&gt; None:\n    \"\"\"\n    Cleanup the server.\n    \"\"\"\n    async with self._cleanup_lock:\n        try:\n            await self.exit_stack.aclose()\n        except Exception as e:\n            logger.error(f\"Error cleaning up server: {e}\")\n        finally:\n            self.session = None\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSse.list_tools","title":"list_tools  <code>async</code>","text":"<pre><code>list_tools() -&gt; list[Tool]\n</code></pre> <p>List the tools available on the server.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>async def list_tools(self) -&gt; list[\"MCPTool\"]:\n    \"\"\"\n    List the tools available on the server.\n    \"\"\"\n    if not self.session:\n        raise RuntimeError(\"Server not initialized. Make sure you call `connect()` first.\")\n\n    # Return from cache if caching is enabled, we have tools, and the cache is not dirty\n    if self.cache_tools_list and not self._cache_dirty and self._tools_list:\n        return self._tools_list\n\n    # Reset the cache dirty to False\n    self._cache_dirty = False\n\n    # Fetch the tools from the server\n    self._tools_list = (await self.session.list_tools()).tools\n    return self._tools_list\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSse.call_tool","title":"call_tool  <code>async</code>","text":"<pre><code>call_tool(tool_name: str, arguments: dict[str, Any] | None) -&gt; CallToolResult\n</code></pre> <p>Invoke a tool on the server.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>async def call_tool(self, tool_name: str, arguments: dict[str, Any] | None) -&gt; \"CallToolResult\":\n    \"\"\"\n    Invoke a tool on the server.\n    \"\"\"\n    if not self.session:\n        raise RuntimeError(\"Server not initialized. Make sure you call `connect()` first.\")\n\n    return await self.session.call_tool(tool_name, arguments)\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSse.invalidate_tools_cache","title":"invalidate_tools_cache","text":"<pre><code>invalidate_tools_cache() -&gt; None\n</code></pre> <p>Invalidate the tools cache.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>def invalidate_tools_cache(self) -&gt; None:\n    \"\"\"\n    Invalidate the tools cache.\n    \"\"\"\n    self._cache_dirty = True\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerSse.create_streams","title":"create_streams","text":"<pre><code>create_streams() -&gt; AbstractAsyncContextManager[tuple[MemoryObjectReceiveStream[SessionMessage | Exception], MemoryObjectSendStream[SessionMessage], GetSessionIdCallback | None]]\n</code></pre> <p>Create the streams for the server.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>def create_streams(\n    self,\n) -&gt; AbstractAsyncContextManager[\n    tuple[\n        \"MemoryObjectReceiveStream[SessionMessage | Exception]\",\n        \"MemoryObjectSendStream[SessionMessage]\",\n        \"GetSessionIdCallback | None\",\n    ]\n]:\n    \"\"\"\n    Create the streams for the server.\n    \"\"\"\n    return sse_client(\n        url=self.params[\"url\"],\n        headers=self.params.get(\"headers\", None),\n        timeout=self.params.get(\"timeout\", 5),\n        sse_read_timeout=self.params.get(\"sse_read_timeout\", 60 * 5),\n    )\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttpParams","title":"ragbits.agents.mcp.server.MCPServerStreamableHttpParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>Mirrors the params in<code>mcp.client.streamable_http.streamablehttp_client</code>.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttpParams.url","title":"url  <code>instance-attribute</code>","text":"<pre><code>url: str\n</code></pre> <p>The URL of the server.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttpParams.headers","title":"headers  <code>instance-attribute</code>","text":"<pre><code>headers: NotRequired[dict[str, str]]\n</code></pre> <p>The headers to send to the server.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttpParams.timeout","title":"timeout  <code>instance-attribute</code>","text":"<pre><code>timeout: NotRequired[timedelta | float]\n</code></pre> <p>The timeout for the HTTP request. Defaults to 5 seconds.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttpParams.sse_read_timeout","title":"sse_read_timeout  <code>instance-attribute</code>","text":"<pre><code>sse_read_timeout: NotRequired[timedelta | float]\n</code></pre> <p>The timeout for the SSE connection, in seconds. Defaults to 5 minutes.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttpParams.terminate_on_close","title":"terminate_on_close  <code>instance-attribute</code>","text":"<pre><code>terminate_on_close: NotRequired[bool]\n</code></pre> <p>Terminate on close</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttp","title":"ragbits.agents.mcp.server.MCPServerStreamableHttp","text":"<pre><code>MCPServerStreamableHttp(params: MCPServerStreamableHttpParams, cache_tools_list: bool = False, name: str | None = None, client_session_timeout_seconds: float | None = 5)\n</code></pre> <p>               Bases: <code>_MCPServerWithClientSession</code></p> <p>MCP server implementation that uses the Streamable HTTP transport. See the spec for details.</p> <p>Create a new MCP server based on the Streamable HTTP transport.</p> PARAMETER DESCRIPTION <code>params</code> <p>The params that configure the server. This includes the URL of the server, the headers to send to the server, the timeout for the HTTP request, and the timeout for the Streamable HTTP connection and whether we need to terminate on close.</p> <p> TYPE: <code>MCPServerStreamableHttpParams</code> </p> <code>cache_tools_list</code> <p>Whether to cache the tools list. If <code>True</code>, the tools list will be cached and only fetched from the server once. If <code>False</code>, the tools list will be fetched from the server on each call to <code>list_tools()</code>. The cache can be invalidated by calling <code>invalidate_tools_cache()</code>. You should set this to <code>True</code> if you know the server will not change its tools list, because it can drastically improve latency (by avoiding a round-trip to the server every time).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>name</code> <p>A readable name for the server. If not provided, we'll create one from the URL.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>client_session_timeout_seconds</code> <p>the read timeout passed to the MCP ClientSession.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>5</code> </p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>def __init__(\n    self,\n    params: MCPServerStreamableHttpParams,\n    cache_tools_list: bool = False,\n    name: str | None = None,\n    client_session_timeout_seconds: float | None = 5,\n) -&gt; None:\n    \"\"\"\n    Create a new MCP server based on the Streamable HTTP transport.\n\n    Args:\n        params: The params that configure the server. This includes the URL of the server,\n            the headers to send to the server, the timeout for the HTTP request, and the\n            timeout for the Streamable HTTP connection and whether we need to\n            terminate on close.\n        cache_tools_list: Whether to cache the tools list. If `True`, the tools list will be\n            cached and only fetched from the server once. If `False`, the tools list will be\n            fetched from the server on each call to `list_tools()`. The cache can be\n            invalidated by calling `invalidate_tools_cache()`. You should set this to `True`\n            if you know the server will not change its tools list, because it can drastically\n            improve latency (by avoiding a round-trip to the server every time).\n        name: A readable name for the server. If not provided, we'll create one from the\n            URL.\n        client_session_timeout_seconds: the read timeout passed to the MCP ClientSession.\n    \"\"\"\n    super().__init__(cache_tools_list, client_session_timeout_seconds)\n\n    self.params = params\n    self._name = name or f\"streamable_http: {self.params['url']}\"\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttp.session","title":"session  <code>instance-attribute</code>","text":"<pre><code>session: ClientSession | None = None\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttp.exit_stack","title":"exit_stack  <code>instance-attribute</code>","text":"<pre><code>exit_stack = AsyncExitStack()\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttp.cache_tools_list","title":"cache_tools_list  <code>instance-attribute</code>","text":"<pre><code>cache_tools_list = cache_tools_list\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttp.server_initialize_result","title":"server_initialize_result  <code>instance-attribute</code>","text":"<pre><code>server_initialize_result: InitializeResult | None = None\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttp.client_session_timeout_seconds","title":"client_session_timeout_seconds  <code>instance-attribute</code>","text":"<pre><code>client_session_timeout_seconds = client_session_timeout_seconds\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttp.params","title":"params  <code>instance-attribute</code>","text":"<pre><code>params = params\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttp.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>A readable name for the server.</p>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttp.connect","title":"connect  <code>async</code>","text":"<pre><code>connect() -&gt; None\n</code></pre> <p>Connect to the server.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>async def connect(self) -&gt; None:\n    \"\"\"\n    Connect to the server.\n    \"\"\"\n    try:\n        transport = await self.exit_stack.enter_async_context(self.create_streams())\n        # streamablehttp_client returns (read, write, get_session_id)\n        # sse_client returns (read, write)\n\n        read, write, *_ = transport\n\n        session = await self.exit_stack.enter_async_context(\n            ClientSession(\n                read,\n                write,\n                timedelta(seconds=self.client_session_timeout_seconds)\n                if self.client_session_timeout_seconds\n                else None,\n            )\n        )\n        server_result = await session.initialize()\n        self.server_initialize_result = server_result\n        self.session = session\n    except Exception as e:\n        logger.error(f\"Error initializing MCP server: {e}\")\n        await self.cleanup()\n        raise\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttp.cleanup","title":"cleanup  <code>async</code>","text":"<pre><code>cleanup() -&gt; None\n</code></pre> <p>Cleanup the server.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>async def cleanup(self) -&gt; None:\n    \"\"\"\n    Cleanup the server.\n    \"\"\"\n    async with self._cleanup_lock:\n        try:\n            await self.exit_stack.aclose()\n        except Exception as e:\n            logger.error(f\"Error cleaning up server: {e}\")\n        finally:\n            self.session = None\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttp.list_tools","title":"list_tools  <code>async</code>","text":"<pre><code>list_tools() -&gt; list[Tool]\n</code></pre> <p>List the tools available on the server.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>async def list_tools(self) -&gt; list[\"MCPTool\"]:\n    \"\"\"\n    List the tools available on the server.\n    \"\"\"\n    if not self.session:\n        raise RuntimeError(\"Server not initialized. Make sure you call `connect()` first.\")\n\n    # Return from cache if caching is enabled, we have tools, and the cache is not dirty\n    if self.cache_tools_list and not self._cache_dirty and self._tools_list:\n        return self._tools_list\n\n    # Reset the cache dirty to False\n    self._cache_dirty = False\n\n    # Fetch the tools from the server\n    self._tools_list = (await self.session.list_tools()).tools\n    return self._tools_list\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttp.call_tool","title":"call_tool  <code>async</code>","text":"<pre><code>call_tool(tool_name: str, arguments: dict[str, Any] | None) -&gt; CallToolResult\n</code></pre> <p>Invoke a tool on the server.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>async def call_tool(self, tool_name: str, arguments: dict[str, Any] | None) -&gt; \"CallToolResult\":\n    \"\"\"\n    Invoke a tool on the server.\n    \"\"\"\n    if not self.session:\n        raise RuntimeError(\"Server not initialized. Make sure you call `connect()` first.\")\n\n    return await self.session.call_tool(tool_name, arguments)\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttp.invalidate_tools_cache","title":"invalidate_tools_cache","text":"<pre><code>invalidate_tools_cache() -&gt; None\n</code></pre> <p>Invalidate the tools cache.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>def invalidate_tools_cache(self) -&gt; None:\n    \"\"\"\n    Invalidate the tools cache.\n    \"\"\"\n    self._cache_dirty = True\n</code></pre>"},{"location":"api_reference/agents/mcp/#ragbits.agents.mcp.server.MCPServerStreamableHttp.create_streams","title":"create_streams","text":"<pre><code>create_streams() -&gt; AbstractAsyncContextManager[tuple[MemoryObjectReceiveStream[SessionMessage | Exception], MemoryObjectSendStream[SessionMessage], GetSessionIdCallback | None]]\n</code></pre> <p>Create the streams for the server.</p> Source code in <code>packages/ragbits-agents/src/ragbits/agents/mcp/server.py</code> <pre><code>def create_streams(\n    self,\n) -&gt; AbstractAsyncContextManager[\n    tuple[\n        \"MemoryObjectReceiveStream[SessionMessage | Exception]\",\n        \"MemoryObjectSendStream[SessionMessage]\",\n        \"GetSessionIdCallback | None\",\n    ]\n]:\n    \"\"\"\n    Create the streams for the server.\n    \"\"\"\n    return streamablehttp_client(\n        url=self.params[\"url\"],\n        headers=self.params.get(\"headers\", None),\n        timeout=self.params.get(\"timeout\", 5),\n        sse_read_timeout=self.params.get(\"sse_read_timeout\", 60 * 5),\n        terminate_on_close=self.params.get(\"terminate_on_close\", True),\n    )\n</code></pre>"},{"location":"api_reference/chat/compressors/base/","title":"Conversation History Compressors","text":"<p>Conversation History Compressors are able to take conversation history and represent it as a single string. What's included in the string depends on the particular compressor.</p>"},{"location":"api_reference/chat/compressors/base/#ragbits.chat.history.compressors.base.ConversationHistoryCompressor","title":"ragbits.chat.history.compressors.base.ConversationHistoryCompressor","text":"<p>               Bases: <code>WithConstructionConfig</code>, <code>ABC</code></p> <p>An abstract class for conversation history compressors, i.e. class that takes the entire conversation history and returns a single string representation of it.</p> <p>The exact logic of what the string should include and represent depends on the specific implementation.</p> <p>Usually used to provide LLM additional context from the conversation history.</p>"},{"location":"api_reference/chat/compressors/base/#ragbits.chat.history.compressors.base.ConversationHistoryCompressor.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = compressors\n</code></pre>"},{"location":"api_reference/chat/compressors/base/#ragbits.chat.history.compressors.base.ConversationHistoryCompressor.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'history_compressor'\n</code></pre>"},{"location":"api_reference/chat/compressors/base/#ragbits.chat.history.compressors.base.ConversationHistoryCompressor.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/chat/compressors/base/#ragbits.chat.history.compressors.base.ConversationHistoryCompressor.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/chat/compressors/base/#ragbits.chat.history.compressors.base.ConversationHistoryCompressor.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/chat/compressors/base/#ragbits.chat.history.compressors.base.ConversationHistoryCompressor.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/chat/compressors/base/#ragbits.chat.history.compressors.base.ConversationHistoryCompressor.compress","title":"compress  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>compress(conversation: ChatFormat) -&gt; str\n</code></pre> <p>Compresses the conversation history to a single string.</p> PARAMETER DESCRIPTION <code>conversation</code> <p>List of dicts with \"role\" and \"content\" keys, representing the chat history so far.</p> <p> TYPE: <code>ChatFormat</code> </p> Source code in <code>packages/ragbits-chat/src/ragbits/chat/history/compressors/base.py</code> <pre><code>@abstractmethod\nasync def compress(self, conversation: ChatFormat) -&gt; str:\n    \"\"\"\n    Compresses the conversation history to a single string.\n\n    Args:\n        conversation:  List of dicts with \"role\" and \"content\" keys, representing the chat history so far.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/","title":"Standalone Message Compressor","text":"<p>A compressor that uses LLM to recontextualize the last message in the history, i.e. create a standalone version of the message that includes necessary context.</p>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressor","title":"ragbits.chat.history.compressors.llm.StandaloneMessageCompressor","text":"<pre><code>StandaloneMessageCompressor(llm: LLM, history_len: int = 5, prompt: type[Prompt[LastMessageAndHistory, str]] | None = None)\n</code></pre> <p>               Bases: <code>ConversationHistoryCompressor</code></p> <p>A compressor that uses LLM to recontextualize the last message in the history, i.e. create a standalone version of the message that includes necessary context.</p> <p>Initialize the StandaloneMessageCompressor compressor with a LLM.</p> PARAMETER DESCRIPTION <code>llm</code> <p>A LLM instance to handle recontextualizing the last message.</p> <p> TYPE: <code>LLM</code> </p> <code>history_len</code> <p>The number of previous messages to include in the history.</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> <code>prompt</code> <p>The prompt to use for recontextualizing the last message.</p> <p> TYPE: <code>type[Prompt[LastMessageAndHistory, str]] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-chat/src/ragbits/chat/history/compressors/llm.py</code> <pre><code>def __init__(self, llm: LLM, history_len: int = 5, prompt: type[Prompt[LastMessageAndHistory, str]] | None = None):\n    \"\"\"\n    Initialize the StandaloneMessageCompressor compressor with a LLM.\n\n    Args:\n        llm: A LLM instance to handle recontextualizing the last message.\n        history_len: The number of previous messages to include in the history.\n        prompt: The prompt to use for recontextualizing the last message.\n    \"\"\"\n    self._llm = llm\n    self._history_len = history_len\n    self._prompt = prompt or StandaloneMessageCompressorPrompt\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressor.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = compressors\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressor.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'history_compressor'\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressor.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressor.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressor.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressor.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressor.compress","title":"compress  <code>async</code>","text":"<pre><code>compress(conversation: ChatFormat) -&gt; str\n</code></pre> <p>Contextualize the last message in the conversation history.</p> PARAMETER DESCRIPTION <code>conversation</code> <p>List of dicts with \"role\" and \"content\" keys, representing the chat history so far. The most recent message should be from the user.</p> <p> TYPE: <code>ChatFormat</code> </p> Source code in <code>packages/ragbits-chat/src/ragbits/chat/history/compressors/llm.py</code> <pre><code>async def compress(self, conversation: ChatFormat) -&gt; str:\n    \"\"\"\n    Contextualize the last message in the conversation history.\n\n    Args:\n        conversation: List of dicts with \"role\" and \"content\" keys, representing the chat history so far.\n            The most recent message should be from the user.\n    \"\"\"\n    if len(conversation) == 0:\n        raise ValueError(\"Conversation history is empty.\")\n\n    last_message = conversation[-1]\n    if last_message[\"role\"] != \"user\":\n        raise ValueError(\"StandaloneMessageCompressor expects the last message to be from the user.\")\n\n    # Only include \"user\" and \"assistant\" messages in the history\n    other_messages = [message for message in conversation[:-1] if message[\"role\"] in [\"user\", \"assistant\"]]\n\n    if not other_messages:\n        # No history to use for recontextualization, simply return the user message\n        return last_message[\"content\"]\n\n    history = [f\"{message['role']}: {message['content']}\" for message in other_messages[-self._history_len :]]\n\n    input_data = LastMessageAndHistory(last_message=last_message[\"content\"], history=history)\n    prompt = self._prompt(input_data)\n    response = await self._llm.generate(prompt)\n    return response\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.LastMessageAndHistory","title":"ragbits.chat.history.compressors.llm.LastMessageAndHistory","text":"<p>               Bases: <code>BaseModel</code></p> <p>A class representing the last message and the history of messages.</p>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.LastMessageAndHistory.last_message","title":"last_message  <code>instance-attribute</code>","text":"<pre><code>last_message: str\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.LastMessageAndHistory.history","title":"history  <code>instance-attribute</code>","text":"<pre><code>history: list[str]\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt","title":"ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt","text":"<pre><code>StandaloneMessageCompressorPrompt(input_data: PromptInputT | None = None, history: ChatFormat | None = None)\n</code></pre> <p>               Bases: <code>Prompt[LastMessageAndHistory, str]</code></p> <p>A prompt for recontextualizing the last message in the history.</p> <p>Initialize the Prompt instance.</p> PARAMETER DESCRIPTION <code>input_data</code> <p>The input data to render the prompt templates with. Must be a Pydantic model instance if the prompt has an input type defined. If None and input_type is defined, a ValueError will be raised.</p> <p> TYPE: <code>PromptInputT | None</code> DEFAULT: <code>None</code> </p> <code>history</code> <p>Optional conversation history to initialize the prompt with. If provided, should be in the standard OpenAI chat format.</p> <p> TYPE: <code>ChatFormat | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If input_data is None when input_type is defined, or if input_data is a string instead of a Pydantic model.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>def __init__(self, input_data: PromptInputT | None = None, history: ChatFormat | None = None) -&gt; None:\n    \"\"\"\n    Initialize the Prompt instance.\n\n    Args:\n        input_data: The input data to render the prompt templates with. Must be a Pydantic model\n            instance if the prompt has an input type defined. If None and input_type is defined,\n            a ValueError will be raised.\n        history: Optional conversation history to initialize the prompt with. If provided,\n            should be in the standard OpenAI chat format.\n\n    Raises:\n        ValueError: If input_data is None when input_type is defined, or if input_data\n            is a string instead of a Pydantic model.\n    \"\"\"\n    if self.input_type and input_data is None:\n        raise ValueError(\"Input data must be provided\")\n\n    if isinstance(input_data, str):\n        raise ValueError(\"Input data must be of pydantic model type\")\n\n    if self.image_input_fields:\n        warnings.warn(\n            message=\"The 'image_input_fields' attribute is deprecated. \"\n            \"Use 'Attachment' objects in the prompt input instead.\",\n            category=UserWarning,\n            stacklevel=2,\n        )\n\n    self.rendered_system_prompt = (\n        self._render_template(self.system_prompt_template, input_data) if self.system_prompt_template else None\n    )\n    self.attachments = self._get_attachments_from_input_data(input_data)\n\n    # Additional few shot examples that can be added dynamically using methods\n    # (in opposite to the static `few_shots` attribute which is defined in the class)\n    self._instance_few_shots: list[FewShotExample[PromptInputT, PromptOutputT]] = []\n\n    # Additional conversation history that can be added dynamically using methods\n    self._conversation_history: list[dict[str, Any]] = history or []\n\n    self.add_user_message(input_data or self._render_template(self.user_prompt_template, input_data))\n    self.rendered_user_prompt = self.chat[-1][\"content\"]\n    super().__init__()\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.chat","title":"chat  <code>property</code>","text":"<pre><code>chat: ChatFormat\n</code></pre> <p>Returns the conversation in the standard OpenAI chat format.</p> RETURNS DESCRIPTION <code>ChatFormat</code> <p>A list of dictionaries, each containing the role and content of a message.</p> <p> TYPE: <code>ChatFormat</code> </p>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.json_mode","title":"json_mode  <code>property</code>","text":"<pre><code>json_mode: bool\n</code></pre> <p>Returns whether the prompt should be sent in JSON mode.</p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the prompt should be sent in JSON mode.</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.few_shots","title":"few_shots  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>few_shots: list[FewShotExample[PromptInputT, PromptOutputT]] = []\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.response_parser","title":"response_parser  <code>instance-attribute</code>","text":"<pre><code>response_parser: Callable[[str], PromptOutputT | Awaitable[PromptOutputT]]\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.input_type","title":"input_type  <code>instance-attribute</code>","text":"<pre><code>input_type: type[PromptInputT] | None\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.output_type","title":"output_type  <code>instance-attribute</code>","text":"<pre><code>output_type: type[PromptOutputT]\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.system_prompt_template","title":"system_prompt_template  <code>instance-attribute</code>","text":"<pre><code>system_prompt_template: Template | None\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.user_prompt_template","title":"user_prompt_template  <code>instance-attribute</code>","text":"<pre><code>user_prompt_template: Template\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.image_input_fields","title":"image_input_fields  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>image_input_fields: list[str] | None = None\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.rendered_system_prompt","title":"rendered_system_prompt  <code>instance-attribute</code>","text":"<pre><code>rendered_system_prompt = _render_template(system_prompt_template, input_data) if system_prompt_template else None\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.attachments","title":"attachments  <code>instance-attribute</code>","text":"<pre><code>attachments = _get_attachments_from_input_data(input_data)\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.rendered_user_prompt","title":"rendered_user_prompt  <code>instance-attribute</code>","text":"<pre><code>rendered_user_prompt = chat[-1]['content']\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.system_prompt","title":"system_prompt  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>system_prompt = '\\n    Given a new message and a history of the conversation, create a standalone version of the message.\\n    If the message references any context from history, it should be added to the message itself.\\n    Return only the recontextualized message.\\n    Do NOT return the history, do NOT answer the question, and do NOT add context irrelevant to the message.\\n    '\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.user_prompt","title":"user_prompt  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>user_prompt = '\\n    Message:\\n    {{ last_message }}\\n\\n    History:\\n    {% for message in history %}\\n    * {{ message }}\\n    {% endfor %}\\n    '\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.output_schema","title":"output_schema","text":"<pre><code>output_schema() -&gt; dict | type[BaseModel] | None\n</code></pre> <p>Returns the schema of the desired output. Can be used to request structured output from the LLM API or to validate the output. Can return either a Pydantic model or a JSON schema.</p> RETURNS DESCRIPTION <code>dict | type[BaseModel] | None</code> <p>Optional[Dict | Type[BaseModel]]: The schema of the desired output or the model describing it.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>def output_schema(self) -&gt; dict | type[BaseModel] | None:\n    \"\"\"\n    Returns the schema of the desired output. Can be used to request structured output from the LLM API\n    or to validate the output. Can return either a Pydantic model or a JSON schema.\n\n    Returns:\n        Optional[Dict | Type[BaseModel]]: The schema of the desired output or the model describing it.\n    \"\"\"\n    return self.output_type if issubclass(self.output_type, BaseModel) else None\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.list_images","title":"list_images","text":"<pre><code>list_images() -&gt; list[str]\n</code></pre> <p>Returns the images in form of URLs or base64 encoded strings.</p> RETURNS DESCRIPTION <code>list[str]</code> <p>list of images</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>def list_images(self) -&gt; list[str]:\n    \"\"\"\n    Returns the images in form of URLs or base64 encoded strings.\n\n    Returns:\n        list of images\n    \"\"\"\n    return [\n        content[\"image_url\"][\"url\"]\n        for message in self.chat\n        if message[\"content\"]\n        for content in message[\"content\"]\n        if isinstance(message[\"content\"], list) and content[\"type\"] == \"image_url\"\n    ]\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.list_pdfs","title":"list_pdfs","text":"<pre><code>list_pdfs() -&gt; list[str]\n</code></pre> <p>Returns the PDFs in form of URLs or base64 encoded strings.</p> RETURNS DESCRIPTION <code>list[str]</code> <p>list of PDFs</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>def list_pdfs(self) -&gt; list[str]:  # noqa: PLR6301\n    \"\"\"\n    Returns the PDFs in form of URLs or base64 encoded strings.\n\n    Returns:\n        list of PDFs\n    \"\"\"\n    return [\n        content[\"file\"].get(\"file_id\") or content[\"file\"][\"file_data\"]\n        for message in self.chat\n        if message[\"content\"]\n        for content in message[\"content\"]\n        if isinstance(message[\"content\"], list) and content[\"type\"] == \"file\"\n    ]\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.add_assistant_message","title":"add_assistant_message","text":"<pre><code>add_assistant_message(message: str | PromptOutputT) -&gt; Self\n</code></pre> <p>Add an assistant message to the conversation history.</p> PARAMETER DESCRIPTION <code>message</code> <p>The assistant message content.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>Prompt[PromptInputT, PromptOutputT]: The current prompt instance to allow chaining.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/base.py</code> <pre><code>def add_assistant_message(self, message: str | PromptOutputT) -&gt; Self:\n    \"\"\"\n    Add an assistant message to the conversation history.\n\n    Args:\n        message (str): The assistant message content.\n\n    Returns:\n        Prompt[PromptInputT, PromptOutputT]: The current prompt instance to allow chaining.\n    \"\"\"\n    if not hasattr(self, \"_conversation_history\"):\n        self._conversation_history = []\n\n    if isinstance(message, BaseModel):\n        message = message.model_dump_json()\n    self._conversation_history.append({\"role\": \"assistant\", \"content\": str(message)})\n    return self\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.add_tool_use_message","title":"add_tool_use_message","text":"<pre><code>add_tool_use_message(id: str, name: str, arguments: dict, result: Any) -&gt; Self\n</code></pre> <p>Add tool call messages to the conversation history.</p> PARAMETER DESCRIPTION <code>id</code> <p>The id of the tool call.</p> <p> TYPE: <code>str</code> </p> <code>name</code> <p>The name of the tool.</p> <p> TYPE: <code>str</code> </p> <code>arguments</code> <p>The arguments of the tool.</p> <p> TYPE: <code>dict</code> </p> <code>result</code> <p>The tool call result.</p> <p> TYPE: <code>any</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>Prompt[PromptInputT, PromptOutputT]: The current prompt instance to allow chaining.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/base.py</code> <pre><code>def add_tool_use_message(\n    self,\n    id: str,\n    name: str,\n    arguments: dict,\n    result: Any,  # noqa: ANN401\n) -&gt; Self:\n    \"\"\"\n    Add tool call messages to the conversation history.\n\n    Args:\n        id (str): The id of the tool call.\n        name (str): The name of the tool.\n        arguments (dict): The arguments of the tool.\n        result (any): The tool call result.\n\n    Returns:\n        Prompt[PromptInputT, PromptOutputT]: The current prompt instance to allow chaining.\n    \"\"\"\n    if not hasattr(self, \"_conversation_history\"):\n        self._conversation_history = []\n\n    self._conversation_history.extend(\n        [\n            {\n                \"role\": \"assistant\",\n                \"content\": None,\n                \"tool_calls\": [\n                    {\n                        \"id\": id,\n                        \"type\": \"function\",\n                        \"function\": {\n                            \"name\": name,\n                            \"arguments\": json.dumps(arguments),\n                        },\n                    }\n                ],\n            },\n            {\n                \"role\": \"tool\",\n                \"tool_call_id\": id,\n                \"content\": str(result),\n            },\n        ]\n    )\n\n    return self\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.add_user_message","title":"add_user_message","text":"<pre><code>add_user_message(message: str | dict[str, Any] | PromptInputT) -&gt; Prompt[PromptInputT, PromptOutputT]\n</code></pre> <p>Add a user message to the conversation history.</p> PARAMETER DESCRIPTION <code>message</code> <p>The user message content. Can be: - A string: Used directly as content - A dictionary: With format {\"type\": \"text\", \"text\": \"message\"} or image content - An PromptInputT model: Will be rendered using the user prompt template</p> <p> TYPE: <code>str | dict[str, Any] | PromptInputT</code> </p> RETURNS DESCRIPTION <code>Prompt[PromptInputT, PromptOutputT]</code> <p>Prompt[PromptInputT, PromptOutputT]: The current prompt instance to allow chaining.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>def add_user_message(self, message: str | dict[str, Any] | PromptInputT) -&gt; \"Prompt[PromptInputT, PromptOutputT]\":  # type: ignore\n    \"\"\"\n    Add a user message to the conversation history.\n\n    Args:\n        message (str | dict[str, Any] | PromptInputT): The user message content. Can be:\n            - A string: Used directly as content\n            - A dictionary: With format {\"type\": \"text\", \"text\": \"message\"} or image content\n            - An PromptInputT model: Will be rendered using the user prompt template\n\n    Returns:\n        Prompt[PromptInputT, PromptOutputT]: The current prompt instance to allow chaining.\n    \"\"\"\n    content: str | list[dict[str, Any]] | dict[str, Any]\n\n    if isinstance(message, BaseModel):\n        # Type checking to ensure we're passing PromptInputT to the methods\n        input_model: PromptInputT = cast(PromptInputT, message)\n\n        # Render the message using the template if it's an input model\n        rendered_text = self._render_template(self.user_prompt_template, input_model)\n        input_attachments = self._get_attachments_from_input_data(input_model)\n\n        content_list: list[dict[str, Any]] = [{\"type\": \"text\", \"text\": rendered_text}]\n        for attachment in input_attachments:\n            content_list.append(self.create_message_with_attachment(attachment))\n\n        content = content_list if len(content_list) &gt; 1 else rendered_text\n    else:\n        content = cast(str | dict[str, Any], message)\n\n    return super().add_user_message(content)\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.parse_response","title":"parse_response  <code>async</code>","text":"<pre><code>parse_response(response: str) -&gt; PromptOutputT\n</code></pre> <p>Parse the response from the LLM to the desired output type.</p> PARAMETER DESCRIPTION <code>response</code> <p>The response from the LLM.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>PromptOutputT</code> <p>The parsed response.</p> <p> TYPE: <code>PromptOutputT</code> </p> RAISES DESCRIPTION <code>ResponseParsingError</code> <p>If the response cannot be parsed.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>async def parse_response(self, response: str) -&gt; PromptOutputT:\n    \"\"\"\n    Parse the response from the LLM to the desired output type.\n\n    Args:\n        response (str): The response from the LLM.\n\n    Returns:\n        PromptOutputT: The parsed response.\n\n    Raises:\n        ResponseParsingError: If the response cannot be parsed.\n    \"\"\"\n    if asyncio.iscoroutinefunction(self.response_parser):\n        result = await self.response_parser(response)\n    else:\n        result = self.response_parser(response)\n    return result\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.add_few_shot","title":"add_few_shot","text":"<pre><code>add_few_shot(user_message: str | PromptInputT, assistant_message: str | PromptOutputT) -&gt; Prompt[PromptInputT, PromptOutputT]\n</code></pre> <p>Add a few-shot example to the conversation.</p> PARAMETER DESCRIPTION <code>user_message</code> <p>The raw user message or input data that will be rendered using the user prompt template.</p> <p> TYPE: <code>str | PromptInputT</code> </p> <code>assistant_message</code> <p>The raw assistant response or output data that will be cast to a string or in case of a Pydantic model, to JSON.</p> <p> TYPE: <code>str | PromptOutputT</code> </p> RETURNS DESCRIPTION <code>Prompt[PromptInputT, PromptOutputT]</code> <p>Prompt[PromptInputT, PromptOutputT]: The current prompt instance in order to allow chaining.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>def add_few_shot(\n    self, user_message: str | PromptInputT, assistant_message: str | PromptOutputT\n) -&gt; \"Prompt[PromptInputT, PromptOutputT]\":\n    \"\"\"\n    Add a few-shot example to the conversation.\n\n    Args:\n        user_message (str | PromptInputT): The raw user message or input data that will be rendered using the\n            user prompt template.\n        assistant_message (str | PromptOutputT): The raw assistant response or output data that will be cast to a\n            string or in case of a Pydantic model, to JSON.\n\n    Returns:\n        Prompt[PromptInputT, PromptOutputT]: The current prompt instance in order to allow chaining.\n    \"\"\"\n    self._instance_few_shots.append((user_message, assistant_message))\n    return self\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.list_few_shots","title":"list_few_shots","text":"<pre><code>list_few_shots() -&gt; ChatFormat\n</code></pre> <p>Returns the few shot examples in the standard OpenAI chat format.</p> RETURNS DESCRIPTION <code>ChatFormat</code> <p>A list of dictionaries, each containing the role and content of a message.</p> <p> TYPE: <code>ChatFormat</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>def list_few_shots(self) -&gt; ChatFormat:\n    \"\"\"\n    Returns the few shot examples in the standard OpenAI chat format.\n\n    Returns:\n        ChatFormat: A list of dictionaries, each containing the role and content of a message.\n    \"\"\"\n    result: ChatFormat = []\n    user_content: str | list[dict[str, Any]]\n    for user_message, assistant_message in self.few_shots + self._instance_few_shots:\n        if not isinstance(user_message, str):\n            rendered_text_message = self._render_template(self.user_prompt_template, user_message)\n            input_attachments = self._get_attachments_from_input_data(user_message)\n\n            user_parts: list[dict[str, Any]] = [{\"type\": \"text\", \"text\": rendered_text_message}]\n            for attachment in input_attachments:\n                user_parts.append(self.create_message_with_attachment(attachment))\n\n            user_content = user_parts if len(user_parts) &gt; 1 else rendered_text_message\n\n        else:\n            user_content = user_message\n\n        if isinstance(assistant_message, BaseModel):\n            assistant_content = assistant_message.model_dump_json()\n        else:\n            assistant_content = str(assistant_message)\n\n        result.append({\"role\": \"user\", \"content\": user_content})\n        result.append({\"role\": \"assistant\", \"content\": assistant_content})\n    return result\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.create_message_with_attachment","title":"create_message_with_attachment  <code>staticmethod</code>","text":"<pre><code>create_message_with_attachment(attachment: Attachment) -&gt; dict[str, Any]\n</code></pre> <p>Create a message with an attachment in the OpenAI chat format.</p> PARAMETER DESCRIPTION <code>attachment</code> <p>The attachment to include in the message.</p> <p> TYPE: <code>Attachment</code> </p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary representing the message with the attachment.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>@staticmethod\ndef create_message_with_attachment(attachment: Attachment) -&gt; dict[str, Any]:\n    \"\"\"\n    Create a message with an attachment in the OpenAI chat format.\n\n    Args:\n        attachment (Attachment): The attachment to include in the message.\n\n    Returns:\n        dict[str, Any]: A dictionary representing the message with the attachment.\n    \"\"\"\n    if not (attachment.data or attachment.url):\n        raise PromptWithEmptyAttachment()\n\n    def get_mime_type() -&gt; str:\n        if attachment.mime_type:\n            return attachment.mime_type\n        if attachment.data:\n            detected = filetype.guess(attachment.data)\n            if detected:\n                return detected.mime\n        if attachment.url:\n            guessed_type, _ = mimetypes.guess_type(attachment.url)\n            if guessed_type:\n                return guessed_type\n        raise PromptWithAttachmentOfUnknownFormat()\n\n    def encode_data_url(data: bytes, mime: str) -&gt; str:\n        return f\"data:{mime};base64,{base64.b64encode(data).decode('utf-8')}\"\n\n    mime_type = get_mime_type()\n\n    if mime_type.startswith(\"image/\"):\n        return {\n            \"type\": \"image_url\",\n            \"image_url\": {\n                \"url\": attachment.url or encode_data_url(attachment.data, mime_type)  # type: ignore[arg-type]\n            },\n        }\n\n    if mime_type == \"application/pdf\":\n        return {\n            \"type\": \"file\",\n            \"file\": {\"file_id\": attachment.url}\n            if attachment.url\n            else {\"file_data\": encode_data_url(attachment.data, mime_type)},  # type: ignore[arg-type]\n        }\n\n    raise PromptWithAttachmentOfUnsupportedFormat(mime_type)\n</code></pre>"},{"location":"api_reference/chat/compressors/llm/#ragbits.chat.history.compressors.llm.StandaloneMessageCompressorPrompt.to_promptfoo","title":"to_promptfoo  <code>classmethod</code>","text":"<pre><code>to_promptfoo(config: dict[str, Any]) -&gt; ChatFormat\n</code></pre> <p>Generate a prompt in the promptfoo format from a promptfoo test configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>The promptfoo test configuration.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>ChatFormat</code> <p>The prompt in the format used by promptfoo.</p> <p> TYPE: <code>ChatFormat</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>@classmethod\ndef to_promptfoo(cls, config: dict[str, Any]) -&gt; ChatFormat:\n    \"\"\"\n    Generate a prompt in the promptfoo format from a promptfoo test configuration.\n\n    Args:\n        config: The promptfoo test configuration.\n\n    Returns:\n        ChatFormat: The prompt in the format used by promptfoo.\n    \"\"\"\n    return cls(cls.input_type.model_validate(config[\"vars\"])).chat  # type: ignore\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/","title":"Chat Interface","text":"<p>The <code>ChatInterface</code> is the main interface for the chat service. It defines the core functionality required for a chat service that can return various types of responses such as:</p> <ul> <li>Text: Regular text responses streamed chunk by chunk</li> <li>References: Source documents used to generate the answer</li> </ul>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface","title":"ragbits.chat.interface.ChatInterface","text":"<p>               Bases: <code>ABC</code></p> <p>Base interface for chat implementations.</p> <p>This interface defines the core functionality required for a chat service that can return various types of responses such as:</p> <ul> <li>Text: Regular text responses streamed chunk by chunk</li> <li>References: Source documents used to generate the answer</li> <li>State updates: Updates to the conversation state</li> </ul> ATTRIBUTE DESCRIPTION <code>upload_handler</code> <p>Optional async callback for handling file uploads. Should accept an UploadFile parameter.</p> <p>Example::</p> <pre><code>async def upload_handler(self, file: UploadFile) -&gt; None:\n    content = await file.read()\n    # process content\n</code></pre> <p> TYPE: <code>Callable[[UploadFile], Any] | None</code> </p>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.feedback_config","title":"feedback_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>feedback_config: FeedbackConfig = FeedbackConfig()\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.user_settings","title":"user_settings  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>user_settings: UserSettings = UserSettings()\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.conversation_history","title":"conversation_history  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>conversation_history: bool = False\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.show_usage","title":"show_usage  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>show_usage: bool = False\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.ui_customization","title":"ui_customization  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ui_customization: UICustomization | None = None\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.history_persistence","title":"history_persistence  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>history_persistence: HistoryPersistenceStrategy | None = None\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.summary_generator","title":"summary_generator  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>summary_generator: SummaryGenerator = HeuristicSummaryGenerator()\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.upload_handler","title":"upload_handler  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>upload_handler: Callable[[UploadFile], Any] | None = None\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.create_text_response","title":"create_text_response  <code>staticmethod</code>","text":"<pre><code>create_text_response(text: str) -&gt; TextResponse\n</code></pre> <p>Helper method to create a text response.</p> Source code in <code>packages/ragbits-chat/src/ragbits/chat/interface/_interface.py</code> <pre><code>@staticmethod\ndef create_text_response(text: str) -&gt; TextResponse:\n    \"\"\"Helper method to create a text response.\"\"\"\n    return TextResponse(content=TextContent(text=text))\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.create_reference","title":"create_reference  <code>staticmethod</code>","text":"<pre><code>create_reference(title: str, content: str, url: str | None = None) -&gt; ReferenceResponse\n</code></pre> <p>Helper method to create a reference response.</p> Source code in <code>packages/ragbits-chat/src/ragbits/chat/interface/_interface.py</code> <pre><code>@staticmethod\ndef create_reference(\n    title: str,\n    content: str,\n    url: str | None = None,\n) -&gt; ReferenceResponse:\n    \"\"\"Helper method to create a reference response.\"\"\"\n    return ReferenceResponse(content=Reference(title=title, content=content, url=url))\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.create_state_update","title":"create_state_update  <code>staticmethod</code>","text":"<pre><code>create_state_update(state: dict[str, Any]) -&gt; StateUpdateResponse\n</code></pre> <p>Helper method to create a state update response with signature.</p> Source code in <code>packages/ragbits-chat/src/ragbits/chat/interface/_interface.py</code> <pre><code>@staticmethod\ndef create_state_update(state: dict[str, Any]) -&gt; StateUpdateResponse:\n    \"\"\"Helper method to create a state update response with signature.\"\"\"\n    signature = ChatInterface._sign_state(state)\n    return StateUpdateResponse(content=StateUpdate(state=state, signature=signature))\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.create_live_update","title":"create_live_update  <code>staticmethod</code>","text":"<pre><code>create_live_update(update_id: str, type: LiveUpdateType, label: str, description: str | None = None) -&gt; LiveUpdateResponse\n</code></pre> <p>Helper method to create a live update response.</p> Source code in <code>packages/ragbits-chat/src/ragbits/chat/interface/_interface.py</code> <pre><code>@staticmethod\ndef create_live_update(\n    update_id: str, type: LiveUpdateType, label: str, description: str | None = None\n) -&gt; LiveUpdateResponse:\n    \"\"\"Helper method to create a live update response.\"\"\"\n    return LiveUpdateResponse(\n        content=LiveUpdate(\n            update_id=update_id, type=type, content=LiveUpdateContent(label=label, description=description)\n        )\n    )\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.create_followup_messages","title":"create_followup_messages  <code>staticmethod</code>","text":"<pre><code>create_followup_messages(messages: list[str]) -&gt; FollowupMessagesResponse\n</code></pre> <p>Helper method to create a live update response.</p> Source code in <code>packages/ragbits-chat/src/ragbits/chat/interface/_interface.py</code> <pre><code>@staticmethod\ndef create_followup_messages(messages: list[str]) -&gt; FollowupMessagesResponse:\n    \"\"\"Helper method to create a live update response.\"\"\"\n    return FollowupMessagesResponse(content=FollowupMessagesContent(messages=messages))\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.create_image_response","title":"create_image_response  <code>staticmethod</code>","text":"<pre><code>create_image_response(image_id: str, image_url: str) -&gt; ImageResponse\n</code></pre> <p>Helper method to create an image response.</p> Source code in <code>packages/ragbits-chat/src/ragbits/chat/interface/_interface.py</code> <pre><code>@staticmethod\ndef create_image_response(image_id: str, image_url: str) -&gt; ImageResponse:\n    \"\"\"Helper method to create an image response.\"\"\"\n    return ImageResponse(content=Image(id=image_id, url=image_url))\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.create_clear_message_response","title":"create_clear_message_response  <code>staticmethod</code>","text":"<pre><code>create_clear_message_response() -&gt; ClearMessageResponse\n</code></pre> <p>Helper method to create an clear message response.</p> Source code in <code>packages/ragbits-chat/src/ragbits/chat/interface/_interface.py</code> <pre><code>@staticmethod\ndef create_clear_message_response() -&gt; ClearMessageResponse:\n    \"\"\"Helper method to create an clear message response.\"\"\"\n    return ClearMessageResponse(content=ClearMessageContent())\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.create_usage_response","title":"create_usage_response  <code>staticmethod</code>","text":"<pre><code>create_usage_response(usage: Usage) -&gt; UsageResponse\n</code></pre> Source code in <code>packages/ragbits-chat/src/ragbits/chat/interface/_interface.py</code> <pre><code>@staticmethod\ndef create_usage_response(usage: Usage) -&gt; UsageResponse:\n    return UsageResponse(\n        content=UsageContent(\n            usage={model: MessageUsage.from_usage(usage) for model, usage in usage.model_breakdown.items()}\n        )\n    )\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.verify_state","title":"verify_state  <code>staticmethod</code>","text":"<pre><code>verify_state(state: dict[str, Any], signature: str) -&gt; bool\n</code></pre> <p>Verify that a state and signature match.</p> PARAMETER DESCRIPTION <code>state</code> <p>The state dictionary to verify</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>signature</code> <p>The signature to check against</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if the signature is valid, False otherwise</p> Source code in <code>packages/ragbits-chat/src/ragbits/chat/interface/_interface.py</code> <pre><code>@staticmethod\ndef verify_state(state: dict[str, Any], signature: str) -&gt; bool:\n    \"\"\"\n    Verify that a state and signature match.\n\n    Args:\n        state: The state dictionary to verify\n        signature: The signature to check against\n\n    Returns:\n        True if the signature is valid, False otherwise\n    \"\"\"\n    expected_signature = ChatInterface._sign_state(state)\n    is_valid = hmac.compare_digest(expected_signature, signature)\n\n    # Track state verification\n    record_metric(\n        ChatCounterMetric.CHAT_STATE_VERIFICATION_COUNT,\n        1,\n        metric_type=MetricType.COUNTER,\n        verification_result=\"success\" if is_valid else \"failure\",\n    )\n\n    return is_valid\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.setup","title":"setup  <code>async</code>","text":"<pre><code>setup() -&gt; None\n</code></pre> <p>Set up the chat interface.</p> <p>This method is called after the chat interface is initialized and before the chat method is called. It is used to set up the chat interface, such as loading the model or initializing the vector store.</p> <p>This method is optional and can be overridden by subclasses.</p> Source code in <code>packages/ragbits-chat/src/ragbits/chat/interface/_interface.py</code> <pre><code>async def setup(self) -&gt; None:  # noqa: B027\n    \"\"\"\n    Set up the chat interface.\n\n    This method is called after the chat interface is initialized and before the chat method is called.\n    It is used to set up the chat interface, such as loading the model or initializing the vector store.\n\n    This method is optional and can be overridden by subclasses.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.chat","title":"chat  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>chat(message: str, history: ChatFormat, context: ChatContext) -&gt; AsyncGenerator[ChatResponseUnion, None]\n</code></pre> <p>Process a chat message and yield responses asynchronously.</p> PARAMETER DESCRIPTION <code>message</code> <p>The current user message</p> <p> TYPE: <code>str</code> </p> <code>history</code> <p>Optional list of previous messages in the conversation</p> <p> TYPE: <code>ChatFormat</code> </p> <code>context</code> <p>Optional context containing conversation metadata and state.     Will be automatically populated with message_id and conversation_id.</p> <p> TYPE: <code>ChatContext</code> </p> YIELDS DESCRIPTION <code>AsyncGenerator[ChatResponseUnion, None]</code> <p>ChatResponse objects containing different types of content:</p> <code>AsyncGenerator[ChatResponseUnion, None]</code> <ul> <li>Text chunks for the actual response</li> </ul> <code>AsyncGenerator[ChatResponseUnion, None]</code> <ul> <li>Reference documents used to generate the response</li> </ul> <code>AsyncGenerator[ChatResponseUnion, None]</code> <ul> <li>State updates when the conversation state changes</li> </ul> Example <pre><code>chat = MyChatImplementation()\nasync for response in chat.chat(\"What is Python?\"):\n    if isinstance(response, TextResponse):\n        print(f\"Text: {response.content}\")\n    elif isinstance(response, ReferenceResponse):\n        print(f\"Reference: {response.content.title}\")\n    elif isinstance(response, StateUpdateResponse):\n        if verify_state(response.content.state, response.content.signature):\n            # Update client state\n            pass\n</code></pre> Source code in <code>packages/ragbits-chat/src/ragbits/chat/interface/_interface.py</code> <pre><code>@abstractmethod\nasync def chat(\n    self,\n    message: str,\n    history: ChatFormat,\n    context: ChatContext,\n) -&gt; AsyncGenerator[ChatResponseUnion, None]:\n    \"\"\"\n    Process a chat message and yield responses asynchronously.\n\n    Args:\n        message: The current user message\n        history: Optional list of previous messages in the conversation\n        context: Optional context containing conversation metadata and state.\n                Will be automatically populated with message_id and conversation_id.\n\n    Yields:\n        ChatResponse objects containing different types of content:\n        - Text chunks for the actual response\n        - Reference documents used to generate the response\n        - State updates when the conversation state changes\n\n    Example:\n        ```python\n        chat = MyChatImplementation()\n        async for response in chat.chat(\"What is Python?\"):\n            if isinstance(response, TextResponse):\n                print(f\"Text: {response.content}\")\n            elif isinstance(response, ReferenceResponse):\n                print(f\"Reference: {response.content.title}\")\n            elif isinstance(response, StateUpdateResponse):\n                if verify_state(response.content.state, response.content.signature):\n                    # Update client state\n                    pass\n        ```\n    \"\"\"\n    yield TextResponse(content=TextContent(text=\"Ragbits cannot respond - please implement chat method!\"))\n    raise NotImplementedError(\"Chat implementations must implement chat method\")\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.save_feedback","title":"save_feedback  <code>async</code>","text":"<pre><code>save_feedback(message_id: str, feedback: FeedbackType, payload: dict[str, Any] | None = None) -&gt; None\n</code></pre> <p>Save feedback about a chat message.</p> PARAMETER DESCRIPTION <code>message_id</code> <p>The ID of the message</p> <p> TYPE: <code>str</code> </p> <code>feedback</code> <p>The type of feedback</p> <p> TYPE: <code>FeedbackType</code> </p> <code>payload</code> <p>The payload of the feedback</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-chat/src/ragbits/chat/interface/_interface.py</code> <pre><code>async def save_feedback(\n    self,\n    message_id: str,\n    feedback: FeedbackType,\n    payload: dict[str, Any] | None = None,\n) -&gt; None:\n    \"\"\"\n    Save feedback about a chat message.\n\n    Args:\n        message_id: The ID of the message\n        feedback: The type of feedback\n        payload: The payload of the feedback\n    \"\"\"\n    # Track feedback submission\n    record_metric(\n        ChatCounterMetric.CHAT_FEEDBACK_COUNT,\n        1,\n        metric_type=MetricType.COUNTER,\n        interface_class=self.__class__.__name__,\n        feedback_type=feedback,\n    )\n\n    logger.info(f\"[{self.__class__.__name__}] Saving {feedback} for message {message_id} with payload {payload}\")\n</code></pre>"},{"location":"api_reference/chat/interface/chat_interface/#ragbits.chat.interface.ChatInterface.generate_conversation_summary","title":"generate_conversation_summary  <code>async</code>","text":"<pre><code>generate_conversation_summary(message: str, history: ChatFormat, context: ChatContext) -&gt; str\n</code></pre> <p>Handles conversation summary generation using the configured summary_generator.</p> Source code in <code>packages/ragbits-chat/src/ragbits/chat/interface/_interface.py</code> <pre><code>async def generate_conversation_summary(self, message: str, history: ChatFormat, context: ChatContext) -&gt; str:\n    \"\"\"Handles conversation summary generation using the configured summary_generator.\"\"\"\n    return await self.summary_generator.generate(message, history, context)\n</code></pre>"},{"location":"api_reference/core/embeddings/","title":"Embedders","text":""},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.base.Embedder","title":"ragbits.core.embeddings.base.Embedder","text":"<pre><code>Embedder(default_options: OptionsT | None = None)\n</code></pre> <p>               Bases: <code>ConfigurableComponent[EmbedderOptionsT]</code>, <code>ABC</code></p> <p>Abstract class that defines a common interface for both sparse and dense embedding models.</p> <p>Constructs a new ConfigurableComponent instance.</p> PARAMETER DESCRIPTION <code>default_options</code> <p>The default options for the component.</p> <p> TYPE: <code>OptionsT | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>def __init__(self, default_options: OptionsT | None = None) -&gt; None:\n    \"\"\"\n    Constructs a new ConfigurableComponent instance.\n\n    Args:\n        default_options: The default options for the component.\n    \"\"\"\n    self.default_options: OptionsT = default_options or self.options_cls()\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.base.Embedder.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.base.Embedder.options_cls","title":"options_cls  <code>instance-attribute</code>","text":"<pre><code>options_cls: type[EmbedderOptionsT]\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.base.Embedder.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = embeddings\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.base.Embedder.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'embedder'\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.base.Embedder.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.base.Embedder.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.base.Embedder.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.base.Embedder.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.base.Embedder.embed_text","title":"embed_text  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>embed_text(data: list[str], options: EmbedderOptionsT | None = None) -&gt; list[list[float]] | list[SparseVector]\n</code></pre> <p>Creates embeddings for the given strings.</p> PARAMETER DESCRIPTION <code>data</code> <p>List of strings to get embeddings for.</p> <p> TYPE: <code>list[str]</code> </p> <code>options</code> <p>Additional settings used by the Embedder model.</p> <p> TYPE: <code>EmbedderOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[list[float]] | list[SparseVector]</code> <p>List of embeddings for the given strings.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/base.py</code> <pre><code>@abstractmethod\nasync def embed_text(\n    self, data: list[str], options: EmbedderOptionsT | None = None\n) -&gt; list[list[float]] | list[SparseVector]:\n    \"\"\"\n    Creates embeddings for the given strings.\n\n    Args:\n        data: List of strings to get embeddings for.\n        options: Additional settings used by the Embedder model.\n\n    Returns:\n        List of embeddings for the given strings.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.base.Embedder.get_vector_size","title":"get_vector_size  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>get_vector_size() -&gt; VectorSize\n</code></pre> <p>Get information about the vector size/dimensions returned by this embedder.</p> RETURNS DESCRIPTION <code>VectorSize</code> <p>VectorSize object containing dimension information and whether vectors are sparse.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/base.py</code> <pre><code>@abstractmethod\nasync def get_vector_size(self) -&gt; VectorSize:\n    \"\"\"\n    Get information about the vector size/dimensions returned by this embedder.\n\n    Returns:\n        VectorSize object containing dimension information and whether vectors are sparse.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.base.Embedder.image_support","title":"image_support","text":"<pre><code>image_support() -&gt; bool\n</code></pre> <p>Check if the model supports image embeddings.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if the model supports image embeddings, False otherwise.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/base.py</code> <pre><code>def image_support(self) -&gt; bool:  # noqa: PLR6301\n    \"\"\"\n    Check if the model supports image embeddings.\n\n    Returns:\n        True if the model supports image embeddings, False otherwise.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.base.Embedder.embed_image","title":"embed_image  <code>async</code>","text":"<pre><code>embed_image(images: list[bytes], options: EmbedderOptionsT | None = None) -&gt; list[list[float]] | list[SparseVector]\n</code></pre> <p>Creates embeddings for the given images.</p> PARAMETER DESCRIPTION <code>images</code> <p>List of images to get embeddings for.</p> <p> TYPE: <code>list[bytes]</code> </p> <code>options</code> <p>Additional settings used by the Embedder model.</p> <p> TYPE: <code>EmbedderOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[list[float]] | list[SparseVector]</code> <p>List of embeddings for the given images.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/base.py</code> <pre><code>async def embed_image(\n    self, images: list[bytes], options: EmbedderOptionsT | None = None\n) -&gt; list[list[float]] | list[SparseVector]:\n    \"\"\"\n    Creates embeddings for the given images.\n\n    Args:\n        images: List of images to get embeddings for.\n        options: Additional settings used by the Embedder model.\n\n    Returns:\n        List of embeddings for the given images.\n    \"\"\"\n    raise NotImplementedError(\"Image embeddings are not supported by this model.\")\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.DenseEmbedder","title":"ragbits.core.embeddings.dense.DenseEmbedder","text":"<pre><code>DenseEmbedder(default_options: OptionsT | None = None)\n</code></pre> <p>               Bases: <code>Embedder[EmbedderOptionsT]</code>, <code>ABC</code></p> <p>Abstract client for communication with dense embedding models.</p> <p>Constructs a new ConfigurableComponent instance.</p> PARAMETER DESCRIPTION <code>default_options</code> <p>The default options for the component.</p> <p> TYPE: <code>OptionsT | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>def __init__(self, default_options: OptionsT | None = None) -&gt; None:\n    \"\"\"\n    Constructs a new ConfigurableComponent instance.\n\n    Args:\n        default_options: The default options for the component.\n    \"\"\"\n    self.default_options: OptionsT = default_options or self.options_cls()\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.DenseEmbedder.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = embeddings\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.DenseEmbedder.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'embedder'\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.DenseEmbedder.options_cls","title":"options_cls  <code>instance-attribute</code>","text":"<pre><code>options_cls: type[EmbedderOptionsT]\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.DenseEmbedder.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.DenseEmbedder.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.DenseEmbedder.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.DenseEmbedder.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.DenseEmbedder.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.DenseEmbedder.image_support","title":"image_support","text":"<pre><code>image_support() -&gt; bool\n</code></pre> <p>Check if the model supports image embeddings.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if the model supports image embeddings, False otherwise.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/base.py</code> <pre><code>def image_support(self) -&gt; bool:  # noqa: PLR6301\n    \"\"\"\n    Check if the model supports image embeddings.\n\n    Returns:\n        True if the model supports image embeddings, False otherwise.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.DenseEmbedder.embed_text","title":"embed_text  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>embed_text(data: list[str], options: EmbedderOptionsT | None = None) -&gt; list[list[float]]\n</code></pre> <p>Creates embeddings for the given strings.</p> PARAMETER DESCRIPTION <code>data</code> <p>List of strings to get embeddings for.</p> <p> TYPE: <code>list[str]</code> </p> <code>options</code> <p>Additional settings used by the Embedder model.</p> <p> TYPE: <code>EmbedderOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[list[float]]</code> <p>List of embeddings for the given strings.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/dense/base.py</code> <pre><code>@abstractmethod\nasync def embed_text(self, data: list[str], options: EmbedderOptionsT | None = None) -&gt; list[list[float]]:\n    \"\"\"\n    Creates embeddings for the given strings.\n\n    Args:\n        data: List of strings to get embeddings for.\n        options: Additional settings used by the Embedder model.\n\n    Returns:\n        List of embeddings for the given strings.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.DenseEmbedder.get_vector_size","title":"get_vector_size  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>get_vector_size() -&gt; VectorSize\n</code></pre> <p>Get information about the dense vector size/dimensions returned by this embedder.</p> RETURNS DESCRIPTION <code>VectorSize</code> <p>VectorSize object with is_sparse=False and the embedding dimension.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/dense/base.py</code> <pre><code>@abstractmethod\nasync def get_vector_size(self) -&gt; VectorSize:\n    \"\"\"\n    Get information about the dense vector size/dimensions returned by this embedder.\n\n    Returns:\n        VectorSize object with is_sparse=False and the embedding dimension.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.DenseEmbedder.embed_image","title":"embed_image  <code>async</code>","text":"<pre><code>embed_image(images: list[bytes], options: EmbedderOptionsT | None = None) -&gt; list[list[float]]\n</code></pre> <p>Creates embeddings for the given images.</p> PARAMETER DESCRIPTION <code>images</code> <p>List of images to get embeddings for.</p> <p> TYPE: <code>list[bytes]</code> </p> <code>options</code> <p>Additional settings used by the Embedder model.</p> <p> TYPE: <code>EmbedderOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[list[float]]</code> <p>List of embeddings for the given images.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/dense/base.py</code> <pre><code>async def embed_image(self, images: list[bytes], options: EmbedderOptionsT | None = None) -&gt; list[list[float]]:\n    \"\"\"\n    Creates embeddings for the given images.\n\n    Args:\n        images: List of images to get embeddings for.\n        options: Additional settings used by the Embedder model.\n\n    Returns:\n        List of embeddings for the given images.\n    \"\"\"\n    raise NotImplementedError(\"Image embeddings are not supported by this model.\")\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.local.LocalEmbedder","title":"ragbits.core.embeddings.dense.local.LocalEmbedder","text":"<pre><code>LocalEmbedder(model_name: str, default_options: LocalEmbedderOptions | None = None, **model_kwargs: Any)\n</code></pre> <p>               Bases: <code>DenseEmbedder[LocalEmbedderOptions]</code></p> <p>Class for interaction with any encoder available in HuggingFace.</p> <p>Note: Local implementation is not dedicated for production. Use it only in experiments / evaluation.</p> <p>Constructs a new local LLM instance.</p> PARAMETER DESCRIPTION <code>model_name</code> <p>Name of the model to use.</p> <p> TYPE: <code>str</code> </p> <code>default_options</code> <p>Default options for the embedding model.</p> <p> TYPE: <code>LocalEmbedderOptions | None</code> DEFAULT: <code>None</code> </p> <code>model_kwargs</code> <p>Additional arguments to pass to the SentenceTransformer.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>ImportError</code> <p>If the 'local' extra requirements are not installed.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/dense/local.py</code> <pre><code>def __init__(\n    self,\n    model_name: str,\n    default_options: LocalEmbedderOptions | None = None,\n    **model_kwargs: Any,  # noqa: ANN401\n) -&gt; None:\n    \"\"\"\n    Constructs a new local LLM instance.\n\n    Args:\n        model_name: Name of the model to use.\n        default_options: Default options for the embedding model.\n        model_kwargs: Additional arguments to pass to the SentenceTransformer.\n\n    Raises:\n        ImportError: If the 'local' extra requirements are not installed.\n    \"\"\"\n    if not HAS_LOCAL_EMBEDDINGS:\n        raise ImportError(\"You need to install the 'local' extra requirements to use local embeddings models\")\n\n    super().__init__(default_options=default_options)\n\n    self.model_name = model_name\n    self.model = SentenceTransformer(self.model_name, **model_kwargs)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.local.LocalEmbedder.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = embeddings\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.local.LocalEmbedder.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'embedder'\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.local.LocalEmbedder.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.local.LocalEmbedder.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls = LocalEmbedderOptions\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.local.LocalEmbedder.model_name","title":"model_name  <code>instance-attribute</code>","text":"<pre><code>model_name = model_name\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.local.LocalEmbedder.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model = SentenceTransformer(model_name, **model_kwargs)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.local.LocalEmbedder.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.local.LocalEmbedder.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.local.LocalEmbedder.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.local.LocalEmbedder.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.local.LocalEmbedder.image_support","title":"image_support","text":"<pre><code>image_support() -&gt; bool\n</code></pre> <p>Check if the model supports image embeddings.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if the model supports image embeddings, False otherwise.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/base.py</code> <pre><code>def image_support(self) -&gt; bool:  # noqa: PLR6301\n    \"\"\"\n    Check if the model supports image embeddings.\n\n    Returns:\n        True if the model supports image embeddings, False otherwise.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.local.LocalEmbedder.embed_image","title":"embed_image  <code>async</code>","text":"<pre><code>embed_image(images: list[bytes], options: EmbedderOptionsT | None = None) -&gt; list[list[float]]\n</code></pre> <p>Creates embeddings for the given images.</p> PARAMETER DESCRIPTION <code>images</code> <p>List of images to get embeddings for.</p> <p> TYPE: <code>list[bytes]</code> </p> <code>options</code> <p>Additional settings used by the Embedder model.</p> <p> TYPE: <code>EmbedderOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[list[float]]</code> <p>List of embeddings for the given images.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/dense/base.py</code> <pre><code>async def embed_image(self, images: list[bytes], options: EmbedderOptionsT | None = None) -&gt; list[list[float]]:\n    \"\"\"\n    Creates embeddings for the given images.\n\n    Args:\n        images: List of images to get embeddings for.\n        options: Additional settings used by the Embedder model.\n\n    Returns:\n        List of embeddings for the given images.\n    \"\"\"\n    raise NotImplementedError(\"Image embeddings are not supported by this model.\")\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.local.LocalEmbedder.get_vector_size","title":"get_vector_size  <code>async</code>","text":"<pre><code>get_vector_size() -&gt; VectorSize\n</code></pre> <p>Get the vector size for this local SentenceTransformer model.</p> RETURNS DESCRIPTION <code>VectorSize</code> <p>VectorSize object with the model's embedding dimension.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/dense/local.py</code> <pre><code>async def get_vector_size(self) -&gt; VectorSize:\n    \"\"\"\n    Get the vector size for this local SentenceTransformer model.\n\n    Returns:\n        VectorSize object with the model's embedding dimension.\n    \"\"\"\n    dimension = self.model.get_sentence_embedding_dimension()\n    if dimension is None:\n        sample_embedding = await self.embed_text([\"sample\"])\n        dimension = len(sample_embedding[0])\n    return VectorSize(size=dimension, is_sparse=False)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.local.LocalEmbedder.embed_text","title":"embed_text  <code>async</code>","text":"<pre><code>embed_text(data: list[str], options: LocalEmbedderOptions | None = None) -&gt; list[list[float]]\n</code></pre> <p>Calls the appropriate encoder endpoint with the given data and options.</p> PARAMETER DESCRIPTION <code>data</code> <p>List of strings to get embeddings for.</p> <p> TYPE: <code>list[str]</code> </p> <code>options</code> <p>Additional options to pass to the embedding model.</p> <p> TYPE: <code>LocalEmbedderOptions | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[list[float]]</code> <p>List of embeddings for the given strings.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/dense/local.py</code> <pre><code>async def embed_text(self, data: list[str], options: LocalEmbedderOptions | None = None) -&gt; list[list[float]]:\n    \"\"\"\n    Calls the appropriate encoder endpoint with the given data and options.\n\n    Args:\n        data: List of strings to get embeddings for.\n        options: Additional options to pass to the embedding model.\n\n    Returns:\n        List of embeddings for the given strings.\n    \"\"\"\n    merged_options = (self.default_options | options) if options else self.default_options\n    with trace(\n        data=data,\n        model_name=self.model_name,\n        model_obj=repr(self.model),\n        options=merged_options.dict(),\n    ) as outputs:\n        outputs.embeddings = self.model.encode(data, **merged_options.encode_kwargs).tolist()\n    return outputs.embeddings\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder","title":"ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder","text":"<pre><code>LiteLLMEmbedder(model_name: str = 'text-embedding-3-small', default_options: LiteLLMEmbedderOptions | None = None, *, api_base: str | None = None, base_url: str | None = None, api_key: str | None = None, api_version: str | None = None, router: Router | None = None)\n</code></pre> <p>               Bases: <code>DenseEmbedder[LiteLLMEmbedderOptions]</code>, <code>LazyLiteLLM</code></p> <p>Client for creating text embeddings using LiteLLM API.</p> <p>Constructs the LiteLLMEmbeddingClient.</p> PARAMETER DESCRIPTION <code>model_name</code> <p>Name of the LiteLLM supported model                to be used. Default is \"text-embedding-3-small\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'text-embedding-3-small'</code> </p> <code>default_options</code> <p>Default options to pass to the LiteLLM API.</p> <p> TYPE: <code>LiteLLMEmbedderOptions | None</code> DEFAULT: <code>None</code> </p> <code>api_base</code> <p>The API endpoint you want to call the model with.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>base_url</code> <p>Alias for api_base. If both are provided, api_base takes precedence.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>api_key</code> <p>API key to be used. If not specified, an environment variable will be used, for more information, follow the instructions for your specific vendor in the                LiteLLM documentation.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>api_version</code> <p>The API version for the call.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>router</code> <p>Router to be used to route requests to different models.</p> <p> TYPE: <code>Router | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/dense/litellm.py</code> <pre><code>def __init__(\n    self,\n    model_name: str = \"text-embedding-3-small\",\n    default_options: LiteLLMEmbedderOptions | None = None,\n    *,\n    api_base: str | None = None,\n    base_url: str | None = None,  # Alias for api_base\n    api_key: str | None = None,\n    api_version: str | None = None,\n    router: \"Router | None\" = None,\n) -&gt; None:\n    \"\"\"\n    Constructs the LiteLLMEmbeddingClient.\n\n    Args:\n        model_name: Name of the [LiteLLM supported model](https://docs.litellm.ai/docs/embedding/supported_embedding)\\\n            to be used. Default is \"text-embedding-3-small\".\n        default_options: Default options to pass to the LiteLLM API.\n        api_base: The API endpoint you want to call the model with.\n        base_url: Alias for api_base. If both are provided, api_base takes precedence.\n        api_key: API key to be used. If not specified, an environment variable will be used,\n            for more information, follow the instructions for your specific vendor in the\\\n            [LiteLLM documentation](https://docs.litellm.ai/docs/embedding/supported_embedding).\n        api_version: The API version for the call.\n        router: Router to be used to [route requests](https://docs.litellm.ai/docs/routing) to different models.\n    \"\"\"\n    super().__init__(default_options=default_options)\n\n    self.model_name = model_name\n    self.api_base = api_base or base_url\n    self.api_key = api_key\n    self.api_version = api_version\n    self.router = router\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = embeddings\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'embedder'\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls = LiteLLMEmbedderOptions\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder.model_name","title":"model_name  <code>instance-attribute</code>","text":"<pre><code>model_name = model_name\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder.api_base","title":"api_base  <code>instance-attribute</code>","text":"<pre><code>api_base = api_base or base_url\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder.api_key","title":"api_key  <code>instance-attribute</code>","text":"<pre><code>api_key = api_key\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder.api_version","title":"api_version  <code>instance-attribute</code>","text":"<pre><code>api_version = api_version\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder.router","title":"router  <code>instance-attribute</code>","text":"<pre><code>router = router\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder.image_support","title":"image_support","text":"<pre><code>image_support() -&gt; bool\n</code></pre> <p>Check if the model supports image embeddings.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if the model supports image embeddings, False otherwise.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/base.py</code> <pre><code>def image_support(self) -&gt; bool:  # noqa: PLR6301\n    \"\"\"\n    Check if the model supports image embeddings.\n\n    Returns:\n        True if the model supports image embeddings, False otherwise.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder.embed_image","title":"embed_image  <code>async</code>","text":"<pre><code>embed_image(images: list[bytes], options: EmbedderOptionsT | None = None) -&gt; list[list[float]]\n</code></pre> <p>Creates embeddings for the given images.</p> PARAMETER DESCRIPTION <code>images</code> <p>List of images to get embeddings for.</p> <p> TYPE: <code>list[bytes]</code> </p> <code>options</code> <p>Additional settings used by the Embedder model.</p> <p> TYPE: <code>EmbedderOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[list[float]]</code> <p>List of embeddings for the given images.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/dense/base.py</code> <pre><code>async def embed_image(self, images: list[bytes], options: EmbedderOptionsT | None = None) -&gt; list[list[float]]:\n    \"\"\"\n    Creates embeddings for the given images.\n\n    Args:\n        images: List of images to get embeddings for.\n        options: Additional settings used by the Embedder model.\n\n    Returns:\n        List of embeddings for the given images.\n    \"\"\"\n    raise NotImplementedError(\"Image embeddings are not supported by this model.\")\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder.get_vector_size","title":"get_vector_size  <code>async</code>","text":"<pre><code>get_vector_size() -&gt; VectorSize\n</code></pre> <p>Get the vector size for this LiteLLM model.</p> <p>If dimensions are specified in default options, use that value. Otherwise, embed a sample text to determine the dimension.</p> RETURNS DESCRIPTION <code>VectorSize</code> <p>VectorSize object with the model's embedding dimension.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/dense/litellm.py</code> <pre><code>async def get_vector_size(self) -&gt; VectorSize:\n    \"\"\"\n    Get the vector size for this LiteLLM model.\n\n    If dimensions are specified in default options, use that value.\n    Otherwise, embed a sample text to determine the dimension.\n\n    Returns:\n        VectorSize object with the model's embedding dimension.\n    \"\"\"\n    # Check if dimensions are explicitly set in default options\n    if (\n        self.default_options\n        and self.default_options.dimensions is not NOT_GIVEN\n        and self.default_options.dimensions is not None\n    ):\n        # We've checked that dimensions is not None and not NOT_GIVEN, so it must be int\n        return VectorSize(size=cast(int, self.default_options.dimensions), is_sparse=False)\n\n    # If no dimensions specified, embed a sample text to determine size\n    sample_embedding = await self.embed_text([\"sample\"])\n    return VectorSize(size=len(sample_embedding[0]), is_sparse=False)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder.embed_text","title":"embed_text  <code>async</code>","text":"<pre><code>embed_text(data: list[str], options: LiteLLMEmbedderOptions | None = None) -&gt; list[list[float]]\n</code></pre> <p>Creates embeddings for the given strings.</p> PARAMETER DESCRIPTION <code>data</code> <p>List of strings to get embeddings for.</p> <p> TYPE: <code>list[str]</code> </p> <code>options</code> <p>Additional options to pass to the Lite LLM API.</p> <p> TYPE: <code>LiteLLMEmbedderOptions | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[list[float]]</code> <p>List of embeddings for the given strings.</p> RAISES DESCRIPTION <code>EmbeddingConnectionError</code> <p>If there is a connection error with the embedding API.</p> <code>EmbeddingEmptyResponseError</code> <p>If the embedding API returns an empty response.</p> <code>EmbeddingStatusError</code> <p>If the embedding API returns an error status code.</p> <code>EmbeddingResponseError</code> <p>If the embedding API response is invalid.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/dense/litellm.py</code> <pre><code>async def embed_text(self, data: list[str], options: LiteLLMEmbedderOptions | None = None) -&gt; list[list[float]]:\n    \"\"\"\n    Creates embeddings for the given strings.\n\n    Args:\n        data: List of strings to get embeddings for.\n        options: Additional options to pass to the Lite LLM API.\n\n    Returns:\n        List of embeddings for the given strings.\n\n    Raises:\n        EmbeddingConnectionError: If there is a connection error with the embedding API.\n        EmbeddingEmptyResponseError: If the embedding API returns an empty response.\n        EmbeddingStatusError: If the embedding API returns an error status code.\n        EmbeddingResponseError: If the embedding API response is invalid.\n    \"\"\"\n    merged_options = (self.default_options | options) if options else self.default_options\n\n    with trace(\n        data=data,\n        model=self.model_name,\n        api_base=self.api_base,\n        api_version=self.api_version,\n        options=merged_options.dict(),\n    ) as outputs:\n        try:\n            entrypoint = self.router or self._litellm\n            response = await entrypoint.aembedding(\n                input=data,\n                model=self.model_name,\n                api_base=self.api_base,\n                api_key=self.api_key,\n                api_version=self.api_version,\n                **merged_options.dict(),\n            )\n        except self._litellm.openai.APIConnectionError as exc:\n            raise EmbeddingConnectionError() from exc\n        except self._litellm.openai.APIStatusError as exc:\n            raise EmbeddingStatusError(exc.message, exc.status_code) from exc\n        except self._litellm.openai.APIResponseValidationError as exc:\n            raise EmbeddingResponseError() from exc\n\n        if not response.data:\n            raise EmbeddingEmptyResponseError()\n\n        outputs.embeddings = [embedding[\"embedding\"] for embedding in response.data]\n        if response.usage:\n            outputs.completion_tokens = response.usage.completion_tokens\n            outputs.prompt_tokens = response.usage.prompt_tokens\n            outputs.total_tokens = response.usage.total_tokens\n\n    return outputs.embeddings\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.litellm.LiteLLMEmbedder.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Creates and returns a LiteLLMEmbedder instance.</p> PARAMETER DESCRIPTION <code>config</code> <p>A configuration object containing the configuration for initializing the LiteLLMEmbedder instance.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>LiteLLMEmbedder</code> <p>An initialized LiteLLMEmbedder instance.</p> <p> TYPE: <code>Self</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/dense/litellm.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Creates and returns a LiteLLMEmbedder instance.\n\n    Args:\n        config: A configuration object containing the configuration for initializing the LiteLLMEmbedder instance.\n\n    Returns:\n        LiteLLMEmbedder: An initialized LiteLLMEmbedder instance.\n    \"\"\"\n    if \"router\" in config:\n        router = cls._get_litellm_module().router.Router(model_list=config[\"router\"])\n        config[\"router\"] = router\n\n    # Map base_url to api_base if present\n    if \"base_url\" in config and \"api_base\" not in config:\n        config[\"api_base\"] = config.pop(\"base_url\")\n\n    return super().from_config(config)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.fastembed.FastEmbedEmbedder","title":"ragbits.core.embeddings.dense.fastembed.FastEmbedEmbedder","text":"<pre><code>FastEmbedEmbedder(model_name: str, use_gpu: bool = False, default_options: FastEmbedOptions | None = None)\n</code></pre> <p>               Bases: <code>DenseEmbedder[FastEmbedOptions]</code></p> <p>Class for creating dense text embeddings using FastEmbed library. For more information, see the FastEmbed GitHub.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/dense/fastembed.py</code> <pre><code>def __init__(self, model_name: str, use_gpu: bool = False, default_options: FastEmbedOptions | None = None):\n    super().__init__(default_options=default_options)\n    self.model_name = model_name\n    self.use_gpu = use_gpu\n    if use_gpu:\n        self._model = TextEmbedding(model_name=model_name, providers=[\"CUDAExecutionProvider\"])\n    else:\n        self._model = TextEmbedding(model_name=model_name)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.fastembed.FastEmbedEmbedder.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = embeddings\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.fastembed.FastEmbedEmbedder.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'embedder'\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.fastembed.FastEmbedEmbedder.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.fastembed.FastEmbedEmbedder.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls = FastEmbedOptions\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.fastembed.FastEmbedEmbedder.model_name","title":"model_name  <code>instance-attribute</code>","text":"<pre><code>model_name = model_name\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.fastembed.FastEmbedEmbedder.use_gpu","title":"use_gpu  <code>instance-attribute</code>","text":"<pre><code>use_gpu = use_gpu\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.fastembed.FastEmbedEmbedder.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.fastembed.FastEmbedEmbedder.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.fastembed.FastEmbedEmbedder.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.fastembed.FastEmbedEmbedder.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.fastembed.FastEmbedEmbedder.image_support","title":"image_support","text":"<pre><code>image_support() -&gt; bool\n</code></pre> <p>Check if the model supports image embeddings.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if the model supports image embeddings, False otherwise.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/base.py</code> <pre><code>def image_support(self) -&gt; bool:  # noqa: PLR6301\n    \"\"\"\n    Check if the model supports image embeddings.\n\n    Returns:\n        True if the model supports image embeddings, False otherwise.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.fastembed.FastEmbedEmbedder.embed_image","title":"embed_image  <code>async</code>","text":"<pre><code>embed_image(images: list[bytes], options: EmbedderOptionsT | None = None) -&gt; list[list[float]]\n</code></pre> <p>Creates embeddings for the given images.</p> PARAMETER DESCRIPTION <code>images</code> <p>List of images to get embeddings for.</p> <p> TYPE: <code>list[bytes]</code> </p> <code>options</code> <p>Additional settings used by the Embedder model.</p> <p> TYPE: <code>EmbedderOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[list[float]]</code> <p>List of embeddings for the given images.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/dense/base.py</code> <pre><code>async def embed_image(self, images: list[bytes], options: EmbedderOptionsT | None = None) -&gt; list[list[float]]:\n    \"\"\"\n    Creates embeddings for the given images.\n\n    Args:\n        images: List of images to get embeddings for.\n        options: Additional settings used by the Embedder model.\n\n    Returns:\n        List of embeddings for the given images.\n    \"\"\"\n    raise NotImplementedError(\"Image embeddings are not supported by this model.\")\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.fastembed.FastEmbedEmbedder.get_vector_size","title":"get_vector_size  <code>async</code>","text":"<pre><code>get_vector_size() -&gt; VectorSize\n</code></pre> <p>Get the vector size for this FastEmbed model.</p> RETURNS DESCRIPTION <code>VectorSize</code> <p>VectorSize object with the model's embedding dimension.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/dense/fastembed.py</code> <pre><code>async def get_vector_size(self) -&gt; VectorSize:\n    \"\"\"\n    Get the vector size for this FastEmbed model.\n\n    Returns:\n        VectorSize object with the model's embedding dimension.\n    \"\"\"\n    # Get model info from FastEmbed's supported models list\n    supported_models = self._model.list_supported_models()\n    model_info = next((model for model in supported_models if model[\"model\"] == self.model_name), None)\n\n    if model_info and \"dim\" in model_info:\n        vector_size = model_info[\"dim\"]\n    else:\n        # Fallback to the original method if metadata is not available\n        sample_embedding = await self.embed_text([\"sample\"])\n        vector_size = len(sample_embedding[0])\n\n    return VectorSize(size=vector_size, is_sparse=False)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.dense.fastembed.FastEmbedEmbedder.embed_text","title":"embed_text  <code>async</code>","text":"<pre><code>embed_text(data: list[str], options: EmbedderOptionsT | None = None) -&gt; list[list[float]]\n</code></pre> <p>Embeds a list of strings into a list of embeddings.</p> PARAMETER DESCRIPTION <code>data</code> <p>List of strings to get embeddings for.</p> <p> TYPE: <code>list[str]</code> </p> <code>options</code> <p>Additional options to pass to the embedding model.</p> <p> TYPE: <code>EmbedderOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[list[float]]</code> <p>List of embeddings for the given strings.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/dense/fastembed.py</code> <pre><code>async def embed_text(self, data: list[str], options: EmbedderOptionsT | None = None) -&gt; list[list[float]]:\n    \"\"\"\n    Embeds a list of strings into a list of embeddings.\n\n    Args:\n        data: List of strings to get embeddings for.\n        options: Additional options to pass to the embedding model.\n\n    Returns:\n        List of embeddings for the given strings.\n    \"\"\"\n    merged_options = (self.default_options | options) if options else self.default_options\n    with trace(\n        data=data, model_name=self.model_name, model_obj=repr(self._model), options=merged_options.dict()\n    ) as outputs:\n        embeddings = [[float(x) for x in result] for result in self._model.embed(data, **merged_options.dict())]\n        outputs.embeddings = embeddings\n    return embeddings\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.base.SparseEmbedder","title":"ragbits.core.embeddings.sparse.base.SparseEmbedder","text":"<pre><code>SparseEmbedder(default_options: OptionsT | None = None)\n</code></pre> <p>               Bases: <code>Embedder[SparseEmbedderOptionsT]</code>, <code>ABC</code></p> <p>Sparse embedding interface</p> <p>Constructs a new ConfigurableComponent instance.</p> PARAMETER DESCRIPTION <code>default_options</code> <p>The default options for the component.</p> <p> TYPE: <code>OptionsT | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>def __init__(self, default_options: OptionsT | None = None) -&gt; None:\n    \"\"\"\n    Constructs a new ConfigurableComponent instance.\n\n    Args:\n        default_options: The default options for the component.\n    \"\"\"\n    self.default_options: OptionsT = default_options or self.options_cls()\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.base.SparseEmbedder.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = embeddings\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.base.SparseEmbedder.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'embedder'\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.base.SparseEmbedder.options_cls","title":"options_cls  <code>instance-attribute</code>","text":"<pre><code>options_cls: type[EmbedderOptionsT]\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.base.SparseEmbedder.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.base.SparseEmbedder.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.base.SparseEmbedder.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.base.SparseEmbedder.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.base.SparseEmbedder.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.base.SparseEmbedder.image_support","title":"image_support","text":"<pre><code>image_support() -&gt; bool\n</code></pre> <p>Check if the model supports image embeddings.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if the model supports image embeddings, False otherwise.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/base.py</code> <pre><code>def image_support(self) -&gt; bool:  # noqa: PLR6301\n    \"\"\"\n    Check if the model supports image embeddings.\n\n    Returns:\n        True if the model supports image embeddings, False otherwise.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.base.SparseEmbedder.embed_text","title":"embed_text  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>embed_text(texts: list[str], options: SparseEmbedderOptionsT | None = None) -&gt; list[SparseVector]\n</code></pre> <p>Transforms a list of texts into sparse vectors.</p> PARAMETER DESCRIPTION <code>texts</code> <p>list of input texts.</p> <p> TYPE: <code>list[str]</code> </p> <code>options</code> <p>optional embedding options</p> <p> TYPE: <code>SparseEmbedderOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[SparseVector]</code> <p>list of sparse embeddings.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/sparse/base.py</code> <pre><code>@abstractmethod\nasync def embed_text(self, texts: list[str], options: SparseEmbedderOptionsT | None = None) -&gt; list[SparseVector]:\n    \"\"\"\n    Transforms a list of texts into sparse vectors.\n\n    Args:\n        texts: list of input texts.\n        options: optional embedding options\n\n    Returns:\n        list of sparse embeddings.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.base.SparseEmbedder.get_vector_size","title":"get_vector_size  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>get_vector_size() -&gt; VectorSize\n</code></pre> <p>Get information about the sparse vector size/dimensions returned by this embedder.</p> RETURNS DESCRIPTION <code>VectorSize</code> <p>VectorSize object with is_sparse=True and the vocabulary size.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/sparse/base.py</code> <pre><code>@abstractmethod\nasync def get_vector_size(self) -&gt; VectorSize:\n    \"\"\"\n    Get information about the sparse vector size/dimensions returned by this embedder.\n\n    Returns:\n        VectorSize object with is_sparse=True and the vocabulary size.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.base.SparseEmbedder.embed_image","title":"embed_image  <code>async</code>","text":"<pre><code>embed_image(images: list[bytes], options: SparseEmbedderOptionsT | None = None) -&gt; list[SparseVector]\n</code></pre> <p>Creates embeddings for the given images.</p> PARAMETER DESCRIPTION <code>images</code> <p>List of images to get embeddings for.</p> <p> TYPE: <code>list[bytes]</code> </p> <code>options</code> <p>Additional settings used by the Embedder model.</p> <p> TYPE: <code>SparseEmbedderOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[SparseVector]</code> <p>List of sparse embeddings for the given images.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/sparse/base.py</code> <pre><code>async def embed_image(\n    self, images: list[bytes], options: SparseEmbedderOptionsT | None = None\n) -&gt; list[SparseVector]:\n    \"\"\"\n    Creates embeddings for the given images.\n\n    Args:\n        images: List of images to get embeddings for.\n        options: Additional settings used by the Embedder model.\n\n    Returns:\n        List of sparse embeddings for the given images.\n    \"\"\"\n    raise NotImplementedError(\"Image embeddings are not supported by this model.\")\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.fastembed.FastEmbedSparseEmbedder","title":"ragbits.core.embeddings.sparse.fastembed.FastEmbedSparseEmbedder","text":"<pre><code>FastEmbedSparseEmbedder(model_name: str, use_gpu: bool = False, default_options: FastEmbedOptions | None = None)\n</code></pre> <p>               Bases: <code>SparseEmbedder[FastEmbedOptions]</code></p> <p>Class for creating sparse text embeddings using FastEmbed library. For more information, see the FastEmbed GitHub.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/sparse/fastembed.py</code> <pre><code>def __init__(self, model_name: str, use_gpu: bool = False, default_options: FastEmbedOptions | None = None):\n    super().__init__(default_options=default_options)\n    self.model_name = model_name\n    self.use_gpu = use_gpu\n    if use_gpu:\n        self._model = SparseTextEmbedding(model_name=model_name, providers=[\"CUDAExecutionProvider\"])\n    else:\n        self._model = SparseTextEmbedding(model_name=model_name)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.fastembed.FastEmbedSparseEmbedder.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = embeddings\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.fastembed.FastEmbedSparseEmbedder.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'embedder'\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.fastembed.FastEmbedSparseEmbedder.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.fastembed.FastEmbedSparseEmbedder.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls = FastEmbedOptions\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.fastembed.FastEmbedSparseEmbedder.model_name","title":"model_name  <code>instance-attribute</code>","text":"<pre><code>model_name = model_name\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.fastembed.FastEmbedSparseEmbedder.use_gpu","title":"use_gpu  <code>instance-attribute</code>","text":"<pre><code>use_gpu = use_gpu\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.fastembed.FastEmbedSparseEmbedder.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.fastembed.FastEmbedSparseEmbedder.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.fastembed.FastEmbedSparseEmbedder.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.fastembed.FastEmbedSparseEmbedder.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.fastembed.FastEmbedSparseEmbedder.image_support","title":"image_support","text":"<pre><code>image_support() -&gt; bool\n</code></pre> <p>Check if the model supports image embeddings.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if the model supports image embeddings, False otherwise.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/base.py</code> <pre><code>def image_support(self) -&gt; bool:  # noqa: PLR6301\n    \"\"\"\n    Check if the model supports image embeddings.\n\n    Returns:\n        True if the model supports image embeddings, False otherwise.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.fastembed.FastEmbedSparseEmbedder.embed_image","title":"embed_image  <code>async</code>","text":"<pre><code>embed_image(images: list[bytes], options: SparseEmbedderOptionsT | None = None) -&gt; list[SparseVector]\n</code></pre> <p>Creates embeddings for the given images.</p> PARAMETER DESCRIPTION <code>images</code> <p>List of images to get embeddings for.</p> <p> TYPE: <code>list[bytes]</code> </p> <code>options</code> <p>Additional settings used by the Embedder model.</p> <p> TYPE: <code>SparseEmbedderOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[SparseVector]</code> <p>List of sparse embeddings for the given images.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/sparse/base.py</code> <pre><code>async def embed_image(\n    self, images: list[bytes], options: SparseEmbedderOptionsT | None = None\n) -&gt; list[SparseVector]:\n    \"\"\"\n    Creates embeddings for the given images.\n\n    Args:\n        images: List of images to get embeddings for.\n        options: Additional settings used by the Embedder model.\n\n    Returns:\n        List of sparse embeddings for the given images.\n    \"\"\"\n    raise NotImplementedError(\"Image embeddings are not supported by this model.\")\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.fastembed.FastEmbedSparseEmbedder.get_vector_size","title":"get_vector_size  <code>async</code>","text":"<pre><code>get_vector_size() -&gt; VectorSize\n</code></pre> <p>Get the vector size for this FastEmbed sparse model.</p> <p>For sparse models, this returns the vocabulary size.</p> RETURNS DESCRIPTION <code>VectorSize</code> <p>VectorSize object with is_sparse=True and the vocabulary size.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/sparse/fastembed.py</code> <pre><code>async def get_vector_size(self) -&gt; VectorSize:\n    \"\"\"\n    Get the vector size for this FastEmbed sparse model.\n\n    For sparse models, this returns the vocabulary size.\n\n    Returns:\n        VectorSize object with is_sparse=True and the vocabulary size.\n    \"\"\"\n    # Get model info from FastEmbed's supported models list\n    supported_models = self._model.list_supported_models()\n    model_info = next((model for model in supported_models if model[\"model\"] == self.model_name), None)\n\n    if model_info and \"vocab_size\" in model_info:\n        vocab_size = model_info[\"vocab_size\"]\n    else:\n        sample_embedding = await self.embed_text([\"sample text with various tokens\"])\n        vocab_size = (\n            max(sample_embedding[0].indices) + 1 if sample_embedding and sample_embedding[0].indices else 30000\n        )\n\n    return VectorSize(size=vocab_size, is_sparse=True)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.fastembed.FastEmbedSparseEmbedder.embed_text","title":"embed_text  <code>async</code>","text":"<pre><code>embed_text(data: list[str], options: EmbedderOptionsT | None = None) -&gt; list[SparseVector]\n</code></pre> <p>Embeds a list of strings into a list of sparse embeddings.</p> PARAMETER DESCRIPTION <code>data</code> <p>List of strings to get embeddings for.</p> <p> TYPE: <code>list[str]</code> </p> <code>options</code> <p>Additional options to pass to the embedding model.</p> <p> TYPE: <code>EmbedderOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[SparseVector]</code> <p>List of embeddings for the given strings.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/sparse/fastembed.py</code> <pre><code>async def embed_text(self, data: list[str], options: EmbedderOptionsT | None = None) -&gt; list[SparseVector]:\n    \"\"\"\n    Embeds a list of strings into a list of sparse embeddings.\n\n    Args:\n        data: List of strings to get embeddings for.\n        options: Additional options to pass to the embedding model.\n\n    Returns:\n        List of embeddings for the given strings.\n    \"\"\"\n    merged_options = (self.default_options | options) if options else self.default_options\n    with trace(\n        data=data, model_name=self.model_name, model_obj=repr(self._model), options=merged_options.dict()\n    ) as outputs:\n        outputs.embeddings = [\n            SparseVector(values=[float(x) for x in result.values], indices=[int(x) for x in result.indices])\n            for result in self._model.embed(data, **merged_options.dict())\n        ]\n    return outputs.embeddings\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.bag_of_tokens.BagOfTokens","title":"ragbits.core.embeddings.sparse.bag_of_tokens.BagOfTokens","text":"<pre><code>BagOfTokens(model_name: str | None = None, encoding_name: str | None = None, default_options: BagOfTokensOptions | None = None)\n</code></pre> <p>               Bases: <code>SparseEmbedder[BagOfTokensOptions]</code></p> <p>BagOfTokens implementations of sparse Embedder interface</p> <p>Initialize the BagOfTokens embedder.</p> PARAMETER DESCRIPTION <code>model_name</code> <p>Name of the model to use for tokenization (e.g., \"gpt-4o\").</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>encoding_name</code> <p>Name of the encoding to use for tokenization.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>default_options</code> <p>Default options for the embedder.</p> <p> TYPE: <code>BagOfTokensOptions | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If both model_name and encoding_name are provided, or if neither is provided.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/sparse/bag_of_tokens.py</code> <pre><code>def __init__(\n    self,\n    model_name: str | None = None,\n    encoding_name: str | None = None,\n    default_options: BagOfTokensOptions | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the BagOfTokens embedder.\n\n    Args:\n        model_name: Name of the model to use for tokenization (e.g., \"gpt-4o\").\n        encoding_name: Name of the encoding to use for tokenization.\n        default_options: Default options for the embedder.\n\n    Raises:\n        ValueError: If both model_name and encoding_name are provided, or if neither is provided.\n    \"\"\"\n    super().__init__(default_options=default_options)\n\n    if encoding_name and model_name:\n        raise ValueError(\"Please specify only one of encoding_name or model_name\")\n    if not (encoding_name or model_name):\n        # Default to gpt-4o if neither is specified\n        model_name = \"gpt-4o\"\n\n    if encoding_name:\n        self._encoder = tiktoken.get_encoding(encoding_name=encoding_name)\n    elif model_name:\n        self._encoder = tiktoken.encoding_for_model(model_name=model_name)\n    else:\n        raise ValueError(\"Either encoding_name or model_name needs to be specified\")\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.bag_of_tokens.BagOfTokens.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = embeddings\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.bag_of_tokens.BagOfTokens.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'embedder'\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.bag_of_tokens.BagOfTokens.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.bag_of_tokens.BagOfTokens.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls = BagOfTokensOptions\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.bag_of_tokens.BagOfTokens.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.bag_of_tokens.BagOfTokens.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.bag_of_tokens.BagOfTokens.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.bag_of_tokens.BagOfTokens.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.bag_of_tokens.BagOfTokens.image_support","title":"image_support","text":"<pre><code>image_support() -&gt; bool\n</code></pre> <p>Check if the model supports image embeddings.</p> RETURNS DESCRIPTION <code>bool</code> <p>True if the model supports image embeddings, False otherwise.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/base.py</code> <pre><code>def image_support(self) -&gt; bool:  # noqa: PLR6301\n    \"\"\"\n    Check if the model supports image embeddings.\n\n    Returns:\n        True if the model supports image embeddings, False otherwise.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.bag_of_tokens.BagOfTokens.embed_image","title":"embed_image  <code>async</code>","text":"<pre><code>embed_image(images: list[bytes], options: SparseEmbedderOptionsT | None = None) -&gt; list[SparseVector]\n</code></pre> <p>Creates embeddings for the given images.</p> PARAMETER DESCRIPTION <code>images</code> <p>List of images to get embeddings for.</p> <p> TYPE: <code>list[bytes]</code> </p> <code>options</code> <p>Additional settings used by the Embedder model.</p> <p> TYPE: <code>SparseEmbedderOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[SparseVector]</code> <p>List of sparse embeddings for the given images.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/sparse/base.py</code> <pre><code>async def embed_image(\n    self, images: list[bytes], options: SparseEmbedderOptionsT | None = None\n) -&gt; list[SparseVector]:\n    \"\"\"\n    Creates embeddings for the given images.\n\n    Args:\n        images: List of images to get embeddings for.\n        options: Additional settings used by the Embedder model.\n\n    Returns:\n        List of sparse embeddings for the given images.\n    \"\"\"\n    raise NotImplementedError(\"Image embeddings are not supported by this model.\")\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.bag_of_tokens.BagOfTokens.get_vector_size","title":"get_vector_size  <code>async</code>","text":"<pre><code>get_vector_size() -&gt; VectorSize\n</code></pre> <p>Get the vector size for this BagOfTokens model.</p> <p>For BagOfTokens, this returns the tokenizer vocabulary size.</p> RETURNS DESCRIPTION <code>VectorSize</code> <p>VectorSize object with is_sparse=True and the vocabulary size.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/sparse/bag_of_tokens.py</code> <pre><code>async def get_vector_size(self) -&gt; VectorSize:\n    \"\"\"\n    Get the vector size for this BagOfTokens model.\n\n    For BagOfTokens, this returns the tokenizer vocabulary size.\n\n    Returns:\n        VectorSize object with is_sparse=True and the vocabulary size.\n    \"\"\"\n    vocab_size = self._encoder.n_vocab\n    return VectorSize(size=vocab_size, is_sparse=True)\n</code></pre>"},{"location":"api_reference/core/embeddings/#ragbits.core.embeddings.sparse.bag_of_tokens.BagOfTokens.embed_text","title":"embed_text  <code>async</code>","text":"<pre><code>embed_text(texts: list[str], options: BagOfTokensOptions | None = None) -&gt; list[SparseVector]\n</code></pre> <p>Transforms a list of texts into sparse vectors using bag-of-tokens representation.</p> PARAMETER DESCRIPTION <code>texts</code> <p>list of input texts.</p> <p> TYPE: <code>list[str]</code> </p> <code>options</code> <p>optional embedding options</p> <p> TYPE: <code>BagOfTokensOptions | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[SparseVector]</code> <p>list of SparseVector instances.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/embeddings/sparse/bag_of_tokens.py</code> <pre><code>async def embed_text(self, texts: list[str], options: BagOfTokensOptions | None = None) -&gt; list[SparseVector]:\n    \"\"\"\n    Transforms a list of texts into sparse vectors using bag-of-tokens representation.\n\n    Args:\n        texts: list of input texts.\n        options: optional embedding options\n\n    Returns:\n        list of SparseVector instances.\n    \"\"\"\n    vectors = []\n    merged_options = self.default_options | options if options else self.default_options\n    with trace(data=texts, options=merged_options.dict()) as outputs:\n        min_token_count = merged_options.min_token_count or float(\"-inf\")\n        for text in texts:\n            tokens = self._encoder.encode(text)\n            token_counts = Counter(tokens)\n            non_zero_dims = []\n            non_zero_vals = []\n\n            for token, count in token_counts.items():\n                if count &lt; min_token_count:\n                    continue\n                non_zero_dims.append(token)\n                non_zero_vals.append(float(count))\n\n            vectors.append(SparseVector(indices=non_zero_dims, values=non_zero_vals))\n        outputs.embeddings = vectors\n    return vectors\n</code></pre>"},{"location":"api_reference/core/hybrid/","title":"Hybrid Vector Store &amp; Fusion Strategies","text":""},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid.HybridSearchVectorStore","title":"ragbits.core.vector_stores.hybrid.HybridSearchVectorStore","text":"<pre><code>HybridSearchVectorStore(*vector_stores: VectorStore, retrieval_strategy: HybridRetrivalStrategy | None = None)\n</code></pre> <p>               Bases: <code>VectorStore</code></p> <p>A vector store that takes multiple vector store objects and proxies requests to them, returning the union of results.</p> <p>Constructs a new HybridSearchVectorStore instance.</p> PARAMETER DESCRIPTION <code>vector_stores</code> <p>The vector stores to proxy requests to.</p> <p> TYPE: <code>VectorStore</code> DEFAULT: <code>()</code> </p> <code>retrieval_strategy</code> <p>The retrieval strategy to use when combining results, uses OrderedHybridRetrivalStrategy by default.</p> <p> TYPE: <code>HybridRetrivalStrategy | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/hybrid.py</code> <pre><code>def __init__(self, *vector_stores: VectorStore, retrieval_strategy: HybridRetrivalStrategy | None = None) -&gt; None:\n    \"\"\"\n    Constructs a new HybridSearchVectorStore instance.\n\n    Args:\n        vector_stores: The vector stores to proxy requests to.\n        retrieval_strategy: The retrieval strategy to use when combining results,\n            uses OrderedHybridRetrivalStrategy by default.\n    \"\"\"\n    self.vector_stores = vector_stores\n    self.retrieval_strategy = retrieval_strategy or OrderedHybridRetrivalStrategy()\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid.HybridSearchVectorStore.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = vector_stores\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid.HybridSearchVectorStore.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'vector_store'\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid.HybridSearchVectorStore.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid.HybridSearchVectorStore.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls = VectorStoreOptions\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid.HybridSearchVectorStore.vector_stores","title":"vector_stores  <code>instance-attribute</code>","text":"<pre><code>vector_stores = vector_stores\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid.HybridSearchVectorStore.retrieval_strategy","title":"retrieval_strategy  <code>instance-attribute</code>","text":"<pre><code>retrieval_strategy = retrieval_strategy or OrderedHybridRetrivalStrategy()\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid.HybridSearchVectorStore.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid.HybridSearchVectorStore.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid.HybridSearchVectorStore.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid.HybridSearchVectorStore.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid.HybridSearchVectorStore.store","title":"store  <code>async</code>","text":"<pre><code>store(entries: list[VectorStoreEntry]) -&gt; None\n</code></pre> <p>Store entries in the vector stores.</p> <p>Sends entries to all vector stores to be stored, although individual vector stores are free to implement their own logic regarding which entries to store. For example, some vector stores may only store entries with specific type of content (images, text, etc.).</p> PARAMETER DESCRIPTION <code>entries</code> <p>The entries to store.</p> <p> TYPE: <code>list[VectorStoreEntry]</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/hybrid.py</code> <pre><code>@traceable\nasync def store(self, entries: list[VectorStoreEntry]) -&gt; None:\n    \"\"\"\n    Store entries in the vector stores.\n\n    Sends entries to all vector stores to be stored, although individual vector stores are free to implement\n    their own logic regarding which entries to store. For example, some vector stores may only store entries\n    with specific type of content (images, text, etc.).\n\n    Args:\n        entries: The entries to store.\n    \"\"\"\n    store_tasks = (vector_store.store(entries) for vector_store in self.vector_stores)\n    await asyncio.gather(*store_tasks)\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid.HybridSearchVectorStore.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(text: str, options: VectorStoreOptions | None = None) -&gt; list[VectorStoreResult]\n</code></pre> <p>Retrieve entries from the vector stores most similar to the provided text. The results are combined using the retrieval strategy provided in the constructor.</p> PARAMETER DESCRIPTION <code>text</code> <p>The text to query the vector store with.</p> <p> TYPE: <code>str</code> </p> <code>options</code> <p>The options for querying the vector stores.</p> <p> TYPE: <code>VectorStoreOptions | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[VectorStoreResult]</code> <p>The entries.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/hybrid.py</code> <pre><code>@traceable\nasync def retrieve(\n    self,\n    text: str,\n    options: VectorStoreOptions | None = None,\n) -&gt; list[VectorStoreResult]:\n    \"\"\"\n    Retrieve entries from the vector stores most similar to the provided text. The results are combined using\n    the retrieval strategy provided in the constructor.\n\n    Args:\n        text: The text to query the vector store with.\n        options: The options for querying the vector stores.\n\n    Returns:\n        The entries.\n    \"\"\"\n    retrieve_tasks = (vector_store.retrieve(text, options) for vector_store in self.vector_stores)\n    results = await asyncio.gather(*retrieve_tasks)\n\n    return self.retrieval_strategy.join(results)\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid.HybridSearchVectorStore.remove","title":"remove  <code>async</code>","text":"<pre><code>remove(ids: list[UUID]) -&gt; None\n</code></pre> <p>Remove entries from all vector stores.</p> PARAMETER DESCRIPTION <code>ids</code> <p>The list of entries' IDs to remove.</p> <p> TYPE: <code>list[UUID]</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/hybrid.py</code> <pre><code>@traceable\nasync def remove(self, ids: list[UUID]) -&gt; None:\n    \"\"\"\n    Remove entries from all vector stores.\n\n    Args:\n        ids: The list of entries' IDs to remove.\n    \"\"\"\n    remove_tasks = (vector_store.remove(ids) for vector_store in self.vector_stores)\n    await asyncio.gather(*remove_tasks)\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid.HybridSearchVectorStore.list","title":"list  <code>async</code>","text":"<pre><code>list(where: WhereQuery | None = None, limit: int | None = None, offset: int = 0) -&gt; list[VectorStoreEntry]\n</code></pre> <p>List entries from the vector stores. The entries can be filtered, limited and offset. Vector stores are queried in the order they were provided in the constructor.</p> PARAMETER DESCRIPTION <code>where</code> <p>The filter dictionary - the keys are the field names and the values are the values to filter by. Not specifying the key means no filtering.</p> <p> TYPE: <code>WhereQuery | None</code> DEFAULT: <code>None</code> </p> <code>limit</code> <p>The maximum number of entries to return.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>offset</code> <p>The number of entries to skip.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> RETURNS DESCRIPTION <code>list[VectorStoreEntry]</code> <p>The entries.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/hybrid.py</code> <pre><code>@traceable\nasync def list(\n    self, where: WhereQuery | None = None, limit: int | None = None, offset: int = 0\n) -&gt; list[VectorStoreEntry]:\n    \"\"\"\n    List entries from the vector stores. The entries can be filtered, limited and offset.\n    Vector stores are queried in the order they were provided in the constructor.\n\n    Args:\n        where: The filter dictionary - the keys are the field names and the values are the values to filter by.\n            Not specifying the key means no filtering.\n        limit: The maximum number of entries to return.\n        offset: The number of entries to skip.\n\n    Returns:\n        The entries.\n    \"\"\"\n    retrieved_results: dict[UUID, VectorStoreEntry] = {}\n    for vector_store in self.vector_stores:\n        if limit is not None and (offset + limit - len(retrieved_results)) &lt;= 0:\n            break\n\n        store_results = await vector_store.list(where)\n        retrieved_results.update({entry.id: entry for entry in store_results})\n\n    results = list(retrieved_results.values())\n    results = results[offset:] if limit is None else results[offset : offset + limit]\n\n    return results\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid_strategies.OrderedHybridRetrivalStrategy","title":"ragbits.core.vector_stores.hybrid_strategies.OrderedHybridRetrivalStrategy","text":"<pre><code>OrderedHybridRetrivalStrategy(sum_scores: bool = False)\n</code></pre> <p>               Bases: <code>HybridRetrivalStrategy</code></p> <p>A class that orders the results by score and deduplicates them by choosing the first occurrence of each entry. This algorithm is also known as \"Relative Score Fusion\".</p> <p>Constructs a new OrderedHybridRetrivalStrategy instance.</p> PARAMETER DESCRIPTION <code>sum_scores</code> <p>if True sums the scores of the same entries, otherwise keeps the best score (i.e., the biggest one). Summing scores boosts the results that are present in results from multiple vector stores.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/hybrid_strategies.py</code> <pre><code>def __init__(self, sum_scores: bool = False) -&gt; None:\n    \"\"\"\n    Constructs a new OrderedHybridRetrivalStrategy instance.\n\n    Args:\n        sum_scores: if True sums the scores of the same entries, otherwise keeps the best score\n            (i.e., the biggest one). Summing scores boosts the results that are present in results\n            from multiple vector stores.\n    \"\"\"\n    self._sum_scores = sum_scores\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid_strategies.OrderedHybridRetrivalStrategy.join","title":"join","text":"<pre><code>join(results: list[list[VectorStoreResult]]) -&gt; list[VectorStoreResult]\n</code></pre> <p>Joins the multiple lists of results into a single list.</p> PARAMETER DESCRIPTION <code>results</code> <p>The lists of results to join.</p> <p> TYPE: <code>list[list[VectorStoreResult]]</code> </p> RETURNS DESCRIPTION <code>list[VectorStoreResult]</code> <p>The joined list of results.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/hybrid_strategies.py</code> <pre><code>def join(self, results: list[list[VectorStoreResult]]) -&gt; list[VectorStoreResult]:\n    \"\"\"\n    Joins the multiple lists of results into a single list.\n\n    Args:\n        results: The lists of results to join.\n\n    Returns:\n        The joined list of results.\n    \"\"\"\n    score_operation = add if self._sum_scores else max\n    all_results = [result for sublist in results for result in sublist]\n    all_results.sort(key=lambda result: result.score, reverse=True)\n    end_results: dict[UUID, VectorStoreResult] = {}\n    for result in all_results:\n        if result.entry.id not in end_results:\n            end_results[result.entry.id] = result.model_copy(update={\"subresults\": [result]})\n        else:\n            end_results[result.entry.id].score = score_operation(end_results[result.entry.id].score, result.score)\n            end_results[result.entry.id].subresults.append(result)\n\n    ordered = list(end_results.values())\n    ordered.sort(key=lambda result: result.score, reverse=True)\n    return ordered\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid_strategies.ReciprocalRankFusion","title":"ragbits.core.vector_stores.hybrid_strategies.ReciprocalRankFusion","text":"<pre><code>ReciprocalRankFusion(k_constant: float = 60.0, sum_scores: bool = True)\n</code></pre> <p>               Bases: <code>HybridRetrivalStrategy</code></p> <p>An implementation of Reciprocal Rank Fusion (RRF) for combining search results, based on the paper \"Reciprocal Rank Fusion outperforms Condorcet and individual Rank Learning Methods\": https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf</p> <p>Constructs a new ReciprocalRankFusion instance.</p> PARAMETER DESCRIPTION <code>k_constant</code> <p>The \"k\" constant used in the RRF formula, meant to mitigate the impact of high rankings by outlier systems. The value of 60 is recommended by the authors of the RRF paper. Qdrant uses a value of 2.</p> <p> TYPE: <code>float</code> DEFAULT: <code>60.0</code> </p> <code>sum_scores</code> <p>if True sums the scores of the same entries, otherwise keeps the best score. (i.e., the biggest one). Summing scores boosts the results that are present in results from multiple vector stores. Not summing will result in a very simple behavior: the list will include first results from all vector stores, then second results (excluding the duplicates), and so on. The original version of RRF sums the scores, so the default value is True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/hybrid_strategies.py</code> <pre><code>def __init__(self, k_constant: float = 60.0, sum_scores: bool = True) -&gt; None:\n    \"\"\"\n    Constructs a new ReciprocalRankFusion instance.\n\n    Args:\n        k_constant: The \"k\" constant used in the RRF formula, meant to mitigate\n            the impact of high rankings by outlier systems. The value of 60 is recommended\n            by the authors of the RRF paper. Qdrant uses a value of 2.\n        sum_scores: if True sums the scores of the same entries, otherwise keeps the best score.\n            (i.e., the biggest one). Summing scores boosts the results that are present in results\n            from multiple vector stores. Not summing will result in a very simple behavior:\n            the list will include first results from all vector stores, then second results\n            (excluding the duplicates), and so on. The original version of RRF sums the scores,\n            so the default value is True.\n    \"\"\"\n    self._k_constant = k_constant\n    self._sum_scores = sum_scores\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid_strategies.ReciprocalRankFusion.join","title":"join","text":"<pre><code>join(results: list[list[VectorStoreResult]]) -&gt; list[VectorStoreResult]\n</code></pre> <p>Joins the multiple lists of results into a single list using Reciprocal Rank Fusion.</p> PARAMETER DESCRIPTION <code>results</code> <p>The lists of results to join.</p> <p> TYPE: <code>list[list[VectorStoreResult]]</code> </p> RETURNS DESCRIPTION <code>list[VectorStoreResult]</code> <p>The joined list of results.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/hybrid_strategies.py</code> <pre><code>def join(self, results: list[list[VectorStoreResult]]) -&gt; list[VectorStoreResult]:\n    \"\"\"\n    Joins the multiple lists of results into a single list using Reciprocal Rank Fusion.\n\n    Args:\n        results: The lists of results to join.\n\n    Returns:\n        The joined list of results.\n    \"\"\"\n    score_operation = add if self._sum_scores else max\n    end_results: dict[UUID, VectorStoreResult] = {}\n    for result_list in results:\n        for i, result in enumerate(result_list):\n            score = 1.0 / (i + 1 + self._k_constant)\n            if result.entry.id not in end_results:\n                end_results[result.entry.id] = result.model_copy(update={\"score\": score, \"subresults\": [result]})\n            else:\n                end_results[result.entry.id].score = score_operation(end_results[result.entry.id].score, score)\n                end_results[result.entry.id].subresults.append(result)\n\n    ordered = list(end_results.values())\n    ordered.sort(key=lambda result: result.score, reverse=True)\n    return ordered\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid_strategies.DistributionBasedScoreFusion","title":"ragbits.core.vector_stores.hybrid_strategies.DistributionBasedScoreFusion","text":"<pre><code>DistributionBasedScoreFusion(sum_scores: bool = False)\n</code></pre> <p>               Bases: <code>HybridRetrivalStrategy</code></p> <p>An implementation of Distribution-Based Score Fusion (DBSF) for combining search results, based on the \"Distribution-Based Score Fusion (DBSF), a new approach to Vector Search Ranking\" post: https://medium.com/plain-simple-software/distribution-based-score-fusion-dbsf-a-new-approach-to-vector-search-ranking-f87c37488b18</p> <p>Constructs a new DistributionBasedScoreFusion instance.</p> PARAMETER DESCRIPTION <code>sum_scores</code> <p>if True sums the scores of the same entries, otherwise keeps the best score. (i.e., the biggest one). Summing scores boosts the results that are present in results from multiple vector stores. The original DBSF article remains neutral on this matter, so the default value is False. Many implementations (like Qdrant) use summing.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/hybrid_strategies.py</code> <pre><code>def __init__(self, sum_scores: bool = False) -&gt; None:\n    \"\"\"\n    Constructs a new DistributionBasedScoreFusion instance.\n\n    Args:\n        sum_scores: if True sums the scores of the same entries, otherwise keeps the best score.\n            (i.e., the biggest one). Summing scores boosts the results that are present in results\n            from multiple vector stores. The original DBSF article remains neutral on this matter,\n            so the default value is False. Many implementations (like Qdrant) use summing.\n    \"\"\"\n    self._sum_scores = sum_scores\n</code></pre>"},{"location":"api_reference/core/hybrid/#ragbits.core.vector_stores.hybrid_strategies.DistributionBasedScoreFusion.join","title":"join","text":"<pre><code>join(results: list[list[VectorStoreResult]]) -&gt; list[VectorStoreResult]\n</code></pre> <p>Joins the multiple lists of results into a single list using Distribution-Based Score Fusion.</p> PARAMETER DESCRIPTION <code>results</code> <p>The lists of results to join.</p> <p> TYPE: <code>list[list[VectorStoreResult]]</code> </p> RETURNS DESCRIPTION <code>list[VectorStoreResult]</code> <p>The joined list of results.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/hybrid_strategies.py</code> <pre><code>def join(self, results: list[list[VectorStoreResult]]) -&gt; list[VectorStoreResult]:  # noqa: PLR6301\n    \"\"\"\n    Joins the multiple lists of results into a single list using Distribution-Based Score Fusion.\n\n    Args:\n        results: The lists of results to join.\n\n    Returns:\n        The joined list of results.\n    \"\"\"\n    score_operation = add if self._sum_scores else max\n    end_results: dict[UUID, VectorStoreResult] = {}\n    scores = [[result.score for result in result_list] for result_list in results]\n\n    # Calculate mean and standard deviation for each result list\n    mean = [sum(score_list) / len(score_list) if score_list else 0 for score_list in scores]\n    std = [\n        (sum((score - mean[i]) ** 2 for score in score_list) / len(score_list)) ** 0.5 if score_list else 0\n        for i, score_list in enumerate(scores)\n    ]\n\n    # Calculate normalization bounds\n    three_std_above = [mean[i] + 3 * std[i] for i in range(len(mean))]\n    three_std_below = [mean[i] - 3 * std[i] for i in range(len(mean))]\n\n    # Normalize scores\n    normalized_scores = []\n    for i, score_list in enumerate(scores):\n        denominator = three_std_above[i] - three_std_below[i]\n        normalized_list = [\n            (score - three_std_below[i]) / denominator if denominator != 0 else 0 for score in score_list\n        ]\n        normalized_scores.append(normalized_list)\n\n    for i, result_list in enumerate(results):\n        for j, result in enumerate(result_list):\n            if result.entry.id not in end_results:\n                end_results[result.entry.id] = result.model_copy(\n                    update={\"score\": normalized_scores[i][j], \"subresults\": [result]}\n                )\n            else:\n                end_results[result.entry.id].score = score_operation(\n                    end_results[result.entry.id].score, normalized_scores[i][j]\n                )\n                end_results[result.entry.id].subresults.append(result)\n\n    ordered = list(end_results.values())\n    ordered.sort(key=lambda result: result.score, reverse=True)\n\n    return ordered\n</code></pre>"},{"location":"api_reference/core/llms/","title":"LLMs","text":""},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM","title":"ragbits.core.llms.LLM","text":"<pre><code>LLM(model_name: str, default_options: LLMClientOptionsT | None = None)\n</code></pre> <p>               Bases: <code>ConfigurableComponent[LLMClientOptionsT]</code>, <code>ABC</code></p> <p>Abstract class for interaction with Large Language Model.</p> <p>Constructs a new LLM instance.</p> PARAMETER DESCRIPTION <code>model_name</code> <p>Name of the model to be used.</p> <p> TYPE: <code>str</code> </p> <code>default_options</code> <p>Default options to be used.</p> <p> TYPE: <code>LLMClientOptionsT | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>If the subclass is missing the 'options_cls' attribute.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>def __init__(self, model_name: str, default_options: LLMClientOptionsT | None = None) -&gt; None:\n    \"\"\"\n    Constructs a new LLM instance.\n\n    Args:\n        model_name: Name of the model to be used.\n        default_options: Default options to be used.\n\n    Raises:\n        TypeError: If the subclass is missing the 'options_cls' attribute.\n    \"\"\"\n    super().__init__(default_options=default_options)\n    self.model_name = model_name\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM.options_cls","title":"options_cls  <code>instance-attribute</code>","text":"<pre><code>options_cls: type[LLMClientOptionsT]\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = llms\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'llm'\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM.model_name","title":"model_name  <code>instance-attribute</code>","text":"<pre><code>model_name = model_name\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM.get_model_id","title":"get_model_id  <code>abstractmethod</code>","text":"<pre><code>get_model_id() -&gt; str\n</code></pre> <p>Returns the model id.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>@abstractmethod\ndef get_model_id(self) -&gt; str:\n    \"\"\"\n    Returns the model id.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM.get_estimated_cost","title":"get_estimated_cost  <code>abstractmethod</code>","text":"<pre><code>get_estimated_cost(prompt_tokens: int, completion_tokens: int) -&gt; float\n</code></pre> <p>Returns the estimated cost of the LLM call.</p> PARAMETER DESCRIPTION <code>prompt_tokens</code> <p>The number of tokens in the prompt.</p> <p> TYPE: <code>int</code> </p> <code>completion_tokens</code> <p>The number of tokens in the completion.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>float</code> <p>The estimated cost of the LLM call.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>@abstractmethod\ndef get_estimated_cost(self, prompt_tokens: int, completion_tokens: int) -&gt; float:\n    \"\"\"\n    Returns the estimated cost of the LLM call.\n\n    Args:\n        prompt_tokens: The number of tokens in the prompt.\n        completion_tokens: The number of tokens in the completion.\n\n    Returns:\n        The estimated cost of the LLM call.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM.count_tokens","title":"count_tokens","text":"<pre><code>count_tokens(prompt: BasePrompt) -&gt; int\n</code></pre> <p>Counts tokens in the prompt.</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Formatted prompt template with conversation and response parsing configuration.</p> <p> TYPE: <code>BasePrompt</code> </p> RETURNS DESCRIPTION <code>int</code> <p>Number of tokens in the prompt.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>def count_tokens(self, prompt: BasePrompt) -&gt; int:  # noqa: PLR6301\n    \"\"\"\n    Counts tokens in the prompt.\n\n    Args:\n        prompt: Formatted prompt template with conversation and response parsing configuration.\n\n    Returns:\n        Number of tokens in the prompt.\n    \"\"\"\n    return sum(len(message[\"content\"]) for message in prompt.chat)\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM.get_token_id","title":"get_token_id","text":"<pre><code>get_token_id(token: str) -&gt; int\n</code></pre> <p>Gets token id.</p> PARAMETER DESCRIPTION <code>token</code> <p>The token to encode.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>int</code> <p>The id for the given token.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>def get_token_id(self, token: str) -&gt; int:\n    \"\"\"\n    Gets token id.\n\n    Args:\n        token: The token to encode.\n\n    Returns:\n        The id for the given token.\n    \"\"\"\n    raise NotImplementedError(\"Token id lookup is not supported by this model\")\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM.generate_raw","title":"generate_raw  <code>async</code>","text":"<pre><code>generate_raw(prompt: BasePrompt | str | ChatFormat, *, options: LLMClientOptionsT | None = None) -&gt; dict\n</code></pre> <p>Prepares and sends a prompt to the LLM and returns the raw response (without parsing).</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Can be one of: - BasePrompt instance: Formatted prompt template with conversation - str: Simple text prompt that will be sent as a user message - ChatFormat: List of message dictionaries in OpenAI chat format</p> <p> TYPE: <code>BasePrompt | str | ChatFormat</code> </p> <code>options</code> <p>Options to use for the LLM client.</p> <p> TYPE: <code>LLMClientOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>Raw response from LLM.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>@deprecated(\"Use generate_with_metadata() instead\")\nasync def generate_raw(\n    self,\n    prompt: BasePrompt | str | ChatFormat,\n    *,\n    options: LLMClientOptionsT | None = None,\n) -&gt; dict:\n    \"\"\"\n    Prepares and sends a prompt to the LLM and returns the raw response (without parsing).\n\n    Args:\n        prompt: Can be one of:\n            - BasePrompt instance: Formatted prompt template with conversation\n            - str: Simple text prompt that will be sent as a user message\n            - ChatFormat: List of message dictionaries in OpenAI chat format\n        options: Options to use for the LLM client.\n\n    Returns:\n        Raw response from LLM.\n    \"\"\"\n    merged_options = (self.default_options | options) if options else self.default_options\n\n    if isinstance(prompt, str | list):\n        prompt = SimplePrompt(prompt)\n\n    response = (\n        await self._call(\n            prompt=[prompt],\n            options=merged_options,\n        )\n    )[0]\n\n    returned = {\n        \"response\": response[\"response\"],\n        \"throughput\": response[\"throughput\"],\n    }\n    for opt in [\"tool_calls\", \"usage\"]:\n        if opt in response:\n            returned[opt] = response[opt]\n\n    return returned\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM.generate","title":"generate  <code>async</code>","text":"<pre><code>generate(prompt: str | ChatFormat | BasePrompt | BasePromptWithParser[PromptOutputT] | MutableSequence[ChatFormat | str] | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]], *, tools: list[Tool] | None = None, tool_choice: ToolChoiceWithCallable | None = None, options: LLMClientOptionsT | None = None) -&gt; str | PromptOutputT | list[ToolCall] | list[list[ToolCall] | str] | list[str | PromptOutputT | list[ToolCall]]\n</code></pre> <p>Prepares and sends a prompt to the LLM and returns the parsed response.</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Can be one of: - BasePrompt instance: Formatted prompt template with conversation - str: Simple text prompt that will be sent as a user message - ChatFormat: List of message dictionaries in OpenAI chat format - Iterable of any of the above (MutableSequence is only for typing purposes)</p> <p> TYPE: <code>str | ChatFormat | BasePrompt | BasePromptWithParser[PromptOutputT] | MutableSequence[ChatFormat | str] | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]]</code> </p> <code>tools</code> <p>Functions to be used as tools by the LLM.</p> <p> TYPE: <code>list[Tool] | None</code> DEFAULT: <code>None</code> </p> <code>tool_choice</code> <p>Parameter that allows to control what tool is used. Can be one of: - \"auto\": let model decide if tool call is needed - \"none\": do not call tool - \"required: enforce tool usage (model decides which one) - dict: tool dict corresponding to one of provided tools - Callable: one of provided tools</p> <p> TYPE: <code>ToolChoiceWithCallable | None</code> DEFAULT: <code>None</code> </p> <code>options</code> <p>Options to use for the LLM client.</p> <p> TYPE: <code>LLMClientOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str | PromptOutputT | list[ToolCall] | list[list[ToolCall] | str] | list[str | PromptOutputT | list[ToolCall]]</code> <p>Parsed response(s) from LLM or list of tool calls.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>async def generate(\n    self,\n    prompt: str\n    | ChatFormat\n    | BasePrompt\n    | BasePromptWithParser[PromptOutputT]\n    | MutableSequence[ChatFormat | str]\n    | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]],\n    *,\n    tools: list[Tool] | None = None,\n    tool_choice: ToolChoiceWithCallable | None = None,\n    options: LLMClientOptionsT | None = None,\n) -&gt; str | PromptOutputT | list[ToolCall] | list[list[ToolCall] | str] | list[str | PromptOutputT | list[ToolCall]]:\n    \"\"\"\n    Prepares and sends a prompt to the LLM and returns the parsed response.\n\n    Args:\n        prompt: Can be one of:\n            - BasePrompt instance: Formatted prompt template with conversation\n            - str: Simple text prompt that will be sent as a user message\n            - ChatFormat: List of message dictionaries in OpenAI chat format\n            - Iterable of any of the above (MutableSequence is only for typing purposes)\n        tools: Functions to be used as tools by the LLM.\n        tool_choice: Parameter that allows to control what tool is used. Can be one of:\n            - \"auto\": let model decide if tool call is needed\n            - \"none\": do not call tool\n            - \"required: enforce tool usage (model decides which one)\n            - dict: tool dict corresponding to one of provided tools\n            - Callable: one of provided tools\n        options: Options to use for the LLM client.\n\n    Returns:\n        Parsed response(s) from LLM or list of tool calls.\n    \"\"\"\n    response = await self.generate_with_metadata(prompt, tools=tools, tool_choice=tool_choice, options=options)\n    if isinstance(response, list):\n        return [r.tool_calls if tools and r.tool_calls else r.content for r in response]\n    else:\n        return response.tool_calls if tools and response.tool_calls else response.content\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM.generate_with_metadata","title":"generate_with_metadata  <code>async</code>","text":"<pre><code>generate_with_metadata(prompt: str | ChatFormat | MutableSequence[str | ChatFormat] | BasePrompt | BasePromptWithParser[PromptOutputT] | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]], *, tools: list[Tool] | None = None, tool_choice: ToolChoiceWithCallable | None = None, options: LLMClientOptionsT | None = None) -&gt; LLMResponseWithMetadata[str] | list[LLMResponseWithMetadata[str]] | LLMResponseWithMetadata[PromptOutputT] | list[LLMResponseWithMetadata[PromptOutputT]]\n</code></pre> <p>Prepares and sends a prompt to the LLM and returns response parsed to the output type of the prompt (if available).</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Can be one of: - BasePrompt instance: Formatted prompt template with conversation - str: Simple text prompt that will be sent as a user message - ChatFormat: List of message dictionaries in OpenAI chat format - Iterable of any of the above (MutableSequence is only for typing purposes)</p> <p> TYPE: <code>str | ChatFormat | MutableSequence[str | ChatFormat] | BasePrompt | BasePromptWithParser[PromptOutputT] | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]]</code> </p> <code>tools</code> <p>Functions to be used as tools by the LLM.</p> <p> TYPE: <code>list[Tool] | None</code> DEFAULT: <code>None</code> </p> <code>tool_choice</code> <p>Parameter that allows to control what tool is used. Can be one of: - \"auto\": let model decide if tool call is needed - \"none\": do not call tool - \"required: enforce tool usage (model decides which one) - dict: tool dict corresponding to one of provided tools - Callable: one of provided tools</p> <p> TYPE: <code>ToolChoiceWithCallable | None</code> DEFAULT: <code>None</code> </p> <code>options</code> <p>Options to use for the LLM client.</p> <p> TYPE: <code>LLMClientOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>LLMResponseWithMetadata[str] | list[LLMResponseWithMetadata[str]] | LLMResponseWithMetadata[PromptOutputT] | list[LLMResponseWithMetadata[PromptOutputT]]</code> <p>ResponseWithMetadata object(s) with text response, list of tool calls and metadata information.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>async def generate_with_metadata(\n    self,\n    prompt: str\n    | ChatFormat\n    | MutableSequence[str | ChatFormat]\n    | BasePrompt\n    | BasePromptWithParser[PromptOutputT]\n    | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]],\n    *,\n    tools: list[Tool] | None = None,\n    tool_choice: ToolChoiceWithCallable | None = None,\n    options: LLMClientOptionsT | None = None,\n) -&gt; (\n    LLMResponseWithMetadata[str]\n    | list[LLMResponseWithMetadata[str]]\n    | LLMResponseWithMetadata[PromptOutputT]\n    | list[LLMResponseWithMetadata[PromptOutputT]]\n):\n    \"\"\"\n    Prepares and sends a prompt to the LLM and returns response parsed to the\n    output type of the prompt (if available).\n\n    Args:\n        prompt: Can be one of:\n            - BasePrompt instance: Formatted prompt template with conversation\n            - str: Simple text prompt that will be sent as a user message\n            - ChatFormat: List of message dictionaries in OpenAI chat format\n            - Iterable of any of the above (MutableSequence is only for typing purposes)\n        tools: Functions to be used as tools by the LLM.\n        tool_choice: Parameter that allows to control what tool is used. Can be one of:\n            - \"auto\": let model decide if tool call is needed\n            - \"none\": do not call tool\n            - \"required: enforce tool usage (model decides which one)\n            - dict: tool dict corresponding to one of provided tools\n            - Callable: one of provided tools\n        options: Options to use for the LLM client.\n\n    Returns:\n        ResponseWithMetadata object(s) with text response, list of tool calls and metadata information.\n    \"\"\"\n    single_prompt = False\n    if isinstance(prompt, BasePrompt | str) or isinstance(prompt[0], dict):\n        single_prompt = True\n        prompt = [prompt]  # type: ignore\n\n    parsed_tools = (\n        [convert_function_to_function_schema(tool) if callable(tool) else tool for tool in tools] if tools else None\n    )\n    parsed_tool_choice = convert_function_to_function_schema(tool_choice) if callable(tool_choice) else tool_choice\n\n    prompts: list[BasePrompt] = [SimplePrompt(p) if isinstance(p, str | list) else p for p in prompt]  # type: ignore\n\n    merged_options = (self.default_options | options) if options else self.default_options\n\n    with trace(name=\"generate\", model_name=self.model_name, prompt=prompts, options=repr(options)) as outputs:\n        results = await self._call(\n            prompt=prompts,\n            options=merged_options,\n            tools=parsed_tools,\n            tool_choice=parsed_tool_choice,\n        )\n\n        parsed_responses = []\n        for prompt, response in zip(prompts, results, strict=True):\n            tool_calls = (\n                [ToolCall.model_validate(tool_call) for tool_call in _tool_calls]\n                if (_tool_calls := response.pop(\"tool_calls\", None)) and tools\n                else None\n            )\n\n            usage = None\n            if usage_data := response.pop(\"usage\", None):\n                usage = Usage.new(\n                    llm=self,\n                    prompt_tokens=cast(int, usage_data.get(\"prompt_tokens\")),\n                    completion_tokens=cast(int, usage_data.get(\"completion_tokens\")),\n                    total_tokens=cast(int, usage_data.get(\"total_tokens\")),\n                )\n\n            content = response.pop(\"response\")\n            reasoning = response.pop(\"reasoning\", None)\n\n            if isinstance(prompt, BasePromptWithParser) and content:\n                content = await prompt.parse_response(content)\n\n            response_with_metadata = LLMResponseWithMetadata[type(content)](  # type: ignore\n                content=content,\n                reasoning=reasoning,\n                tool_calls=tool_calls,\n                metadata=response,\n                usage=usage,\n            )\n            parsed_responses.append(response_with_metadata)\n        outputs.response = parsed_responses\n\n        prompt_tokens = sum(r.usage.prompt_tokens for r in parsed_responses if r.usage)\n        outputs.prompt_tokens_batch = prompt_tokens\n        record_metric(\n            metric=LLMMetric.INPUT_TOKENS,\n            value=prompt_tokens,\n            metric_type=MetricType.HISTOGRAM,\n            model=self.model_name,\n        )\n\n        total_throughput = sum(r[\"throughput\"] for r in results if \"throughput\" in r)\n        outputs.throughput_batch = total_throughput\n        record_metric(\n            metric=LLMMetric.PROMPT_THROUGHPUT,\n            value=total_throughput,\n            metric_type=MetricType.HISTOGRAM,\n            model=self.model_name,\n        )\n\n        total_tokens = sum(r.usage.total_tokens for r in parsed_responses if r.usage)\n        outputs.total_tokens_batch = total_tokens\n        record_metric(\n            metric=LLMMetric.TOKEN_THROUGHPUT,\n            value=total_tokens / total_throughput,\n            metric_type=MetricType.HISTOGRAM,\n            model=self.model_name,\n        )\n\n    if single_prompt:\n        return parsed_responses[0]\n\n    return parsed_responses\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.LLM.generate_streaming","title":"generate_streaming","text":"<pre><code>generate_streaming(prompt: str | ChatFormat | BasePrompt, *, tools: list[Tool] | None = None, tool_choice: ToolChoiceWithCallable | None = None, options: LLMClientOptionsT | None = None) -&gt; LLMResultStreaming\n</code></pre> <p>This method returns an <code>LLMResultStreaming</code> object that can be asynchronously iterated over. After the loop completes, metadata is available as <code>metadata</code> attribute.</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Formatted prompt template with conversation.</p> <p> TYPE: <code>str | ChatFormat | BasePrompt</code> </p> <code>tools</code> <p>Functions to be used as tools by the LLM.</p> <p> TYPE: <code>list[Tool] | None</code> DEFAULT: <code>None</code> </p> <code>tool_choice</code> <p>Parameter that allows to control what tool is used. Can be one of: - \"auto\": let model decide if tool call is needed - \"none\": do not call tool - \"required: enforce tool usage (model decides which one) - dict: tool dict corresponding to one of provided tools - Callable: one of provided tools</p> <p> TYPE: <code>ToolChoiceWithCallable | None</code> DEFAULT: <code>None</code> </p> <code>options</code> <p>Options to use for the LLM.</p> <p> TYPE: <code>LLMClientOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>LLMResultStreaming</code> <p>Response stream from LLM or list of tool calls.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>def generate_streaming(\n    self,\n    prompt: str | ChatFormat | BasePrompt,\n    *,\n    tools: list[Tool] | None = None,\n    tool_choice: ToolChoiceWithCallable | None = None,\n    options: LLMClientOptionsT | None = None,\n) -&gt; LLMResultStreaming:\n    \"\"\"\n    This method returns an `LLMResultStreaming` object that can be asynchronously\n    iterated over. After the loop completes, metadata is available as `metadata` attribute.\n\n    Args:\n        prompt: Formatted prompt template with conversation.\n        tools: Functions to be used as tools by the LLM.\n        tool_choice: Parameter that allows to control what tool is used. Can be one of:\n            - \"auto\": let model decide if tool call is needed\n            - \"none\": do not call tool\n            - \"required: enforce tool usage (model decides which one)\n            - dict: tool dict corresponding to one of provided tools\n            - Callable: one of provided tools\n        options: Options to use for the LLM.\n\n    Returns:\n        Response stream from LLM or list of tool calls.\n    \"\"\"\n    return LLMResultStreaming(self._stream_internal(prompt, tools=tools, tool_choice=tool_choice, options=options))\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM","title":"ragbits.core.llms.local.LocalLLM","text":"<pre><code>LocalLLM(model_name: str, default_options: LocalLLMOptions | None = None, *, api_key: str | None = None, price_per_prompt_token: float = 0.0, price_per_completion_token: float = 0.0)\n</code></pre> <p>               Bases: <code>LLM[LocalLLMOptions]</code></p> <p>Class for interaction with any LLM available in HuggingFace.</p> <p>Note: Local implementation is not dedicated for production. Use it only in experiments / evaluation</p> <p>Constructs a new local LLM instance.</p> PARAMETER DESCRIPTION <code>model_name</code> <p>Name of the model to use. This should be a model from the CausalLM class.</p> <p> TYPE: <code>str</code> </p> <code>default_options</code> <p>Default options for the LLM.</p> <p> TYPE: <code>LocalLLMOptions | None</code> DEFAULT: <code>None</code> </p> <code>api_key</code> <p>The API key for Hugging Face authentication.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>price_per_prompt_token</code> <p>The price per prompt token.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>price_per_completion_token</code> <p>The price per completion token.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> RAISES DESCRIPTION <code>ImportError</code> <p>If the 'local' extra requirements are not installed.</p> <code>ValueError</code> <p>If the model was not trained as a chat model.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/local.py</code> <pre><code>def __init__(\n    self,\n    model_name: str,\n    default_options: LocalLLMOptions | None = None,\n    *,\n    api_key: str | None = None,\n    price_per_prompt_token: float = 0.0,\n    price_per_completion_token: float = 0.0,\n) -&gt; None:\n    \"\"\"\n    Constructs a new local LLM instance.\n\n    Args:\n        model_name: Name of the model to use. This should be a model from the CausalLM class.\n        default_options: Default options for the LLM.\n        api_key: The API key for Hugging Face authentication.\n        price_per_prompt_token: The price per prompt token.\n        price_per_completion_token: The price per completion token.\n\n    Raises:\n        ImportError: If the 'local' extra requirements are not installed.\n        ValueError: If the model was not trained as a chat model.\n    \"\"\"\n    deps = self._lazy_import_local_deps()\n    if deps is None:\n        raise ImportError(\"You need to install the 'local' extra requirements to use local LLM models\")\n    torch, AutoModelForCausalLM, AutoTokenizer, self.TextIteratorStreamer = deps\n\n    super().__init__(model_name, default_options)\n    self.model = AutoModelForCausalLM.from_pretrained(\n        model_name, device_map=\"auto\", torch_dtype=torch.bfloat16, token=api_key\n    )\n    self.tokenizer = AutoTokenizer.from_pretrained(model_name, token=api_key)\n    try:\n        self.tokenizer.get_chat_template()\n    except ValueError as e:\n        raise ValueError(\n            f\"{model_name} was not trained as a chat model - it doesn't support chat template. Select another model\"\n        ) from e\n    self.api_key = api_key\n    self._price_per_prompt_token = price_per_prompt_token\n    self._price_per_completion_token = price_per_completion_token\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = llms\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'llm'\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.model_name","title":"model_name  <code>instance-attribute</code>","text":"<pre><code>model_name = model_name\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls = LocalLLMOptions\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model = from_pretrained(model_name, device_map='auto', torch_dtype=bfloat16, token=api_key)\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.tokenizer","title":"tokenizer  <code>instance-attribute</code>","text":"<pre><code>tokenizer = from_pretrained(model_name, token=api_key)\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.api_key","title":"api_key  <code>instance-attribute</code>","text":"<pre><code>api_key = api_key\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.get_token_id","title":"get_token_id","text":"<pre><code>get_token_id(token: str) -&gt; int\n</code></pre> <p>Gets token id.</p> PARAMETER DESCRIPTION <code>token</code> <p>The token to encode.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>int</code> <p>The id for the given token.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>def get_token_id(self, token: str) -&gt; int:\n    \"\"\"\n    Gets token id.\n\n    Args:\n        token: The token to encode.\n\n    Returns:\n        The id for the given token.\n    \"\"\"\n    raise NotImplementedError(\"Token id lookup is not supported by this model\")\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.generate_raw","title":"generate_raw  <code>async</code>","text":"<pre><code>generate_raw(prompt: BasePrompt | str | ChatFormat, *, options: LLMClientOptionsT | None = None) -&gt; dict\n</code></pre> <p>Prepares and sends a prompt to the LLM and returns the raw response (without parsing).</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Can be one of: - BasePrompt instance: Formatted prompt template with conversation - str: Simple text prompt that will be sent as a user message - ChatFormat: List of message dictionaries in OpenAI chat format</p> <p> TYPE: <code>BasePrompt | str | ChatFormat</code> </p> <code>options</code> <p>Options to use for the LLM client.</p> <p> TYPE: <code>LLMClientOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>Raw response from LLM.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>@deprecated(\"Use generate_with_metadata() instead\")\nasync def generate_raw(\n    self,\n    prompt: BasePrompt | str | ChatFormat,\n    *,\n    options: LLMClientOptionsT | None = None,\n) -&gt; dict:\n    \"\"\"\n    Prepares and sends a prompt to the LLM and returns the raw response (without parsing).\n\n    Args:\n        prompt: Can be one of:\n            - BasePrompt instance: Formatted prompt template with conversation\n            - str: Simple text prompt that will be sent as a user message\n            - ChatFormat: List of message dictionaries in OpenAI chat format\n        options: Options to use for the LLM client.\n\n    Returns:\n        Raw response from LLM.\n    \"\"\"\n    merged_options = (self.default_options | options) if options else self.default_options\n\n    if isinstance(prompt, str | list):\n        prompt = SimplePrompt(prompt)\n\n    response = (\n        await self._call(\n            prompt=[prompt],\n            options=merged_options,\n        )\n    )[0]\n\n    returned = {\n        \"response\": response[\"response\"],\n        \"throughput\": response[\"throughput\"],\n    }\n    for opt in [\"tool_calls\", \"usage\"]:\n        if opt in response:\n            returned[opt] = response[opt]\n\n    return returned\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.generate","title":"generate  <code>async</code>","text":"<pre><code>generate(prompt: str | ChatFormat | BasePrompt | BasePromptWithParser[PromptOutputT] | MutableSequence[ChatFormat | str] | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]], *, tools: list[Tool] | None = None, tool_choice: ToolChoiceWithCallable | None = None, options: LLMClientOptionsT | None = None) -&gt; str | PromptOutputT | list[ToolCall] | list[list[ToolCall] | str] | list[str | PromptOutputT | list[ToolCall]]\n</code></pre> <p>Prepares and sends a prompt to the LLM and returns the parsed response.</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Can be one of: - BasePrompt instance: Formatted prompt template with conversation - str: Simple text prompt that will be sent as a user message - ChatFormat: List of message dictionaries in OpenAI chat format - Iterable of any of the above (MutableSequence is only for typing purposes)</p> <p> TYPE: <code>str | ChatFormat | BasePrompt | BasePromptWithParser[PromptOutputT] | MutableSequence[ChatFormat | str] | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]]</code> </p> <code>tools</code> <p>Functions to be used as tools by the LLM.</p> <p> TYPE: <code>list[Tool] | None</code> DEFAULT: <code>None</code> </p> <code>tool_choice</code> <p>Parameter that allows to control what tool is used. Can be one of: - \"auto\": let model decide if tool call is needed - \"none\": do not call tool - \"required: enforce tool usage (model decides which one) - dict: tool dict corresponding to one of provided tools - Callable: one of provided tools</p> <p> TYPE: <code>ToolChoiceWithCallable | None</code> DEFAULT: <code>None</code> </p> <code>options</code> <p>Options to use for the LLM client.</p> <p> TYPE: <code>LLMClientOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str | PromptOutputT | list[ToolCall] | list[list[ToolCall] | str] | list[str | PromptOutputT | list[ToolCall]]</code> <p>Parsed response(s) from LLM or list of tool calls.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>async def generate(\n    self,\n    prompt: str\n    | ChatFormat\n    | BasePrompt\n    | BasePromptWithParser[PromptOutputT]\n    | MutableSequence[ChatFormat | str]\n    | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]],\n    *,\n    tools: list[Tool] | None = None,\n    tool_choice: ToolChoiceWithCallable | None = None,\n    options: LLMClientOptionsT | None = None,\n) -&gt; str | PromptOutputT | list[ToolCall] | list[list[ToolCall] | str] | list[str | PromptOutputT | list[ToolCall]]:\n    \"\"\"\n    Prepares and sends a prompt to the LLM and returns the parsed response.\n\n    Args:\n        prompt: Can be one of:\n            - BasePrompt instance: Formatted prompt template with conversation\n            - str: Simple text prompt that will be sent as a user message\n            - ChatFormat: List of message dictionaries in OpenAI chat format\n            - Iterable of any of the above (MutableSequence is only for typing purposes)\n        tools: Functions to be used as tools by the LLM.\n        tool_choice: Parameter that allows to control what tool is used. Can be one of:\n            - \"auto\": let model decide if tool call is needed\n            - \"none\": do not call tool\n            - \"required: enforce tool usage (model decides which one)\n            - dict: tool dict corresponding to one of provided tools\n            - Callable: one of provided tools\n        options: Options to use for the LLM client.\n\n    Returns:\n        Parsed response(s) from LLM or list of tool calls.\n    \"\"\"\n    response = await self.generate_with_metadata(prompt, tools=tools, tool_choice=tool_choice, options=options)\n    if isinstance(response, list):\n        return [r.tool_calls if tools and r.tool_calls else r.content for r in response]\n    else:\n        return response.tool_calls if tools and response.tool_calls else response.content\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.generate_with_metadata","title":"generate_with_metadata  <code>async</code>","text":"<pre><code>generate_with_metadata(prompt: str | ChatFormat | MutableSequence[str | ChatFormat] | BasePrompt | BasePromptWithParser[PromptOutputT] | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]], *, tools: list[Tool] | None = None, tool_choice: ToolChoiceWithCallable | None = None, options: LLMClientOptionsT | None = None) -&gt; LLMResponseWithMetadata[str] | list[LLMResponseWithMetadata[str]] | LLMResponseWithMetadata[PromptOutputT] | list[LLMResponseWithMetadata[PromptOutputT]]\n</code></pre> <p>Prepares and sends a prompt to the LLM and returns response parsed to the output type of the prompt (if available).</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Can be one of: - BasePrompt instance: Formatted prompt template with conversation - str: Simple text prompt that will be sent as a user message - ChatFormat: List of message dictionaries in OpenAI chat format - Iterable of any of the above (MutableSequence is only for typing purposes)</p> <p> TYPE: <code>str | ChatFormat | MutableSequence[str | ChatFormat] | BasePrompt | BasePromptWithParser[PromptOutputT] | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]]</code> </p> <code>tools</code> <p>Functions to be used as tools by the LLM.</p> <p> TYPE: <code>list[Tool] | None</code> DEFAULT: <code>None</code> </p> <code>tool_choice</code> <p>Parameter that allows to control what tool is used. Can be one of: - \"auto\": let model decide if tool call is needed - \"none\": do not call tool - \"required: enforce tool usage (model decides which one) - dict: tool dict corresponding to one of provided tools - Callable: one of provided tools</p> <p> TYPE: <code>ToolChoiceWithCallable | None</code> DEFAULT: <code>None</code> </p> <code>options</code> <p>Options to use for the LLM client.</p> <p> TYPE: <code>LLMClientOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>LLMResponseWithMetadata[str] | list[LLMResponseWithMetadata[str]] | LLMResponseWithMetadata[PromptOutputT] | list[LLMResponseWithMetadata[PromptOutputT]]</code> <p>ResponseWithMetadata object(s) with text response, list of tool calls and metadata information.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>async def generate_with_metadata(\n    self,\n    prompt: str\n    | ChatFormat\n    | MutableSequence[str | ChatFormat]\n    | BasePrompt\n    | BasePromptWithParser[PromptOutputT]\n    | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]],\n    *,\n    tools: list[Tool] | None = None,\n    tool_choice: ToolChoiceWithCallable | None = None,\n    options: LLMClientOptionsT | None = None,\n) -&gt; (\n    LLMResponseWithMetadata[str]\n    | list[LLMResponseWithMetadata[str]]\n    | LLMResponseWithMetadata[PromptOutputT]\n    | list[LLMResponseWithMetadata[PromptOutputT]]\n):\n    \"\"\"\n    Prepares and sends a prompt to the LLM and returns response parsed to the\n    output type of the prompt (if available).\n\n    Args:\n        prompt: Can be one of:\n            - BasePrompt instance: Formatted prompt template with conversation\n            - str: Simple text prompt that will be sent as a user message\n            - ChatFormat: List of message dictionaries in OpenAI chat format\n            - Iterable of any of the above (MutableSequence is only for typing purposes)\n        tools: Functions to be used as tools by the LLM.\n        tool_choice: Parameter that allows to control what tool is used. Can be one of:\n            - \"auto\": let model decide if tool call is needed\n            - \"none\": do not call tool\n            - \"required: enforce tool usage (model decides which one)\n            - dict: tool dict corresponding to one of provided tools\n            - Callable: one of provided tools\n        options: Options to use for the LLM client.\n\n    Returns:\n        ResponseWithMetadata object(s) with text response, list of tool calls and metadata information.\n    \"\"\"\n    single_prompt = False\n    if isinstance(prompt, BasePrompt | str) or isinstance(prompt[0], dict):\n        single_prompt = True\n        prompt = [prompt]  # type: ignore\n\n    parsed_tools = (\n        [convert_function_to_function_schema(tool) if callable(tool) else tool for tool in tools] if tools else None\n    )\n    parsed_tool_choice = convert_function_to_function_schema(tool_choice) if callable(tool_choice) else tool_choice\n\n    prompts: list[BasePrompt] = [SimplePrompt(p) if isinstance(p, str | list) else p for p in prompt]  # type: ignore\n\n    merged_options = (self.default_options | options) if options else self.default_options\n\n    with trace(name=\"generate\", model_name=self.model_name, prompt=prompts, options=repr(options)) as outputs:\n        results = await self._call(\n            prompt=prompts,\n            options=merged_options,\n            tools=parsed_tools,\n            tool_choice=parsed_tool_choice,\n        )\n\n        parsed_responses = []\n        for prompt, response in zip(prompts, results, strict=True):\n            tool_calls = (\n                [ToolCall.model_validate(tool_call) for tool_call in _tool_calls]\n                if (_tool_calls := response.pop(\"tool_calls\", None)) and tools\n                else None\n            )\n\n            usage = None\n            if usage_data := response.pop(\"usage\", None):\n                usage = Usage.new(\n                    llm=self,\n                    prompt_tokens=cast(int, usage_data.get(\"prompt_tokens\")),\n                    completion_tokens=cast(int, usage_data.get(\"completion_tokens\")),\n                    total_tokens=cast(int, usage_data.get(\"total_tokens\")),\n                )\n\n            content = response.pop(\"response\")\n            reasoning = response.pop(\"reasoning\", None)\n\n            if isinstance(prompt, BasePromptWithParser) and content:\n                content = await prompt.parse_response(content)\n\n            response_with_metadata = LLMResponseWithMetadata[type(content)](  # type: ignore\n                content=content,\n                reasoning=reasoning,\n                tool_calls=tool_calls,\n                metadata=response,\n                usage=usage,\n            )\n            parsed_responses.append(response_with_metadata)\n        outputs.response = parsed_responses\n\n        prompt_tokens = sum(r.usage.prompt_tokens for r in parsed_responses if r.usage)\n        outputs.prompt_tokens_batch = prompt_tokens\n        record_metric(\n            metric=LLMMetric.INPUT_TOKENS,\n            value=prompt_tokens,\n            metric_type=MetricType.HISTOGRAM,\n            model=self.model_name,\n        )\n\n        total_throughput = sum(r[\"throughput\"] for r in results if \"throughput\" in r)\n        outputs.throughput_batch = total_throughput\n        record_metric(\n            metric=LLMMetric.PROMPT_THROUGHPUT,\n            value=total_throughput,\n            metric_type=MetricType.HISTOGRAM,\n            model=self.model_name,\n        )\n\n        total_tokens = sum(r.usage.total_tokens for r in parsed_responses if r.usage)\n        outputs.total_tokens_batch = total_tokens\n        record_metric(\n            metric=LLMMetric.TOKEN_THROUGHPUT,\n            value=total_tokens / total_throughput,\n            metric_type=MetricType.HISTOGRAM,\n            model=self.model_name,\n        )\n\n    if single_prompt:\n        return parsed_responses[0]\n\n    return parsed_responses\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.generate_streaming","title":"generate_streaming","text":"<pre><code>generate_streaming(prompt: str | ChatFormat | BasePrompt, *, tools: list[Tool] | None = None, tool_choice: ToolChoiceWithCallable | None = None, options: LLMClientOptionsT | None = None) -&gt; LLMResultStreaming\n</code></pre> <p>This method returns an <code>LLMResultStreaming</code> object that can be asynchronously iterated over. After the loop completes, metadata is available as <code>metadata</code> attribute.</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Formatted prompt template with conversation.</p> <p> TYPE: <code>str | ChatFormat | BasePrompt</code> </p> <code>tools</code> <p>Functions to be used as tools by the LLM.</p> <p> TYPE: <code>list[Tool] | None</code> DEFAULT: <code>None</code> </p> <code>tool_choice</code> <p>Parameter that allows to control what tool is used. Can be one of: - \"auto\": let model decide if tool call is needed - \"none\": do not call tool - \"required: enforce tool usage (model decides which one) - dict: tool dict corresponding to one of provided tools - Callable: one of provided tools</p> <p> TYPE: <code>ToolChoiceWithCallable | None</code> DEFAULT: <code>None</code> </p> <code>options</code> <p>Options to use for the LLM.</p> <p> TYPE: <code>LLMClientOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>LLMResultStreaming</code> <p>Response stream from LLM or list of tool calls.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>def generate_streaming(\n    self,\n    prompt: str | ChatFormat | BasePrompt,\n    *,\n    tools: list[Tool] | None = None,\n    tool_choice: ToolChoiceWithCallable | None = None,\n    options: LLMClientOptionsT | None = None,\n) -&gt; LLMResultStreaming:\n    \"\"\"\n    This method returns an `LLMResultStreaming` object that can be asynchronously\n    iterated over. After the loop completes, metadata is available as `metadata` attribute.\n\n    Args:\n        prompt: Formatted prompt template with conversation.\n        tools: Functions to be used as tools by the LLM.\n        tool_choice: Parameter that allows to control what tool is used. Can be one of:\n            - \"auto\": let model decide if tool call is needed\n            - \"none\": do not call tool\n            - \"required: enforce tool usage (model decides which one)\n            - dict: tool dict corresponding to one of provided tools\n            - Callable: one of provided tools\n        options: Options to use for the LLM.\n\n    Returns:\n        Response stream from LLM or list of tool calls.\n    \"\"\"\n    return LLMResultStreaming(self._stream_internal(prompt, tools=tools, tool_choice=tool_choice, options=options))\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.get_model_id","title":"get_model_id","text":"<pre><code>get_model_id() -&gt; str\n</code></pre> <p>Returns the model id.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/local.py</code> <pre><code>def get_model_id(self) -&gt; str:\n    \"\"\"\n    Returns the model id.\n    \"\"\"\n    return \"local:\" + self.model_name\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.get_estimated_cost","title":"get_estimated_cost","text":"<pre><code>get_estimated_cost(prompt_tokens: int, completion_tokens: int) -&gt; float\n</code></pre> <p>Returns the estimated cost of the LLM call.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/local.py</code> <pre><code>def get_estimated_cost(self, prompt_tokens: int, completion_tokens: int) -&gt; float:\n    \"\"\"\n    Returns the estimated cost of the LLM call.\n    \"\"\"\n    return self._price_per_prompt_token * prompt_tokens + self._price_per_completion_token * completion_tokens\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.local.LocalLLM.count_tokens","title":"count_tokens","text":"<pre><code>count_tokens(prompt: BasePrompt) -&gt; int\n</code></pre> <p>Counts tokens in the messages.</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Messages to count tokens for.</p> <p> TYPE: <code>BasePrompt</code> </p> RETURNS DESCRIPTION <code>int</code> <p>Number of tokens in the messages.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/local.py</code> <pre><code>def count_tokens(self, prompt: BasePrompt) -&gt; int:\n    \"\"\"\n    Counts tokens in the messages.\n\n    Args:\n        prompt: Messages to count tokens for.\n\n    Returns:\n        Number of tokens in the messages.\n    \"\"\"\n    input_ids = self.tokenizer.apply_chat_template(prompt.chat)\n    return len(input_ids)\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM","title":"ragbits.core.llms.litellm.LiteLLM","text":"<pre><code>LiteLLM(model_name: str = 'gpt-3.5-turbo', default_options: LiteLLMOptions | None = None, *, api_base: str | None = None, base_url: str | None = None, api_key: str | None = None, api_version: str | None = None, use_structured_output: bool = False, router: Router | None = None, custom_model_cost_config: dict | None = None)\n</code></pre> <p>               Bases: <code>LLM[LiteLLMOptions]</code>, <code>LazyLiteLLM</code></p> <p>Class for interaction with any LLM supported by LiteLLM API.</p> <p>Constructs a new LiteLLM instance.</p> PARAMETER DESCRIPTION <code>model_name</code> <p>Name of the LiteLLM supported model to be used.                Default is \"gpt-3.5-turbo\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gpt-3.5-turbo'</code> </p> <code>default_options</code> <p>Default options to be used.</p> <p> TYPE: <code>LiteLLMOptions | None</code> DEFAULT: <code>None</code> </p> <code>api_base</code> <p>Base URL of the LLM API.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>base_url</code> <p>Alias for api_base. If both are provided, api_base takes precedence.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>api_key</code> <p>API key to be used. API key to be used. If not specified, an environment variable will be used, for more information, follow the instructions for your specific vendor in the                LiteLLM documentation.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>api_version</code> <p>API version to be used. If not specified, the default version will be used.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>use_structured_output</code> <p>Whether to request a structured output from the model. Default is False. Can only be combined with models that support structured output.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>router</code> <p>Router to be used to route requests to different models.</p> <p> TYPE: <code>Router | None</code> DEFAULT: <code>None</code> </p> <code>custom_model_cost_config</code> <p>Custom cost and capabilities configuration for the model. Necessary for custom model cost and capabilities tracking in LiteLLM. See the LiteLLM documentation for more information.</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/litellm.py</code> <pre><code>def __init__(\n    self,\n    model_name: str = \"gpt-3.5-turbo\",\n    default_options: LiteLLMOptions | None = None,\n    *,\n    api_base: str | None = None,\n    base_url: str | None = None,  # Alias for api_base\n    api_key: str | None = None,\n    api_version: str | None = None,\n    use_structured_output: bool = False,\n    router: \"Router | None\" = None,\n    custom_model_cost_config: dict | None = None,\n) -&gt; None:\n    \"\"\"\n    Constructs a new LiteLLM instance.\n\n    Args:\n        model_name: Name of the [LiteLLM supported model](https://docs.litellm.ai/docs/providers) to be used.\\\n            Default is \"gpt-3.5-turbo\".\n        default_options: Default options to be used.\n        api_base: Base URL of the LLM API.\n        base_url: Alias for api_base. If both are provided, api_base takes precedence.\n        api_key: API key to be used. API key to be used. If not specified, an environment variable will be used,\n            for more information, follow the instructions for your specific vendor in the\\\n            [LiteLLM documentation](https://docs.litellm.ai/docs/providers).\n        api_version: API version to be used. If not specified, the default version will be used.\n        use_structured_output: Whether to request a\n            [structured output](https://docs.litellm.ai/docs/completion/json_mode#pass-in-json_schema)\n            from the model. Default is False. Can only be combined with models that support structured output.\n        router: Router to be used to [route requests](https://docs.litellm.ai/docs/routing) to different models.\n        custom_model_cost_config: Custom cost and capabilities configuration for the model.\n            Necessary for custom model cost and capabilities tracking in LiteLLM.\n            See the [LiteLLM documentation](https://docs.litellm.ai/docs/completion/token_usage#9-register_model)\n            for more information.\n    \"\"\"\n    super().__init__(model_name, default_options)\n    self.api_base = api_base or base_url\n    self.api_key = api_key\n    self.api_version = api_version\n    self.use_structured_output = use_structured_output\n    self.router = router\n    self.custom_model_cost_config = custom_model_cost_config\n    if custom_model_cost_config:\n        self._litellm.register_model(custom_model_cost_config)\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = llms\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'llm'\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.model_name","title":"model_name  <code>instance-attribute</code>","text":"<pre><code>model_name = model_name\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls = LiteLLMOptions\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.api_base","title":"api_base  <code>instance-attribute</code>","text":"<pre><code>api_base = api_base or base_url\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.api_key","title":"api_key  <code>instance-attribute</code>","text":"<pre><code>api_key = api_key\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.api_version","title":"api_version  <code>instance-attribute</code>","text":"<pre><code>api_version = api_version\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.use_structured_output","title":"use_structured_output  <code>instance-attribute</code>","text":"<pre><code>use_structured_output = use_structured_output\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.router","title":"router  <code>instance-attribute</code>","text":"<pre><code>router = router\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.custom_model_cost_config","title":"custom_model_cost_config  <code>instance-attribute</code>","text":"<pre><code>custom_model_cost_config = custom_model_cost_config\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.base_url","title":"base_url  <code>property</code>","text":"<pre><code>base_url: str | None\n</code></pre> <p>Returns the base URL of the LLM API. Alias for <code>api_base</code>.</p>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.generate_raw","title":"generate_raw  <code>async</code>","text":"<pre><code>generate_raw(prompt: BasePrompt | str | ChatFormat, *, options: LLMClientOptionsT | None = None) -&gt; dict\n</code></pre> <p>Prepares and sends a prompt to the LLM and returns the raw response (without parsing).</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Can be one of: - BasePrompt instance: Formatted prompt template with conversation - str: Simple text prompt that will be sent as a user message - ChatFormat: List of message dictionaries in OpenAI chat format</p> <p> TYPE: <code>BasePrompt | str | ChatFormat</code> </p> <code>options</code> <p>Options to use for the LLM client.</p> <p> TYPE: <code>LLMClientOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>Raw response from LLM.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>@deprecated(\"Use generate_with_metadata() instead\")\nasync def generate_raw(\n    self,\n    prompt: BasePrompt | str | ChatFormat,\n    *,\n    options: LLMClientOptionsT | None = None,\n) -&gt; dict:\n    \"\"\"\n    Prepares and sends a prompt to the LLM and returns the raw response (without parsing).\n\n    Args:\n        prompt: Can be one of:\n            - BasePrompt instance: Formatted prompt template with conversation\n            - str: Simple text prompt that will be sent as a user message\n            - ChatFormat: List of message dictionaries in OpenAI chat format\n        options: Options to use for the LLM client.\n\n    Returns:\n        Raw response from LLM.\n    \"\"\"\n    merged_options = (self.default_options | options) if options else self.default_options\n\n    if isinstance(prompt, str | list):\n        prompt = SimplePrompt(prompt)\n\n    response = (\n        await self._call(\n            prompt=[prompt],\n            options=merged_options,\n        )\n    )[0]\n\n    returned = {\n        \"response\": response[\"response\"],\n        \"throughput\": response[\"throughput\"],\n    }\n    for opt in [\"tool_calls\", \"usage\"]:\n        if opt in response:\n            returned[opt] = response[opt]\n\n    return returned\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.generate","title":"generate  <code>async</code>","text":"<pre><code>generate(prompt: str | ChatFormat | BasePrompt | BasePromptWithParser[PromptOutputT] | MutableSequence[ChatFormat | str] | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]], *, tools: list[Tool] | None = None, tool_choice: ToolChoiceWithCallable | None = None, options: LLMClientOptionsT | None = None) -&gt; str | PromptOutputT | list[ToolCall] | list[list[ToolCall] | str] | list[str | PromptOutputT | list[ToolCall]]\n</code></pre> <p>Prepares and sends a prompt to the LLM and returns the parsed response.</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Can be one of: - BasePrompt instance: Formatted prompt template with conversation - str: Simple text prompt that will be sent as a user message - ChatFormat: List of message dictionaries in OpenAI chat format - Iterable of any of the above (MutableSequence is only for typing purposes)</p> <p> TYPE: <code>str | ChatFormat | BasePrompt | BasePromptWithParser[PromptOutputT] | MutableSequence[ChatFormat | str] | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]]</code> </p> <code>tools</code> <p>Functions to be used as tools by the LLM.</p> <p> TYPE: <code>list[Tool] | None</code> DEFAULT: <code>None</code> </p> <code>tool_choice</code> <p>Parameter that allows to control what tool is used. Can be one of: - \"auto\": let model decide if tool call is needed - \"none\": do not call tool - \"required: enforce tool usage (model decides which one) - dict: tool dict corresponding to one of provided tools - Callable: one of provided tools</p> <p> TYPE: <code>ToolChoiceWithCallable | None</code> DEFAULT: <code>None</code> </p> <code>options</code> <p>Options to use for the LLM client.</p> <p> TYPE: <code>LLMClientOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str | PromptOutputT | list[ToolCall] | list[list[ToolCall] | str] | list[str | PromptOutputT | list[ToolCall]]</code> <p>Parsed response(s) from LLM or list of tool calls.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>async def generate(\n    self,\n    prompt: str\n    | ChatFormat\n    | BasePrompt\n    | BasePromptWithParser[PromptOutputT]\n    | MutableSequence[ChatFormat | str]\n    | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]],\n    *,\n    tools: list[Tool] | None = None,\n    tool_choice: ToolChoiceWithCallable | None = None,\n    options: LLMClientOptionsT | None = None,\n) -&gt; str | PromptOutputT | list[ToolCall] | list[list[ToolCall] | str] | list[str | PromptOutputT | list[ToolCall]]:\n    \"\"\"\n    Prepares and sends a prompt to the LLM and returns the parsed response.\n\n    Args:\n        prompt: Can be one of:\n            - BasePrompt instance: Formatted prompt template with conversation\n            - str: Simple text prompt that will be sent as a user message\n            - ChatFormat: List of message dictionaries in OpenAI chat format\n            - Iterable of any of the above (MutableSequence is only for typing purposes)\n        tools: Functions to be used as tools by the LLM.\n        tool_choice: Parameter that allows to control what tool is used. Can be one of:\n            - \"auto\": let model decide if tool call is needed\n            - \"none\": do not call tool\n            - \"required: enforce tool usage (model decides which one)\n            - dict: tool dict corresponding to one of provided tools\n            - Callable: one of provided tools\n        options: Options to use for the LLM client.\n\n    Returns:\n        Parsed response(s) from LLM or list of tool calls.\n    \"\"\"\n    response = await self.generate_with_metadata(prompt, tools=tools, tool_choice=tool_choice, options=options)\n    if isinstance(response, list):\n        return [r.tool_calls if tools and r.tool_calls else r.content for r in response]\n    else:\n        return response.tool_calls if tools and response.tool_calls else response.content\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.generate_with_metadata","title":"generate_with_metadata  <code>async</code>","text":"<pre><code>generate_with_metadata(prompt: str | ChatFormat | MutableSequence[str | ChatFormat] | BasePrompt | BasePromptWithParser[PromptOutputT] | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]], *, tools: list[Tool] | None = None, tool_choice: ToolChoiceWithCallable | None = None, options: LLMClientOptionsT | None = None) -&gt; LLMResponseWithMetadata[str] | list[LLMResponseWithMetadata[str]] | LLMResponseWithMetadata[PromptOutputT] | list[LLMResponseWithMetadata[PromptOutputT]]\n</code></pre> <p>Prepares and sends a prompt to the LLM and returns response parsed to the output type of the prompt (if available).</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Can be one of: - BasePrompt instance: Formatted prompt template with conversation - str: Simple text prompt that will be sent as a user message - ChatFormat: List of message dictionaries in OpenAI chat format - Iterable of any of the above (MutableSequence is only for typing purposes)</p> <p> TYPE: <code>str | ChatFormat | MutableSequence[str | ChatFormat] | BasePrompt | BasePromptWithParser[PromptOutputT] | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]]</code> </p> <code>tools</code> <p>Functions to be used as tools by the LLM.</p> <p> TYPE: <code>list[Tool] | None</code> DEFAULT: <code>None</code> </p> <code>tool_choice</code> <p>Parameter that allows to control what tool is used. Can be one of: - \"auto\": let model decide if tool call is needed - \"none\": do not call tool - \"required: enforce tool usage (model decides which one) - dict: tool dict corresponding to one of provided tools - Callable: one of provided tools</p> <p> TYPE: <code>ToolChoiceWithCallable | None</code> DEFAULT: <code>None</code> </p> <code>options</code> <p>Options to use for the LLM client.</p> <p> TYPE: <code>LLMClientOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>LLMResponseWithMetadata[str] | list[LLMResponseWithMetadata[str]] | LLMResponseWithMetadata[PromptOutputT] | list[LLMResponseWithMetadata[PromptOutputT]]</code> <p>ResponseWithMetadata object(s) with text response, list of tool calls and metadata information.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>async def generate_with_metadata(\n    self,\n    prompt: str\n    | ChatFormat\n    | MutableSequence[str | ChatFormat]\n    | BasePrompt\n    | BasePromptWithParser[PromptOutputT]\n    | MutableSequence[BasePrompt | BasePromptWithParser[PromptOutputT]],\n    *,\n    tools: list[Tool] | None = None,\n    tool_choice: ToolChoiceWithCallable | None = None,\n    options: LLMClientOptionsT | None = None,\n) -&gt; (\n    LLMResponseWithMetadata[str]\n    | list[LLMResponseWithMetadata[str]]\n    | LLMResponseWithMetadata[PromptOutputT]\n    | list[LLMResponseWithMetadata[PromptOutputT]]\n):\n    \"\"\"\n    Prepares and sends a prompt to the LLM and returns response parsed to the\n    output type of the prompt (if available).\n\n    Args:\n        prompt: Can be one of:\n            - BasePrompt instance: Formatted prompt template with conversation\n            - str: Simple text prompt that will be sent as a user message\n            - ChatFormat: List of message dictionaries in OpenAI chat format\n            - Iterable of any of the above (MutableSequence is only for typing purposes)\n        tools: Functions to be used as tools by the LLM.\n        tool_choice: Parameter that allows to control what tool is used. Can be one of:\n            - \"auto\": let model decide if tool call is needed\n            - \"none\": do not call tool\n            - \"required: enforce tool usage (model decides which one)\n            - dict: tool dict corresponding to one of provided tools\n            - Callable: one of provided tools\n        options: Options to use for the LLM client.\n\n    Returns:\n        ResponseWithMetadata object(s) with text response, list of tool calls and metadata information.\n    \"\"\"\n    single_prompt = False\n    if isinstance(prompt, BasePrompt | str) or isinstance(prompt[0], dict):\n        single_prompt = True\n        prompt = [prompt]  # type: ignore\n\n    parsed_tools = (\n        [convert_function_to_function_schema(tool) if callable(tool) else tool for tool in tools] if tools else None\n    )\n    parsed_tool_choice = convert_function_to_function_schema(tool_choice) if callable(tool_choice) else tool_choice\n\n    prompts: list[BasePrompt] = [SimplePrompt(p) if isinstance(p, str | list) else p for p in prompt]  # type: ignore\n\n    merged_options = (self.default_options | options) if options else self.default_options\n\n    with trace(name=\"generate\", model_name=self.model_name, prompt=prompts, options=repr(options)) as outputs:\n        results = await self._call(\n            prompt=prompts,\n            options=merged_options,\n            tools=parsed_tools,\n            tool_choice=parsed_tool_choice,\n        )\n\n        parsed_responses = []\n        for prompt, response in zip(prompts, results, strict=True):\n            tool_calls = (\n                [ToolCall.model_validate(tool_call) for tool_call in _tool_calls]\n                if (_tool_calls := response.pop(\"tool_calls\", None)) and tools\n                else None\n            )\n\n            usage = None\n            if usage_data := response.pop(\"usage\", None):\n                usage = Usage.new(\n                    llm=self,\n                    prompt_tokens=cast(int, usage_data.get(\"prompt_tokens\")),\n                    completion_tokens=cast(int, usage_data.get(\"completion_tokens\")),\n                    total_tokens=cast(int, usage_data.get(\"total_tokens\")),\n                )\n\n            content = response.pop(\"response\")\n            reasoning = response.pop(\"reasoning\", None)\n\n            if isinstance(prompt, BasePromptWithParser) and content:\n                content = await prompt.parse_response(content)\n\n            response_with_metadata = LLMResponseWithMetadata[type(content)](  # type: ignore\n                content=content,\n                reasoning=reasoning,\n                tool_calls=tool_calls,\n                metadata=response,\n                usage=usage,\n            )\n            parsed_responses.append(response_with_metadata)\n        outputs.response = parsed_responses\n\n        prompt_tokens = sum(r.usage.prompt_tokens for r in parsed_responses if r.usage)\n        outputs.prompt_tokens_batch = prompt_tokens\n        record_metric(\n            metric=LLMMetric.INPUT_TOKENS,\n            value=prompt_tokens,\n            metric_type=MetricType.HISTOGRAM,\n            model=self.model_name,\n        )\n\n        total_throughput = sum(r[\"throughput\"] for r in results if \"throughput\" in r)\n        outputs.throughput_batch = total_throughput\n        record_metric(\n            metric=LLMMetric.PROMPT_THROUGHPUT,\n            value=total_throughput,\n            metric_type=MetricType.HISTOGRAM,\n            model=self.model_name,\n        )\n\n        total_tokens = sum(r.usage.total_tokens for r in parsed_responses if r.usage)\n        outputs.total_tokens_batch = total_tokens\n        record_metric(\n            metric=LLMMetric.TOKEN_THROUGHPUT,\n            value=total_tokens / total_throughput,\n            metric_type=MetricType.HISTOGRAM,\n            model=self.model_name,\n        )\n\n    if single_prompt:\n        return parsed_responses[0]\n\n    return parsed_responses\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.generate_streaming","title":"generate_streaming","text":"<pre><code>generate_streaming(prompt: str | ChatFormat | BasePrompt, *, tools: list[Tool] | None = None, tool_choice: ToolChoiceWithCallable | None = None, options: LLMClientOptionsT | None = None) -&gt; LLMResultStreaming\n</code></pre> <p>This method returns an <code>LLMResultStreaming</code> object that can be asynchronously iterated over. After the loop completes, metadata is available as <code>metadata</code> attribute.</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Formatted prompt template with conversation.</p> <p> TYPE: <code>str | ChatFormat | BasePrompt</code> </p> <code>tools</code> <p>Functions to be used as tools by the LLM.</p> <p> TYPE: <code>list[Tool] | None</code> DEFAULT: <code>None</code> </p> <code>tool_choice</code> <p>Parameter that allows to control what tool is used. Can be one of: - \"auto\": let model decide if tool call is needed - \"none\": do not call tool - \"required: enforce tool usage (model decides which one) - dict: tool dict corresponding to one of provided tools - Callable: one of provided tools</p> <p> TYPE: <code>ToolChoiceWithCallable | None</code> DEFAULT: <code>None</code> </p> <code>options</code> <p>Options to use for the LLM.</p> <p> TYPE: <code>LLMClientOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>LLMResultStreaming</code> <p>Response stream from LLM or list of tool calls.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/base.py</code> <pre><code>def generate_streaming(\n    self,\n    prompt: str | ChatFormat | BasePrompt,\n    *,\n    tools: list[Tool] | None = None,\n    tool_choice: ToolChoiceWithCallable | None = None,\n    options: LLMClientOptionsT | None = None,\n) -&gt; LLMResultStreaming:\n    \"\"\"\n    This method returns an `LLMResultStreaming` object that can be asynchronously\n    iterated over. After the loop completes, metadata is available as `metadata` attribute.\n\n    Args:\n        prompt: Formatted prompt template with conversation.\n        tools: Functions to be used as tools by the LLM.\n        tool_choice: Parameter that allows to control what tool is used. Can be one of:\n            - \"auto\": let model decide if tool call is needed\n            - \"none\": do not call tool\n            - \"required: enforce tool usage (model decides which one)\n            - dict: tool dict corresponding to one of provided tools\n            - Callable: one of provided tools\n        options: Options to use for the LLM.\n\n    Returns:\n        Response stream from LLM or list of tool calls.\n    \"\"\"\n    return LLMResultStreaming(self._stream_internal(prompt, tools=tools, tool_choice=tool_choice, options=options))\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.get_model_id","title":"get_model_id","text":"<pre><code>get_model_id() -&gt; str\n</code></pre> <p>Returns the model id.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/litellm.py</code> <pre><code>def get_model_id(self) -&gt; str:\n    \"\"\"\n    Returns the model id.\n    \"\"\"\n    return \"litellm:\" + self.model_name\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.get_estimated_cost","title":"get_estimated_cost","text":"<pre><code>get_estimated_cost(prompt_tokens: int, completion_tokens: int) -&gt; float\n</code></pre> <p>Returns the estimated cost of the LLM call.</p> PARAMETER DESCRIPTION <code>prompt_tokens</code> <p>The number of tokens in the prompt.</p> <p> TYPE: <code>int</code> </p> <code>completion_tokens</code> <p>The number of tokens in the completion.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>float</code> <p>The estimated cost of the LLM call.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/litellm.py</code> <pre><code>def get_estimated_cost(self, prompt_tokens: int, completion_tokens: int) -&gt; float:\n    \"\"\"\n    Returns the estimated cost of the LLM call.\n\n    Args:\n        prompt_tokens: The number of tokens in the prompt.\n        completion_tokens: The number of tokens in the completion.\n\n    Returns:\n        The estimated cost of the LLM call.\n    \"\"\"\n    response_cost = self._litellm.get_model_info(self.model_name)\n    response_cost_input = prompt_tokens * response_cost[\"input_cost_per_token\"]\n    response_cost_output = completion_tokens * response_cost[\"output_cost_per_token\"]\n    return response_cost_input + response_cost_output\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.count_tokens","title":"count_tokens","text":"<pre><code>count_tokens(prompt: BasePrompt) -&gt; int\n</code></pre> <p>Counts tokens in the prompt.</p> PARAMETER DESCRIPTION <code>prompt</code> <p>Formatted prompt template with conversation and response parsing configuration.</p> <p> TYPE: <code>BasePrompt</code> </p> RETURNS DESCRIPTION <code>int</code> <p>Number of tokens in the prompt.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/litellm.py</code> <pre><code>def count_tokens(self, prompt: BasePrompt) -&gt; int:\n    \"\"\"\n    Counts tokens in the prompt.\n\n    Args:\n        prompt: Formatted prompt template with conversation and response parsing configuration.\n\n    Returns:\n        Number of tokens in the prompt.\n    \"\"\"\n    return sum(\n        self._litellm.token_counter(model=self.model_name, text=message.get(\"content\") or \"\")\n        for message in prompt.chat\n    )\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.get_token_id","title":"get_token_id","text":"<pre><code>get_token_id(token: str) -&gt; int\n</code></pre> <p>Gets token id.</p> PARAMETER DESCRIPTION <code>token</code> <p>The token to encode.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>int</code> <p>The id for the given token.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/litellm.py</code> <pre><code>def get_token_id(self, token: str) -&gt; int:\n    \"\"\"\n    Gets token id.\n\n    Args:\n        token: The token to encode.\n\n    Returns:\n        The id for the given token.\n    \"\"\"\n    try:\n        tokenizer = tiktoken.encoding_for_model(self.model_name)\n        return tokenizer.encode_single_token(token)\n    except KeyError:\n        return self._litellm.encode(model=self.model_name, text=token)[0]\n</code></pre>"},{"location":"api_reference/core/llms/#ragbits.core.llms.litellm.LiteLLM.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Creates and returns a LiteLLM instance.</p> PARAMETER DESCRIPTION <code>config</code> <p>A configuration object containing the configuration for initializing the LiteLLM instance.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>LiteLLM</code> <p>An initialized LiteLLM instance.</p> <p> TYPE: <code>Self</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/llms/litellm.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Creates and returns a LiteLLM instance.\n\n    Args:\n        config: A configuration object containing the configuration for initializing the LiteLLM instance.\n\n    Returns:\n        LiteLLM: An initialized LiteLLM instance.\n    \"\"\"\n    if \"router\" in config:\n        router = cls._get_litellm_module().Router(model_list=config[\"router\"])\n        config[\"router\"] = router\n\n    # Map base_url to api_base if present\n    if \"base_url\" in config and \"api_base\" not in config:\n        config[\"api_base\"] = config.pop(\"base_url\")\n\n    return super().from_config(config)\n</code></pre>"},{"location":"api_reference/core/prompt/","title":"Prompt","text":""},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt","title":"ragbits.core.prompt.Prompt","text":"<pre><code>Prompt(input_data: PromptInputT | None = None, history: ChatFormat | None = None)\n</code></pre> <p>               Bases: <code>Generic[PromptInputT, PromptOutputT]</code>, <code>BasePromptWithParser[PromptOutputT]</code></p> <p>Generic class for prompts. It contains the system and user prompts, and additional messages.</p> <p>To create a new prompt, subclass this class and provide the system and user prompts, and optionally the input and output types. The system prompt is optional.</p> <p>Initialize the Prompt instance.</p> PARAMETER DESCRIPTION <code>input_data</code> <p>The input data to render the prompt templates with. Must be a Pydantic model instance if the prompt has an input type defined. If None and input_type is defined, a ValueError will be raised.</p> <p> TYPE: <code>PromptInputT | None</code> DEFAULT: <code>None</code> </p> <code>history</code> <p>Optional conversation history to initialize the prompt with. If provided, should be in the standard OpenAI chat format.</p> <p> TYPE: <code>ChatFormat | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If input_data is None when input_type is defined, or if input_data is a string instead of a Pydantic model.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>def __init__(self, input_data: PromptInputT | None = None, history: ChatFormat | None = None) -&gt; None:\n    \"\"\"\n    Initialize the Prompt instance.\n\n    Args:\n        input_data: The input data to render the prompt templates with. Must be a Pydantic model\n            instance if the prompt has an input type defined. If None and input_type is defined,\n            a ValueError will be raised.\n        history: Optional conversation history to initialize the prompt with. If provided,\n            should be in the standard OpenAI chat format.\n\n    Raises:\n        ValueError: If input_data is None when input_type is defined, or if input_data\n            is a string instead of a Pydantic model.\n    \"\"\"\n    if self.input_type and input_data is None:\n        raise ValueError(\"Input data must be provided\")\n\n    if isinstance(input_data, str):\n        raise ValueError(\"Input data must be of pydantic model type\")\n\n    if self.image_input_fields:\n        warnings.warn(\n            message=\"The 'image_input_fields' attribute is deprecated. \"\n            \"Use 'Attachment' objects in the prompt input instead.\",\n            category=UserWarning,\n            stacklevel=2,\n        )\n\n    self.rendered_system_prompt = (\n        self._render_template(self.system_prompt_template, input_data) if self.system_prompt_template else None\n    )\n    self.attachments = self._get_attachments_from_input_data(input_data)\n\n    # Additional few shot examples that can be added dynamically using methods\n    # (in opposite to the static `few_shots` attribute which is defined in the class)\n    self._instance_few_shots: list[FewShotExample[PromptInputT, PromptOutputT]] = []\n\n    # Additional conversation history that can be added dynamically using methods\n    self._conversation_history: list[dict[str, Any]] = history or []\n\n    self.add_user_message(input_data or self._render_template(self.user_prompt_template, input_data))\n    self.rendered_user_prompt = self.chat[-1][\"content\"]\n    super().__init__()\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.system_prompt","title":"system_prompt  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>system_prompt: str | None = None\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.user_prompt","title":"user_prompt  <code>instance-attribute</code>","text":"<pre><code>user_prompt: str\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.few_shots","title":"few_shots  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>few_shots: list[FewShotExample[PromptInputT, PromptOutputT]] = []\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.response_parser","title":"response_parser  <code>instance-attribute</code>","text":"<pre><code>response_parser: Callable[[str], PromptOutputT | Awaitable[PromptOutputT]]\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.input_type","title":"input_type  <code>instance-attribute</code>","text":"<pre><code>input_type: type[PromptInputT] | None\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.output_type","title":"output_type  <code>instance-attribute</code>","text":"<pre><code>output_type: type[PromptOutputT]\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.system_prompt_template","title":"system_prompt_template  <code>instance-attribute</code>","text":"<pre><code>system_prompt_template: Template | None\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.user_prompt_template","title":"user_prompt_template  <code>instance-attribute</code>","text":"<pre><code>user_prompt_template: Template\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.image_input_fields","title":"image_input_fields  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>image_input_fields: list[str] | None = None\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.rendered_system_prompt","title":"rendered_system_prompt  <code>instance-attribute</code>","text":"<pre><code>rendered_system_prompt = _render_template(system_prompt_template, input_data) if system_prompt_template else None\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.attachments","title":"attachments  <code>instance-attribute</code>","text":"<pre><code>attachments = _get_attachments_from_input_data(input_data)\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.rendered_user_prompt","title":"rendered_user_prompt  <code>instance-attribute</code>","text":"<pre><code>rendered_user_prompt = chat[-1]['content']\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.chat","title":"chat  <code>property</code>","text":"<pre><code>chat: ChatFormat\n</code></pre> <p>Returns the conversation in the standard OpenAI chat format.</p> RETURNS DESCRIPTION <code>ChatFormat</code> <p>A list of dictionaries, each containing the role and content of a message.</p> <p> TYPE: <code>ChatFormat</code> </p>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.json_mode","title":"json_mode  <code>property</code>","text":"<pre><code>json_mode: bool\n</code></pre> <p>Returns whether the prompt should be sent in JSON mode.</p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the prompt should be sent in JSON mode.</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.add_assistant_message","title":"add_assistant_message","text":"<pre><code>add_assistant_message(message: str | PromptOutputT) -&gt; Self\n</code></pre> <p>Add an assistant message to the conversation history.</p> PARAMETER DESCRIPTION <code>message</code> <p>The assistant message content.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>Prompt[PromptInputT, PromptOutputT]: The current prompt instance to allow chaining.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/base.py</code> <pre><code>def add_assistant_message(self, message: str | PromptOutputT) -&gt; Self:\n    \"\"\"\n    Add an assistant message to the conversation history.\n\n    Args:\n        message (str): The assistant message content.\n\n    Returns:\n        Prompt[PromptInputT, PromptOutputT]: The current prompt instance to allow chaining.\n    \"\"\"\n    if not hasattr(self, \"_conversation_history\"):\n        self._conversation_history = []\n\n    if isinstance(message, BaseModel):\n        message = message.model_dump_json()\n    self._conversation_history.append({\"role\": \"assistant\", \"content\": str(message)})\n    return self\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.add_tool_use_message","title":"add_tool_use_message","text":"<pre><code>add_tool_use_message(id: str, name: str, arguments: dict, result: Any) -&gt; Self\n</code></pre> <p>Add tool call messages to the conversation history.</p> PARAMETER DESCRIPTION <code>id</code> <p>The id of the tool call.</p> <p> TYPE: <code>str</code> </p> <code>name</code> <p>The name of the tool.</p> <p> TYPE: <code>str</code> </p> <code>arguments</code> <p>The arguments of the tool.</p> <p> TYPE: <code>dict</code> </p> <code>result</code> <p>The tool call result.</p> <p> TYPE: <code>any</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>Prompt[PromptInputT, PromptOutputT]: The current prompt instance to allow chaining.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/base.py</code> <pre><code>def add_tool_use_message(\n    self,\n    id: str,\n    name: str,\n    arguments: dict,\n    result: Any,  # noqa: ANN401\n) -&gt; Self:\n    \"\"\"\n    Add tool call messages to the conversation history.\n\n    Args:\n        id (str): The id of the tool call.\n        name (str): The name of the tool.\n        arguments (dict): The arguments of the tool.\n        result (any): The tool call result.\n\n    Returns:\n        Prompt[PromptInputT, PromptOutputT]: The current prompt instance to allow chaining.\n    \"\"\"\n    if not hasattr(self, \"_conversation_history\"):\n        self._conversation_history = []\n\n    self._conversation_history.extend(\n        [\n            {\n                \"role\": \"assistant\",\n                \"content\": None,\n                \"tool_calls\": [\n                    {\n                        \"id\": id,\n                        \"type\": \"function\",\n                        \"function\": {\n                            \"name\": name,\n                            \"arguments\": json.dumps(arguments),\n                        },\n                    }\n                ],\n            },\n            {\n                \"role\": \"tool\",\n                \"tool_call_id\": id,\n                \"content\": str(result),\n            },\n        ]\n    )\n\n    return self\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.add_few_shot","title":"add_few_shot","text":"<pre><code>add_few_shot(user_message: str | PromptInputT, assistant_message: str | PromptOutputT) -&gt; Prompt[PromptInputT, PromptOutputT]\n</code></pre> <p>Add a few-shot example to the conversation.</p> PARAMETER DESCRIPTION <code>user_message</code> <p>The raw user message or input data that will be rendered using the user prompt template.</p> <p> TYPE: <code>str | PromptInputT</code> </p> <code>assistant_message</code> <p>The raw assistant response or output data that will be cast to a string or in case of a Pydantic model, to JSON.</p> <p> TYPE: <code>str | PromptOutputT</code> </p> RETURNS DESCRIPTION <code>Prompt[PromptInputT, PromptOutputT]</code> <p>Prompt[PromptInputT, PromptOutputT]: The current prompt instance in order to allow chaining.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>def add_few_shot(\n    self, user_message: str | PromptInputT, assistant_message: str | PromptOutputT\n) -&gt; \"Prompt[PromptInputT, PromptOutputT]\":\n    \"\"\"\n    Add a few-shot example to the conversation.\n\n    Args:\n        user_message (str | PromptInputT): The raw user message or input data that will be rendered using the\n            user prompt template.\n        assistant_message (str | PromptOutputT): The raw assistant response or output data that will be cast to a\n            string or in case of a Pydantic model, to JSON.\n\n    Returns:\n        Prompt[PromptInputT, PromptOutputT]: The current prompt instance in order to allow chaining.\n    \"\"\"\n    self._instance_few_shots.append((user_message, assistant_message))\n    return self\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.list_few_shots","title":"list_few_shots","text":"<pre><code>list_few_shots() -&gt; ChatFormat\n</code></pre> <p>Returns the few shot examples in the standard OpenAI chat format.</p> RETURNS DESCRIPTION <code>ChatFormat</code> <p>A list of dictionaries, each containing the role and content of a message.</p> <p> TYPE: <code>ChatFormat</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>def list_few_shots(self) -&gt; ChatFormat:\n    \"\"\"\n    Returns the few shot examples in the standard OpenAI chat format.\n\n    Returns:\n        ChatFormat: A list of dictionaries, each containing the role and content of a message.\n    \"\"\"\n    result: ChatFormat = []\n    user_content: str | list[dict[str, Any]]\n    for user_message, assistant_message in self.few_shots + self._instance_few_shots:\n        if not isinstance(user_message, str):\n            rendered_text_message = self._render_template(self.user_prompt_template, user_message)\n            input_attachments = self._get_attachments_from_input_data(user_message)\n\n            user_parts: list[dict[str, Any]] = [{\"type\": \"text\", \"text\": rendered_text_message}]\n            for attachment in input_attachments:\n                user_parts.append(self.create_message_with_attachment(attachment))\n\n            user_content = user_parts if len(user_parts) &gt; 1 else rendered_text_message\n\n        else:\n            user_content = user_message\n\n        if isinstance(assistant_message, BaseModel):\n            assistant_content = assistant_message.model_dump_json()\n        else:\n            assistant_content = str(assistant_message)\n\n        result.append({\"role\": \"user\", \"content\": user_content})\n        result.append({\"role\": \"assistant\", \"content\": assistant_content})\n    return result\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.add_user_message","title":"add_user_message","text":"<pre><code>add_user_message(message: str | dict[str, Any] | PromptInputT) -&gt; Prompt[PromptInputT, PromptOutputT]\n</code></pre> <p>Add a user message to the conversation history.</p> PARAMETER DESCRIPTION <code>message</code> <p>The user message content. Can be: - A string: Used directly as content - A dictionary: With format {\"type\": \"text\", \"text\": \"message\"} or image content - An PromptInputT model: Will be rendered using the user prompt template</p> <p> TYPE: <code>str | dict[str, Any] | PromptInputT</code> </p> RETURNS DESCRIPTION <code>Prompt[PromptInputT, PromptOutputT]</code> <p>Prompt[PromptInputT, PromptOutputT]: The current prompt instance to allow chaining.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>def add_user_message(self, message: str | dict[str, Any] | PromptInputT) -&gt; \"Prompt[PromptInputT, PromptOutputT]\":  # type: ignore\n    \"\"\"\n    Add a user message to the conversation history.\n\n    Args:\n        message (str | dict[str, Any] | PromptInputT): The user message content. Can be:\n            - A string: Used directly as content\n            - A dictionary: With format {\"type\": \"text\", \"text\": \"message\"} or image content\n            - An PromptInputT model: Will be rendered using the user prompt template\n\n    Returns:\n        Prompt[PromptInputT, PromptOutputT]: The current prompt instance to allow chaining.\n    \"\"\"\n    content: str | list[dict[str, Any]] | dict[str, Any]\n\n    if isinstance(message, BaseModel):\n        # Type checking to ensure we're passing PromptInputT to the methods\n        input_model: PromptInputT = cast(PromptInputT, message)\n\n        # Render the message using the template if it's an input model\n        rendered_text = self._render_template(self.user_prompt_template, input_model)\n        input_attachments = self._get_attachments_from_input_data(input_model)\n\n        content_list: list[dict[str, Any]] = [{\"type\": \"text\", \"text\": rendered_text}]\n        for attachment in input_attachments:\n            content_list.append(self.create_message_with_attachment(attachment))\n\n        content = content_list if len(content_list) &gt; 1 else rendered_text\n    else:\n        content = cast(str | dict[str, Any], message)\n\n    return super().add_user_message(content)\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.list_images","title":"list_images","text":"<pre><code>list_images() -&gt; list[str]\n</code></pre> <p>Returns the images in form of URLs or base64 encoded strings.</p> RETURNS DESCRIPTION <code>list[str]</code> <p>list of images</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>def list_images(self) -&gt; list[str]:\n    \"\"\"\n    Returns the images in form of URLs or base64 encoded strings.\n\n    Returns:\n        list of images\n    \"\"\"\n    return [\n        content[\"image_url\"][\"url\"]\n        for message in self.chat\n        if message[\"content\"]\n        for content in message[\"content\"]\n        if isinstance(message[\"content\"], list) and content[\"type\"] == \"image_url\"\n    ]\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.list_pdfs","title":"list_pdfs","text":"<pre><code>list_pdfs() -&gt; list[str]\n</code></pre> <p>Returns the PDFs in form of URLs or base64 encoded strings.</p> RETURNS DESCRIPTION <code>list[str]</code> <p>list of PDFs</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>def list_pdfs(self) -&gt; list[str]:  # noqa: PLR6301\n    \"\"\"\n    Returns the PDFs in form of URLs or base64 encoded strings.\n\n    Returns:\n        list of PDFs\n    \"\"\"\n    return [\n        content[\"file\"].get(\"file_id\") or content[\"file\"][\"file_data\"]\n        for message in self.chat\n        if message[\"content\"]\n        for content in message[\"content\"]\n        if isinstance(message[\"content\"], list) and content[\"type\"] == \"file\"\n    ]\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.create_message_with_attachment","title":"create_message_with_attachment  <code>staticmethod</code>","text":"<pre><code>create_message_with_attachment(attachment: Attachment) -&gt; dict[str, Any]\n</code></pre> <p>Create a message with an attachment in the OpenAI chat format.</p> PARAMETER DESCRIPTION <code>attachment</code> <p>The attachment to include in the message.</p> <p> TYPE: <code>Attachment</code> </p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary representing the message with the attachment.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>@staticmethod\ndef create_message_with_attachment(attachment: Attachment) -&gt; dict[str, Any]:\n    \"\"\"\n    Create a message with an attachment in the OpenAI chat format.\n\n    Args:\n        attachment (Attachment): The attachment to include in the message.\n\n    Returns:\n        dict[str, Any]: A dictionary representing the message with the attachment.\n    \"\"\"\n    if not (attachment.data or attachment.url):\n        raise PromptWithEmptyAttachment()\n\n    def get_mime_type() -&gt; str:\n        if attachment.mime_type:\n            return attachment.mime_type\n        if attachment.data:\n            detected = filetype.guess(attachment.data)\n            if detected:\n                return detected.mime\n        if attachment.url:\n            guessed_type, _ = mimetypes.guess_type(attachment.url)\n            if guessed_type:\n                return guessed_type\n        raise PromptWithAttachmentOfUnknownFormat()\n\n    def encode_data_url(data: bytes, mime: str) -&gt; str:\n        return f\"data:{mime};base64,{base64.b64encode(data).decode('utf-8')}\"\n\n    mime_type = get_mime_type()\n\n    if mime_type.startswith(\"image/\"):\n        return {\n            \"type\": \"image_url\",\n            \"image_url\": {\n                \"url\": attachment.url or encode_data_url(attachment.data, mime_type)  # type: ignore[arg-type]\n            },\n        }\n\n    if mime_type == \"application/pdf\":\n        return {\n            \"type\": \"file\",\n            \"file\": {\"file_id\": attachment.url}\n            if attachment.url\n            else {\"file_data\": encode_data_url(attachment.data, mime_type)},  # type: ignore[arg-type]\n        }\n\n    raise PromptWithAttachmentOfUnsupportedFormat(mime_type)\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.output_schema","title":"output_schema","text":"<pre><code>output_schema() -&gt; dict | type[BaseModel] | None\n</code></pre> <p>Returns the schema of the desired output. Can be used to request structured output from the LLM API or to validate the output. Can return either a Pydantic model or a JSON schema.</p> RETURNS DESCRIPTION <code>dict | type[BaseModel] | None</code> <p>Optional[Dict | Type[BaseModel]]: The schema of the desired output or the model describing it.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>def output_schema(self) -&gt; dict | type[BaseModel] | None:\n    \"\"\"\n    Returns the schema of the desired output. Can be used to request structured output from the LLM API\n    or to validate the output. Can return either a Pydantic model or a JSON schema.\n\n    Returns:\n        Optional[Dict | Type[BaseModel]]: The schema of the desired output or the model describing it.\n    \"\"\"\n    return self.output_type if issubclass(self.output_type, BaseModel) else None\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.parse_response","title":"parse_response  <code>async</code>","text":"<pre><code>parse_response(response: str) -&gt; PromptOutputT\n</code></pre> <p>Parse the response from the LLM to the desired output type.</p> PARAMETER DESCRIPTION <code>response</code> <p>The response from the LLM.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>PromptOutputT</code> <p>The parsed response.</p> <p> TYPE: <code>PromptOutputT</code> </p> RAISES DESCRIPTION <code>ResponseParsingError</code> <p>If the response cannot be parsed.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>async def parse_response(self, response: str) -&gt; PromptOutputT:\n    \"\"\"\n    Parse the response from the LLM to the desired output type.\n\n    Args:\n        response (str): The response from the LLM.\n\n    Returns:\n        PromptOutputT: The parsed response.\n\n    Raises:\n        ResponseParsingError: If the response cannot be parsed.\n    \"\"\"\n    if asyncio.iscoroutinefunction(self.response_parser):\n        result = await self.response_parser(response)\n    else:\n        result = self.response_parser(response)\n    return result\n</code></pre>"},{"location":"api_reference/core/prompt/#ragbits.core.prompt.Prompt.to_promptfoo","title":"to_promptfoo  <code>classmethod</code>","text":"<pre><code>to_promptfoo(config: dict[str, Any]) -&gt; ChatFormat\n</code></pre> <p>Generate a prompt in the promptfoo format from a promptfoo test configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>The promptfoo test configuration.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>ChatFormat</code> <p>The prompt in the format used by promptfoo.</p> <p> TYPE: <code>ChatFormat</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/prompt/prompt.py</code> <pre><code>@classmethod\ndef to_promptfoo(cls, config: dict[str, Any]) -&gt; ChatFormat:\n    \"\"\"\n    Generate a prompt in the promptfoo format from a promptfoo test configuration.\n\n    Args:\n        config: The promptfoo test configuration.\n\n    Returns:\n        ChatFormat: The prompt in the format used by promptfoo.\n    \"\"\"\n    return cls(cls.input_type.model_validate(config[\"vars\"])).chat  # type: ignore\n</code></pre>"},{"location":"api_reference/core/sources/","title":"Sources","text":""},{"location":"api_reference/core/sources/#ragbits.core.sources.base.Source","title":"ragbits.core.sources.base.Source","text":"<p>               Bases: <code>WithConstructionConfig</code>, <code>BaseModel</code>, <code>ABC</code></p> <p>Base class for data sources.</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.base.Source.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = sources\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.base.Source.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'source'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.base.Source.protocol","title":"protocol  <code>class-attribute</code>","text":"<pre><code>protocol: str\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.base.Source.id","title":"id  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Get the source identifier.</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.base.Source.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.base.Source.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.base.Source.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.base.Source.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.base.Source.class_identifier","title":"class_identifier  <code>classmethod</code>","text":"<pre><code>class_identifier() -&gt; str\n</code></pre> <p>Get an identifier for the source type.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@classmethod\ndef class_identifier(cls) -&gt; str:\n    \"\"\"\n    Get an identifier for the source type.\n    \"\"\"\n    return to_snake(cls.__name__)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.base.Source.source_type","title":"source_type","text":"<pre><code>source_type() -&gt; str\n</code></pre> <p>Pydantic field based on the class identifier.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@computed_field\ndef source_type(self) -&gt; str:\n    \"\"\"\n    Pydantic field based on the class identifier.\n    \"\"\"\n    return self.class_identifier()\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.base.Source.fetch","title":"fetch  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>fetch() -&gt; Path\n</code></pre> <p>Load the source.</p> RETURNS DESCRIPTION <code>Path</code> <p>The path to the source.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@abstractmethod\nasync def fetch(self) -&gt; Path:\n    \"\"\"\n    Load the source.\n\n    Returns:\n        The path to the source.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.base.Source.list_sources","title":"list_sources  <code>abstractmethod</code> <code>async</code> <code>classmethod</code>","text":"<pre><code>list_sources(*args: Any, **kwargs: Any) -&gt; Iterable[Self]\n</code></pre> <p>List all sources from the given storage.</p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>The iterable of Source objects.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@classmethod\n@abstractmethod\nasync def list_sources(cls, *args: Any, **kwargs: Any) -&gt; Iterable[Self]:  # noqa: ANN401\n    \"\"\"\n    List all sources from the given storage.\n\n    Returns:\n        The iterable of Source objects.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.base.Source.from_uri","title":"from_uri  <code>abstractmethod</code> <code>async</code> <code>classmethod</code>","text":"<pre><code>from_uri(path: str) -&gt; Iterable[Self]\n</code></pre> <p>Create Source instances from a URI path.</p> <p>The path can contain glob patterns (asterisks) to match multiple sources, but pattern support varies by source type. Each source implementation defines which patterns it supports.</p> PARAMETER DESCRIPTION <code>path</code> <p>The path part of the URI (after protocol://). Pattern support depends on source type.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>The iterable of Source objects matching the path pattern.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@classmethod\n@abstractmethod\nasync def from_uri(cls, path: str) -&gt; Iterable[Self]:\n    \"\"\"\n    Create Source instances from a URI path.\n\n    The path can contain glob patterns (asterisks) to match multiple sources, but pattern support\n    varies by source type. Each source implementation defines which patterns it supports.\n\n    Args:\n        path: The path part of the URI (after protocol://). Pattern support depends on source type.\n\n    Returns:\n        The iterable of Source objects matching the path pattern.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.azure.AzureBlobStorageSource","title":"ragbits.core.sources.azure.AzureBlobStorageSource","text":"<p>               Bases: <code>Source</code></p> <p>Source for data stored in the Azure Blob Storage.</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.azure.AzureBlobStorageSource.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = sources\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.azure.AzureBlobStorageSource.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'source'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.azure.AzureBlobStorageSource.protocol","title":"protocol  <code>class-attribute</code>","text":"<pre><code>protocol: str = 'azure'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.azure.AzureBlobStorageSource.account_name","title":"account_name  <code>instance-attribute</code>","text":"<pre><code>account_name: str\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.azure.AzureBlobStorageSource.container_name","title":"container_name  <code>instance-attribute</code>","text":"<pre><code>container_name: str\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.azure.AzureBlobStorageSource.blob_name","title":"blob_name  <code>instance-attribute</code>","text":"<pre><code>blob_name: str\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.azure.AzureBlobStorageSource.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Get the source identifier.</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.azure.AzureBlobStorageSource.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.azure.AzureBlobStorageSource.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.azure.AzureBlobStorageSource.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.azure.AzureBlobStorageSource.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.azure.AzureBlobStorageSource.class_identifier","title":"class_identifier  <code>classmethod</code>","text":"<pre><code>class_identifier() -&gt; str\n</code></pre> <p>Get an identifier for the source type.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@classmethod\ndef class_identifier(cls) -&gt; str:\n    \"\"\"\n    Get an identifier for the source type.\n    \"\"\"\n    return to_snake(cls.__name__)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.azure.AzureBlobStorageSource.source_type","title":"source_type","text":"<pre><code>source_type() -&gt; str\n</code></pre> <p>Pydantic field based on the class identifier.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@computed_field\ndef source_type(self) -&gt; str:\n    \"\"\"\n    Pydantic field based on the class identifier.\n    \"\"\"\n    return self.class_identifier()\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.azure.AzureBlobStorageSource.fetch","title":"fetch  <code>async</code>","text":"<pre><code>fetch() -&gt; Path\n</code></pre> <p>Downloads the blob to a temporary local file and returns the file path.</p> RETURNS DESCRIPTION <code>Path</code> <p>The local path to the downloaded file.</p> RAISES DESCRIPTION <code>SourceNotFoundError</code> <p>If the blob source is not available.</p> <code>SourceConnectionError</code> <p>If the blob service connection is not available.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/azure.py</code> <pre><code>@requires_dependencies([\"azure.storage.blob\", \"azure.core.exceptions\"], \"azure\")\nasync def fetch(self) -&gt; Path:\n    \"\"\"\n    Downloads the blob to a temporary local file and returns the file path.\n\n    Returns:\n        The local path to the downloaded file.\n\n    Raises:\n        SourceNotFoundError: If the blob source is not available.\n        SourceConnectionError: If the blob service connection is not available.\n    \"\"\"\n    container_local_dir = get_local_storage_dir() / self.account_name / self.container_name\n    container_local_dir.mkdir(parents=True, exist_ok=True)\n    path = container_local_dir / self.blob_name\n    with trace(account_name=self.account_name, container=self.container_name, blob=self.blob_name) as outputs:\n        try:\n            blob_service = self._get_blob_service(self.account_name)\n            blob_client = blob_service.get_blob_client(container=self.container_name, blob=self.blob_name)\n            Path(path).parent.mkdir(parents=True, exist_ok=True)\n            stream = blob_client.download_blob()\n            content = stream.readall()\n            with open(path, \"wb\") as file:\n                file.write(content)\n\n        except ResourceNotFoundError as e:\n            raise SourceNotFoundError(f\"Blob {self.blob_name} not found in container {self.container_name}\") from e\n        except Exception as e:\n            raise SourceConnectionError() from e\n        outputs.path = path\n    return path\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.azure.AzureBlobStorageSource.list_sources","title":"list_sources  <code>async</code> <code>classmethod</code>","text":"<pre><code>list_sources(account_name: str, container: str, blob_name: str = '') -&gt; Iterable[Self]\n</code></pre> <p>List all sources in the given Azure container, matching the prefix.</p> PARAMETER DESCRIPTION <code>account_name</code> <p>The Azure storage account name.</p> <p> TYPE: <code>str</code> </p> <code>container</code> <p>The Azure container name.</p> <p> TYPE: <code>str</code> </p> <code>blob_name</code> <p>The prefix to match.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>The iterable of sources from the Azure Blob Storage container.</p> RAISES DESCRIPTION <code>SourceConnectionError</code> <p>If there's an error connecting to Azure</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/azure.py</code> <pre><code>@classmethod\n@requires_dependencies([\"azure.storage.blob\"], \"azure\")\nasync def list_sources(\n    cls,\n    account_name: str,\n    container: str,\n    blob_name: str = \"\",\n) -&gt; Iterable[Self]:\n    \"\"\"\n    List all sources in the given Azure container, matching the prefix.\n\n    Args:\n        account_name: The Azure storage account name.\n        container: The Azure container name.\n        blob_name: The prefix to match.\n\n    Returns:\n        The iterable of sources from the Azure Blob Storage container.\n\n    Raises:\n        SourceConnectionError: If there's an error connecting to Azure\n    \"\"\"\n    with trace(account_name=account_name, container=container, blob_name=blob_name) as outputs:\n        try:\n            blob_service = cls._get_blob_service(account_name)\n            container_client = blob_service.get_container_client(container)\n            blobs = container_client.list_blobs(name_starts_with=blob_name)\n            outputs.results = [\n                cls(container_name=container, blob_name=blob.name, account_name=account_name) for blob in blobs\n            ]\n            return outputs.results\n        except Exception as e:\n            raise SourceConnectionError() from e\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.azure.AzureBlobStorageSource.from_uri","title":"from_uri  <code>async</code> <code>classmethod</code>","text":"<pre><code>from_uri(path: str) -&gt; Iterable[Self]\n</code></pre> <p>Create AzureBlobStorageSource instances from a URI path.</p> <p>The supported URI formats: - https://.blob.core.windows.net// PARAMETER DESCRIPTION <code>path</code> <p>The URI path in the format described above.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>The iterable of sources from the Azure Blob Storage container.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the Azure Blob Storage URI is invalid.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/azure.py</code> <pre><code>@classmethod\n@traceable\nasync def from_uri(cls, path: str) -&gt; Iterable[Self]:\n    \"\"\"\n    Create AzureBlobStorageSource instances from a URI path.\n\n    The supported URI formats:\n    - https://&lt;account-name&gt;.blob.core.windows.net/&lt;container-name&gt;/&lt;blob-name&gt;\n\n    Args:\n        path: The URI path in the format described above.\n\n    Returns:\n        The iterable of sources from the Azure Blob Storage container.\n\n    Raises:\n        ValueError: If the Azure Blob Storage URI is invalid.\n    \"\"\"\n    if \"**\" in path or \"?\" in path:\n        raise ValueError(\n            \"AzureBlobStorageSource only supports '*' at the end of path. \"\n            \"Patterns like '**' or '?' are not supported.\"\n        )\n    parsed = urlparse(path)\n    if not parsed.netloc or not parsed.path:\n        raise ValueError(\"Invalid Azure Blob Storage URI format.\")\n\n    if parsed.scheme != \"https\":\n        raise ValueError(\"Invalid scheme, expected 'https://account_name.blob.core.windows.net'.\")\n\n    if parsed.netloc.endswith(\"blob.core.windows.net\"):\n        account_name = parsed.netloc.replace(\".blob.core.windows.net\", \"\")\n    else:\n        raise ValueError(\"Invalid scheme, expected 'https://account_name.blob.core.windows.net'.\")\n\n    path_parts = parsed.path.lstrip(\"/\").split(\"/\", 1)\n    if len(path_parts) != 2:  # noqa PLR2004\n        raise ValueError(\"URI must include both container and blob name.\")\n\n    container_name, blob_name = path_parts\n    if \"*\" in blob_name:\n        if not blob_name.endswith(\"*\") or \"*\" in blob_name[:-1]:\n            raise ValueError(\n                f\"AzureBlobStorageSource only supports '*' at the end of path. Invalid pattern: {blob_name}.\"\n            )\n        blob_name = blob_name[:-1]\n        return await cls.list_sources(container=container_name, blob_name=blob_name, account_name=account_name)\n\n    # Return a single-element list (consistent with other sources)\n    return [cls(account_name=account_name, container_name=container_name, blob_name=blob_name)]\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.gcs.GCSSource","title":"ragbits.core.sources.gcs.GCSSource","text":"<p>               Bases: <code>Source</code></p> <p>Source for data stored in the Google Cloud Storage.</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.gcs.GCSSource.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = sources\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.gcs.GCSSource.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'source'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.gcs.GCSSource.protocol","title":"protocol  <code>class-attribute</code>","text":"<pre><code>protocol: str = 'gcs'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.gcs.GCSSource.bucket","title":"bucket  <code>instance-attribute</code>","text":"<pre><code>bucket: str\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.gcs.GCSSource.object_name","title":"object_name  <code>instance-attribute</code>","text":"<pre><code>object_name: str\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.gcs.GCSSource.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Get the source identifier.</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.gcs.GCSSource.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.gcs.GCSSource.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.gcs.GCSSource.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.gcs.GCSSource.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.gcs.GCSSource.class_identifier","title":"class_identifier  <code>classmethod</code>","text":"<pre><code>class_identifier() -&gt; str\n</code></pre> <p>Get an identifier for the source type.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@classmethod\ndef class_identifier(cls) -&gt; str:\n    \"\"\"\n    Get an identifier for the source type.\n    \"\"\"\n    return to_snake(cls.__name__)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.gcs.GCSSource.source_type","title":"source_type","text":"<pre><code>source_type() -&gt; str\n</code></pre> <p>Pydantic field based on the class identifier.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@computed_field\ndef source_type(self) -&gt; str:\n    \"\"\"\n    Pydantic field based on the class identifier.\n    \"\"\"\n    return self.class_identifier()\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.gcs.GCSSource.set_storage","title":"set_storage  <code>classmethod</code>","text":"<pre><code>set_storage(storage: Storage | None) -&gt; None\n</code></pre> <p>Set the storage client for all instances.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/gcs.py</code> <pre><code>@classmethod\ndef set_storage(cls, storage: \"StorageClient | None\") -&gt; None:\n    \"\"\"\n    Set the storage client for all instances.\n    \"\"\"\n    cls._storage = storage\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.gcs.GCSSource.fetch","title":"fetch  <code>async</code>","text":"<pre><code>fetch() -&gt; Path\n</code></pre> <p>Fetch the file from Google Cloud Storage and store it locally.</p> <p>The file is downloaded to a local directory specified by <code>local_dir</code>. If the file already exists locally, it will not be downloaded again. If the file doesn't exist locally, it will be fetched from GCS. The local directory is determined by the environment variable <code>LOCAL_STORAGE_DIR</code>. If this environment variable is not set, a temporary directory is used.</p> RETURNS DESCRIPTION <code>Path</code> <p>The local path to the downloaded file.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/gcs.py</code> <pre><code>@traceable\n@requires_dependencies([\"gcloud.aio.storage\"], \"gcs\")\nasync def fetch(self) -&gt; Path:\n    \"\"\"\n    Fetch the file from Google Cloud Storage and store it locally.\n\n    The file is downloaded to a local directory specified by `local_dir`. If the file already exists locally,\n    it will not be downloaded again. If the file doesn't exist locally, it will be fetched from GCS.\n    The local directory is determined by the environment variable `LOCAL_STORAGE_DIR`. If this environment\n    variable is not set, a temporary directory is used.\n\n    Returns:\n        The local path to the downloaded file.\n    \"\"\"\n    local_dir = get_local_storage_dir()\n    bucket_local_dir = local_dir / self.bucket\n    bucket_local_dir.mkdir(parents=True, exist_ok=True)\n    path = bucket_local_dir / self.object_name\n    with trace(bucket=self.bucket, object=self.object_name) as outputs:\n        if not path.is_file():\n            storage = await self._get_storage()\n            async with storage as client:\n                content = await client.download(self.bucket, self.object_name)\n                Path(bucket_local_dir / self.object_name).parent.mkdir(parents=True, exist_ok=True)\n                with open(path, mode=\"wb+\") as file_object:\n                    file_object.write(content)\n        outputs.path = path\n    return path\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.gcs.GCSSource.list_sources","title":"list_sources  <code>async</code> <code>classmethod</code>","text":"<pre><code>list_sources(bucket: str, prefix: str = '') -&gt; Iterable[Self]\n</code></pre> <p>List all sources in the given GCS bucket, matching the prefix.</p> PARAMETER DESCRIPTION <code>bucket</code> <p>The GCS bucket.</p> <p> TYPE: <code>str</code> </p> <code>prefix</code> <p>The prefix to match.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>The iterable of sources from the GCS bucket.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/gcs.py</code> <pre><code>@classmethod\n@requires_dependencies([\"gcloud.aio.storage\"], \"gcs\")\nasync def list_sources(cls, bucket: str, prefix: str = \"\") -&gt; Iterable[Self]:\n    \"\"\"\n    List all sources in the given GCS bucket, matching the prefix.\n\n    Args:\n        bucket: The GCS bucket.\n        prefix: The prefix to match.\n\n    Returns:\n        The iterable of sources from the GCS bucket.\n    \"\"\"\n    with trace() as outputs:\n        async with await cls._get_storage() as storage:\n            result = await storage.list_objects(bucket, params={\"prefix\": prefix})\n            items = result.get(\"items\", [])\n            outputs.results = [\n                cls(bucket=bucket, object_name=item[\"name\"]) for item in items if not item[\"name\"].endswith(\"/\")\n            ]\n            return outputs.results\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.gcs.GCSSource.from_uri","title":"from_uri  <code>async</code> <code>classmethod</code>","text":"<pre><code>from_uri(path: str) -&gt; Iterable[Self]\n</code></pre> <p>Create GCSSource instances from a URI path.</p> <p>The supported URI formats: - //\" - matches all files in the folder - //\" - matches all files starting with prefix PARAMETER DESCRIPTION <code>path</code> <p>The URI path in the format described above.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>The iterable of sources from the GCS bucket.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If an unsupported pattern is used</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/gcs.py</code> <pre><code>@classmethod\n@traceable\nasync def from_uri(cls, path: str) -&gt; Iterable[Self]:\n    \"\"\"\n    Create GCSSource instances from a URI path.\n\n    The supported URI formats:\n    - &lt;bucket&gt;/&lt;folder&gt;/*\" - matches all files in the folder\n    - &lt;bucket&gt;/&lt;folder&gt;/&lt;prefix&gt;*\" - matches all files starting with prefix\n\n    Args:\n        path: The URI path in the format described above.\n\n    Returns:\n        The iterable of sources from the GCS bucket.\n\n    Raises:\n        ValueError: If an unsupported pattern is used\n    \"\"\"\n    if \"**\" in path or \"?\" in path:\n        raise ValueError(\n            \"GCSSource only supports '*' at the end of path. Patterns like '**' or '?' are not supported.\"\n        )\n\n    # Split into bucket and prefix\n    bucket, prefix = path.split(\"/\", 1) if \"/\" in path else (path, \"\")\n\n    if \"*\" in prefix:\n        if not prefix.endswith(\"*\"):\n            raise ValueError(f\"GCSSource only supports '*' at the end of path. Invalid pattern: {prefix}\")\n        # Remove the trailing * for GCS prefix listing\n        prefix = prefix[:-1]\n        return await cls.list_sources(bucket=bucket, prefix=prefix)\n\n    return [cls(bucket=bucket, object_name=prefix)]\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource","title":"ragbits.core.sources.google_drive.GoogleDriveSource","text":"<p>               Bases: <code>Source</code></p> <p>Handles source connection for Google Drive and provides methods to fetch files.</p> <p>NOTE(Do not define variables at class level that you pass to google client, define them at instance level, or else google client will complain.):</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = sources\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'source'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.file_id","title":"file_id  <code>instance-attribute</code>","text":"<pre><code>file_id: str\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.file_name","title":"file_name  <code>instance-attribute</code>","text":"<pre><code>file_name: str\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.mime_type","title":"mime_type  <code>instance-attribute</code>","text":"<pre><code>mime_type: str\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.is_folder","title":"is_folder  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>is_folder: bool = False\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.protocol","title":"protocol  <code>class-attribute</code>","text":"<pre><code>protocol: str = 'google_drive'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.impersonate","title":"impersonate  <code>class-attribute</code>","text":"<pre><code>impersonate: bool | None = None\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.impersonate_target_email","title":"impersonate_target_email  <code>class-attribute</code>","text":"<pre><code>impersonate_target_email: str | None = None\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Get the source identifier.</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.class_identifier","title":"class_identifier  <code>classmethod</code>","text":"<pre><code>class_identifier() -&gt; str\n</code></pre> <p>Get an identifier for the source type.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@classmethod\ndef class_identifier(cls) -&gt; str:\n    \"\"\"\n    Get an identifier for the source type.\n    \"\"\"\n    return to_snake(cls.__name__)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.source_type","title":"source_type","text":"<pre><code>source_type() -&gt; str\n</code></pre> <p>Pydantic field based on the class identifier.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@computed_field\ndef source_type(self) -&gt; str:\n    \"\"\"\n    Pydantic field based on the class identifier.\n    \"\"\"\n    return self.class_identifier()\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.set_credentials_file_path","title":"set_credentials_file_path  <code>classmethod</code>","text":"<pre><code>set_credentials_file_path(path: str) -&gt; None\n</code></pre> <p>Set the path to the service account credentials file.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/google_drive.py</code> <pre><code>@classmethod\ndef set_credentials_file_path(cls, path: str) -&gt; None:\n    \"\"\"Set the path to the service account credentials file.\"\"\"\n    cls._credentials_file_path = path\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.set_impersonation_target","title":"set_impersonation_target  <code>classmethod</code>","text":"<pre><code>set_impersonation_target(target_mail: str) -&gt; None\n</code></pre> <p>Sets the email address to impersonate when accessing Google Drive resources.</p> PARAMETER DESCRIPTION <code>target_mail</code> <p>The email address to impersonate.</p> <p> TYPE: <code>str</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If the provided email address is invalid (empty or missing '@').</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/google_drive.py</code> <pre><code>@classmethod\ndef set_impersonation_target(cls, target_mail: str) -&gt; None:\n    \"\"\"\n    Sets the email address to impersonate when accessing Google Drive resources.\n\n    Args:\n        target_mail (str): The email address to impersonate.\n\n    Raises:\n        ValueError: If the provided email address is invalid (empty or missing '@').\n    \"\"\"\n    # check if email is a valid email.\n    if not target_mail or \"@\" not in target_mail:\n        raise ValueError(\"Invalid email address provided for impersonation.\")\n    cls.impersonate = True\n    cls.impersonate_target_email = target_mail\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.verify_drive_api_enabled","title":"verify_drive_api_enabled  <code>classmethod</code>","text":"<pre><code>verify_drive_api_enabled() -&gt; None\n</code></pre> <p>Makes a lightweight API call to verify that the Drive API is enabled. If the API is not enabled, an HttpError should be raised.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/google_drive.py</code> <pre><code>@classmethod\n@requires_dependencies([\"googleapiclient\"], \"google_drive\")\ndef verify_drive_api_enabled(cls) -&gt; None:\n    \"\"\"\n    Makes a lightweight API call to verify that the Drive API is enabled.\n    If the API is not enabled, an HttpError should be raised.\n    \"\"\"\n    try:\n        client = cls._get_client()\n        client.files().list(\n            supportsAllDrives=True,\n            includeItemsFromAllDrives=True,\n            spaces=\"drive\",\n            pageSize=1,\n            fields=\"files(id)\",\n        ).execute()\n    except HttpError as e:\n        error_content = e.content.decode() if hasattr(e, \"content\") else \"\"\n        lower_error = error_content.lower()\n        if \"drive api\" in lower_error and (\"not enabled\" in lower_error or \"not been used\" in lower_error):\n            raise Exception(\n                \"Google Drive API is not enabled for your project. \" \"Please enable it in the Google Cloud Console.\"\n            ) from e\n        else:\n            raise Exception(f\"Google Drive API unreachable for an unknown reason: {e}\") from e\n    except Exception as e:\n        raise Exception(f\"An unexpected error occurred during API verification: {e}\") from e\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.fetch","title":"fetch  <code>async</code>","text":"<pre><code>fetch(*, export_format: GoogleDriveExportFormat | None = None) -&gt; Path\n</code></pre> <p>Fetch the file from Google Drive and store it locally.</p> <p>The file is downloaded to a local directory specified by <code>local_dir</code>. If the file already exists locally, it will not be downloaded again. If the file doesn't exist locally, it will be fetched from Google Drive. The local directory is determined by the environment variable <code>LOCAL_STORAGE_DIR</code>. If this environment variable is not set, a temporary directory is used.</p> PARAMETER DESCRIPTION <code>export_format</code> <p>Optional override for the export MIME type when downloading Google-native documents.</p> <p> TYPE: <code>GoogleDriveExportFormat | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Path</code> <p>The local path to the downloaded file.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the source instance represents a folder.</p> <code>FileNotFoundError</code> <p>If the file is not found on Google Drive.</p> <code>RuntimeError</code> <p>If an error occurs during download.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/google_drive.py</code> <pre><code>@traceable\n@requires_dependencies([\"googleapiclient\"], \"google_drive\")\nasync def fetch(\n    self,\n    *,\n    export_format: \"GoogleDriveExportFormat | None\" = None,\n) -&gt; Path:\n    \"\"\"\n    Fetch the file from Google Drive and store it locally.\n\n    The file is downloaded to a local directory specified by `local_dir`. If the file already exists locally,\n    it will not be downloaded again. If the file doesn't exist locally, it will be fetched from Google Drive.\n    The local directory is determined by the environment variable `LOCAL_STORAGE_DIR`. If this environment\n    variable is not set, a temporary directory is used.\n\n    Args:\n        export_format: Optional override for the export MIME type when downloading Google-native documents.\n\n    Returns:\n        The local path to the downloaded file.\n\n    Raises:\n        ValueError: If the source instance represents a folder.\n        FileNotFoundError: If the file is not found on Google Drive.\n        RuntimeError: If an error occurs during download.\n    \"\"\"\n    if self.is_folder:\n        raise ValueError(f\"Cannot directly fetch a folder. Use list_sources and iterate. Folder ID: {self.file_id}\")\n\n    local_dir = get_local_storage_dir()\n    file_local_dir = local_dir / self.file_id\n    file_local_dir.mkdir(parents=True, exist_ok=True)\n\n    override_mime = export_format.value if export_format else None\n    export_mime_type, file_extension = self._determine_file_extension(override_mime=override_mime)\n    local_file_name = f\"{self.file_name}{file_extension}\"\n    path = file_local_dir / local_file_name\n\n    with trace(file_id=self.file_id, file_name=self.file_name, mime_type=self.mime_type) as outputs:\n        if not path.is_file():\n            client = self._get_client()\n            try:\n                request = None\n                if self.mime_type.startswith(\"application/vnd.google-apps\"):\n                    request = client.files().export_media(fileId=self.file_id, mimeType=export_mime_type)\n                else:\n                    request = client.files().get_media(fileId=self.file_id)\n\n                with open(path, \"wb\") as fh:\n                    downloader = MediaIoBaseDownload(fh, request)\n                    done = False\n                    while not done:\n                        _, done = downloader.next_chunk()\n\n            except HttpError as e:\n                if e.resp.status == _HTTP_NOT_FOUND:\n                    raise FileNotFoundError(f\"File with ID {self.file_id} not found on Google Drive.\") from e\n                raise RuntimeError(f\"Error downloading file {self.file_id}: {e}\") from e\n            except Exception as e:\n                raise RuntimeError(\n                    f\"An unexpected error occurred during file download for {self.file_id}: {e}\"\n                ) from e\n        outputs.path = path\n    return path\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.list_sources","title":"list_sources  <code>async</code> <code>classmethod</code>","text":"<pre><code>list_sources(drive_id: str, recursive: bool = True) -&gt; Iterable[Self]\n</code></pre> <p>Lists all files (and optionally recursively, subfolders and their files) within a given Google Drive folder/Shared Drive ID.</p> PARAMETER DESCRIPTION <code>drive_id</code> <p>The ID of the folder or Shared Drive to list files from.</p> <p> TYPE: <code>str</code> </p> <code>recursive</code> <p>If True, lists files in subfolders recursively.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>An iterable of GoogleDriveSource instances representing the found files.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/google_drive.py</code> <pre><code>@classmethod\n@requires_dependencies([\"googleapiclient\"], \"google_drive\")\nasync def list_sources(cls, drive_id: str, recursive: bool = True) -&gt; Iterable[Self]:\n    \"\"\"\n    Lists all files (and optionally recursively, subfolders and their files)\n    within a given Google Drive folder/Shared Drive ID.\n\n    Args:\n        drive_id: The ID of the folder or Shared Drive to list files from.\n        recursive: If True, lists files in subfolders recursively.\n\n    Returns:\n        An iterable of GoogleDriveSource instances representing the found files.\n    \"\"\"\n    with trace(drive_id=drive_id, recursive=recursive) as outputs:\n        client = cls._get_client()\n\n        # Check if the drive_id is a folder, shared drive, or file\n        is_folder, is_shared_drive, root_file_name = await cls._check_drive_type(client, drive_id)\n\n        # If it's not a folder, return the single file\n        if not is_folder:\n            if not root_file_name:  # Error occurred in _check_drive_type\n                outputs.results = []\n                return outputs.results\n\n            file_meta = (\n                client.files().get(fileId=drive_id, fields=\"id, name, mimeType\", supportsAllDrives=True).execute()\n            )\n            outputs.results = [\n                cls(\n                    file_id=file_meta[\"id\"],\n                    file_name=file_meta[\"name\"],\n                    mime_type=file_meta[\"mimeType\"],\n                    is_folder=False,\n                )\n            ]\n            return outputs.results\n\n        # Process folder contents\n        all_files_info: dict[str, Any] = {}\n\n        await cls._recursive_list_files(client, drive_id, all_files_info, recursive, is_shared_drive)\n\n        sources = [\n            cls(file_id=info[\"id\"], file_name=info[\"name\"], mime_type=info[\"mimeType\"], is_folder=info[\"is_folder\"])\n            for info in all_files_info.values()\n        ]\n        outputs.results = sources\n        return outputs.results\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.google_drive.GoogleDriveSource.from_uri","title":"from_uri  <code>async</code> <code>classmethod</code>","text":"<pre><code>from_uri(path: str) -&gt; Iterable[Self]\n</code></pre> <p>Create GoogleDriveSource instances from a URI path.</p> <p>The supported URI formats: -  - Matches a single file or folder by ID. - /\" - Matches all files directly within the folder/Shared Drive. - /\" - Matches all files directly within the folder/Shared Drive starting with prefix. - /**\" - Matches all files recursively within the folder/Shared Drive. PARAMETER DESCRIPTION <code>path</code> <p>The URI path in the format described above.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>The iterable of sources from Google Drive.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If an unsupported pattern is used or path format is incorrect.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/google_drive.py</code> <pre><code>@classmethod\n@traceable\nasync def from_uri(cls, path: str) -&gt; Iterable[Self]:\n    \"\"\"\n    Create GoogleDriveSource instances from a URI path.\n\n    The supported URI formats:\n    - &lt;drive_id&gt; - Matches a single file or folder by ID.\n    - &lt;folder_id&gt;/*\" - Matches all files directly within the folder/Shared Drive.\n    - &lt;folder_id&gt;/&lt;prefix&gt;*\" - Matches all files directly within the folder/Shared Drive starting with prefix.\n    - &lt;folder_id&gt;/**\" - Matches all files recursively within the folder/Shared Drive.\n\n    Args:\n        path: The URI path in the format described above.\n\n    Returns:\n        The iterable of sources from Google Drive.\n\n    Raises:\n        ValueError: If an unsupported pattern is used or path format is incorrect.\n    \"\"\"\n    parts = path.split(\"/\")\n    drive_id = parts[0]\n\n    if len(parts) == 1:\n        return await cls._handle_single_id(drive_id)\n\n    elif len(parts) &gt; 1 and parts[-1] == \"**\":\n        folder_id = parts[0]\n        if not folder_id:\n            raise ValueError(\"Folder ID cannot be empty for recursive listing.\")\n        return await cls.list_sources(drive_id=folder_id, recursive=True)\n\n    elif len(parts) &gt; 1 and parts[-1].endswith(\"*\"):\n        folder_id = parts[0]\n        prefix_pattern = parts[-1][:-1]\n        if not folder_id:\n            raise ValueError(\"Folder ID cannot be empty for prefix listing.\")\n\n        all_direct_files = await cls.list_sources(drive_id=folder_id, recursive=False)\n        filtered_sources = [source for source in all_direct_files if source.file_name.startswith(prefix_pattern)]\n        return filtered_sources\n\n    elif len(parts) &gt; 1 and parts[-1] == \"*\":\n        folder_id = parts[0]\n        if not folder_id:\n            raise ValueError(\"Folder ID cannot be empty for listing all direct children.\")\n        return await cls.list_sources(drive_id=folder_id, recursive=False)\n\n    else:\n        raise ValueError(f\"Unsupported Google Drive URI pattern: {path}\")\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.git.GitSource","title":"ragbits.core.sources.git.GitSource","text":"<p>               Bases: <code>Source</code></p> <p>Source for data stored in the Git repository.</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.git.GitSource.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = sources\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.git.GitSource.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'source'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.git.GitSource.protocol","title":"protocol  <code>class-attribute</code>","text":"<pre><code>protocol: str = 'git'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.git.GitSource.repo_url","title":"repo_url  <code>instance-attribute</code>","text":"<pre><code>repo_url: str\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.git.GitSource.file_path","title":"file_path  <code>instance-attribute</code>","text":"<pre><code>file_path: str\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.git.GitSource.branch","title":"branch  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>branch: str | None = None\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.git.GitSource.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Get the source identifier.</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.git.GitSource.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.git.GitSource.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.git.GitSource.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.git.GitSource.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.git.GitSource.class_identifier","title":"class_identifier  <code>classmethod</code>","text":"<pre><code>class_identifier() -&gt; str\n</code></pre> <p>Get an identifier for the source type.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@classmethod\ndef class_identifier(cls) -&gt; str:\n    \"\"\"\n    Get an identifier for the source type.\n    \"\"\"\n    return to_snake(cls.__name__)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.git.GitSource.source_type","title":"source_type","text":"<pre><code>source_type() -&gt; str\n</code></pre> <p>Pydantic field based on the class identifier.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@computed_field\ndef source_type(self) -&gt; str:\n    \"\"\"\n    Pydantic field based on the class identifier.\n    \"\"\"\n    return self.class_identifier()\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.git.GitSource.fetch","title":"fetch  <code>async</code>","text":"<pre><code>fetch() -&gt; Path\n</code></pre> <p>Clone the Git repository and return the path to the specific file.</p> RETURNS DESCRIPTION <code>Path</code> <p>The local path to the downloaded file.</p> RAISES DESCRIPTION <code>SourceNotFoundError</code> <p>If the repository cannot be cloned or the file doesn't exist.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/git.py</code> <pre><code>@requires_dependencies([\"git\"])\n@traceable\nasync def fetch(self) -&gt; Path:\n    \"\"\"\n    Clone the Git repository and return the path to the specific file.\n\n    Returns:\n        The local path to the downloaded file.\n\n    Raises:\n        SourceNotFoundError: If the repository cannot be cloned or the file doesn't exist.\n    \"\"\"\n    repo_dir = self._get_repo_dir(self.repo_url, self.branch)\n    self._ensure_repo(self.repo_url, repo_dir, self.branch)\n\n    # Check if the file exists in the repository\n    file_path = repo_dir / self.file_path\n    if not file_path.exists() or not file_path.is_file():\n        raise SourceNotFoundError(f\"File {self.file_path} not found in repository\")\n\n    return file_path\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.git.GitSource.list_sources","title":"list_sources  <code>async</code> <code>classmethod</code>","text":"<pre><code>list_sources(repo_url: str, file_pattern: str = '**/*', branch: str | None = None) -&gt; Iterable[Self]\n</code></pre> <p>List all files in the repository matching the pattern.</p> PARAMETER DESCRIPTION <code>repo_url</code> <p>URL of the git repository.</p> <p> TYPE: <code>str</code> </p> <code>file_pattern</code> <p>The glob pattern to match files.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'**/*'</code> </p> <code>branch</code> <p>Optional branch name.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>The iterable of sources from the git repository.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/git.py</code> <pre><code>@classmethod\n@traceable\nasync def list_sources(cls, repo_url: str, file_pattern: str = \"**/*\", branch: str | None = None) -&gt; Iterable[Self]:\n    \"\"\"\n    List all files in the repository matching the pattern.\n\n    Args:\n        repo_url: URL of the git repository.\n        file_pattern: The glob pattern to match files.\n        branch: Optional branch name.\n\n    Returns:\n        The iterable of sources from the git repository.\n    \"\"\"\n    repo_dir = cls._get_repo_dir(repo_url, branch)\n    cls._ensure_repo(repo_url, repo_dir, branch)\n\n    # Find all files matching the pattern\n    matched_files = repo_dir.glob(file_pattern)\n    file_sources = []\n\n    for file_path in matched_files:\n        if file_path.is_file():\n            # Convert to relative path within the repository\n            relative_path = file_path.relative_to(repo_dir)\n            file_sources.append(cls(repo_url=repo_url, file_path=str(relative_path), branch=branch))\n\n    return file_sources\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.git.GitSource.from_uri","title":"from_uri  <code>async</code> <code>classmethod</code>","text":"<pre><code>from_uri(path: str) -&gt; Iterable[Self]\n</code></pre> <p>Create GitSource instances from a URI path.</p> <p>Supported URI formats: - git://https://github.com/username/repo.git:path/to/file.txt - git://https://github.com/username/repo.git:branch:path/to/file.txt - git@github.com:username/repo.git:path/to/file.txt - git@github.com:username/repo.git:branch:path/to/file.txt</p> PARAMETER DESCRIPTION <code>path</code> <p>The URI path in the format described above.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>The iterable of sources from the git repository.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/git.py</code> <pre><code>@classmethod\n@traceable\nasync def from_uri(cls, path: str) -&gt; Iterable[Self]:\n    \"\"\"\n    Create GitSource instances from a URI path.\n\n    Supported URI formats:\n    - git://https://github.com/username/repo.git:path/to/file.txt\n    - git://https://github.com/username/repo.git:branch:path/to/file.txt\n    - git@github.com:username/repo.git:path/to/file.txt\n    - git@github.com:username/repo.git:branch:path/to/file.txt\n\n    Args:\n        path: The URI path in the format described above.\n\n    Returns:\n        The iterable of sources from the git repository.\n    \"\"\"\n    # Check if URI starts with git:// protocol\n    if path.startswith(\"git://\"):\n        path = path[6:]  # Remove the git:// prefix\n\n    parts = path.split(\":\")\n    sources = []\n\n    if len(parts) == _REPO_AND_FILE_PARTS:\n        # Repo URL and file path\n        sources.append(cls(repo_url=parts[0], file_path=parts[1]))\n    elif len(parts) &gt;= _MIN_PARTS_WITH_PROTOCOL:\n        # Handle SSH format (git@github.com:username/repo.git)\n        if parts[0].startswith(\"git@\"):\n            repo_url = f\"{parts[0]}:{parts[1]}\"  # Reconstruct full SSH URL\n            file_path = parts[2] if len(parts) == _MIN_PARTS_WITH_PROTOCOL else parts[3]\n            branch = None if len(parts) == _MIN_PARTS_WITH_PROTOCOL else parts[2]\n            sources.append(cls(repo_url=repo_url, file_path=file_path, branch=branch))\n        # Handle HTTPS format\n        elif parts[0] in [\"http\", \"https\"]:\n            repo_url = f\"{parts[0]}:{parts[1]}\"\n            file_path = parts[2] if len(parts) == _MIN_PARTS_WITH_PROTOCOL else parts[3]\n            branch = None if len(parts) == _MIN_PARTS_WITH_PROTOCOL else parts[2]\n            sources.append(cls(repo_url=repo_url, file_path=file_path, branch=branch))\n        else:\n            # Repo URL, branch, and file path in standard format\n            sources.append(cls(repo_url=parts[0], branch=parts[1], file_path=parts[2]))\n\n    return sources\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.hf.HuggingFaceSource","title":"ragbits.core.sources.hf.HuggingFaceSource","text":"<p>               Bases: <code>Source</code></p> <p>Source for data stored in the Hugging Face repository.</p> <p>Supports two formats: 1. Complete dataset: When no row is specified, downloads the entire dataset. Used for QA datasets. 2. Single row: When a specific row is specified, downloads only that row. Used for document datasets     (requires \"content\" and \"source\" columns).</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.hf.HuggingFaceSource.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = sources\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.hf.HuggingFaceSource.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'source'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.hf.HuggingFaceSource.protocol","title":"protocol  <code>class-attribute</code>","text":"<pre><code>protocol: str = 'hf'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.hf.HuggingFaceSource.path","title":"path  <code>instance-attribute</code>","text":"<pre><code>path: str\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.hf.HuggingFaceSource.split","title":"split  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>split: str = 'train'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.hf.HuggingFaceSource.row","title":"row  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>row: int | None = None\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.hf.HuggingFaceSource.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Get the source identifier.</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.hf.HuggingFaceSource.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.hf.HuggingFaceSource.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.hf.HuggingFaceSource.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.hf.HuggingFaceSource.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.hf.HuggingFaceSource.class_identifier","title":"class_identifier  <code>classmethod</code>","text":"<pre><code>class_identifier() -&gt; str\n</code></pre> <p>Get an identifier for the source type.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@classmethod\ndef class_identifier(cls) -&gt; str:\n    \"\"\"\n    Get an identifier for the source type.\n    \"\"\"\n    return to_snake(cls.__name__)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.hf.HuggingFaceSource.source_type","title":"source_type","text":"<pre><code>source_type() -&gt; str\n</code></pre> <p>Pydantic field based on the class identifier.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@computed_field\ndef source_type(self) -&gt; str:\n    \"\"\"\n    Pydantic field based on the class identifier.\n    \"\"\"\n    return self.class_identifier()\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.hf.HuggingFaceSource.fetch","title":"fetch  <code>async</code>","text":"<pre><code>fetch() -&gt; Path\n</code></pre> <p>Fetch the file from Hugging Face and store it locally.</p> RETURNS DESCRIPTION <code>Path</code> <p>The local path to the downloaded file.</p> RAISES DESCRIPTION <code>SourceConnectionError</code> <p>If the source connection fails.</p> <code>SourceNotFoundError</code> <p>If the source document is not found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/hf.py</code> <pre><code>@requires_dependencies([\"datasets\"], \"hf\")\nasync def fetch(self) -&gt; Path:\n    \"\"\"\n    Fetch the file from Hugging Face and store it locally.\n\n    Returns:\n        The local path to the downloaded file.\n\n    Raises:\n        SourceConnectionError: If the source connection fails.\n        SourceNotFoundError: If the source document is not found.\n    \"\"\"\n    from datasets import load_dataset\n    from datasets.exceptions import DatasetNotFoundError\n\n    with trace(path=self.path, split=self.split, row=self.row) as outputs:\n        if self.row is not None:\n            try:\n                dataset = load_dataset(self.path, split=self.split, streaming=True)\n            except ConnectionError as exc:\n                raise SourceConnectionError() from exc\n            except DatasetNotFoundError as exc:\n                raise SourceNotFoundError(source_id=self.id) from exc\n\n            try:\n                data = next(iter(dataset.skip(self.row).take(1)))\n            except StopIteration as exc:\n                raise SourceNotFoundError(source_id=self.id) from exc\n\n            storage_dir = get_local_storage_dir()\n            source_dir = storage_dir / Path(data[\"source\"]).parent\n            source_dir.mkdir(parents=True, exist_ok=True)\n            path = storage_dir / data[\"source\"]\n\n            if not path.is_file():\n                with open(path, mode=\"w\", encoding=\"utf-8\") as file:\n                    file.write(data[\"content\"])\n            outputs.path = path\n        else:\n            storage_dir = get_local_storage_dir()\n            source_dir = storage_dir / self.path\n            source_dir.mkdir(parents=True, exist_ok=True)\n            path = source_dir / f\"{self.split}.json\"\n\n            if not path.is_file():\n                try:\n                    dataset = load_dataset(self.path, split=self.split)\n                except ConnectionError as exc:\n                    raise SourceConnectionError() from exc\n                except DatasetNotFoundError as exc:\n                    raise SourceNotFoundError(source_id=self.id) from exc\n\n                dataset.to_json(path)\n            outputs.path = path\n\n    return outputs.path\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.hf.HuggingFaceSource.list_sources","title":"list_sources  <code>async</code> <code>classmethod</code>","text":"<pre><code>list_sources(path: str, split: str) -&gt; Iterable[Self]\n</code></pre> <p>List all sources in the Hugging Face repository.</p> PARAMETER DESCRIPTION <code>path</code> <p>Path or name of the dataset.</p> <p> TYPE: <code>str</code> </p> <code>split</code> <p>Dataset split.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>The iterable of sources from the Hugging Face repository.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/hf.py</code> <pre><code>@classmethod\n@traceable\nasync def list_sources(cls, path: str, split: str) -&gt; Iterable[Self]:\n    \"\"\"\n    List all sources in the Hugging Face repository.\n\n    Args:\n        path: Path or name of the dataset.\n        split: Dataset split.\n\n    Returns:\n        The iterable of sources from the Hugging Face repository.\n    \"\"\"\n    from datasets import load_dataset\n\n    sources = load_dataset(path, split=split)\n    cleaned_split = re.sub(r\"\\[.*?\\]\", \"\", split)\n    return [\n        cls(\n            path=path,\n            split=cleaned_split,\n            row=row,\n        )\n        for row in range(len(sources))\n    ]\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.hf.HuggingFaceSource.from_uri","title":"from_uri  <code>async</code> <code>classmethod</code>","text":"<pre><code>from_uri(path: str) -&gt; Iterable[Self]\n</code></pre> <p>Create HuggingFaceSource instances from a URI path.</p> <p>The supported URI formats: - // PARAMETER DESCRIPTION <code>path</code> <p>The URI path in the format described above.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>The iterable of sources from the Hugging Face repository.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the path contains patterns or has invalid format.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/hf.py</code> <pre><code>@classmethod\n@traceable\nasync def from_uri(cls, path: str) -&gt; Iterable[Self]:\n    \"\"\"\n    Create HuggingFaceSource instances from a URI path.\n\n    The supported URI formats:\n    - &lt;dataset-path&gt;/&lt;split&gt;/&lt;row&gt;\n\n    Args:\n        path: The URI path in the format described above.\n\n    Returns:\n       The iterable of sources from the Hugging Face repository.\n\n    Raises:\n        ValueError: If the path contains patterns or has invalid format.\n    \"\"\"\n    if \"*\" in path or \"?\" in path:\n        raise ValueError(\n            \"HuggingFaceSource does not support patterns. Path must be in format: dataset_path/split/row\"\n        )\n\n    try:\n        dataset_path, split, row = path.split(\"/\")\n        return [cls(path=dataset_path, split=split, row=int(row))]\n    except ValueError as err:\n        raise ValueError(\"Invalid HuggingFace path format. Expected: dataset_path/split/row\") from err\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.local.LocalFileSource","title":"ragbits.core.sources.local.LocalFileSource","text":"<p>               Bases: <code>Source</code></p> <p>Source for data stored on the local disk.</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.local.LocalFileSource.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = sources\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.local.LocalFileSource.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'source'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.local.LocalFileSource.protocol","title":"protocol  <code>class-attribute</code>","text":"<pre><code>protocol: str = 'local'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.local.LocalFileSource.path","title":"path  <code>instance-attribute</code>","text":"<pre><code>path: Path\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.local.LocalFileSource.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Get the source identifier.</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.local.LocalFileSource.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.local.LocalFileSource.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.local.LocalFileSource.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.local.LocalFileSource.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.local.LocalFileSource.class_identifier","title":"class_identifier  <code>classmethod</code>","text":"<pre><code>class_identifier() -&gt; str\n</code></pre> <p>Get an identifier for the source type.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@classmethod\ndef class_identifier(cls) -&gt; str:\n    \"\"\"\n    Get an identifier for the source type.\n    \"\"\"\n    return to_snake(cls.__name__)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.local.LocalFileSource.source_type","title":"source_type","text":"<pre><code>source_type() -&gt; str\n</code></pre> <p>Pydantic field based on the class identifier.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@computed_field\ndef source_type(self) -&gt; str:\n    \"\"\"\n    Pydantic field based on the class identifier.\n    \"\"\"\n    return self.class_identifier()\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.local.LocalFileSource.fetch","title":"fetch  <code>async</code>","text":"<pre><code>fetch() -&gt; Path\n</code></pre> <p>Fetch the source.</p> RETURNS DESCRIPTION <code>Path</code> <p>The local path to the file.</p> RAISES DESCRIPTION <code>SourceNotFoundError</code> <p>If the source document is not found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/local.py</code> <pre><code>@traceable\nasync def fetch(self) -&gt; Path:\n    \"\"\"\n    Fetch the source.\n\n    Returns:\n        The local path to the file.\n\n    Raises:\n        SourceNotFoundError: If the source document is not found.\n    \"\"\"\n    if not self.path.is_file():\n        raise SourceNotFoundError(source_id=self.id)\n    return self.path\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.local.LocalFileSource.list_sources","title":"list_sources  <code>async</code> <code>classmethod</code>","text":"<pre><code>list_sources(path: Path, file_pattern: str = '*') -&gt; Iterable[Self]\n</code></pre> <p>List all sources in the given directory, matching the file pattern.</p> PARAMETER DESCRIPTION <code>path</code> <p>The path to the directory.</p> <p> TYPE: <code>Path</code> </p> <code>file_pattern</code> <p>The file pattern to match.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'*'</code> </p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>The iterable of sources from the local file system.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/local.py</code> <pre><code>@classmethod\n@traceable\nasync def list_sources(cls, path: Path, file_pattern: str = \"*\") -&gt; Iterable[Self]:\n    \"\"\"\n    List all sources in the given directory, matching the file pattern.\n\n    Args:\n        path: The path to the directory.\n        file_pattern: The file pattern to match.\n\n    Returns:\n        The iterable of sources from the local file system.\n    \"\"\"\n    return [cls(path=file_path) for file_path in path.glob(file_pattern)]\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.local.LocalFileSource.from_uri","title":"from_uri  <code>async</code> <code>classmethod</code>","text":"<pre><code>from_uri(path: str) -&gt; Iterable[Self]\n</code></pre> <p>Create LocalFileSource instances from a URI path.</p> <p>The supported URI formats: - \"/.txt\" - all .txt files in any subdirectory - \".py\" - all Python files in the current directory - \"/*\" - all files in any subdirectory - '?' matches exactly one character</p> PARAMETER DESCRIPTION <code>path</code> <p>The URI path in the format described above.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>The iterable of sources from the local file system.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/local.py</code> <pre><code>@classmethod\n@traceable\nasync def from_uri(cls, path: str) -&gt; Iterable[Self]:\n    \"\"\"\n    Create LocalFileSource instances from a URI path.\n\n    The supported URI formats:\n    - \"**/*.txt\" - all .txt files in any subdirectory\n    - \"*.py\" - all Python files in the current directory\n    - \"**/*\" - all files in any subdirectory\n    - '?' matches exactly one character\n\n    Args:\n        path: The URI path in the format described above.\n\n    Returns:\n        The iterable of sources from the local file system.\n    \"\"\"\n    path_obj: Path = Path(path)\n    base_path, pattern = cls._split_path_and_pattern(path=path_obj)\n    if base_path.is_file():\n        return [cls(path=base_path)]\n    if not pattern:\n        return []\n    return [cls(path=f) for f in base_path.glob(pattern) if f.is_file()]\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.s3.S3Source","title":"ragbits.core.sources.s3.S3Source","text":"<p>               Bases: <code>Source</code></p> <p>Source for data stored in the AWS S3 bucket.</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.s3.S3Source.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = sources\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.s3.S3Source.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'source'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.s3.S3Source.protocol","title":"protocol  <code>class-attribute</code>","text":"<pre><code>protocol: str = 's3'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.s3.S3Source.bucket_name","title":"bucket_name  <code>instance-attribute</code>","text":"<pre><code>bucket_name: str\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.s3.S3Source.key","title":"key  <code>instance-attribute</code>","text":"<pre><code>key: str\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.s3.S3Source.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Get the source identifier.</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.s3.S3Source.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.s3.S3Source.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.s3.S3Source.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.s3.S3Source.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.s3.S3Source.class_identifier","title":"class_identifier  <code>classmethod</code>","text":"<pre><code>class_identifier() -&gt; str\n</code></pre> <p>Get an identifier for the source type.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@classmethod\ndef class_identifier(cls) -&gt; str:\n    \"\"\"\n    Get an identifier for the source type.\n    \"\"\"\n    return to_snake(cls.__name__)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.s3.S3Source.source_type","title":"source_type","text":"<pre><code>source_type() -&gt; str\n</code></pre> <p>Pydantic field based on the class identifier.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@computed_field\ndef source_type(self) -&gt; str:\n    \"\"\"\n    Pydantic field based on the class identifier.\n    \"\"\"\n    return self.class_identifier()\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.s3.S3Source.fetch","title":"fetch  <code>async</code>","text":"<pre><code>fetch() -&gt; Path\n</code></pre> <p>Download a file in the given bucket name and key.</p> RETURNS DESCRIPTION <code>Path</code> <p>The local path to the downloaded file.</p> RAISES DESCRIPTION <code>ClientError</code> <p>If the file doesn't exist or credentials are incomplete.</p> <code>NoCredentialsError</code> <p>If no credentials are available.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/s3.py</code> <pre><code>@requires_dependencies([\"boto3\"], \"s3\")\nasync def fetch(self) -&gt; Path:\n    \"\"\"\n    Download a file in the given bucket name and key.\n\n    Returns:\n        The local path to the downloaded file.\n\n    Raises:\n        ClientError: If the file doesn't exist or credentials are incomplete.\n        NoCredentialsError: If no credentials are available.\n    \"\"\"\n    if self._s3_client is None:\n        self._set_client(self.bucket_name)\n\n    if self._s3_client is None:\n        raise RuntimeError(\"S3 client is not initialized.\")\n\n    local_dir = get_local_storage_dir()\n    container_local_dir = local_dir / self.bucket_name\n    container_local_dir.mkdir(parents=True, exist_ok=True)\n    normalized_key = self.key.replace(\"/\", \"_\")\n    path = container_local_dir / normalized_key\n    with trace(bucket=self.bucket_name, key=self.key) as outputs:\n        try:\n            self._s3_client.download_file(self.bucket_name, self.key, path)\n        except ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                raise FileNotFoundError(f\"The object does not exist: {self.key}\") from e\n            elif e.response[\"Error\"][\"Code\"] == \"403\":\n                raise PermissionError(f\"Access denied. No permission to download: {self.key}\") from e\n            else:\n                raise RuntimeError(f\"S3 Client Error: {e}\") from e\n        except (NoCredentialsError, PartialCredentialsError) as e:\n            raise ValueError(\"AWS credentials are missing or invalid.\") from e\n        outputs.path = path\n    return path\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.s3.S3Source.list_sources","title":"list_sources  <code>async</code> <code>classmethod</code>","text":"<pre><code>list_sources(bucket_name: str, prefix: str) -&gt; Iterable[Self]\n</code></pre> <p>List all files under the given bucket name and with the given prefix.</p> PARAMETER DESCRIPTION <code>bucket_name</code> <p>The name of the S3 bucket to use.</p> <p> TYPE: <code>str</code> </p> <code>prefix</code> <p>The path to the files and prefix to look for.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>The iterable of sources from the S3 bucket.</p> RAISES DESCRIPTION <code>ClientError</code> <p>If the source doesn't exist.</p> <code>NoCredentialsError</code> <p>If no credentials are available.</p> <code>PartialCredentialsError</code> <p>If credentials are incomplete.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/s3.py</code> <pre><code>@classmethod\n@requires_dependencies([\"boto3\"], \"s3\")\nasync def list_sources(cls, bucket_name: str, prefix: str) -&gt; Iterable[Self]:\n    \"\"\"\n    List all files under the given bucket name and with the given prefix.\n\n    Args:\n        bucket_name: The name of the S3 bucket to use.\n        prefix: The path to the files and prefix to look for.\n\n    Returns:\n        The iterable of sources from the S3 bucket.\n\n    Raises:\n        ClientError: If the source doesn't exist.\n        NoCredentialsError: If no credentials are available.\n        PartialCredentialsError: If credentials are incomplete.\n    \"\"\"\n    cls._set_client(bucket_name)\n    if cls._s3_client is None:\n        raise RuntimeError(\"S3 client is not initialized.\")\n    with trace(bucket=bucket_name, key=prefix) as outputs:\n        try:\n            aws_sources_list = []\n            paginator = cls._s3_client.get_paginator(\"list_objects_v2\")\n            for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):\n                for obj in page.get(\"Contents\", []):\n                    key = obj[\"Key\"]\n                    aws_sources_list.append(cls(bucket_name=bucket_name, key=key))\n            outputs.sources = aws_sources_list\n            return aws_sources_list\n        except (NoCredentialsError, PartialCredentialsError) as e:\n            raise ValueError(\"AWS credentials are missing or incomplete. Please configure them.\") from e\n        except ClientError as e:\n            raise RuntimeError(f\"Failed to list files in bucket {bucket_name}: {e}\") from e\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.s3.S3Source.from_uri","title":"from_uri  <code>async</code> <code>classmethod</code>","text":"<pre><code>from_uri(path: str) -&gt; Iterable[Self]\n</code></pre> <p>Create S3Source instances from a URI path.</p> <p>The supported URI formats: - s3:/// - https://s3..amazonaws.com/ - https://s3..amazonaws.com// PARAMETER DESCRIPTION <code>path</code> <p>The URI path in the format described above.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>The iterable of sources from the S3 bucket.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the path has invalid format</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/s3.py</code> <pre><code>@classmethod\n@traceable\nasync def from_uri(cls, path: str) -&gt; Iterable[Self]:\n    \"\"\"\n    Create S3Source instances from a URI path.\n\n    The supported URI formats:\n    - s3://&lt;bucket-name&gt;/&lt;key&gt;\n    - https://&lt;bucket-name&gt;s3.&lt;region&gt;.amazonaws.com/&lt;key&gt;\n    - https://s3.&lt;region&gt;.amazonaws.com/&lt;bucket-name&gt;/&lt;key&gt;\n\n    Args:\n        path: The URI path in the format described above.\n\n    Returns:\n        The iterable of sources from the S3 bucket.\n\n    Raises:\n        ValueError: If the path has invalid format\n    \"\"\"\n    if \"**\" in path or \"?\" in path:\n        raise ValueError(\n            \"S3Source only supports '*' at the end of path. Patterns like '**' or '?' are not supported.\"\n        )\n\n    parsed = urlparse(path)\n    if not parsed.netloc or not parsed.path:\n        raise ValueError(\"Invalid AWS Source URI format.\")\n    if parsed.scheme not in {\"s3\", \"https\"}:\n        raise ValueError(\"Invalid AWS Source URI format.\")\n\n    if parsed.scheme == \"s3\":\n        bucket_name = parsed.netloc\n        path_to_file = parsed.path.lstrip(\"/\")\n    elif parsed.scheme == \"https\":\n        if not parsed.netloc.endswith(\"amazonaws.com\"):\n            raise ValueError(\"Invalid AWS Source URI format.\")\n        elif parsed.netloc.startswith(\"s3\"):\n            parts = parsed.path.split(\"/\")\n            bucket_name = parts[1]\n            path_to_file = \"/\".join(parts[2:])\n        else:\n            bucket_name = parsed.netloc.split(\".\")[0]\n            path_to_file = parsed.path.lstrip(\"/\")\n\n    else:\n        raise ValueError(\"Invalid AWS Source URI format.\")\n\n    if \"*\" in path_to_file:\n        if not path_to_file.endswith(\"*\") or \"*\" in path_to_file[:-1]:\n            raise ValueError(f\"AWS Source only supports '*' at the end of path. Invalid pattern: {[path_to_file]}.\")\n        path_to_file = path_to_file[:-1]\n        return await cls.list_sources(bucket_name=bucket_name, prefix=path_to_file)\n\n    return [cls(bucket_name=bucket_name, key=path_to_file)]\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.web.WebSource","title":"ragbits.core.sources.web.WebSource","text":"<p>               Bases: <code>Source</code></p> <p>Source for data stored in the web.</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.web.WebSource.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = sources\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.web.WebSource.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'source'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.web.WebSource.protocol","title":"protocol  <code>class-attribute</code>","text":"<pre><code>protocol: str = 'web'\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.web.WebSource.url","title":"url  <code>instance-attribute</code>","text":"<pre><code>url: str\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.web.WebSource.headers","title":"headers  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>headers: dict[str, str] | None = None\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.web.WebSource.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Get the source identifier.</p>"},{"location":"api_reference/core/sources/#ragbits.core.sources.web.WebSource.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.web.WebSource.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.web.WebSource.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.web.WebSource.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.web.WebSource.class_identifier","title":"class_identifier  <code>classmethod</code>","text":"<pre><code>class_identifier() -&gt; str\n</code></pre> <p>Get an identifier for the source type.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@classmethod\ndef class_identifier(cls) -&gt; str:\n    \"\"\"\n    Get an identifier for the source type.\n    \"\"\"\n    return to_snake(cls.__name__)\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.web.WebSource.source_type","title":"source_type","text":"<pre><code>source_type() -&gt; str\n</code></pre> <p>Pydantic field based on the class identifier.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/base.py</code> <pre><code>@computed_field\ndef source_type(self) -&gt; str:\n    \"\"\"\n    Pydantic field based on the class identifier.\n    \"\"\"\n    return self.class_identifier()\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.web.WebSource.fetch","title":"fetch  <code>async</code>","text":"<pre><code>fetch() -&gt; Path\n</code></pre> <p>Download a file available in the given url.</p> RETURNS DESCRIPTION <code>Path</code> <p>The local path to the downloaded file.</p> RAISES DESCRIPTION <code>SourceDownloadError</code> <p>If the download failed.</p> <code>SourceNotFoundError</code> <p>If the URL is invalid.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/web.py</code> <pre><code>async def fetch(self) -&gt; Path:\n    \"\"\"\n    Download a file available in the given url.\n\n    Returns:\n        The local path to the downloaded file.\n\n    Raises:\n        SourceDownloadError: If the download failed.\n        SourceNotFoundError: If the URL is invalid.\n    \"\"\"\n    parsed_url = urlparse(self.url)\n    url_path, file_name = (\"/\" + parsed_url.netloc + parsed_url.path).rsplit(\"/\", 1)\n    normalized_url_path = re.sub(r\"\\W\", \"_\", url_path) + file_name\n    domain_name = parsed_url.netloc\n\n    local_dir = get_local_storage_dir()\n    container_local_dir = local_dir / domain_name\n    container_local_dir.mkdir(parents=True, exist_ok=True)\n    path = container_local_dir / normalized_url_path\n\n    try:\n        async with aiohttp.ClientSession() as session, session.get(self.url, headers=self.headers) as response:\n            if response.ok:\n                with open(path, \"wb\") as f:\n                    async for chunk in response.content.iter_chunked(1024):\n                        f.write(chunk)\n            else:\n                raise SourceDownloadError(url=self.url, code=response.status)\n    except (aiohttp.ClientError, IsADirectoryError) as e:\n        raise SourceNotFoundError(self.id) from e\n\n    return path\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.web.WebSource.list_sources","title":"list_sources  <code>async</code> <code>classmethod</code>","text":"<pre><code>list_sources(url: str) -&gt; Iterable[Self]\n</code></pre> <p>List the file under the given URL.</p> PARAMETER DESCRIPTION <code>url</code> <p>The URL to the file.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>The iterable of sources from the web.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/web.py</code> <pre><code>@classmethod\nasync def list_sources(cls, url: str) -&gt; Iterable[Self]:\n    \"\"\"\n    List the file under the given URL.\n\n    Args:\n        url: The URL to the file.\n\n    Returns:\n        The iterable of sources from the web.\n    \"\"\"\n    return [cls(url=url)]\n</code></pre>"},{"location":"api_reference/core/sources/#ragbits.core.sources.web.WebSource.from_uri","title":"from_uri  <code>async</code> <code>classmethod</code>","text":"<pre><code>from_uri(path: str) -&gt; Iterable[Self]\n</code></pre> <p>Create WebSource instances from a URI path.</p> <p>The supported URI formats: - :////. PARAMETER DESCRIPTION <code>path</code> <p>The URI path in the format described above.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Iterable[Self]</code> <p>The iterable of sources from the web.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/sources/web.py</code> <pre><code>@classmethod\nasync def from_uri(cls, path: str) -&gt; Iterable[Self]:\n    \"\"\"\n    Create WebSource instances from a URI path.\n\n    The supported URI formats:\n    - &lt;protocol&gt;://&lt;domain&gt;/&lt;path&gt;/&lt;filename&gt;.&lt;file_extension&gt;\n\n    Args:\n        path: The URI path in the format described above.\n\n    Returns:\n        The iterable of sources from the web.\n    \"\"\"\n    return [cls(url=path)]\n</code></pre>"},{"location":"api_reference/core/vector-stores/","title":"Vector Stores","text":""},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStoreEntry","title":"ragbits.core.vector_stores.base.VectorStoreEntry","text":"<p>               Bases: <code>BaseModel</code></p> <p>An object representing a vector database entry. Contains text and/or image for embedding + metadata.</p>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStoreEntry.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: UUID\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStoreEntry.text","title":"text  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>text: str | None = None\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStoreEntry.image_bytes","title":"image_bytes  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>image_bytes: SerializableBytes | None = None\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStoreEntry.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: dict = {}\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStoreEntry.validate_metadata_serializable","title":"validate_metadata_serializable","text":"<pre><code>validate_metadata_serializable() -&gt; Self\n</code></pre> <p>Validates that metadata is JSON serializable.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If metadata contains non-serializable values.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/base.py</code> <pre><code>@pydantic.model_validator(mode=\"after\")\ndef validate_metadata_serializable(self) -&gt; Self:\n    \"\"\"\n    Validates that metadata is JSON serializable.\n\n    Raises:\n        ValueError: If metadata contains non-serializable values.\n    \"\"\"\n    try:\n        self.model_dump_json()\n    except Exception as e:\n        raise ValueError(f\"Metadata must be JSON serializable. Error: {str(e)}\") from e\n    return self\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStoreEntry.text_or_image_required","title":"text_or_image_required","text":"<pre><code>text_or_image_required() -&gt; Self\n</code></pre> <p>Validates that either text or image_bytes are provided.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If neither text nor image_bytes are provided.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/base.py</code> <pre><code>@pydantic.model_validator(mode=\"after\")\ndef text_or_image_required(self) -&gt; Self:\n    \"\"\"\n    Validates that either text or image_bytes are provided.\n\n    Raises:\n        ValueError: If neither text nor image_bytes are provided.\n    \"\"\"\n    if not self.text and not self.image_bytes:\n        raise ValueError(\"Either text or image_bytes must be provided.\")\n    return self\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStoreOptions","title":"ragbits.core.vector_stores.base.VectorStoreOptions","text":"<p>               Bases: <code>Options</code></p> <p>An object representing the options for the vector store.</p> ATTRIBUTE DESCRIPTION <code>k</code> <p>The number of entries to return.</p> <p> TYPE: <code>int</code> </p> <code>score_threshold</code> <p>The minimum similarity score for an entry to be returned. Note that this is based on score, which may be different from the raw similarity metric used by the vector store (see <code>VectorStoreResult</code> for more details).</p> <p> TYPE: <code>float | None</code> </p> <code>where</code> <p>The filter dictionary - the keys are the field names and the values are the values to filter by. Not specifying the key means no filtering.</p> <p> TYPE: <code>WhereQuery | None</code> </p>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStoreOptions.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(extra='allow', arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStoreOptions.k","title":"k  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>k: int = 5\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStoreOptions.score_threshold","title":"score_threshold  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>score_threshold: float | None = None\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStoreOptions.where","title":"where  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>where: WhereQuery | None = None\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStoreOptions.dict","title":"dict","text":"<pre><code>dict() -&gt; dict[str, Any]\n</code></pre> <p>Creates a dictionary representation of the Options instance. If a value is None, it will be replaced with a provider-specific not-given sentinel.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>A dictionary representation of the Options instance.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/options.py</code> <pre><code>def dict(self) -&gt; dict[str, Any]:  # type: ignore # mypy complains about overriding BaseModel.dict\n    \"\"\"\n    Creates a dictionary representation of the Options instance.\n    If a value is None, it will be replaced with a provider-specific not-given sentinel.\n\n    Returns:\n        A dictionary representation of the Options instance.\n    \"\"\"\n    options = self.model_dump()\n\n    return {\n        key: self._not_given if value is None or isinstance(value, NotGiven) else value\n        for key, value in options.items()\n    }\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStore","title":"ragbits.core.vector_stores.base.VectorStore","text":"<pre><code>VectorStore(default_options: OptionsT | None = None)\n</code></pre> <p>               Bases: <code>ConfigurableComponent[VectorStoreOptionsT]</code>, <code>ABC</code></p> <p>A class with an implementation of Vector Store, allowing to store and retrieve vectors by similarity function.</p> <p>Constructs a new ConfigurableComponent instance.</p> PARAMETER DESCRIPTION <code>default_options</code> <p>The default options for the component.</p> <p> TYPE: <code>OptionsT | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>def __init__(self, default_options: OptionsT | None = None) -&gt; None:\n    \"\"\"\n    Constructs a new ConfigurableComponent instance.\n\n    Args:\n        default_options: The default options for the component.\n    \"\"\"\n    self.default_options: OptionsT = default_options or self.options_cls()\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStore.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStore.options_cls","title":"options_cls  <code>instance-attribute</code>","text":"<pre><code>options_cls: type[VectorStoreOptionsT]\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStore.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = vector_stores\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStore.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'vector_store'\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStore.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStore.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStore.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStore.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStore.store","title":"store  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>store(entries: list[VectorStoreEntry]) -&gt; None\n</code></pre> <p>Store entries in the vector store.</p> PARAMETER DESCRIPTION <code>entries</code> <p>The entries to store.</p> <p> TYPE: <code>list[VectorStoreEntry]</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/base.py</code> <pre><code>@abstractmethod\nasync def store(self, entries: list[VectorStoreEntry]) -&gt; None:\n    \"\"\"\n    Store entries in the vector store.\n\n    Args:\n        entries: The entries to store.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStore.retrieve","title":"retrieve  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>retrieve(text: str, options: VectorStoreOptionsT | None = None) -&gt; list[VectorStoreResult]\n</code></pre> <p>Retrieve entries from the vector store most similar to the provided text.</p> PARAMETER DESCRIPTION <code>text</code> <p>The text to query the vector store with.</p> <p> TYPE: <code>str</code> </p> <code>options</code> <p>The options for querying the vector store.</p> <p> TYPE: <code>VectorStoreOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[VectorStoreResult]</code> <p>The entries.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/base.py</code> <pre><code>@abstractmethod\nasync def retrieve(\n    self,\n    text: str,\n    options: VectorStoreOptionsT | None = None,\n) -&gt; list[VectorStoreResult]:\n    \"\"\"\n    Retrieve entries from the vector store most similar to the provided text.\n\n    Args:\n        text: The text to query the vector store with.\n        options: The options for querying the vector store.\n\n    Returns:\n        The entries.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStore.remove","title":"remove  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>remove(ids: list[UUID]) -&gt; None\n</code></pre> <p>Remove entries from the vector store.</p> PARAMETER DESCRIPTION <code>ids</code> <p>The list of entries' IDs to remove.</p> <p> TYPE: <code>list[UUID]</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/base.py</code> <pre><code>@abstractmethod\nasync def remove(self, ids: list[UUID]) -&gt; None:\n    \"\"\"\n    Remove entries from the vector store.\n\n    Args:\n        ids: The list of entries' IDs to remove.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.base.VectorStore.list","title":"list  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>list(where: WhereQuery | None = None, limit: int | None = None, offset: int = 0) -&gt; list[VectorStoreEntry]\n</code></pre> <p>List entries from the vector store. The entries can be filtered, limited and offset.</p> PARAMETER DESCRIPTION <code>where</code> <p>The filter dictionary - the keys are the field names and the values are the values to filter by. Not specifying the key means no filtering.</p> <p> TYPE: <code>WhereQuery | None</code> DEFAULT: <code>None</code> </p> <code>limit</code> <p>The maximum number of entries to return.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>offset</code> <p>The number of entries to skip.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> RETURNS DESCRIPTION <code>list[VectorStoreEntry]</code> <p>The entries.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/base.py</code> <pre><code>@abstractmethod\nasync def list(\n    self, where: WhereQuery | None = None, limit: int | None = None, offset: int = 0\n) -&gt; list[VectorStoreEntry]:\n    \"\"\"\n    List entries from the vector store. The entries can be filtered, limited and offset.\n\n    Args:\n        where: The filter dictionary - the keys are the field names and the values are the values to filter by.\n            Not specifying the key means no filtering.\n        limit: The maximum number of entries to return.\n        offset: The number of entries to skip.\n\n    Returns:\n        The entries.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.in_memory.InMemoryVectorStore","title":"ragbits.core.vector_stores.in_memory.InMemoryVectorStore","text":"<pre><code>InMemoryVectorStore(embedder: Embedder, embedding_type: EmbeddingType = EmbeddingType.TEXT, default_options: VectorStoreOptions | None = None)\n</code></pre> <p>               Bases: <code>VectorStoreWithEmbedder[VectorStoreOptions]</code></p> <p>A simple in-memory implementation of Vector Store, storing vectors in memory.</p> <p>Constructs a new InMemoryVectorStore instance.</p> PARAMETER DESCRIPTION <code>default_options</code> <p>The default options for querying the vector store.</p> <p> TYPE: <code>VectorStoreOptions | None</code> DEFAULT: <code>None</code> </p> <code>embedder</code> <p>The embedder to use for converting entries to vectors. Can be a regular Embedder for dense vectors      or a SparseEmbedder for sparse vectors.</p> <p> TYPE: <code>Embedder</code> </p> <code>embedding_type</code> <p>Which part of the entry to embed, either text or image. The other part will be ignored.</p> <p> TYPE: <code>EmbeddingType</code> DEFAULT: <code>TEXT</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/in_memory.py</code> <pre><code>def __init__(\n    self,\n    embedder: Embedder,\n    embedding_type: EmbeddingType = EmbeddingType.TEXT,\n    default_options: VectorStoreOptions | None = None,\n) -&gt; None:\n    \"\"\"\n    Constructs a new InMemoryVectorStore instance.\n\n    Args:\n        default_options: The default options for querying the vector store.\n        embedder: The embedder to use for converting entries to vectors. Can be a regular Embedder for dense vectors\n                 or a SparseEmbedder for sparse vectors.\n        embedding_type: Which part of the entry to embed, either text or image. The other part will be ignored.\n    \"\"\"\n    super().__init__(\n        default_options=default_options,\n        embedder=embedder,\n        embedding_type=embedding_type,\n    )\n    self._entries: dict[UUID, VectorStoreEntry] = {}\n    self._embeddings: dict[UUID, list[float] | SparseVector] = {}\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.in_memory.InMemoryVectorStore.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = vector_stores\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.in_memory.InMemoryVectorStore.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'vector_store'\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.in_memory.InMemoryVectorStore.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.in_memory.InMemoryVectorStore.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls = VectorStoreOptions\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.in_memory.InMemoryVectorStore.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.in_memory.InMemoryVectorStore.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.in_memory.InMemoryVectorStore.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.in_memory.InMemoryVectorStore.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/base.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n\n    embedder_config = config.pop(\"embedder\")\n    embedder: Embedder = Embedder.subclass_from_config(ObjectConstructionConfig.model_validate(embedder_config))\n\n    return cls(**config, default_options=options, embedder=embedder)\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.in_memory.InMemoryVectorStore.store","title":"store  <code>async</code>","text":"<pre><code>store(entries: list[VectorStoreEntry]) -&gt; None\n</code></pre> <p>Store entries in the vector store.</p> PARAMETER DESCRIPTION <code>entries</code> <p>The entries to store.</p> <p> TYPE: <code>list[VectorStoreEntry]</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/in_memory.py</code> <pre><code>async def store(self, entries: list[VectorStoreEntry]) -&gt; None:\n    \"\"\"\n    Store entries in the vector store.\n\n    Args:\n        entries: The entries to store.\n    \"\"\"\n    with trace(\n        entries=entries,\n        embedder=repr(self._embedder),\n        embedding_type=self._embedding_type,\n    ) as outputs:\n        embeddings = await self._create_embeddings(entries)\n        self._embeddings.update(embeddings)\n        self._entries.update({entry.id: entry for entry in entries if entry.id in embeddings})\n        outputs.embeddings = self._embeddings\n        outputs.entries = self._entries\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.in_memory.InMemoryVectorStore.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(text: str, options: VectorStoreOptions | None = None) -&gt; list[VectorStoreResult]\n</code></pre> <p>Retrieve entries from the vector store most similar to the provided text.</p> PARAMETER DESCRIPTION <code>text</code> <p>The text to query the vector store with.</p> <p> TYPE: <code>str</code> </p> <code>options</code> <p>The options for querying the vector store.</p> <p> TYPE: <code>VectorStoreOptions | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[VectorStoreResult]</code> <p>The entries.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/in_memory.py</code> <pre><code>async def retrieve(\n    self,\n    text: str,\n    options: VectorStoreOptions | None = None,\n) -&gt; list[VectorStoreResult]:\n    \"\"\"\n    Retrieve entries from the vector store most similar to the provided text.\n\n    Args:\n        text: The text to query the vector store with.\n        options: The options for querying the vector store.\n\n    Returns:\n        The entries.\n    \"\"\"\n    merged_options = (self.default_options | options) if options else self.default_options\n    with trace(\n        text=text,\n        options=merged_options.dict(),\n        embedder=repr(self._embedder),\n        embedding_type=self._embedding_type,\n    ) as outputs:\n        query_vector = (await self._embedder.embed_text([text]))[0]\n        results: list[VectorStoreResult] = []\n\n        for entry_id, vector in self._embeddings.items():\n            entry = self._entries[entry_id]\n\n            # Apply metadata filtering\n            if merged_options.where and not all(\n                entry.metadata.get(key) == value for key, value in merged_options.where.items()\n            ):\n                continue\n\n            # Calculate score based on vector type\n            if isinstance(query_vector, SparseVector) and isinstance(vector, SparseVector):\n                # For sparse vectors, use dot product between query and document vectors\n                # Create dictionaries for efficient lookup\n                vector_dict = dict(zip(vector.indices, vector.values, strict=False))\n\n                # Calculate dot product of overlapping indices\n                score = 0.0\n                for idx, val in zip(query_vector.indices, query_vector.values, strict=False):\n                    if idx in vector_dict:\n                        score += val * vector_dict[idx]\n            else:\n                # For dense vectors, use negative L2 distance\n                query_vector_dense = cast(list[float], query_vector)\n                vector_dense = cast(list[float], vector)\n                score = -math.sqrt(\n                    sum((a - b) ** 2 for a, b in zip(vector_dense, query_vector_dense, strict=False))\n                )\n\n            result = VectorStoreResult(entry=self._entries[entry_id], vector=vector, score=score)\n            if merged_options.score_threshold is None or result.score &gt;= merged_options.score_threshold:\n                results.append(result)\n\n        outputs.results = sorted(results, key=lambda r: r.score, reverse=True)[: merged_options.k]\n        return outputs.results\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.in_memory.InMemoryVectorStore.remove","title":"remove  <code>async</code>","text":"<pre><code>remove(ids: list[UUID]) -&gt; None\n</code></pre> <p>Remove entries from the vector store.</p> PARAMETER DESCRIPTION <code>ids</code> <p>The list of entries' IDs to remove.</p> <p> TYPE: <code>list[UUID]</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/in_memory.py</code> <pre><code>@traceable\nasync def remove(self, ids: list[UUID]) -&gt; None:\n    \"\"\"\n    Remove entries from the vector store.\n\n    Args:\n        ids: The list of entries' IDs to remove.\n    \"\"\"\n    for id in ids:\n        del self._entries[id]\n        del self._embeddings[id]\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.in_memory.InMemoryVectorStore.list","title":"list  <code>async</code>","text":"<pre><code>list(where: WhereQuery | None = None, limit: int | None = None, offset: int = 0) -&gt; list[VectorStoreEntry]\n</code></pre> <p>List entries from the vector store. The entries can be filtered, limited and offset.</p> PARAMETER DESCRIPTION <code>where</code> <p>The filter dictionary - the keys are the field names and the values are the values to filter by. Not specifying the key means no filtering.</p> <p> TYPE: <code>WhereQuery | None</code> DEFAULT: <code>None</code> </p> <code>limit</code> <p>The maximum number of entries to return.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>offset</code> <p>The number of entries to skip.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> RETURNS DESCRIPTION <code>list[VectorStoreEntry]</code> <p>The entries.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/in_memory.py</code> <pre><code>@traceable\nasync def list(\n    self, where: WhereQuery | None = None, limit: int | None = None, offset: int = 0\n) -&gt; list[VectorStoreEntry]:\n    \"\"\"\n    List entries from the vector store. The entries can be filtered, limited and offset.\n\n    Args:\n        where: The filter dictionary - the keys are the field names and the values are the values to filter by.\n            Not specifying the key means no filtering.\n        limit: The maximum number of entries to return.\n        offset: The number of entries to skip.\n\n    Returns:\n        The entries.\n    \"\"\"\n    entries = iter(self._entries.values())\n\n    entries = (entry for entry in entries if entry.id in self._embeddings)\n\n    if where:\n        entries = (\n            entry for entry in entries if all(entry.metadata.get(key) == value for key, value in where.items())\n        )\n\n    if offset:\n        entries = islice(entries, offset, None)\n\n    if limit:\n        entries = islice(entries, limit)\n\n    return list(entries)\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.chroma.ChromaVectorStore","title":"ragbits.core.vector_stores.chroma.ChromaVectorStore","text":"<pre><code>ChromaVectorStore(client: ClientAPI, index_name: str, embedder: DenseEmbedder, embedding_type: EmbeddingType = EmbeddingType.TEXT, distance_method: Literal['l2', 'ip', 'cosine'] = 'cosine', default_options: VectorStoreOptions | None = None)\n</code></pre> <p>               Bases: <code>VectorStoreWithDenseEmbedder[VectorStoreOptions]</code></p> <p>Vector store implementation using Chroma.</p> <p>Constructs a new ChromaVectorStore instance.</p> PARAMETER DESCRIPTION <code>client</code> <p>The ChromaDB client.</p> <p> TYPE: <code>ClientAPI</code> </p> <code>index_name</code> <p>The name of the index.</p> <p> TYPE: <code>str</code> </p> <code>embedder</code> <p>The embedder to use for converting entries to vectors.</p> <p> TYPE: <code>DenseEmbedder</code> </p> <code>embedding_type</code> <p>Which part of the entry to embed, either text or image. The other part will be ignored.</p> <p> TYPE: <code>EmbeddingType</code> DEFAULT: <code>TEXT</code> </p> <code>distance_method</code> <p>The distance method to use.</p> <p> TYPE: <code>Literal['l2', 'ip', 'cosine']</code> DEFAULT: <code>'cosine'</code> </p> <code>default_options</code> <p>The default options for querying the vector store.</p> <p> TYPE: <code>VectorStoreOptions | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/chroma.py</code> <pre><code>def __init__(\n    self,\n    client: ClientAPI,\n    index_name: str,\n    embedder: DenseEmbedder,\n    embedding_type: EmbeddingType = EmbeddingType.TEXT,\n    distance_method: Literal[\"l2\", \"ip\", \"cosine\"] = \"cosine\",\n    default_options: VectorStoreOptions | None = None,\n) -&gt; None:\n    \"\"\"\n    Constructs a new ChromaVectorStore instance.\n\n    Args:\n        client: The ChromaDB client.\n        index_name: The name of the index.\n        embedder: The embedder to use for converting entries to vectors.\n        embedding_type: Which part of the entry to embed, either text or image. The other part will be ignored.\n        distance_method: The distance method to use.\n        default_options: The default options for querying the vector store.\n    \"\"\"\n    super().__init__(\n        default_options=default_options,\n        embedder=embedder,\n        embedding_type=embedding_type,\n    )\n    self._client = client\n    self._index_name = index_name\n    self._distance_method = distance_method\n    self._collection = self._client.get_or_create_collection(\n        name=self._index_name,\n        metadata={\"hnsw:space\": self._distance_method},\n    )\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.chroma.ChromaVectorStore.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = vector_stores\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.chroma.ChromaVectorStore.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'vector_store'\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.chroma.ChromaVectorStore.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.chroma.ChromaVectorStore.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls = VectorStoreOptions\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.chroma.ChromaVectorStore.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.chroma.ChromaVectorStore.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.chroma.ChromaVectorStore.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.chroma.ChromaVectorStore.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/chroma.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    client_options = ObjectConstructionConfig.model_validate(config[\"client\"])\n    client_cls = import_by_path(client_options.type, chromadb)\n    config[\"client\"] = client_cls(**client_options.config)\n    return super().from_config(config)\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.chroma.ChromaVectorStore.store","title":"store  <code>async</code>","text":"<pre><code>store(entries: list[VectorStoreEntry]) -&gt; None\n</code></pre> <p>Stores entries in the ChromaDB collection.</p> <p>In case entry contains both text and image embeddings, only one of them will get embedded - text by default, unless the option <code>prefer_image</code> is set to True.</p> PARAMETER DESCRIPTION <code>entries</code> <p>The entries to store.</p> <p> TYPE: <code>list[VectorStoreEntry]</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/chroma.py</code> <pre><code>async def store(self, entries: list[VectorStoreEntry]) -&gt; None:\n    \"\"\"\n    Stores entries in the ChromaDB collection.\n\n    In case entry contains both text and image embeddings,\n    only one of them will get embedded - text by default, unless\n    the option `prefer_image` is set to True.\n\n    Args:\n        entries: The entries to store.\n    \"\"\"\n    with trace(\n        entries=entries,\n        index_name=self._index_name,\n        collection=self._collection,\n        distance_method=self._distance_method,\n        embedder=repr(self._embedder),\n        embedding_type=self._embedding_type,\n    ):\n        if not entries:\n            return\n\n        ids = []\n        documents = []\n        metadatas: list[Mapping] = []\n        embeddings: list[Sequence[float]] = []\n\n        raw_embeddings = await self._create_embeddings(entries)\n        for entry in entries:\n            if not raw_embeddings.get(entry.id):\n                continue\n\n            # The class doesn't support sparse embeddings, so we can safely cast\n            embedding = cast(list[float], raw_embeddings[entry.id])\n            embeddings.append(embedding)\n            ids.append(str(entry.id))\n            documents.append(entry.text or \"\")\n            metadatas.append(\n                self._flatten_metadata(\n                    {\n                        **entry.metadata,\n                        **{\n                            \"__image\": entry.image_bytes.hex() if entry.image_bytes else None,\n                        },\n                    }\n                )\n            )\n\n        self._collection.add(\n            ids=ids,\n            embeddings=embeddings,\n            metadatas=metadatas,\n            documents=documents,\n        )\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.chroma.ChromaVectorStore.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(text: str, options: VectorStoreOptions | None = None) -&gt; list[VectorStoreResult]\n</code></pre> <p>Retrieves entries from the ChromaDB collection.</p> PARAMETER DESCRIPTION <code>text</code> <p>The text to query the vector store with.</p> <p> TYPE: <code>str</code> </p> <code>options</code> <p>The options for querying the vector store.</p> <p> TYPE: <code>VectorStoreOptions | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[VectorStoreResult]</code> <p>The retrieved entries.</p> RAISES DESCRIPTION <code>MetadataNotFoundError</code> <p>If the metadata is not found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/chroma.py</code> <pre><code>async def retrieve(\n    self,\n    text: str,\n    options: VectorStoreOptions | None = None,\n) -&gt; list[VectorStoreResult]:\n    \"\"\"\n    Retrieves entries from the ChromaDB collection.\n\n    Args:\n        text: The text to query the vector store with.\n        options: The options for querying the vector store.\n\n    Returns:\n        The retrieved entries.\n\n    Raises:\n        MetadataNotFoundError: If the metadata is not found.\n    \"\"\"\n    merged_options = (self.default_options | options) if options else self.default_options\n\n    with trace(\n        text=text,\n        options=merged_options.dict(),\n        index_name=self._index_name,\n        collection=self._collection,\n        distance_method=self._distance_method,\n        embedder=repr(self._embedder),\n        embedding_type=self._embedding_type,\n    ) as outputs:\n        query_vector = (await self._embedder.embed_text([text]))[0]\n        query_vector = cast(list[float], query_vector)\n\n        where_dict = self._create_chroma_filter(merged_options.where)\n\n        results = self._collection.query(\n            query_embeddings=query_vector,\n            n_results=merged_options.k,\n            include=IncludeMetadataDocumentsEmbeddingsDistances,\n            where=where_dict,\n        )\n\n        ids = [id for batch in results.get(\"ids\", []) for id in batch]\n        scores = [self._calculate_score(distance) for batch in results.get(\"distances\") or [] for distance in batch]\n        documents = [document for batch in results.get(\"documents\") or [] for document in batch]\n        embeddings = [embedding for batch in results.get(\"embeddings\") or [] for embedding in batch]\n\n        metadatas: Sequence = [dict(metadata) for batch in results.get(\"metadatas\") or [] for metadata in batch]\n\n        # Convert metadata back to nested structure\n        unflattened_metadatas: list[dict] = [unflatten_dict(metadata) if metadata else {} for metadata in metadatas]\n\n        images: list[bytes | None] = [metadata.pop(\"__image\", None) for metadata in unflattened_metadatas]\n\n        outputs.results = [\n            VectorStoreResult(\n                score=score,\n                vector=vector,\n                entry=VectorStoreEntry(\n                    id=id,\n                    text=document,\n                    image_bytes=image,\n                    metadata=metadata,\n                ),\n            )\n            for id, metadata, score, document, image, vector in zip(\n                ids, unflattened_metadatas, scores, documents, images, embeddings, strict=True\n            )\n            if merged_options.score_threshold is None or score &gt;= merged_options.score_threshold\n        ]\n\n        return outputs.results\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.chroma.ChromaVectorStore.remove","title":"remove  <code>async</code>","text":"<pre><code>remove(ids: list[UUID]) -&gt; None\n</code></pre> <p>Remove entries from the vector store.</p> PARAMETER DESCRIPTION <code>ids</code> <p>The list of entries' IDs to remove.</p> <p> TYPE: <code>list[UUID]</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/chroma.py</code> <pre><code>async def remove(self, ids: list[UUID]) -&gt; None:\n    \"\"\"\n    Remove entries from the vector store.\n\n    Args:\n        ids: The list of entries' IDs to remove.\n    \"\"\"\n    with trace(ids=ids, collection=self._collection, index_name=self._index_name):\n        self._collection.delete(ids=[str(id) for id in ids])\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.chroma.ChromaVectorStore.list","title":"list  <code>async</code>","text":"<pre><code>list(where: WhereQuery | None = None, limit: int | None = None, offset: int = 0) -&gt; list[VectorStoreEntry]\n</code></pre> <p>List entries from the vector store. The entries can be filtered, limited and offset.</p> PARAMETER DESCRIPTION <code>where</code> <p>The filter dictionary - the keys are the field names and the values are the values to filter by. Not specifying the key means no filtering.</p> <p> TYPE: <code>WhereQuery | None</code> DEFAULT: <code>None</code> </p> <code>limit</code> <p>The maximum number of entries to return.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>offset</code> <p>The number of entries to skip.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> RETURNS DESCRIPTION <code>list[VectorStoreEntry]</code> <p>The entries.</p> RAISES DESCRIPTION <code>MetadataNotFoundError</code> <p>If the metadata is not found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/chroma.py</code> <pre><code>async def list(\n    self, where: WhereQuery | None = None, limit: int | None = None, offset: int = 0\n) -&gt; list[VectorStoreEntry]:\n    \"\"\"\n    List entries from the vector store. The entries can be filtered, limited and offset.\n\n    Args:\n        where: The filter dictionary - the keys are the field names and the values are the values to filter by.\n            Not specifying the key means no filtering.\n        limit: The maximum number of entries to return.\n        offset: The number of entries to skip.\n\n    Returns:\n        The entries.\n\n    Raises:\n        MetadataNotFoundError: If the metadata is not found.\n    \"\"\"\n    with trace(\n        where=where, collection=self._collection, index_name=self._index_name, limit=limit, offset=offset\n    ) as outputs:\n        where_chroma = self._create_chroma_filter(where)\n\n        results = self._collection.get(\n            where=where_chroma,\n            limit=limit,\n            offset=offset,\n            include=IncludeMetadataDocuments,\n        )\n\n        ids = results.get(\"ids\") or []\n        documents = results.get(\"documents\") or []\n        metadatas: Sequence = results.get(\"metadatas\") or []\n\n        # Convert metadata back to nested structure\n        unflattened_metadatas: list[dict] = [unflatten_dict(metadata) if metadata else {} for metadata in metadatas]\n\n        images: list[bytes | None] = [metadata.pop(\"__image\", None) for metadata in unflattened_metadatas]\n\n        outputs.results = [\n            VectorStoreEntry(\n                id=UUID(id),\n                text=document,\n                metadata=metadata,\n                image_bytes=image,\n            )\n            for id, metadata, document, image in zip(ids, unflattened_metadatas, documents, images, strict=True)\n        ]\n\n        return outputs.results\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.qdrant.QdrantVectorStore","title":"ragbits.core.vector_stores.qdrant.QdrantVectorStore","text":"<pre><code>QdrantVectorStore(client: AsyncQdrantClient, index_name: str, embedder: Embedder, embedding_type: EmbeddingType = EmbeddingType.TEXT, distance_method: Distance = Distance.COSINE, default_options: VectorStoreOptions | None = None)\n</code></pre> <p>               Bases: <code>VectorStoreWithEmbedder[VectorStoreOptions]</code></p> <p>Vector store implementation using Qdrant.</p> <p>Constructs a new QdrantVectorStore instance.</p> PARAMETER DESCRIPTION <code>client</code> <p>An instance of the Qdrant client.</p> <p> TYPE: <code>AsyncQdrantClient</code> </p> <code>index_name</code> <p>The name of the index.</p> <p> TYPE: <code>str</code> </p> <code>embedder</code> <p>The embedder to use for converting entries to vectors. Can be a regular Embedder for dense vectors      or a SparseEmbedder for sparse vectors.</p> <p> TYPE: <code>Embedder</code> </p> <code>embedding_type</code> <p>Which part of the entry to embed, either text or image. The other part will be ignored.</p> <p> TYPE: <code>EmbeddingType</code> DEFAULT: <code>TEXT</code> </p> <code>distance_method</code> <p>The distance metric to use when creating the collection.</p> <p> TYPE: <code>Distance</code> DEFAULT: <code>COSINE</code> </p> <code>default_options</code> <p>The default options for querying the vector store.</p> <p> TYPE: <code>VectorStoreOptions | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/qdrant.py</code> <pre><code>def __init__(\n    self,\n    client: AsyncQdrantClient,\n    index_name: str,\n    embedder: Embedder,\n    embedding_type: EmbeddingType = EmbeddingType.TEXT,\n    distance_method: Distance = Distance.COSINE,\n    default_options: VectorStoreOptions | None = None,\n) -&gt; None:\n    \"\"\"\n    Constructs a new QdrantVectorStore instance.\n\n    Args:\n        client: An instance of the Qdrant client.\n        index_name: The name of the index.\n        embedder: The embedder to use for converting entries to vectors. Can be a regular Embedder for dense vectors\n                 or a SparseEmbedder for sparse vectors.\n        embedding_type: Which part of the entry to embed, either text or image. The other part will be ignored.\n        distance_method: The distance metric to use when creating the collection.\n        default_options: The default options for querying the vector store.\n    \"\"\"\n    super().__init__(\n        default_options=default_options,\n        embedder=embedder,\n        embedding_type=embedding_type,\n    )\n    self._client = client\n    self._index_name = index_name\n    self._distance_method = distance_method\n    self.is_sparse = isinstance(embedder, SparseEmbedder)\n    self._vector_name = \"sparse\" if self.is_sparse else \"dense\"\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.qdrant.QdrantVectorStore.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = vector_stores\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.qdrant.QdrantVectorStore.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'vector_store'\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.qdrant.QdrantVectorStore.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.qdrant.QdrantVectorStore.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls = VectorStoreOptions\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.qdrant.QdrantVectorStore.is_sparse","title":"is_sparse  <code>instance-attribute</code>","text":"<pre><code>is_sparse = isinstance(embedder, SparseEmbedder)\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.qdrant.QdrantVectorStore.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.qdrant.QdrantVectorStore.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.qdrant.QdrantVectorStore.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.qdrant.QdrantVectorStore.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/qdrant.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    client_options = ObjectConstructionConfig.model_validate(config[\"client\"])\n    client_cls = import_by_path(client_options.type, qdrant_client)\n    if \"limits\" in client_options.config:\n        limits = httpx.Limits(**client_options.config[\"limits\"])\n        client_options.config[\"limits\"] = limits\n    config[\"client\"] = client_cls(**client_options.config)\n    return super().from_config(config)\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.qdrant.QdrantVectorStore.store","title":"store  <code>async</code>","text":"<pre><code>store(entries: list[VectorStoreEntry]) -&gt; None\n</code></pre> <p>Stores vector entries in the Qdrant collection.</p> PARAMETER DESCRIPTION <code>entries</code> <p>List of VectorStoreEntry objects to store</p> <p> TYPE: <code>list[VectorStoreEntry]</code> </p> RAISES DESCRIPTION <code>QdrantException</code> <p>If upload to collection fails.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/qdrant.py</code> <pre><code>async def store(self, entries: list[VectorStoreEntry]) -&gt; None:\n    \"\"\"\n    Stores vector entries in the Qdrant collection.\n\n    Args:\n        entries: List of VectorStoreEntry objects to store\n\n    Raises:\n        QdrantException: If upload to collection fails.\n    \"\"\"\n    with trace(\n        entries=entries,\n        index_name=self._index_name,\n        distance_method=self._distance_method,\n        embedder=repr(self._embedder),\n        embedding_type=self._embedding_type,\n    ):\n        if not entries:\n            return\n\n        embeddings: dict = await self._create_embeddings(entries)\n\n        if not await self._client.collection_exists(self._index_name):\n            vectors_config = {}\n            sparse_vectors_config = None\n            if self.is_sparse:\n                sparse_vectors_config = {self._vector_name: models.SparseVectorParams()}\n            else:\n                vector_size = len(next(iter(embeddings.values())))\n                vectors_config = {self._vector_name: VectorParams(size=vector_size, distance=self._distance_method)}\n\n            await self._client.create_collection(\n                collection_name=self._index_name,\n                vectors_config=vectors_config,\n                sparse_vectors_config=sparse_vectors_config,\n            )\n\n        points = (\n            models.PointStruct(\n                id=str(entry.id),\n                vector={self._vector_name: self._to_qdrant_vector(embeddings[entry.id])},  # type: ignore\n                payload=entry.model_dump(exclude_none=True, mode=\"json\"),\n            )\n            for entry in entries\n            if entry.id in embeddings\n        )\n\n        self._client.upload_points(\n            collection_name=self._index_name,\n            points=points,\n            wait=True,\n        )\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.qdrant.QdrantVectorStore.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(text: str, options: VectorStoreOptions | None = None) -&gt; list[VectorStoreResult]\n</code></pre> <p>Retrieves entries from the Qdrant collection based on vector similarity.</p> PARAMETER DESCRIPTION <code>text</code> <p>The text to query the vector store with.</p> <p> TYPE: <code>str</code> </p> <code>options</code> <p>The options for querying the vector store.</p> <p> TYPE: <code>VectorStoreOptions | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[VectorStoreResult]</code> <p>The retrieved entries.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/qdrant.py</code> <pre><code>async def retrieve(\n    self,\n    text: str,\n    options: VectorStoreOptions | None = None,\n) -&gt; list[VectorStoreResult]:\n    \"\"\"\n    Retrieves entries from the Qdrant collection based on vector similarity.\n\n    Args:\n        text: The text to query the vector store with.\n        options: The options for querying the vector store.\n\n    Returns:\n        The retrieved entries.\n    \"\"\"\n    merged_options = (self.default_options | options) if options else self.default_options\n\n    # Ragbits has a \"larger is better\" convention for all scores, so we need to reverse the score if the distance\n    # method is \"smaller is better\".\n    reverse_score = distance_to_order(self._distance_method) == DistanceOrder.SMALLER_IS_BETTER\n    score_multiplier = -1 if reverse_score else 1\n    score_threshold = (\n        None if merged_options.score_threshold is None else merged_options.score_threshold * score_multiplier\n    )\n    with trace(\n        text=text,\n        options=merged_options.dict(),\n        index_name=self._index_name,\n        distance_method=self._distance_method,\n        embedder=repr(self._embedder),\n        embedding_type=self._embedding_type,\n    ) as outputs:\n        query_vector = (await self._embedder.embed_text([text]))[0]\n\n        query_results = await self._client.query_points(\n            collection_name=self._index_name,\n            query=self._to_qdrant_vector(query_vector),\n            using=self._vector_name,\n            limit=merged_options.k,\n            score_threshold=score_threshold,\n            with_payload=True,\n            with_vectors=True,\n            query_filter=self._create_qdrant_filter(merged_options.where),\n        )\n\n        outputs.results = []\n        for point in query_results.points:\n            entry = VectorStoreEntry.model_validate(point.payload)\n\n            outputs.results.append(\n                VectorStoreResult(\n                    entry=entry,\n                    score=point.score * score_multiplier,\n                    vector=self._from_qdrant_vector(point.vector[self._vector_name])\n                    if isinstance(point.vector, dict)\n                    else self._from_qdrant_vector(point.vector),\n                )\n            )\n\n        return outputs.results\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.qdrant.QdrantVectorStore.remove","title":"remove  <code>async</code>","text":"<pre><code>remove(ids: list[UUID]) -&gt; None\n</code></pre> <p>Remove entries from the vector store.</p> PARAMETER DESCRIPTION <code>ids</code> <p>The list of entries' IDs to remove.</p> <p> TYPE: <code>list[UUID]</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If collection named <code>self._index_name</code> is not present in the vector store.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/qdrant.py</code> <pre><code>async def remove(self, ids: list[UUID]) -&gt; None:\n    \"\"\"\n    Remove entries from the vector store.\n\n    Args:\n        ids: The list of entries' IDs to remove.\n\n    Raises:\n        ValueError: If collection named `self._index_name` is not present in the vector store.\n    \"\"\"\n    with (\n        trace(ids=ids, index_name=self._index_name),\n        contextlib.suppress(KeyError),  # it's ok if a point already doesn't exist\n    ):\n        await self._client.delete(\n            collection_name=self._index_name,\n            points_selector=models.PointIdsList(points=[str(id) for id in ids]),\n        )\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.qdrant.QdrantVectorStore.list","title":"list  <code>async</code>","text":"<pre><code>list(where: WhereQuery | None = None, limit: int | None = None, offset: int = 0) -&gt; list[VectorStoreEntry]\n</code></pre> <p>List entries from the vector store. The entries can be filtered, limited and offset.</p> PARAMETER DESCRIPTION <code>where</code> <p>Conditions for filtering results. Reference: https://qdrant.tech/documentation/concepts/filtering</p> <p> TYPE: <code>WhereQuery | None</code> DEFAULT: <code>None</code> </p> <code>limit</code> <p>The maximum number of entries to return.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>offset</code> <p>The number of entries to skip.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> RETURNS DESCRIPTION <code>list[VectorStoreEntry]</code> <p>The entries.</p> RAISES DESCRIPTION <code>MetadataNotFoundError</code> <p>If the metadata is not found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/qdrant.py</code> <pre><code>async def list(\n    self,\n    where: WhereQuery | None = None,\n    limit: int | None = None,\n    offset: int = 0,\n) -&gt; list[VectorStoreEntry]:\n    \"\"\"\n    List entries from the vector store. The entries can be filtered, limited and offset.\n\n    Args:\n        where: Conditions for filtering results.\n            Reference: https://qdrant.tech/documentation/concepts/filtering\n        limit: The maximum number of entries to return.\n        offset: The number of entries to skip.\n\n    Returns:\n        The entries.\n\n    Raises:\n        MetadataNotFoundError: If the metadata is not found.\n    \"\"\"\n    with trace(where=where, index_name=self._index_name, limit=limit, offset=offset) as outputs:\n        collection_exists = await self._client.collection_exists(collection_name=self._index_name)\n        if not collection_exists:\n            return []\n\n        limit = limit or (await self._client.count(collection_name=self._index_name)).count\n        limit = max(1, limit)\n\n        qdrant_filter = self._create_qdrant_filter(where) if where else None\n\n        results = await self._client.query_points(\n            collection_name=self._index_name,\n            query_filter=qdrant_filter,\n            limit=limit,\n            offset=offset,\n            with_payload=True,\n            with_vectors=True,\n        )\n\n        outputs.results = [VectorStoreEntry.model_validate(point.payload) for point in results.points]\n\n        return outputs.results\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.pgvector.PgVectorStore","title":"ragbits.core.vector_stores.pgvector.PgVectorStore","text":"<pre><code>PgVectorStore(client: Pool, table_name: str, embedder: Embedder, vector_size: int | None = None, embedding_type: EmbeddingType = EmbeddingType.TEXT, distance_method: str | None = None, is_hnsw: bool = True, params: dict | None = None, default_options: VectorStoreOptions | None = None)\n</code></pre> <p>               Bases: <code>VectorStoreWithEmbedder[VectorStoreOptions]</code></p> <p>Vector store implementation using [pgvector]</p> <p>Constructs a new PgVectorStore instance.</p> PARAMETER DESCRIPTION <code>client</code> <p>The pgVector database connection pool.</p> <p> TYPE: <code>Pool</code> </p> <code>table_name</code> <p>The name of the table.</p> <p> TYPE: <code>str</code> </p> <code>embedder</code> <p>The embedder to use for converting entries to vectors.</p> <p> TYPE: <code>Embedder</code> </p> <code>vector_size</code> <p>The size of the vectors. If None, will be determined automatically from the embedder.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>embedding_type</code> <p>Which part of the entry to embed, either text or image. The other part will be ignored.</p> <p> TYPE: <code>EmbeddingType</code> DEFAULT: <code>TEXT</code> </p> <code>distance_method</code> <p>The distance method to use, default is \"cosine\" for dense vectors and \"sparsevec_l2\" for sparse vectors.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>is_hnsw</code> <p>if hnsw or ivfflat indexing should be used</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>params</code> <p>The parameters for the HNSW index. If None, the default parameters will be used.</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>default_options</code> <p>The default options for querying the vector store.</p> <p> TYPE: <code>VectorStoreOptions | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/pgvector.py</code> <pre><code>def __init__(\n    self,\n    client: asyncpg.Pool,\n    table_name: str,\n    embedder: Embedder,\n    vector_size: int | None = None,\n    embedding_type: EmbeddingType = EmbeddingType.TEXT,\n    distance_method: str | None = None,\n    is_hnsw: bool = True,\n    params: dict | None = None,\n    default_options: VectorStoreOptions | None = None,\n) -&gt; None:\n    \"\"\"\n    Constructs a new PgVectorStore instance.\n\n    Args:\n        client: The pgVector database connection pool.\n        table_name: The name of the table.\n        embedder: The embedder to use for converting entries to vectors.\n        vector_size: The size of the vectors. If None, will be determined automatically from the embedder.\n        embedding_type: Which part of the entry to embed, either text or image. The other part will be ignored.\n        distance_method: The distance method to use, default is \"cosine\" for dense vectors\n            and \"sparsevec_l2\" for sparse vectors.\n        is_hnsw: if hnsw or ivfflat indexing should be used\n        params: The parameters for the HNSW index. If None, the default parameters will be used.\n        default_options: The default options for querying the vector store.\n    \"\"\"\n    (\n        super().__init__(\n            default_options=default_options,\n            embedder=embedder,\n            embedding_type=embedding_type,\n        ),\n    )\n\n    if not re.match(r\"^[a-zA-Z_][a-zA-Z0-9_]*$\", table_name):\n        raise ValueError(f\"Invalid table name: {table_name}\")\n    if vector_size is not None and (not isinstance(vector_size, int) or vector_size &lt;= 0):\n        raise ValueError(\"Vector size must be a positive integer.\")\n\n    if params is None and is_hnsw:\n        params = {\"m\": 4, \"ef_construction\": 10}\n    elif params is None and not is_hnsw:\n        params = {\"lists\": 100}\n    elif not isinstance(params, dict):\n        raise ValueError(\"params must be a dictionary.\")\n    elif \"m\" not in params or \"ef_construction\" not in params and is_hnsw:\n        raise ValueError(\"params must contain 'm' and 'ef_construction' keys for hnsw indexing.\")\n    elif not isinstance(params[\"m\"], int) or params[\"m\"] &lt;= 0 and is_hnsw:\n        raise ValueError(\"m must be a positive integer for hnsw indexing.\")\n    elif not isinstance(params[\"ef_construction\"], int) or params[\"ef_construction\"] &lt;= 0 and is_hnsw:\n        raise ValueError(\"ef_construction must be a positive integer for hnsw indexing.\")\n    elif \"lists\" not in params and not is_hnsw:\n        raise ValueError(\"params must contain 'lists' key for IVFFlat indexing.\")\n    elif not isinstance(params[\"lists\"], int) or params[\"lists\"] &lt;= 0 and not is_hnsw:\n        raise ValueError(\"lists must be a positive integer for IVFFlat indexing.\")\n\n    if distance_method is None:\n        distance_method = \"sparsevec_l2\" if isinstance(embedder, SparseEmbedder) else \"cosine\"\n    self._client = client\n    self._table_name = table_name\n    self._vector_size = vector_size\n    self._vector_size_info: VectorSize | None = None\n    self._distance_method = distance_method\n    self._indexing_params = params\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.pgvector.PgVectorStore.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = vector_stores\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.pgvector.PgVectorStore.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'vector_store'\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.pgvector.PgVectorStore.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.pgvector.PgVectorStore.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls = VectorStoreOptions\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.pgvector.PgVectorStore.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.pgvector.PgVectorStore.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.pgvector.PgVectorStore.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.pgvector.PgVectorStore.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/base.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n\n    embedder_config = config.pop(\"embedder\")\n    embedder: Embedder = Embedder.subclass_from_config(ObjectConstructionConfig.model_validate(embedder_config))\n\n    return cls(**config, default_options=options, embedder=embedder)\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.pgvector.PgVectorStore.create_table","title":"create_table  <code>async</code>","text":"<pre><code>create_table() -&gt; None\n</code></pre> <p>Create a pgVector table with an HNSW/IVFFlat index for given similarity.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/pgvector.py</code> <pre><code>async def create_table(self) -&gt; None:\n    \"\"\"\n    Create a pgVector table with an HNSW/IVFFlat index for given similarity.\n    \"\"\"\n    vector_size = await self._get_vector_size()\n\n    with trace(\n        table_name=self._table_name,\n        distance_method=self._distance_method,\n        vector_size=vector_size,\n        hnsw_index_parameters=self._indexing_params,\n    ):\n        distance = DISTANCE_OPS[self._distance_method].function_name\n        create_vector_extension = \"CREATE EXTENSION IF NOT EXISTS vector;\"\n        # _table_name and has been validated in the class constructor, and it is a valid table name.\n        # vector_size has been validated in the class constructor or obtained from embedder,\n        # and it is a valid vector size.\n\n        is_sparse = isinstance(self._embedder, SparseEmbedder)\n\n        # Check vector size\n        # if greater than 2000 then choose type HALFVEC\n        # More info: https://github.com/pgvector/pgvector\n        vector_func = (\n            \"HALFVEC\"\n            if vector_size &gt; MAX_VECTOR_SIZE and re.search(\"halfvec\", distance)\n            else \"VECTOR\"\n            if not is_sparse\n            else \"SPARSEVEC\"\n        )\n\n        create_table_query = f\"\"\"\n        CREATE TABLE {self._table_name}\n        (id UUID, text TEXT, image_bytes BYTEA, vector {vector_func}({vector_size}), metadata JSONB);\n        \"\"\"\n        # _idexing_params has been validated in the class constructor, and it is valid dict[str,int].\n        if \"lists\" in self._indexing_params:\n            index_type = \"ivfflat\"\n            index_params = f\"(lists = {self._indexing_params['lists']});\"\n        else:\n            index_type = \"hnsw\"\n            index_params = (\n                f\"(m = {self._indexing_params['m']}, ef_construction = {self._indexing_params['ef_construction']});\"\n            )\n\n        create_index_query = f\"\"\"\n        CREATE INDEX {self._table_name + \"_\" + index_type + \"_idx\"} ON {self._table_name}\n        USING {index_type} (vector {distance})\n        WITH {index_params}\n        \"\"\"\n\n        if await self._check_table_exists():\n            print(f\"Table {self._table_name} already exist!\")\n            return\n        async with self._client.acquire() as conn:\n            await conn.execute(create_vector_extension)\n\n            try:\n                async with conn.transaction():\n                    await conn.execute(create_table_query)\n                    await conn.execute(create_index_query)\n\n                print(\"Table and index created!\")\n            except Exception as e:\n                print(f\"Failed to create table and index: {e}\")\n                raise\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.pgvector.PgVectorStore.store","title":"store  <code>async</code>","text":"<pre><code>store(entries: list[VectorStoreEntry]) -&gt; None\n</code></pre> <p>Stores entries in the pgVector collection.</p> PARAMETER DESCRIPTION <code>entries</code> <p>The entries to store.</p> <p> TYPE: <code>list[VectorStoreEntry]</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/pgvector.py</code> <pre><code>async def store(self, entries: list[VectorStoreEntry]) -&gt; None:\n    \"\"\"\n    Stores entries in the pgVector collection.\n\n    Args:\n        entries: The entries to store.\n    \"\"\"\n    if not entries:\n        return\n\n    # Ensure vector size is determined before processing\n    vector_size = await self._get_vector_size()\n\n    # _table_name has been validated in the class constructor, and it is a valid table name.\n    insert_query = f\"\"\"\n    INSERT INTO {self._table_name} (id, text, image_bytes, vector, metadata)\n    VALUES ($1, $2, $3, $4, $5)\n    \"\"\"  # noqa S608\n    with trace(\n        table_name=self._table_name,\n        entries=entries,\n        vector_size=vector_size,\n        embedder=repr(self._embedder),\n        embedding_type=self._embedding_type,\n    ):\n        embeddings = await self._create_embeddings(entries)\n        exists = await self._check_table_exists()\n        if not exists:\n            print(f\"Table {self._table_name} does not exist. Creating the table.\")\n            try:\n                await self.create_table()\n            except Exception as e:\n                print(f\"Failed to handle missing table: {e}\")\n                return\n\n        async with self._client.acquire() as conn:\n            for entry in entries:\n                if entry.id not in embeddings:\n                    continue\n\n                await conn.execute(\n                    insert_query,\n                    str(entry.id),\n                    entry.text,\n                    entry.image_bytes,\n                    self._vector_to_string(embeddings[entry.id]),\n                    json.dumps(entry.metadata, default=pydantic_encoder),\n                )\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.pgvector.PgVectorStore.remove","title":"remove  <code>async</code>","text":"<pre><code>remove(ids: list[UUID]) -&gt; None\n</code></pre> <p>Remove entries from the vector store.</p> PARAMETER DESCRIPTION <code>ids</code> <p>The list of entries' IDs to remove.</p> <p> TYPE: <code>list[UUID]</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/pgvector.py</code> <pre><code>async def remove(self, ids: list[UUID]) -&gt; None:\n    \"\"\"\n    Remove entries from the vector store.\n\n    Args:\n        ids: The list of entries' IDs to remove.\n    \"\"\"\n    if not ids:\n        print(\"No IDs provided, nothing to remove\")\n        return\n    # _table_name has been validated in the class constructor, and it is a valid table name.\n    remove_query = f\"\"\"\n    DELETE FROM {self._table_name}\n    WHERE id = ANY($1)\n    \"\"\"  # noqa S608\n    with trace(table_name=self._table_name, ids=ids):\n        try:\n            async with self._client.acquire() as conn:\n                await conn.execute(remove_query, ids)\n        except asyncpg.exceptions.UndefinedTableError:\n            print(f\"Table {self._table_name} does not exist.\")\n            return\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.pgvector.PgVectorStore.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(text: str, options: VectorStoreOptionsT | None = None) -&gt; list[VectorStoreResult]\n</code></pre> <p>Retrieves entries from the pgVector collection.</p> PARAMETER DESCRIPTION <code>text</code> <p>The text to query the vector store with.</p> <p> TYPE: <code>str</code> </p> <code>options</code> <p>The options for querying the vector store.</p> <p> TYPE: <code>VectorStoreOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[VectorStoreResult]</code> <p>The retrieved entries.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/pgvector.py</code> <pre><code>async def retrieve(\n    self,\n    text: str,\n    options: VectorStoreOptionsT | None = None,\n) -&gt; list[VectorStoreResult]:\n    \"\"\"\n    Retrieves entries from the pgVector collection.\n\n    Args:\n        text: The text to query the vector store with.\n        options: The options for querying the vector store.\n\n    Returns:\n        The retrieved entries.\n    \"\"\"\n    merged_options = (self.default_options | options) if options else self.default_options\n\n    # Ensure vector size is determined before processing\n    vector_size = await self._get_vector_size()\n\n    with trace(\n        text=text,\n        options=merged_options.dict(),\n        table_name=self._table_name,\n        vector_size=vector_size,\n        distance_method=self._distance_method,\n        embedder=repr(self._embedder),\n        embedding_type=self._embedding_type,\n    ) as outputs:\n        query_vector = (await self._embedder.embed_text([text]))[0]\n        query, values = self._create_retrieve_query(query_vector, merged_options)\n\n        try:\n            async with self._client.acquire() as conn:\n                results = await conn.fetch(query, *values)\n\n            outputs.results = [\n                VectorStoreResult(\n                    entry=VectorStoreEntry(\n                        id=record[\"id\"],\n                        text=record[\"text\"],\n                        image_bytes=record[\"image_bytes\"],\n                        metadata=json.loads(record[\"metadata\"]),\n                    ),\n                    vector=self._string_to_vector(record[\"vector\"]),\n                    score=record[\"score\"],\n                )\n                for record in results\n            ]\n\n        except asyncpg.exceptions.UndefinedTableError:\n            print(f\"Table {self._table_name} does not exist.\")\n            outputs.results = []\n        return outputs.results\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.pgvector.PgVectorStore.list","title":"list  <code>async</code>","text":"<pre><code>list(where: WhereQuery | None = None, limit: int | None = None, offset: int = 0) -&gt; list[VectorStoreEntry]\n</code></pre> <p>List entries from the vector store. The entries can be filtered, limited and offset.</p> PARAMETER DESCRIPTION <code>where</code> <p>The filter dictionary - the keys are the field names and the values are the values to filter by. Not specifying the key means no filtering.</p> <p> TYPE: <code>WhereQuery | None</code> DEFAULT: <code>None</code> </p> <code>limit</code> <p>The maximum number of entries to return.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>offset</code> <p>The number of entries to skip.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> RETURNS DESCRIPTION <code>list[VectorStoreEntry]</code> <p>The entries.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/pgvector.py</code> <pre><code>async def list(\n    self, where: WhereQuery | None = None, limit: int | None = None, offset: int = 0\n) -&gt; list[VectorStoreEntry]:\n    \"\"\"\n    List entries from the vector store. The entries can be filtered, limited and offset.\n\n    Args:\n        where: The filter dictionary - the keys are the field names and the values are the values to filter by.\n            Not specifying the key means no filtering.\n        limit: The maximum number of entries to return.\n        offset: The number of entries to skip.\n\n    Returns:\n        The entries.\n    \"\"\"\n    with trace(table=self._table_name, query=where, limit=limit, offset=offset) as outputs:\n        list_query, values = self._create_list_query(where, limit, offset)\n        try:\n            async with self._client.acquire() as conn:\n                results = await conn.fetch(list_query, *values)\n            outputs.listed_entries = [\n                VectorStoreEntry(\n                    id=record[\"id\"],\n                    text=record[\"text\"],\n                    image_bytes=record[\"image_bytes\"],\n                    metadata=json.loads(record[\"metadata\"]),\n                )\n                for record in results\n            ]\n\n        except asyncpg.exceptions.UndefinedTableError:\n            print(f\"Table {self._table_name} does not exist.\")\n            outputs.listed_entries = []\n        return outputs.listed_entries\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.weaviate.WeaviateVectorStore","title":"ragbits.core.vector_stores.weaviate.WeaviateVectorStore","text":"<pre><code>WeaviateVectorStore(client: WeaviateAsyncClient, index_name: str, embedder: Embedder, embedding_type: EmbeddingType = EmbeddingType.TEXT, distance_method: VectorDistances = VectorDistances.COSINE, default_options: WeaviateVectorStoreOptions | None = None)\n</code></pre> <p>               Bases: <code>VectorStoreWithEmbedder[WeaviateVectorStoreOptions]</code></p> <p>Vector store implementation using Weaviate.</p> <p>Constructs a new WeaviateVectorStore instance.</p> PARAMETER DESCRIPTION <code>client</code> <p>An instance of the Weaviate client.</p> <p> TYPE: <code>WeaviateAsyncClient</code> </p> <code>index_name</code> <p>The name of the index.</p> <p> TYPE: <code>str</code> </p> <code>embedder</code> <p>The embedder to use for converting entries to vectors. Can be a regular Embedder for dense vectors      or a SparseEmbedder for sparse vectors.</p> <p> TYPE: <code>Embedder</code> </p> <code>embedding_type</code> <p>Which part of the entry to embed, either text or image. The other part will be ignored.</p> <p> TYPE: <code>EmbeddingType</code> DEFAULT: <code>TEXT</code> </p> <code>distance_method</code> <p>The distance metric to use when creating the collection.</p> <p> TYPE: <code>VectorDistances</code> DEFAULT: <code>COSINE</code> </p> <code>default_options</code> <p>The default options for querying the vector store.</p> <p> TYPE: <code>WeaviateVectorStoreOptions | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/weaviate.py</code> <pre><code>def __init__(\n    self,\n    client: WeaviateAsyncClient,\n    index_name: str,\n    embedder: Embedder,\n    embedding_type: EmbeddingType = EmbeddingType.TEXT,\n    distance_method: VectorDistances = VectorDistances.COSINE,\n    default_options: WeaviateVectorStoreOptions | None = None,\n) -&gt; None:\n    \"\"\"\n    Constructs a new WeaviateVectorStore instance.\n\n    Args:\n        client: An instance of the Weaviate client.\n        index_name: The name of the index.\n        embedder: The embedder to use for converting entries to vectors. Can be a regular Embedder for dense vectors\n                 or a SparseEmbedder for sparse vectors.\n        embedding_type: Which part of the entry to embed, either text or image. The other part will be ignored.\n        distance_method: The distance metric to use when creating the collection.\n        default_options: The default options for querying the vector store.\n    \"\"\"\n    super().__init__(\n        default_options=default_options,\n        embedder=embedder,\n        embedding_type=embedding_type,\n    )\n    self._client = client\n    self._index_name = index_name\n    self._distance_method = distance_method\n    # Weaviate doesn't support filtering by nested keys and doesn't allow keys with dots,\n    # so we use ___ as nested keys separator. It also doesn't allow keys with [],\n    # so currently properties containing lists are not supported by ragbits.\n    self._separator = \"___\"\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.weaviate.WeaviateVectorStore.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = vector_stores\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.weaviate.WeaviateVectorStore.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'vector_store'\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.weaviate.WeaviateVectorStore.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.weaviate.WeaviateVectorStore.TYPE_TO_PROPERTY_MAPPING","title":"TYPE_TO_PROPERTY_MAPPING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TYPE_TO_PROPERTY_MAPPING = {int: INT, str: TEXT, float: NUMBER, bool: BOOL}\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.weaviate.WeaviateVectorStore.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls = WeaviateVectorStoreOptions\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.weaviate.WeaviateVectorStore.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.weaviate.WeaviateVectorStore.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.weaviate.WeaviateVectorStore.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.weaviate.WeaviateVectorStore.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/weaviate.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    client_options = ObjectConstructionConfig.model_validate(config[\"client\"])\n    client_cls = import_by_path(client_options.type, weaviate)\n    config[\"client\"] = client_cls(**client_options.config)\n    return super().from_config(config)\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.weaviate.WeaviateVectorStore.store","title":"store  <code>async</code>","text":"<pre><code>store(entries: list[VectorStoreEntry]) -&gt; None\n</code></pre> <p>Stores vector entries in the Weaviate collection.</p> PARAMETER DESCRIPTION <code>entries</code> <p>List of VectorStoreEntry objects to store</p> <p> TYPE: <code>list[VectorStoreEntry]</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/weaviate.py</code> <pre><code>async def store(self, entries: list[VectorStoreEntry]) -&gt; None:\n    \"\"\"\n    Stores vector entries in the Weaviate collection.\n\n    Args:\n        entries: List of VectorStoreEntry objects to store\n    \"\"\"\n    async with self._client:\n        with trace(\n            entries=entries,\n            index_name=self._index_name,\n            distance_method=self._distance_method,\n            embedder=repr(self._embedder),\n            embedding_type=self._embedding_type,\n        ):\n            if not entries:\n                return\n\n            embeddings: dict = await self._create_embeddings(entries)\n\n            if not await self._client.collections.exists(self._index_name):\n                properties_with_types: dict[str, DataType] = {}\n                for entry in entries:\n                    for k, v in self._flatten_metadata(\n                        entry.model_dump(exclude={\"id\", \"text\"}, exclude_none=True, mode=\"json\")\n                    ).items():\n                        value_type = WeaviateVectorStore.TYPE_TO_PROPERTY_MAPPING.get(type(v), None)\n                        if not value_type:\n                            warnings.warn(\n                                f\"Unsupported type of metadata field with key {k}: {type(v)}, it will be ignored.\"\n                            )\n                            continue\n                        if k in properties_with_types and value_type != properties_with_types[k]:\n                            raise ValueError(\n                                f\"Key {k} was already mapped to {properties_with_types[k]}\"\n                                f\", cannot be changed to {value_type}\"\n                            )\n                        properties_with_types[k] = value_type\n\n                await self._client.collections.create(\n                    name=self._index_name,\n                    vectorizer_config=Configure.Vectorizer.none(),\n                    vector_index_config=Configure.VectorIndex.hnsw(distance_metric=self._distance_method),\n                    properties=[\n                        Property(\n                            name=k, data_type=v, tokenization=Tokenization.FIELD if v == DataType.TEXT else None\n                        )\n                        for k, v in properties_with_types.items()\n                    ],\n                )\n\n            index = self._client.collections.get(self._index_name)\n\n            objects = []\n            for entry in entries:\n                if entry.id in embeddings:\n                    objects.append(\n                        wvc.data.DataObject(\n                            uuid=str(entry.id),\n                            properties=self._flatten_metadata(\n                                entry.model_dump(exclude={\"id\"}, exclude_none=True, mode=\"json\")\n                            ),\n                            vector=embeddings[entry.id],\n                        )\n                    )\n\n            if objects:\n                await index.data.insert_many(objects)\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.weaviate.WeaviateVectorStore.retrieve","title":"retrieve  <code>async</code>","text":"<pre><code>retrieve(text: str, options: WeaviateVectorStoreOptionsT | None = None) -&gt; list[VectorStoreResult]\n</code></pre> <p>Retrieves entries from the Weaviate collection based on vector similarity.</p> PARAMETER DESCRIPTION <code>text</code> <p>The text to query the vector store with.</p> <p> TYPE: <code>str</code> </p> <code>options</code> <p>The options for querying the vector store.</p> <p> TYPE: <code>WeaviateVectorStoreOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[VectorStoreResult]</code> <p>The retrieved entries.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/weaviate.py</code> <pre><code>async def retrieve(self, text: str, options: WeaviateVectorStoreOptionsT | None = None) -&gt; list[VectorStoreResult]:\n    \"\"\"\n    Retrieves entries from the Weaviate collection based on vector similarity.\n\n    Args:\n        text: The text to query the vector store with.\n        options: The options for querying the vector store.\n\n    Returns:\n        The retrieved entries.\n    \"\"\"\n    merged_options = (self.default_options | options) if options else self.default_options\n\n    # Ragbits has a \"larger is better\" convention for all scores, so we need to reverse the score if the distance\n    # method is \"smaller is better\".\n    # Weaviate documentation says that all distance methods are \"smaller is better\":\n    # https://weaviate.io/developers/weaviate/config-refs/distances#available-distance-metrics\n    score_multiplier = -1\n    score_threshold = merged_options.score_threshold\n    async with self._client:\n        with trace(\n            text=text,\n            options=merged_options,\n            index_name=self._index_name,\n            distance_method=self._distance_method,\n            embedder=repr(self._embedder),\n            embedding_type=self._embedding_type,\n        ) as outputs:\n            collection_exists = await self._client.collections.exists(self._index_name)\n\n            if not collection_exists:\n                return []\n\n            index = self._client.collections.get(self._index_name)\n\n            filters = (\n                self._create_weaviate_filter(merged_options.where, self._separator)\n                if merged_options.where\n                else None\n            )\n\n            if merged_options.use_keyword_search:\n                results = await index.query.bm25(\n                    query=text,\n                    filters=filters,\n                    limit=merged_options.k,\n                    return_metadata=MetadataQuery(score=True),\n                    include_vector=True,\n                )\n            else:\n                query_vector = (await self._embedder.embed_text([text]))[0]\n                results = await index.query.near_vector(\n                    near_vector=cast(Sequence[float], query_vector),\n                    filters=filters,\n                    limit=merged_options.k,\n                    distance=score_threshold,  # max accepted distance\n                    return_metadata=MetadataQuery(distance=True),\n                    include_vector=True,\n                )\n\n            outputs_results = []\n            for object_ in results.objects:\n                entry_raw = {\"uuid\": object_.uuid, \"properties\": self._unflatten_metadata(object_.properties)}\n                entry_dict = {\n                    \"id\": entry_raw[\"uuid\"],\n                    \"text\": cast(dict, entry_raw[\"properties\"]).get(\"text\", None),\n                    \"image_bytes\": cast(dict, entry_raw[\"properties\"]).get(\"image_bytes\", None),\n                    \"metadata\": cast(dict, entry_raw[\"properties\"]).get(\"metadata\", {}),\n                }\n                entry = VectorStoreEntry.model_validate(entry_dict)\n\n                if merged_options.use_keyword_search:\n                    # For keyword search score follows \"larger is better\" rule,\n                    # so we don't need to multiply it by score_multiplier\n                    score = object_.metadata.score\n                else:\n                    score = (\n                        object_.metadata.distance * score_multiplier\n                        if object_.metadata.distance is not None\n                        else None\n                    )\n\n                if score is not None:\n                    outputs_results.append(\n                        VectorStoreResult(\n                            entry=entry,\n                            score=score,\n                            vector=cast(list[float], object_.vector[\"default\"]),\n                        )\n                    )\n\n            outputs.results = outputs_results\n\n            return outputs.results\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.weaviate.WeaviateVectorStore.remove","title":"remove  <code>async</code>","text":"<pre><code>remove(ids: list[UUID]) -&gt; None\n</code></pre> <p>Remove entries from the vector store.</p> PARAMETER DESCRIPTION <code>ids</code> <p>The list of entries' IDs to remove.</p> <p> TYPE: <code>list[UUID]</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/weaviate.py</code> <pre><code>async def remove(self, ids: list[UUID]) -&gt; None:\n    \"\"\"\n    Remove entries from the vector store.\n\n    Args:\n        ids: The list of entries' IDs to remove.\n    \"\"\"\n    async with self._client:\n        with trace(ids=ids, index_name=self._index_name):\n            collection_exists = await self._client.collections.exists(self._index_name)\n            if collection_exists:\n                index = self._client.collections.get(self._index_name)\n                await index.data.delete_many(where=Filter.by_id().contains_any(ids))\n</code></pre>"},{"location":"api_reference/core/vector-stores/#ragbits.core.vector_stores.weaviate.WeaviateVectorStore.list","title":"list  <code>async</code>","text":"<pre><code>list(where: WhereQuery | None = None, limit: int | None = None, offset: int = 0) -&gt; list[VectorStoreEntry]\n</code></pre> <p>List entries from the vector store. The entries can be filtered, limited and offset.</p> PARAMETER DESCRIPTION <code>where</code> <p>Conditions for filtering results. Reference: https://weaviate.io/developers/weaviate/search/filters</p> <p> TYPE: <code>WhereQuery | None</code> DEFAULT: <code>None</code> </p> <code>limit</code> <p>The maximum number of entries to return.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>offset</code> <p>The number of entries to skip.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> RETURNS DESCRIPTION <code>list[VectorStoreEntry]</code> <p>The entries.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/vector_stores/weaviate.py</code> <pre><code>async def list(\n    self,\n    where: WhereQuery | None = None,\n    limit: int | None = None,\n    offset: int = 0,\n) -&gt; list[VectorStoreEntry]:\n    \"\"\"\n    List entries from the vector store. The entries can be filtered, limited and offset.\n\n    Args:\n        where: Conditions for filtering results.\n            Reference: https://weaviate.io/developers/weaviate/search/filters\n        limit: The maximum number of entries to return.\n        offset: The number of entries to skip.\n\n    Returns:\n        The entries.\n    \"\"\"\n    async with self._client:\n        with trace(where=where, index_name=self._index_name, limit=limit, offset=offset) as outputs:\n            collection_exists = await self._client.collections.exists(self._index_name)\n\n            if not collection_exists:\n                return []\n\n            index = self._client.collections.get(self._index_name)\n\n            limit = limit or (await index.aggregate.over_all(total_count=True)).total_count\n            limit = max(1, limit) if limit is not None else None\n\n            filters = self._create_weaviate_filter(where, self._separator) if where else None\n\n            results = await index.query.fetch_objects(\n                limit=limit, offset=offset, filters=filters, include_vector=True\n            )\n\n            results_objects = [\n                {\n                    \"uuid\": object_.uuid,\n                    \"properties\": self._unflatten_metadata(object_.properties),\n                }\n                for object_ in results.objects\n            ]\n\n            objects = [\n                {\n                    \"id\": object[\"uuid\"],\n                    \"text\": cast(dict, object[\"properties\"]).get(\"text\", None),\n                    \"image_bytes\": cast(dict, object[\"properties\"]).get(\"image_bytes\", None),\n                    \"metadata\": cast(dict, object[\"properties\"]).get(\"metadata\", {}),\n                }\n                for object in results_objects\n            ]\n            outputs.results = [VectorStoreEntry.model_validate(object) for object in objects]\n\n            return outputs.results\n</code></pre>"},{"location":"api_reference/core/audit/metrics/","title":"Metrics","text":""},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.set_metric_handlers","title":"ragbits.core.audit.metrics.set_metric_handlers","text":"<pre><code>set_metric_handlers(handlers: Handler | list[Handler]) -&gt; None\n</code></pre> <p>Set the global metric handlers.</p> PARAMETER DESCRIPTION <code>handlers</code> <p>List of metric handlers to be used.</p> <p> TYPE: <code>Handler | list[Handler]</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If handler is not found.</p> <code>TypeError</code> <p>If handler type is invalid.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/metrics/__init__.py</code> <pre><code>def set_metric_handlers(handlers: Handler | list[Handler]) -&gt; None:\n    \"\"\"\n    Set the global metric handlers.\n\n    Args:\n        handlers: List of metric handlers to be used.\n\n    Raises:\n        ValueError: If handler is not found.\n        TypeError: If handler type is invalid.\n    \"\"\"\n    global _metric_handlers  # noqa: PLW0602\n\n    if isinstance(handlers, Handler):\n        handlers = [handlers]\n\n    for handler in handlers:\n        if isinstance(handler, MetricHandler):\n            _metric_handlers.append(handler)\n        elif isinstance(handler, str):\n            match handler.lower():\n                case \"otel\":\n                    from ragbits.core.audit.metrics.otel import OtelMetricHandler\n\n                    if not any(isinstance(item, OtelMetricHandler) for item in _metric_handlers):\n                        _metric_handlers.append(OtelMetricHandler())\n\n                case \"logfire\":\n                    from ragbits.core.audit.metrics.logfire import LogfireMetricHandler\n\n                    if not any(isinstance(item, LogfireMetricHandler) for item in _metric_handlers):\n                        _metric_handlers.append(LogfireMetricHandler())\n\n                case _:\n                    raise ValueError(f\"Not found handler: {handler}\")\n        else:\n            raise TypeError(f\"Invalid handler type: {type(handler)}\")\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.clear_metric_handlers","title":"ragbits.core.audit.metrics.clear_metric_handlers","text":"<pre><code>clear_metric_handlers() -&gt; None\n</code></pre> <p>Clear all metric handlers.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/metrics/__init__.py</code> <pre><code>def clear_metric_handlers() -&gt; None:\n    \"\"\"\n    Clear all metric handlers.\n    \"\"\"\n    global _metric_handlers  # noqa: PLW0602\n    _metric_handlers.clear()\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.register_metric","title":"ragbits.core.audit.metrics.register_metric","text":"<pre><code>register_metric(key: str | Enum, metric: Metric) -&gt; None\n</code></pre> <p>Register a new metric in the global registry by type.</p> PARAMETER DESCRIPTION <code>key</code> <p>The metric key (enum value or string)</p> <p> TYPE: <code>str | Enum</code> </p> <code>metric</code> <p>The metric configuration</p> <p> TYPE: <code>Metric</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/metrics/base.py</code> <pre><code>def register_metric(key: str | Enum, metric: Metric) -&gt; None:\n    \"\"\"\n    Register a new metric in the global registry by type.\n\n    Args:\n        key: The metric key (enum value or string)\n        metric: The metric configuration\n    \"\"\"\n    METRICS_REGISTRY[metric.type][key] = metric\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.record_metric","title":"ragbits.core.audit.metrics.record_metric","text":"<pre><code>record_metric(metric: str | Enum, value: int | float, metric_type: MetricType, **attributes: Any) -&gt; None\n</code></pre> <p>Record a metric of any type using the global metric handlers.</p> PARAMETER DESCRIPTION <code>metric</code> <p>The metric key (name or enum value) to record</p> <p> TYPE: <code>str | Enum</code> </p> <code>value</code> <p>The value to record</p> <p> TYPE: <code>int | float</code> </p> <code>metric_type</code> <p>The type of metric (histogram, counter, gauge)</p> <p> TYPE: <code>MetricType</code> </p> <code>**attributes</code> <p>Additional metadata for the metric</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/metrics/__init__.py</code> <pre><code>def record_metric(\n    metric: str | Enum,\n    value: int | float,\n    metric_type: MetricType,\n    **attributes: Any,  # noqa: ANN401\n) -&gt; None:\n    \"\"\"\n    Record a metric of any type using the global metric handlers.\n\n    Args:\n        metric: The metric key (name or enum value) to record\n        value: The value to record\n        metric_type: The type of metric (histogram, counter, gauge)\n        **attributes: Additional metadata for the metric\n    \"\"\"\n    for handler in _metric_handlers:\n        handler.record_metric(metric_key=metric, value=value, attributes=attributes, metric_type=metric_type)\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.MetricType","title":"ragbits.core.audit.metrics.base.MetricType","text":"<p>               Bases: <code>Enum</code></p> <p>Supported metric types.</p>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.MetricType.HISTOGRAM","title":"HISTOGRAM  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HISTOGRAM = 'histogram'\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.MetricType.COUNTER","title":"COUNTER  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>COUNTER = 'counter'\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.MetricType.GAUGE","title":"GAUGE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>GAUGE = 'gauge'\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.Metric","title":"ragbits.core.audit.metrics.base.Metric  <code>dataclass</code>","text":"<pre><code>Metric(name: str, description: str, unit: str, type: MetricType)\n</code></pre> <p>Represents the metric configuration data.</p>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.Metric.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.Metric.description","title":"description  <code>instance-attribute</code>","text":"<pre><code>description: str\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.Metric.unit","title":"unit  <code>instance-attribute</code>","text":"<pre><code>unit: str\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.Metric.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: MetricType\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.LLMMetric","title":"ragbits.core.audit.metrics.base.LLMMetric","text":"<p>               Bases: <code>Enum</code></p> <p>LLM-related metrics that can be recorded. Each metric has a predefined type and is registered in the global registry.</p>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.LLMMetric.PROMPT_THROUGHPUT","title":"PROMPT_THROUGHPUT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PROMPT_THROUGHPUT = auto()\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.LLMMetric.TOKEN_THROUGHPUT","title":"TOKEN_THROUGHPUT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TOKEN_THROUGHPUT = auto()\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.LLMMetric.INPUT_TOKENS","title":"INPUT_TOKENS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>INPUT_TOKENS = auto()\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.LLMMetric.TIME_TO_FIRST_TOKEN","title":"TIME_TO_FIRST_TOKEN  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TIME_TO_FIRST_TOKEN = auto()\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.MetricHandler","title":"ragbits.core.audit.metrics.base.MetricHandler","text":"<pre><code>MetricHandler(metric_prefix: str = 'ragbits')\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for all metric handlers.</p> <p>Initialize the MetricHandler instance.</p> PARAMETER DESCRIPTION <code>metric_prefix</code> <p>Prefix for all metric names.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'ragbits'</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/metrics/base.py</code> <pre><code>def __init__(self, metric_prefix: str = \"ragbits\") -&gt; None:\n    \"\"\"\n    Initialize the MetricHandler instance.\n\n    Args:\n        metric_prefix: Prefix for all metric names.\n    \"\"\"\n    super().__init__()\n    self._metric_prefix = metric_prefix\n    self._metrics: dict[str, Any] = {}\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.MetricHandler.create_metric","title":"create_metric  <code>abstractmethod</code>","text":"<pre><code>create_metric(name: str, unit: str = '', description: str = '', metric_type: MetricType = MetricType.HISTOGRAM) -&gt; Any\n</code></pre> <p>Create a metric of the given type.</p> PARAMETER DESCRIPTION <code>name</code> <p>The metric name.</p> <p> TYPE: <code>str</code> </p> <code>unit</code> <p>The metric unit.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>description</code> <p>The metric description.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>metric_type</code> <p>The type of the metric (histogram, counter, gauge).</p> <p> TYPE: <code>MetricType</code> DEFAULT: <code>HISTOGRAM</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The initialized metric.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/metrics/base.py</code> <pre><code>@abstractmethod\ndef create_metric(\n    self, name: str, unit: str = \"\", description: str = \"\", metric_type: MetricType = MetricType.HISTOGRAM\n) -&gt; Any:  # noqa: ANN401\n    \"\"\"\n    Create a metric of the given type.\n\n    Args:\n        name: The metric name.\n        unit: The metric unit.\n        description: The metric description.\n        metric_type: The type of the metric (histogram, counter, gauge).\n\n    Returns:\n        The initialized metric.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.MetricHandler.register_metric_instance","title":"register_metric_instance","text":"<pre><code>register_metric_instance(name: str, unit: str = '', description: str = '', metric_type: MetricType = MetricType.HISTOGRAM) -&gt; None\n</code></pre> <p>Register a metric instance.</p> PARAMETER DESCRIPTION <code>name</code> <p>The metric name.</p> <p> TYPE: <code>str</code> </p> <code>unit</code> <p>The metric unit.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>description</code> <p>The metric description.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>metric_type</code> <p>The type of the metric (histogram, counter, gauge).</p> <p> TYPE: <code>MetricType</code> DEFAULT: <code>HISTOGRAM</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/metrics/base.py</code> <pre><code>def register_metric_instance(\n    self, name: str, unit: str = \"\", description: str = \"\", metric_type: MetricType = MetricType.HISTOGRAM\n) -&gt; None:\n    \"\"\"\n    Register a metric instance.\n\n    Args:\n        name: The metric name.\n        unit: The metric unit.\n        description: The metric description.\n        metric_type: The type of the metric (histogram, counter, gauge).\n    \"\"\"\n    self._metrics[name] = self.create_metric(\n        name=f\"{self._metric_prefix}_{name}\",\n        unit=unit,\n        description=description,\n        metric_type=metric_type,\n    )\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.base.MetricHandler.record_metric","title":"record_metric","text":"<pre><code>record_metric(metric_key: str | Enum, value: int | float, attributes: dict | None = None, metric_type: MetricType = MetricType.HISTOGRAM) -&gt; None\n</code></pre> <p>Record the value for a specified metric.</p> PARAMETER DESCRIPTION <code>metric_key</code> <p>The metric key (name or enum value) to record.</p> <p> TYPE: <code>str | Enum</code> </p> <code>value</code> <p>The value to record for the metric.</p> <p> TYPE: <code>int | float</code> </p> <code>attributes</code> <p>Additional metadata for the metric.</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>metric_type</code> <p>The type of the metric (histogram, counter, gauge).</p> <p> TYPE: <code>MetricType</code> DEFAULT: <code>HISTOGRAM</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/metrics/base.py</code> <pre><code>def record_metric(\n    self,\n    metric_key: str | Enum,\n    value: int | float,\n    attributes: dict | None = None,\n    metric_type: MetricType = MetricType.HISTOGRAM,\n) -&gt; None:\n    \"\"\"\n    Record the value for a specified metric.\n\n    Args:\n        metric_key: The metric key (name or enum value) to record.\n        value: The value to record for the metric.\n        attributes: Additional metadata for the metric.\n        metric_type: The type of the metric (histogram, counter, gauge).\n    \"\"\"\n    metric_cfg = get_metric(metric_key, metric_type)\n    if metric_cfg:\n        metric_name = metric_cfg.name\n        if metric_name not in self._metrics:\n            self.register_metric_instance(\n                name=metric_name,\n                unit=metric_cfg.unit,\n                description=metric_cfg.description,\n                metric_type=metric_type,\n            )\n    else:\n        metric_name = str(metric_key)\n        if metric_name not in self._metrics:\n            self.register_metric_instance(metric_name, metric_type=metric_type)\n    self._record(\n        metric=self._metrics[metric_name],\n        value=value,\n        attributes=attributes,\n    )\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.otel.OtelMetricHandler","title":"ragbits.core.audit.metrics.otel.OtelMetricHandler","text":"<pre><code>OtelMetricHandler(provider: MeterProvider | None = None, metric_prefix: str = 'ragbits')\n</code></pre> <p>               Bases: <code>MetricHandler</code></p> <p>OpenTelemetry metric handler.</p> <p>Initialize the OtelMetricHandler instance.</p> PARAMETER DESCRIPTION <code>provider</code> <p>The meter provider to use.</p> <p> TYPE: <code>MeterProvider | None</code> DEFAULT: <code>None</code> </p> <code>metric_prefix</code> <p>Prefix for all metric names.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'ragbits'</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/metrics/otel.py</code> <pre><code>def __init__(self, provider: MeterProvider | None = None, metric_prefix: str = \"ragbits\") -&gt; None:\n    \"\"\"\n    Initialize the OtelMetricHandler instance.\n\n    Args:\n        provider: The meter provider to use.\n        metric_prefix: Prefix for all metric names.\n    \"\"\"\n    super().__init__(metric_prefix=metric_prefix)\n    self._meter = get_meter(name=__name__, meter_provider=provider)\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.otel.OtelMetricHandler.register_metric_instance","title":"register_metric_instance","text":"<pre><code>register_metric_instance(name: str, unit: str = '', description: str = '', metric_type: MetricType = MetricType.HISTOGRAM) -&gt; None\n</code></pre> <p>Register a metric instance.</p> PARAMETER DESCRIPTION <code>name</code> <p>The metric name.</p> <p> TYPE: <code>str</code> </p> <code>unit</code> <p>The metric unit.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>description</code> <p>The metric description.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>metric_type</code> <p>The type of the metric (histogram, counter, gauge).</p> <p> TYPE: <code>MetricType</code> DEFAULT: <code>HISTOGRAM</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/metrics/base.py</code> <pre><code>def register_metric_instance(\n    self, name: str, unit: str = \"\", description: str = \"\", metric_type: MetricType = MetricType.HISTOGRAM\n) -&gt; None:\n    \"\"\"\n    Register a metric instance.\n\n    Args:\n        name: The metric name.\n        unit: The metric unit.\n        description: The metric description.\n        metric_type: The type of the metric (histogram, counter, gauge).\n    \"\"\"\n    self._metrics[name] = self.create_metric(\n        name=f\"{self._metric_prefix}_{name}\",\n        unit=unit,\n        description=description,\n        metric_type=metric_type,\n    )\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.otel.OtelMetricHandler.record_metric","title":"record_metric","text":"<pre><code>record_metric(metric_key: str | Enum, value: int | float, attributes: dict | None = None, metric_type: MetricType = MetricType.HISTOGRAM) -&gt; None\n</code></pre> <p>Record the value for a specified metric.</p> PARAMETER DESCRIPTION <code>metric_key</code> <p>The metric key (name or enum value) to record.</p> <p> TYPE: <code>str | Enum</code> </p> <code>value</code> <p>The value to record for the metric.</p> <p> TYPE: <code>int | float</code> </p> <code>attributes</code> <p>Additional metadata for the metric.</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>metric_type</code> <p>The type of the metric (histogram, counter, gauge).</p> <p> TYPE: <code>MetricType</code> DEFAULT: <code>HISTOGRAM</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/metrics/base.py</code> <pre><code>def record_metric(\n    self,\n    metric_key: str | Enum,\n    value: int | float,\n    attributes: dict | None = None,\n    metric_type: MetricType = MetricType.HISTOGRAM,\n) -&gt; None:\n    \"\"\"\n    Record the value for a specified metric.\n\n    Args:\n        metric_key: The metric key (name or enum value) to record.\n        value: The value to record for the metric.\n        attributes: Additional metadata for the metric.\n        metric_type: The type of the metric (histogram, counter, gauge).\n    \"\"\"\n    metric_cfg = get_metric(metric_key, metric_type)\n    if metric_cfg:\n        metric_name = metric_cfg.name\n        if metric_name not in self._metrics:\n            self.register_metric_instance(\n                name=metric_name,\n                unit=metric_cfg.unit,\n                description=metric_cfg.description,\n                metric_type=metric_type,\n            )\n    else:\n        metric_name = str(metric_key)\n        if metric_name not in self._metrics:\n            self.register_metric_instance(metric_name, metric_type=metric_type)\n    self._record(\n        metric=self._metrics[metric_name],\n        value=value,\n        attributes=attributes,\n    )\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.otel.OtelMetricHandler.create_metric","title":"create_metric","text":"<pre><code>create_metric(name: str, unit: str = '', description: str = '', metric_type: MetricType = MetricType.HISTOGRAM) -&gt; Any\n</code></pre> <p>Create a metric of the specified type.</p> PARAMETER DESCRIPTION <code>name</code> <p>The metric name.</p> <p> TYPE: <code>str</code> </p> <code>unit</code> <p>The metric unit.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>description</code> <p>The metric description.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>metric_type</code> <p>The type of the metric (histogram, counter, gauge).</p> <p> TYPE: <code>MetricType</code> DEFAULT: <code>HISTOGRAM</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The initialized metric.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/metrics/otel.py</code> <pre><code>def create_metric(\n    self, name: str, unit: str = \"\", description: str = \"\", metric_type: MetricType = MetricType.HISTOGRAM\n) -&gt; Any:  # noqa: ANN401\n    \"\"\"\n    Create a metric of the specified type.\n\n    Args:\n        name: The metric name.\n        unit: The metric unit.\n        description: The metric description.\n        metric_type: The type of the metric (histogram, counter, gauge).\n\n    Returns:\n        The initialized metric.\n    \"\"\"\n    if metric_type == MetricType.HISTOGRAM:\n        return self._meter.create_histogram(name=name, unit=unit, description=description)\n    elif metric_type == MetricType.COUNTER:\n        return self._meter.create_counter(name=name, unit=unit, description=description)\n    elif metric_type == MetricType.GAUGE:\n        return self._meter.create_gauge(name=name, unit=unit, description=description)\n    else:\n        raise ValueError(f\"Unsupported metric type: {metric_type}\")\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.logfire.LogfireMetricHandler","title":"ragbits.core.audit.metrics.logfire.LogfireMetricHandler","text":"<pre><code>LogfireMetricHandler(metric_prefix: str = 'ragbits', *args: Any, **kwargs: Any)\n</code></pre> <p>               Bases: <code>OtelMetricHandler</code></p> <p>Logfire metric handler.</p> <p>Initialize the LogfireMetricHandler instance.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/metrics/logfire.py</code> <pre><code>def __init__(self, metric_prefix: str = \"ragbits\", *args: Any, **kwargs: Any) -&gt; None:  # noqa: ANN401\n    \"\"\"\n    Initialize the LogfireMetricHandler instance.\n    \"\"\"\n    logfire.configure(*args, **kwargs)\n    logfire.instrument_system_metrics()\n    super().__init__(metric_prefix=metric_prefix)\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.logfire.LogfireMetricHandler.create_metric","title":"create_metric","text":"<pre><code>create_metric(name: str, unit: str = '', description: str = '', metric_type: MetricType = MetricType.HISTOGRAM) -&gt; Any\n</code></pre> <p>Create a metric of the specified type.</p> PARAMETER DESCRIPTION <code>name</code> <p>The metric name.</p> <p> TYPE: <code>str</code> </p> <code>unit</code> <p>The metric unit.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>description</code> <p>The metric description.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>metric_type</code> <p>The type of the metric (histogram, counter, gauge).</p> <p> TYPE: <code>MetricType</code> DEFAULT: <code>HISTOGRAM</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The initialized metric.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/metrics/otel.py</code> <pre><code>def create_metric(\n    self, name: str, unit: str = \"\", description: str = \"\", metric_type: MetricType = MetricType.HISTOGRAM\n) -&gt; Any:  # noqa: ANN401\n    \"\"\"\n    Create a metric of the specified type.\n\n    Args:\n        name: The metric name.\n        unit: The metric unit.\n        description: The metric description.\n        metric_type: The type of the metric (histogram, counter, gauge).\n\n    Returns:\n        The initialized metric.\n    \"\"\"\n    if metric_type == MetricType.HISTOGRAM:\n        return self._meter.create_histogram(name=name, unit=unit, description=description)\n    elif metric_type == MetricType.COUNTER:\n        return self._meter.create_counter(name=name, unit=unit, description=description)\n    elif metric_type == MetricType.GAUGE:\n        return self._meter.create_gauge(name=name, unit=unit, description=description)\n    else:\n        raise ValueError(f\"Unsupported metric type: {metric_type}\")\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.logfire.LogfireMetricHandler.register_metric_instance","title":"register_metric_instance","text":"<pre><code>register_metric_instance(name: str, unit: str = '', description: str = '', metric_type: MetricType = MetricType.HISTOGRAM) -&gt; None\n</code></pre> <p>Register a metric instance.</p> PARAMETER DESCRIPTION <code>name</code> <p>The metric name.</p> <p> TYPE: <code>str</code> </p> <code>unit</code> <p>The metric unit.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>description</code> <p>The metric description.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>metric_type</code> <p>The type of the metric (histogram, counter, gauge).</p> <p> TYPE: <code>MetricType</code> DEFAULT: <code>HISTOGRAM</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/metrics/base.py</code> <pre><code>def register_metric_instance(\n    self, name: str, unit: str = \"\", description: str = \"\", metric_type: MetricType = MetricType.HISTOGRAM\n) -&gt; None:\n    \"\"\"\n    Register a metric instance.\n\n    Args:\n        name: The metric name.\n        unit: The metric unit.\n        description: The metric description.\n        metric_type: The type of the metric (histogram, counter, gauge).\n    \"\"\"\n    self._metrics[name] = self.create_metric(\n        name=f\"{self._metric_prefix}_{name}\",\n        unit=unit,\n        description=description,\n        metric_type=metric_type,\n    )\n</code></pre>"},{"location":"api_reference/core/audit/metrics/#ragbits.core.audit.metrics.logfire.LogfireMetricHandler.record_metric","title":"record_metric","text":"<pre><code>record_metric(metric_key: str | Enum, value: int | float, attributes: dict | None = None, metric_type: MetricType = MetricType.HISTOGRAM) -&gt; None\n</code></pre> <p>Record the value for a specified metric.</p> PARAMETER DESCRIPTION <code>metric_key</code> <p>The metric key (name or enum value) to record.</p> <p> TYPE: <code>str | Enum</code> </p> <code>value</code> <p>The value to record for the metric.</p> <p> TYPE: <code>int | float</code> </p> <code>attributes</code> <p>Additional metadata for the metric.</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>metric_type</code> <p>The type of the metric (histogram, counter, gauge).</p> <p> TYPE: <code>MetricType</code> DEFAULT: <code>HISTOGRAM</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/metrics/base.py</code> <pre><code>def record_metric(\n    self,\n    metric_key: str | Enum,\n    value: int | float,\n    attributes: dict | None = None,\n    metric_type: MetricType = MetricType.HISTOGRAM,\n) -&gt; None:\n    \"\"\"\n    Record the value for a specified metric.\n\n    Args:\n        metric_key: The metric key (name or enum value) to record.\n        value: The value to record for the metric.\n        attributes: Additional metadata for the metric.\n        metric_type: The type of the metric (histogram, counter, gauge).\n    \"\"\"\n    metric_cfg = get_metric(metric_key, metric_type)\n    if metric_cfg:\n        metric_name = metric_cfg.name\n        if metric_name not in self._metrics:\n            self.register_metric_instance(\n                name=metric_name,\n                unit=metric_cfg.unit,\n                description=metric_cfg.description,\n                metric_type=metric_type,\n            )\n    else:\n        metric_name = str(metric_key)\n        if metric_name not in self._metrics:\n            self.register_metric_instance(metric_name, metric_type=metric_type)\n    self._record(\n        metric=self._metrics[metric_name],\n        value=value,\n        attributes=attributes,\n    )\n</code></pre>"},{"location":"api_reference/core/audit/traces/","title":"Traces","text":""},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.set_trace_handlers","title":"ragbits.core.audit.traces.set_trace_handlers","text":"<pre><code>set_trace_handlers(handlers: Handler | list[Handler]) -&gt; None\n</code></pre> <p>Set the global trace handlers.</p> PARAMETER DESCRIPTION <code>handlers</code> <p>List of trace handlers to be used.</p> <p> TYPE: <code>Handler | list[Handler]</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If handler is not found.</p> <code>TypeError</code> <p>If handler type is invalid.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/__init__.py</code> <pre><code>def set_trace_handlers(handlers: Handler | list[Handler]) -&gt; None:\n    \"\"\"\n    Set the global trace handlers.\n\n    Args:\n        handlers: List of trace handlers to be used.\n\n    Raises:\n        ValueError: If handler is not found.\n        TypeError: If handler type is invalid.\n    \"\"\"\n    global _trace_handlers  # noqa: PLW0602\n\n    if isinstance(handlers, Handler):\n        handlers = [handlers]\n\n    for handler in handlers:  # type: ignore\n        if isinstance(handler, TraceHandler):\n            _trace_handlers.append(handler)\n        elif isinstance(handler, str):\n            match handler.lower():\n                case \"otel\":\n                    from ragbits.core.audit.traces.otel import OtelTraceHandler\n\n                    if not any(isinstance(item, OtelTraceHandler) for item in _trace_handlers):\n                        _trace_handlers.append(OtelTraceHandler())\n\n                case \"logfire\":\n                    from ragbits.core.audit.traces.logfire import LogfireTraceHandler\n\n                    if not any(isinstance(item, LogfireTraceHandler) for item in _trace_handlers):\n                        _trace_handlers.append(LogfireTraceHandler())\n\n                case \"cli\":\n                    from ragbits.core.audit.traces.cli import CLITraceHandler\n\n                    if not any(isinstance(item, CLITraceHandler) for item in _trace_handlers):\n                        _trace_handlers.append(CLITraceHandler())\n\n                case _:\n                    raise ValueError(f\"Handler {handler} not found.\")\n        else:\n            raise TypeError(f\"Invalid handler type: {type(handler)}\")\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.clear_trace_handlers","title":"ragbits.core.audit.traces.clear_trace_handlers","text":"<pre><code>clear_trace_handlers() -&gt; None\n</code></pre> <p>Clear all trace handlers.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/__init__.py</code> <pre><code>def clear_trace_handlers() -&gt; None:\n    \"\"\"\n    Clear all trace handlers.\n    \"\"\"\n    global _trace_handlers  # noqa: PLW0602\n    _trace_handlers.clear()\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.trace","title":"ragbits.core.audit.traces.trace","text":"<pre><code>trace(name: str | None = None, **inputs: Any) -&gt; Iterator[SimpleNamespace]\n</code></pre> <p>Context manager for processing a trace.</p> PARAMETER DESCRIPTION <code>name</code> <p>The name of the trace.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>inputs</code> <p>The input data.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> YIELDS DESCRIPTION <code>SimpleNamespace</code> <p>The output data.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/__init__.py</code> <pre><code>@contextmanager\ndef trace(name: str | None = None, **inputs: Any) -&gt; Iterator[SimpleNamespace]:  # noqa: ANN401\n    \"\"\"\n    Context manager for processing a trace.\n\n    Args:\n        name: The name of the trace.\n        inputs: The input data.\n\n    Yields:\n        The output data.\n    \"\"\"\n    # We need to go up 2 frames (trace() and __enter__()) to get the parent function.\n    parent_frame = inspect.stack()[2].frame\n    name = (\n        (\n            f\"{cls.__class__.__qualname__}.{parent_frame.f_code.co_name}\"\n            if (cls := parent_frame.f_locals.get(\"self\"))\n            else parent_frame.f_code.co_name\n        )\n        if name is None\n        else name\n    )\n\n    with ExitStack() as stack:\n        outputs = [stack.enter_context(handler.trace(name, **inputs)) for handler in _trace_handlers]\n        yield (out := SimpleNamespace())\n        for output in outputs:\n            output.__dict__.update(vars(out))\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.traceable","title":"ragbits.core.audit.traces.traceable","text":"<pre><code>traceable(func: Callable[P, R]) -&gt; Callable[P, R]\n</code></pre> <p>Decorator for making a function traceable.</p> PARAMETER DESCRIPTION <code>func</code> <p>The function to be decorated.</p> <p> TYPE: <code>Callable[P, R]</code> </p> RETURNS DESCRIPTION <code>Callable[P, R]</code> <p>The decorated function.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/__init__.py</code> <pre><code>def traceable(func: Callable[P, R]) -&gt; Callable[P, R]:\n    \"\"\"\n    Decorator for making a function traceable.\n\n    Args:\n        func: The function to be decorated.\n\n    Returns:\n        The decorated function.\n    \"\"\"\n\n    @wraps(func)\n    def wrapper(*args: P.args, **kwargs: P.kwargs) -&gt; R:\n        inputs = _get_function_inputs(func, args, kwargs)\n        with trace(name=func.__qualname__, **inputs) as outputs:\n            returned = func(*args, **kwargs)\n            if returned is not None:\n                outputs.returned = returned\n        return returned\n\n    @wraps(func)\n    async def wrapper_async(*args: P.args, **kwargs: P.kwargs) -&gt; R:\n        inputs = _get_function_inputs(func, args, kwargs)\n        with trace(name=func.__qualname__, **inputs) as outputs:\n            returned = await func(*args, **kwargs)  # type: ignore\n            if returned is not None:\n                outputs.returned = returned\n        return returned\n\n    return wrapper_async if asyncio.iscoroutinefunction(func) else wrapper  # type: ignore\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.base.TraceHandler","title":"ragbits.core.audit.traces.base.TraceHandler","text":"<pre><code>TraceHandler()\n</code></pre> <p>               Bases: <code>Generic[SpanT]</code>, <code>ABC</code></p> <p>Base class for all trace handlers.</p> <p>Initialize the TraceHandler instance.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/base.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"\n    Initialize the TraceHandler instance.\n    \"\"\"\n    super().__init__()\n    self._spans = ContextVar[list[SpanT]](\"_spans\")\n    self._spans.set([])\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.base.TraceHandler.start","title":"start  <code>abstractmethod</code>","text":"<pre><code>start(name: str, inputs: dict, current_span: SpanT | None = None) -&gt; SpanT\n</code></pre> <p>Log input data at the beginning of the trace.</p> PARAMETER DESCRIPTION <code>name</code> <p>The name of the trace.</p> <p> TYPE: <code>str</code> </p> <code>inputs</code> <p>The input data.</p> <p> TYPE: <code>dict</code> </p> <code>current_span</code> <p>The current trace span.</p> <p> TYPE: <code>SpanT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>SpanT</code> <p>The updated current trace span.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/base.py</code> <pre><code>@abstractmethod\ndef start(self, name: str, inputs: dict, current_span: SpanT | None = None) -&gt; SpanT:\n    \"\"\"\n    Log input data at the beginning of the trace.\n\n    Args:\n        name: The name of the trace.\n        inputs: The input data.\n        current_span: The current trace span.\n\n    Returns:\n        The updated current trace span.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.base.TraceHandler.stop","title":"stop  <code>abstractmethod</code>","text":"<pre><code>stop(outputs: dict, current_span: SpanT) -&gt; None\n</code></pre> <p>Log output data at the end of the trace.</p> PARAMETER DESCRIPTION <code>outputs</code> <p>The output data.</p> <p> TYPE: <code>dict</code> </p> <code>current_span</code> <p>The current trace span.</p> <p> TYPE: <code>SpanT</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/base.py</code> <pre><code>@abstractmethod\ndef stop(self, outputs: dict, current_span: SpanT) -&gt; None:\n    \"\"\"\n    Log output data at the end of the trace.\n\n    Args:\n        outputs: The output data.\n        current_span: The current trace span.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.base.TraceHandler.error","title":"error  <code>abstractmethod</code>","text":"<pre><code>error(error: Exception, current_span: SpanT) -&gt; None\n</code></pre> <p>Log error during the trace.</p> PARAMETER DESCRIPTION <code>error</code> <p>The error that occurred.</p> <p> TYPE: <code>Exception</code> </p> <code>current_span</code> <p>The current trace span.</p> <p> TYPE: <code>SpanT</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/base.py</code> <pre><code>@abstractmethod\ndef error(self, error: Exception, current_span: SpanT) -&gt; None:\n    \"\"\"\n    Log error during the trace.\n\n    Args:\n        error: The error that occurred.\n        current_span: The current trace span.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.base.TraceHandler.trace","title":"trace","text":"<pre><code>trace(name: str, **inputs: Any) -&gt; Iterator[SimpleNamespace]\n</code></pre> <p>Context manager for processing a trace.</p> PARAMETER DESCRIPTION <code>name</code> <p>The name of the trace.</p> <p> TYPE: <code>str</code> </p> <code>inputs</code> <p>The input data.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> YIELDS DESCRIPTION <code>SimpleNamespace</code> <p>The output data.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/base.py</code> <pre><code>@contextmanager\ndef trace(self, name: str, **inputs: Any) -&gt; Iterator[SimpleNamespace]:  # noqa: ANN401\n    \"\"\"\n    Context manager for processing a trace.\n\n    Args:\n        name: The name of the trace.\n        inputs: The input data.\n\n    Yields:\n        The output data.\n    \"\"\"\n    self._spans.set(self._spans.get([])[:])\n    current_span = self._spans.get()[-1] if self._spans.get() else None\n\n    span = self.start(\n        name=name,\n        inputs=inputs,\n        current_span=current_span,\n    )\n    self._spans.get().append(span)\n\n    try:\n        yield (outputs := SimpleNamespace())\n    except Exception as exc:\n        span = self._spans.get().pop()\n        self.error(error=exc, current_span=span)\n        raise exc\n\n    span = self._spans.get().pop()\n    self.stop(outputs=vars(outputs), current_span=span)\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.cli.CLITraceHandler","title":"ragbits.core.audit.traces.cli.CLITraceHandler","text":"<pre><code>CLITraceHandler()\n</code></pre> <p>               Bases: <code>TraceHandler[CLISpan]</code></p> <p>CLI trace handler.</p> <p>Initialize the CLITraceHandler instance.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/cli.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"\n    Initialize the CLITraceHandler instance.\n    \"\"\"\n    super().__init__()\n    self.live = Live(auto_refresh=False, vertical_overflow=\"visible\")\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.cli.CLITraceHandler.live","title":"live  <code>instance-attribute</code>","text":"<pre><code>live = Live(auto_refresh=False, vertical_overflow='visible')\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.cli.CLITraceHandler.trace","title":"trace","text":"<pre><code>trace(name: str, **inputs: Any) -&gt; Iterator[SimpleNamespace]\n</code></pre> <p>Context manager for processing a trace.</p> PARAMETER DESCRIPTION <code>name</code> <p>The name of the trace.</p> <p> TYPE: <code>str</code> </p> <code>inputs</code> <p>The input data.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> YIELDS DESCRIPTION <code>SimpleNamespace</code> <p>The output data.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/base.py</code> <pre><code>@contextmanager\ndef trace(self, name: str, **inputs: Any) -&gt; Iterator[SimpleNamespace]:  # noqa: ANN401\n    \"\"\"\n    Context manager for processing a trace.\n\n    Args:\n        name: The name of the trace.\n        inputs: The input data.\n\n    Yields:\n        The output data.\n    \"\"\"\n    self._spans.set(self._spans.get([])[:])\n    current_span = self._spans.get()[-1] if self._spans.get() else None\n\n    span = self.start(\n        name=name,\n        inputs=inputs,\n        current_span=current_span,\n    )\n    self._spans.get().append(span)\n\n    try:\n        yield (outputs := SimpleNamespace())\n    except Exception as exc:\n        span = self._spans.get().pop()\n        self.error(error=exc, current_span=span)\n        raise exc\n\n    span = self._spans.get().pop()\n    self.stop(outputs=vars(outputs), current_span=span)\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.cli.CLITraceHandler.start","title":"start","text":"<pre><code>start(name: str, inputs: dict, current_span: CLISpan | None = None) -&gt; CLISpan\n</code></pre> <p>Log input data at the beginning of the trace.</p> PARAMETER DESCRIPTION <code>name</code> <p>The name of the trace.</p> <p> TYPE: <code>str</code> </p> <code>inputs</code> <p>The input data.</p> <p> TYPE: <code>dict</code> </p> <code>current_span</code> <p>The current trace span.</p> <p> TYPE: <code>CLISpan | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>CLISpan</code> <p>The updated current trace span.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/cli.py</code> <pre><code>def start(self, name: str, inputs: dict, current_span: CLISpan | None = None) -&gt; CLISpan:\n    \"\"\"\n    Log input data at the beginning of the trace.\n\n    Args:\n        name: The name of the trace.\n        inputs: The input data.\n        current_span: The current trace span.\n\n    Returns:\n        The updated current trace span.\n    \"\"\"\n    formatter = AttributeFormatter(data=inputs, prefix=\"inputs\")\n    formatter.process_attributes()\n    attributes = formatter.flattened\n\n    span = CLISpan(\n        name=name,\n        attributes=attributes,\n        parent=current_span,\n    )\n    if current_span is None:\n        self.live = Live(auto_refresh=False, vertical_overflow=\"visible\")\n        self.live.start()\n        self.tree = span.tree\n\n    span.update()\n    self.live.update(self.tree, refresh=True)\n\n    return span\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.cli.CLITraceHandler.stop","title":"stop","text":"<pre><code>stop(outputs: dict, current_span: CLISpan) -&gt; None\n</code></pre> <p>Log output data at the end of the trace.</p> PARAMETER DESCRIPTION <code>outputs</code> <p>The output data.</p> <p> TYPE: <code>dict</code> </p> <code>current_span</code> <p>The current trace span.</p> <p> TYPE: <code>CLISpan</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/cli.py</code> <pre><code>def stop(self, outputs: dict, current_span: CLISpan) -&gt; None:\n    \"\"\"\n    Log output data at the end of the trace.\n\n    Args:\n        outputs: The output data.\n        current_span: The current trace span.\n    \"\"\"\n    formatter = AttributeFormatter(data=outputs, prefix=\"outputs\")\n    formatter.process_attributes()\n    attributes = formatter.flattened\n    current_span.attributes.update(attributes)\n    current_span.status = SpanStatus.COMPLETED\n    current_span.end()\n\n    current_span.update()\n    self.live.update(self.tree, refresh=True)\n\n    if current_span.parent is None:\n        self.live.stop()\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.cli.CLITraceHandler.error","title":"error","text":"<pre><code>error(error: Exception, current_span: CLISpan) -&gt; None\n</code></pre> <p>Log error during the trace.</p> PARAMETER DESCRIPTION <code>error</code> <p>The error that occurred.</p> <p> TYPE: <code>Exception</code> </p> <code>current_span</code> <p>The current trace span.</p> <p> TYPE: <code>CLISpan</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/cli.py</code> <pre><code>def error(self, error: Exception, current_span: CLISpan) -&gt; None:\n    \"\"\"\n    Log error during the trace.\n\n    Args:\n        error: The error that occurred.\n        current_span: The current trace span.\n    \"\"\"\n    formatter = AttributeFormatter({\"message\": str(error), **vars(error)}, prefix=\"error\")\n    formatter.process_attributes()\n    attributes = formatter.flattened\n    current_span.attributes.update(attributes)\n    current_span.status = SpanStatus.ERROR\n    current_span.end()\n\n    current_span.update()\n    self.live.update(self.tree, refresh=True)\n\n    if current_span.parent is None:\n        self.live.stop()\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.otel.OtelTraceHandler","title":"ragbits.core.audit.traces.otel.OtelTraceHandler","text":"<pre><code>OtelTraceHandler(provider: TracerProvider | None = None)\n</code></pre> <p>               Bases: <code>TraceHandler[Span]</code></p> <p>OpenTelemetry trace handler.</p> <p>Initialize the OtelTraceHandler instance.</p> PARAMETER DESCRIPTION <code>provider</code> <p>The tracer provider to use.</p> <p> TYPE: <code>TracerProvider | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/otel.py</code> <pre><code>def __init__(self, provider: TracerProvider | None = None) -&gt; None:\n    \"\"\"\n    Initialize the OtelTraceHandler instance.\n\n    Args:\n        provider: The tracer provider to use.\n    \"\"\"\n    super().__init__()\n    self._tracer = get_tracer(instrumenting_module_name=__name__, tracer_provider=provider)\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.otel.OtelTraceHandler.trace","title":"trace","text":"<pre><code>trace(name: str, **inputs: Any) -&gt; Iterator[SimpleNamespace]\n</code></pre> <p>Context manager for processing a trace.</p> PARAMETER DESCRIPTION <code>name</code> <p>The name of the trace.</p> <p> TYPE: <code>str</code> </p> <code>inputs</code> <p>The input data.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> YIELDS DESCRIPTION <code>SimpleNamespace</code> <p>The output data.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/base.py</code> <pre><code>@contextmanager\ndef trace(self, name: str, **inputs: Any) -&gt; Iterator[SimpleNamespace]:  # noqa: ANN401\n    \"\"\"\n    Context manager for processing a trace.\n\n    Args:\n        name: The name of the trace.\n        inputs: The input data.\n\n    Yields:\n        The output data.\n    \"\"\"\n    self._spans.set(self._spans.get([])[:])\n    current_span = self._spans.get()[-1] if self._spans.get() else None\n\n    span = self.start(\n        name=name,\n        inputs=inputs,\n        current_span=current_span,\n    )\n    self._spans.get().append(span)\n\n    try:\n        yield (outputs := SimpleNamespace())\n    except Exception as exc:\n        span = self._spans.get().pop()\n        self.error(error=exc, current_span=span)\n        raise exc\n\n    span = self._spans.get().pop()\n    self.stop(outputs=vars(outputs), current_span=span)\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.otel.OtelTraceHandler.start","title":"start","text":"<pre><code>start(name: str, inputs: dict, current_span: Span | None = None) -&gt; Span\n</code></pre> <p>Log input data at the beginning of the trace.</p> PARAMETER DESCRIPTION <code>name</code> <p>The name of the trace.</p> <p> TYPE: <code>str</code> </p> <code>inputs</code> <p>The input data.</p> <p> TYPE: <code>dict</code> </p> <code>current_span</code> <p>The current trace span.</p> <p> TYPE: <code>Span | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Span</code> <p>The updated current trace span.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/otel.py</code> <pre><code>def start(self, name: str, inputs: dict, current_span: Span | None = None) -&gt; Span:\n    \"\"\"\n    Log input data at the beginning of the trace.\n\n    Args:\n        name: The name of the trace.\n        inputs: The input data.\n        current_span: The current trace span.\n\n    Returns:\n        The updated current trace span.\n    \"\"\"\n    context = set_span_in_context(current_span) if current_span else None\n    with self._tracer.start_as_current_span(name, context=context, end_on_exit=False) as span:\n        attributes = format_attributes(inputs, prefix=\"inputs\")\n        span.set_attributes(attributes)\n    return span\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.otel.OtelTraceHandler.stop","title":"stop","text":"<pre><code>stop(outputs: dict, current_span: Span) -&gt; None\n</code></pre> <p>Log output data at the end of the trace.</p> PARAMETER DESCRIPTION <code>outputs</code> <p>The output data.</p> <p> TYPE: <code>dict</code> </p> <code>current_span</code> <p>The current trace span.</p> <p> TYPE: <code>Span</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/otel.py</code> <pre><code>def stop(self, outputs: dict, current_span: Span) -&gt; None:  # noqa: PLR6301\n    \"\"\"\n    Log output data at the end of the trace.\n\n    Args:\n        outputs: The output data.\n        current_span: The current trace span.\n    \"\"\"\n    attributes = format_attributes(outputs, prefix=\"outputs\")\n    current_span.set_attributes(attributes)\n    current_span.set_status(StatusCode.OK)\n    current_span.end()\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.otel.OtelTraceHandler.error","title":"error","text":"<pre><code>error(error: Exception, current_span: Span) -&gt; None\n</code></pre> <p>Log error during the trace.</p> PARAMETER DESCRIPTION <code>error</code> <p>The error that occurred.</p> <p> TYPE: <code>Exception</code> </p> <code>current_span</code> <p>The current trace span.</p> <p> TYPE: <code>Span</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/otel.py</code> <pre><code>def error(self, error: Exception, current_span: Span) -&gt; None:  # noqa: PLR6301\n    \"\"\"\n    Log error during the trace.\n\n    Args:\n        error: The error that occurred.\n        current_span: The current trace span.\n    \"\"\"\n    attributes = format_attributes({\"message\": str(error), **vars(error)}, prefix=\"error\")\n    current_span.set_attributes(attributes)\n    current_span.set_status(StatusCode.ERROR)\n    current_span.end()\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.logfire.LogfireTraceHandler","title":"ragbits.core.audit.traces.logfire.LogfireTraceHandler","text":"<pre><code>LogfireTraceHandler(*args: Any, **kwargs: Any)\n</code></pre> <p>               Bases: <code>OtelTraceHandler</code></p> <p>Logfire trace handler.</p> <p>Initialize the LogfireTraceHandler instance.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/logfire.py</code> <pre><code>def __init__(self, *args: Any, **kwargs: Any) -&gt; None:  # noqa: ANN401\n    \"\"\"\n    Initialize the LogfireTraceHandler instance.\n    \"\"\"\n    logfire.configure(*args, **kwargs)\n    super().__init__()\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.logfire.LogfireTraceHandler.start","title":"start","text":"<pre><code>start(name: str, inputs: dict, current_span: Span | None = None) -&gt; Span\n</code></pre> <p>Log input data at the beginning of the trace.</p> PARAMETER DESCRIPTION <code>name</code> <p>The name of the trace.</p> <p> TYPE: <code>str</code> </p> <code>inputs</code> <p>The input data.</p> <p> TYPE: <code>dict</code> </p> <code>current_span</code> <p>The current trace span.</p> <p> TYPE: <code>Span | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Span</code> <p>The updated current trace span.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/otel.py</code> <pre><code>def start(self, name: str, inputs: dict, current_span: Span | None = None) -&gt; Span:\n    \"\"\"\n    Log input data at the beginning of the trace.\n\n    Args:\n        name: The name of the trace.\n        inputs: The input data.\n        current_span: The current trace span.\n\n    Returns:\n        The updated current trace span.\n    \"\"\"\n    context = set_span_in_context(current_span) if current_span else None\n    with self._tracer.start_as_current_span(name, context=context, end_on_exit=False) as span:\n        attributes = format_attributes(inputs, prefix=\"inputs\")\n        span.set_attributes(attributes)\n    return span\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.logfire.LogfireTraceHandler.stop","title":"stop","text":"<pre><code>stop(outputs: dict, current_span: Span) -&gt; None\n</code></pre> <p>Log output data at the end of the trace.</p> PARAMETER DESCRIPTION <code>outputs</code> <p>The output data.</p> <p> TYPE: <code>dict</code> </p> <code>current_span</code> <p>The current trace span.</p> <p> TYPE: <code>Span</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/otel.py</code> <pre><code>def stop(self, outputs: dict, current_span: Span) -&gt; None:  # noqa: PLR6301\n    \"\"\"\n    Log output data at the end of the trace.\n\n    Args:\n        outputs: The output data.\n        current_span: The current trace span.\n    \"\"\"\n    attributes = format_attributes(outputs, prefix=\"outputs\")\n    current_span.set_attributes(attributes)\n    current_span.set_status(StatusCode.OK)\n    current_span.end()\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.logfire.LogfireTraceHandler.error","title":"error","text":"<pre><code>error(error: Exception, current_span: Span) -&gt; None\n</code></pre> <p>Log error during the trace.</p> PARAMETER DESCRIPTION <code>error</code> <p>The error that occurred.</p> <p> TYPE: <code>Exception</code> </p> <code>current_span</code> <p>The current trace span.</p> <p> TYPE: <code>Span</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/otel.py</code> <pre><code>def error(self, error: Exception, current_span: Span) -&gt; None:  # noqa: PLR6301\n    \"\"\"\n    Log error during the trace.\n\n    Args:\n        error: The error that occurred.\n        current_span: The current trace span.\n    \"\"\"\n    attributes = format_attributes({\"message\": str(error), **vars(error)}, prefix=\"error\")\n    current_span.set_attributes(attributes)\n    current_span.set_status(StatusCode.ERROR)\n    current_span.end()\n</code></pre>"},{"location":"api_reference/core/audit/traces/#ragbits.core.audit.traces.logfire.LogfireTraceHandler.trace","title":"trace","text":"<pre><code>trace(name: str, **inputs: Any) -&gt; Iterator[SimpleNamespace]\n</code></pre> <p>Context manager for processing a trace.</p> PARAMETER DESCRIPTION <code>name</code> <p>The name of the trace.</p> <p> TYPE: <code>str</code> </p> <code>inputs</code> <p>The input data.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> YIELDS DESCRIPTION <code>SimpleNamespace</code> <p>The output data.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/audit/traces/base.py</code> <pre><code>@contextmanager\ndef trace(self, name: str, **inputs: Any) -&gt; Iterator[SimpleNamespace]:  # noqa: ANN401\n    \"\"\"\n    Context manager for processing a trace.\n\n    Args:\n        name: The name of the trace.\n        inputs: The input data.\n\n    Yields:\n        The output data.\n    \"\"\"\n    self._spans.set(self._spans.get([])[:])\n    current_span = self._spans.get()[-1] if self._spans.get() else None\n\n    span = self.start(\n        name=name,\n        inputs=inputs,\n        current_span=current_span,\n    )\n    self._spans.get().append(span)\n\n    try:\n        yield (outputs := SimpleNamespace())\n    except Exception as exc:\n        span = self._spans.get().pop()\n        self.error(error=exc, current_span=span)\n        raise exc\n\n    span = self._spans.get().pop()\n    self.stop(outputs=vars(outputs), current_span=span)\n</code></pre>"},{"location":"api_reference/document_search/","title":"Document Search","text":""},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearchOptions","title":"ragbits.document_search.DocumentSearchOptions","text":"<p>               Bases: <code>Options</code>, <code>Generic[QueryRephraserOptionsT, VectorStoreOptionsT, RerankerOptionsT]</code></p> <p>Object representing the options for the document search.</p> ATTRIBUTE DESCRIPTION <code>query_rephraser_options</code> <p>The options for the query rephraser.</p> <p> TYPE: <code>QueryRephraserOptionsT | None | NotGiven</code> </p> <code>vector_store_options</code> <p>The options for the vector store.</p> <p> TYPE: <code>VectorStoreOptionsT | None | NotGiven</code> </p> <code>reranker_options</code> <p>The options for the reranker.</p> <p> TYPE: <code>RerankerOptionsT | None | NotGiven</code> </p>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearchOptions.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(extra='allow', arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearchOptions.query_rephraser_options","title":"query_rephraser_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>query_rephraser_options: QueryRephraserOptionsT | None | NotGiven = NOT_GIVEN\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearchOptions.vector_store_options","title":"vector_store_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>vector_store_options: VectorStoreOptionsT | None | NotGiven = NOT_GIVEN\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearchOptions.reranker_options","title":"reranker_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>reranker_options: RerankerOptionsT | None | NotGiven = NOT_GIVEN\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearchOptions.dict","title":"dict","text":"<pre><code>dict() -&gt; dict[str, Any]\n</code></pre> <p>Creates a dictionary representation of the Options instance. If a value is None, it will be replaced with a provider-specific not-given sentinel.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>A dictionary representation of the Options instance.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/options.py</code> <pre><code>def dict(self) -&gt; dict[str, Any]:  # type: ignore # mypy complains about overriding BaseModel.dict\n    \"\"\"\n    Creates a dictionary representation of the Options instance.\n    If a value is None, it will be replaced with a provider-specific not-given sentinel.\n\n    Returns:\n        A dictionary representation of the Options instance.\n    \"\"\"\n    options = self.model_dump()\n\n    return {\n        key: self._not_given if value is None or isinstance(value, NotGiven) else value\n        for key, value in options.items()\n    }\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearch","title":"ragbits.document_search.DocumentSearch","text":"<pre><code>DocumentSearch(vector_store: VectorStore[VectorStoreOptionsT], *, query_rephraser: QueryRephraser[QueryRephraserOptionsT] | None = None, reranker: Reranker[RerankerOptionsT] | None = None, default_options: DocumentSearchOptions[QueryRephraserOptionsT, VectorStoreOptionsT, RerankerOptionsT] | None = None, ingest_strategy: IngestStrategy | None = None, parser_router: DocumentParserRouter | None = None, enricher_router: ElementEnricherRouter | None = None)\n</code></pre> <p>               Bases: <code>ConfigurableComponent[DocumentSearchOptions[QueryRephraserOptionsT, VectorStoreOptionsT, RerankerOptionsT]]</code></p> <p>Main entrypoint to the document search functionality. It provides methods for document retrieval and ingestion.</p> Retrieval <ol> <li>Uses QueryRephraser to rephrase the query.</li> <li>Uses VectorStore to retrieve the most relevant elements.</li> <li>Uses Reranker to rerank the elements.</li> </ol> Ingestion <ol> <li>Uses IngestStrategy to orchestrate ingestion process.</li> <li>Uses DocumentParserRouter to route the document to the appropriate DocumentParser to parse the content.</li> <li>Uses ElementEnricherRouter to redirect the element to the appropriate ElementEnricher to enrich the element.</li> </ol> <p>Initialize the DocumentSearch instance.</p> PARAMETER DESCRIPTION <code>vector_store</code> <p>The vector store to use for retrieval.</p> <p> TYPE: <code>VectorStore[VectorStoreOptionsT]</code> </p> <code>query_rephraser</code> <p>The query rephraser to use for retrieval.</p> <p> TYPE: <code>QueryRephraser[QueryRephraserOptionsT] | None</code> DEFAULT: <code>None</code> </p> <code>reranker</code> <p>The reranker to use for retrieval.</p> <p> TYPE: <code>Reranker[RerankerOptionsT] | None</code> DEFAULT: <code>None</code> </p> <code>default_options</code> <p>The default options for the search.</p> <p> TYPE: <code>DocumentSearchOptions[QueryRephraserOptionsT, VectorStoreOptionsT, RerankerOptionsT] | None</code> DEFAULT: <code>None</code> </p> <code>ingest_strategy</code> <p>The ingestion strategy to use for ingestion.</p> <p> TYPE: <code>IngestStrategy | None</code> DEFAULT: <code>None</code> </p> <code>parser_router</code> <p>The document parser router to use for ingestion.</p> <p> TYPE: <code>DocumentParserRouter | None</code> DEFAULT: <code>None</code> </p> <code>enricher_router</code> <p>The element enricher router to use for ingestion.</p> <p> TYPE: <code>ElementEnricherRouter | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/_main.py</code> <pre><code>def __init__(\n    self,\n    vector_store: VectorStore[VectorStoreOptionsT],\n    *,\n    query_rephraser: QueryRephraser[QueryRephraserOptionsT] | None = None,\n    reranker: Reranker[RerankerOptionsT] | None = None,\n    default_options: DocumentSearchOptions[\n        QueryRephraserOptionsT,\n        VectorStoreOptionsT,\n        RerankerOptionsT,\n    ]\n    | None = None,\n    ingest_strategy: IngestStrategy | None = None,\n    parser_router: DocumentParserRouter | None = None,\n    enricher_router: ElementEnricherRouter | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the DocumentSearch instance.\n\n    Args:\n        vector_store: The vector store to use for retrieval.\n        query_rephraser: The query rephraser to use for retrieval.\n        reranker: The reranker to use for retrieval.\n        default_options: The default options for the search.\n        ingest_strategy: The ingestion strategy to use for ingestion.\n        parser_router: The document parser router to use for ingestion.\n        enricher_router: The element enricher router to use for ingestion.\n    \"\"\"\n    super().__init__(default_options=default_options)\n    self.vector_store = vector_store\n    self.query_rephraser = query_rephraser or NoopQueryRephraser()\n    self.reranker = reranker or NoopReranker()\n    self.ingest_strategy = ingest_strategy or SequentialIngestStrategy()\n    self.parser_router = parser_router or DocumentParserRouter()\n    self.enricher_router = enricher_router or ElementEnricherRouter()\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearch.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearch.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls: type[DocumentSearchOptions] = DocumentSearchOptions\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearch.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = document_search\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearch.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'document_search'\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearch.vector_store","title":"vector_store  <code>instance-attribute</code>","text":"<pre><code>vector_store = vector_store\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearch.query_rephraser","title":"query_rephraser  <code>instance-attribute</code>","text":"<pre><code>query_rephraser = query_rephraser or NoopQueryRephraser()\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearch.reranker","title":"reranker  <code>instance-attribute</code>","text":"<pre><code>reranker = reranker or NoopReranker()\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearch.ingest_strategy","title":"ingest_strategy  <code>instance-attribute</code>","text":"<pre><code>ingest_strategy = ingest_strategy or SequentialIngestStrategy()\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearch.parser_router","title":"parser_router  <code>instance-attribute</code>","text":"<pre><code>parser_router = parser_router or DocumentParserRouter()\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearch.enricher_router","title":"enricher_router  <code>instance-attribute</code>","text":"<pre><code>enricher_router = enricher_router or ElementEnricherRouter()\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearch.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearch.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearch.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Creates and returns an instance of the DocumentSearch class from the given configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A configuration object containing the configuration for initializing the DocumentSearch instance.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>DocumentSearch</code> <p>An initialized instance of the DocumentSearch class.</p> <p> TYPE: <code>Self</code> </p> RAISES DESCRIPTION <code>ValidationError</code> <p>If the configuration doesn't follow the expected format.</p> <code>InvalidConfigError</code> <p>If one of the specified classes can't be found or is not the correct type.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/_main.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Creates and returns an instance of the DocumentSearch class from the given configuration.\n\n    Args:\n        config: A configuration object containing the configuration for initializing the DocumentSearch instance.\n\n    Returns:\n        DocumentSearch: An initialized instance of the DocumentSearch class.\n\n    Raises:\n        ValidationError: If the configuration doesn't follow the expected format.\n        InvalidConfigError: If one of the specified classes can't be found or is not the correct type.\n    \"\"\"\n    model = DocumentSearchConfig.model_validate(config)\n\n    query_rephraser: QueryRephraser = QueryRephraser.subclass_from_config(model.rephraser)\n    vector_store: VectorStore = VectorStore.subclass_from_config(model.vector_store)\n    reranker: Reranker = Reranker.subclass_from_config(model.reranker)\n\n    ingest_strategy = IngestStrategy.subclass_from_config(model.ingest_strategy)\n    parser_router = DocumentParserRouter.from_config(model.parser_router)\n    enricher_router = ElementEnricherRouter.from_config(model.enricher_router)\n\n    return cls(\n        vector_store=vector_store,\n        query_rephraser=query_rephraser,\n        reranker=reranker,\n        ingest_strategy=ingest_strategy,\n        parser_router=parser_router,\n        enricher_router=enricher_router,\n    )\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearch.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component prefferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration. Looks for the configuration under the key \"document_search\", and if not found, instantiates the class with the preferred configuration for each component.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/_main.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls,\n    config: CoreConfig,\n    factory_path_override: str | None = None,\n    yaml_path_override: Path | None = None,\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component prefferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration. Looks for the configuration under the key \"document_search\",\n            and if not found, instantiates the class with the preferred configuration for each component.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n\n        # Look for explicit document search configuration\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n        # Instantiate the class with the preferred configuration for each component\n        return cls.from_config(preferences)\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if config.component_preference_config_path is not None:\n        # Look for explicit document search configuration\n        if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n        # Instantiate the class with the preferred configuration for each component\n        return cls.from_config(config.preferred_instances_config)\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearch.search","title":"search  <code>async</code>","text":"<pre><code>search(query: str, options: DocumentSearchOptions[QueryRephraserOptionsT, VectorStoreOptionsT, RerankerOptionsT] | None = None) -&gt; Sequence[Element]\n</code></pre> <p>Search for the most relevant chunks for a query.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to search for.</p> <p> TYPE: <code>str</code> </p> <code>options</code> <p>The document search retrieval options.</p> <p> TYPE: <code>DocumentSearchOptions[QueryRephraserOptionsT, VectorStoreOptionsT, RerankerOptionsT] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Sequence[Element]</code> <p>A list of chunks.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/_main.py</code> <pre><code>async def search(\n    self,\n    query: str,\n    options: DocumentSearchOptions[QueryRephraserOptionsT, VectorStoreOptionsT, RerankerOptionsT] | None = None,\n) -&gt; Sequence[Element]:\n    \"\"\"\n    Search for the most relevant chunks for a query.\n\n    Args:\n        query: The query to search for.\n        options: The document search retrieval options.\n\n    Returns:\n        A list of chunks.\n    \"\"\"\n    merged_options = (self.default_options | options) if options else self.default_options\n    query_rephraser_options = merged_options.query_rephraser_options or None\n    vector_store_options = merged_options.vector_store_options or None\n    reranker_options = merged_options.reranker_options or None\n\n    with trace(query=query, options=merged_options) as outputs:\n        queries = await self.query_rephraser.rephrase(query, query_rephraser_options)\n        elements = [\n            [\n                Element.from_vector_db_entry(result.entry, result.score)\n                for result in await self.vector_store.retrieve(query, vector_store_options)\n            ]\n            for query in queries\n        ]\n        outputs.results = await self.reranker.rerank(\n            elements=elements,\n            query=query,\n            options=reranker_options,\n        )\n\n    return outputs.results\n</code></pre>"},{"location":"api_reference/document_search/#ragbits.document_search.DocumentSearch.ingest","title":"ingest  <code>async</code>","text":"<pre><code>ingest(documents: str | Iterable[DocumentMeta | Document | Source], fail_on_error: bool = True) -&gt; IngestExecutionResult\n</code></pre> <p>Ingest documents into the search index.</p> PARAMETER DESCRIPTION <code>documents</code> <p>A string representing a source-specific URI (e.g., \"gcs://bucket/\") or an iterable of        <code>Document</code>, <code>DocumentMeta</code>, or <code>Source</code> objects. Examples of URI formats include:        - \"file:///path/to/files/.txt\"        - \"gcs://bucket/folder/*\"        - \"huggingface://dataset/split/row\"</p> <p> TYPE: <code>str | Iterable[DocumentMeta | Document | Source]</code> </p> <code>fail_on_error</code> <p>If True, raises IngestExecutionError when any errors are encountered during ingestion.            If False, returns all errors encountered in the IngestExecutionResult.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>IngestExecutionResult</code> <p>An IngestExecutionResult containing the results of the ingestion process.</p> RAISES DESCRIPTION <code>IngestExecutionError</code> <p>If fail_on_error is True and any errors are encountered during ingestion.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/_main.py</code> <pre><code>@traceable\nasync def ingest(\n    self,\n    documents: str | Iterable[DocumentMeta | Document | Source],\n    fail_on_error: bool = True,\n) -&gt; IngestExecutionResult:\n    \"\"\"\n    Ingest documents into the search index.\n\n    Args:\n        documents: A string representing a source-specific URI (e.g., \"gcs://bucket/*\") or an iterable of\n                   `Document`, `DocumentMeta`, or `Source` objects. Examples of URI formats include:\n                   - \"file:///path/to/files/*.txt\"\n                   - \"gcs://bucket/folder/*\"\n                   - \"huggingface://dataset/split/row\"\n        fail_on_error: If True, raises IngestExecutionError when any errors are encountered during ingestion.\n                       If False, returns all errors encountered in the IngestExecutionResult.\n\n    Returns:\n        An IngestExecutionResult containing the results of the ingestion process.\n\n    Raises:\n        IngestExecutionError: If fail_on_error is True and any errors are encountered during ingestion.\n    \"\"\"\n    resolved_documents = await SourceResolver.resolve(documents) if isinstance(documents, str) else documents\n    results = await self.ingest_strategy(\n        documents=resolved_documents,\n        vector_store=self.vector_store,\n        parser_router=self.parser_router,\n        enricher_router=self.enricher_router,\n    )\n\n    if fail_on_error and results.failed:\n        raise IngestExecutionError(results.failed)\n\n    return results\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/","title":"Documents","text":""},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.Document","title":"ragbits.document_search.documents.document.Document","text":"<p>               Bases: <code>BaseModel</code></p> <p>An object representing a document which is downloaded and stored locally.</p>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.Document.local_path","title":"local_path  <code>instance-attribute</code>","text":"<pre><code>local_path: Path\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.Document.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: DocumentMeta\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.Document.from_document_meta","title":"from_document_meta  <code>classmethod</code>","text":"<pre><code>from_document_meta(document_meta: DocumentMeta, local_path: Path) -&gt; Document\n</code></pre> <p>Create a document from a document metadata. Based on the document type, it will return a different object.</p> PARAMETER DESCRIPTION <code>document_meta</code> <p>The document metadata.</p> <p> TYPE: <code>DocumentMeta</code> </p> <code>local_path</code> <p>The local path to the document.</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>Document</code> <p>The document.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/documents/document.py</code> <pre><code>@classmethod\ndef from_document_meta(cls, document_meta: DocumentMeta, local_path: Path) -&gt; \"Document\":\n    \"\"\"\n    Create a document from a document metadata.\n    Based on the document type, it will return a different object.\n\n    Args:\n        document_meta: The document metadata.\n        local_path: The local path to the document.\n\n    Returns:\n        The document.\n    \"\"\"\n    if document_meta.document_type in [DocumentType.MD, DocumentType.TXT]:\n        return TextDocument(local_path=local_path, metadata=document_meta)\n    return cls(local_path=local_path, metadata=document_meta)\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.TextDocument","title":"ragbits.document_search.documents.document.TextDocument","text":"<p>               Bases: <code>Document</code></p> <p>An object representing a text document.</p>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.TextDocument.local_path","title":"local_path  <code>instance-attribute</code>","text":"<pre><code>local_path: Path\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.TextDocument.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: DocumentMeta\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.TextDocument.content","title":"content  <code>property</code>","text":"<pre><code>content: str\n</code></pre> <p>Get the content of the document.</p> RETURNS DESCRIPTION <code>str</code> <p>The content of the document.</p>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.TextDocument.from_document_meta","title":"from_document_meta  <code>classmethod</code>","text":"<pre><code>from_document_meta(document_meta: DocumentMeta, local_path: Path) -&gt; Document\n</code></pre> <p>Create a document from a document metadata. Based on the document type, it will return a different object.</p> PARAMETER DESCRIPTION <code>document_meta</code> <p>The document metadata.</p> <p> TYPE: <code>DocumentMeta</code> </p> <code>local_path</code> <p>The local path to the document.</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>Document</code> <p>The document.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/documents/document.py</code> <pre><code>@classmethod\ndef from_document_meta(cls, document_meta: DocumentMeta, local_path: Path) -&gt; \"Document\":\n    \"\"\"\n    Create a document from a document metadata.\n    Based on the document type, it will return a different object.\n\n    Args:\n        document_meta: The document metadata.\n        local_path: The local path to the document.\n\n    Returns:\n        The document.\n    \"\"\"\n    if document_meta.document_type in [DocumentType.MD, DocumentType.TXT]:\n        return TextDocument(local_path=local_path, metadata=document_meta)\n    return cls(local_path=local_path, metadata=document_meta)\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentMeta","title":"ragbits.document_search.documents.document.DocumentMeta","text":"<p>               Bases: <code>BaseModel</code></p> <p>An object representing a document metadata.</p>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentMeta.document_type","title":"document_type  <code>instance-attribute</code>","text":"<pre><code>document_type: DocumentType\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentMeta.source","title":"source  <code>instance-attribute</code>","text":"<pre><code>source: Source\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentMeta.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Get the document ID.</p> RETURNS DESCRIPTION <code>str</code> <p>The document ID.</p>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentMeta.fetch","title":"fetch  <code>async</code>","text":"<pre><code>fetch() -&gt; Document\n</code></pre> <p>This method fetches the document from source (potentially remote) and creates an object to interface with it. Based on the document type, it will return a different object.</p> RETURNS DESCRIPTION <code>Document</code> <p>The document.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/documents/document.py</code> <pre><code>async def fetch(self) -&gt; \"Document\":\n    \"\"\"\n    This method fetches the document from source (potentially remote) and creates an object to interface with it.\n    Based on the document type, it will return a different object.\n\n    Returns:\n        The document.\n    \"\"\"\n    local_path = await self.source.fetch()\n    return Document.from_document_meta(self, local_path)\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentMeta.create_text_document_from_literal","title":"create_text_document_from_literal  <code>classmethod</code>","text":"<pre><code>create_text_document_from_literal(content: str) -&gt; DocumentMeta\n</code></pre> <p>Create a text document from a literal content. This method is deprecated, use from_literal() instead.</p> PARAMETER DESCRIPTION <code>content</code> <p>The content of the document.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>DocumentMeta</code> <p>The document metadata.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/documents/document.py</code> <pre><code>@classmethod\n@deprecated(\"Use from_literal() instead\")\ndef create_text_document_from_literal(cls, content: str) -&gt; \"DocumentMeta\":\n    \"\"\"\n    Create a text document from a literal content. This method is deprecated, use from_literal() instead.\n\n    Args:\n        content: The content of the document.\n\n    Returns:\n        The document metadata.\n    \"\"\"\n    return cls.from_literal(content)\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentMeta.from_literal","title":"from_literal  <code>classmethod</code>","text":"<pre><code>from_literal(content: str) -&gt; DocumentMeta\n</code></pre> <p>Create a text document from a literal content.</p> PARAMETER DESCRIPTION <code>content</code> <p>The content of the document.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>DocumentMeta</code> <p>The document metadata.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/documents/document.py</code> <pre><code>@classmethod\ndef from_literal(cls, content: str) -&gt; \"DocumentMeta\":\n    \"\"\"\n    Create a text document from a literal content.\n\n    Args:\n        content: The content of the document.\n\n    Returns:\n        The document metadata.\n    \"\"\"\n    with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n        temp_file.write(content.encode())\n\n    return cls(\n        document_type=DocumentType.TXT,\n        source=LocalFileSource(path=Path(temp_file.name)),\n    )\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentMeta.from_local_path","title":"from_local_path  <code>classmethod</code>","text":"<pre><code>from_local_path(local_path: Path) -&gt; DocumentMeta\n</code></pre> <p>Create a document metadata from a local path.</p> PARAMETER DESCRIPTION <code>local_path</code> <p>The local path to the document.</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>DocumentMeta</code> <p>The document metadata.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/documents/document.py</code> <pre><code>@classmethod\ndef from_local_path(cls, local_path: Path) -&gt; \"DocumentMeta\":\n    \"\"\"\n    Create a document metadata from a local path.\n\n    Args:\n        local_path: The local path to the document.\n\n    Returns:\n        The document metadata.\n    \"\"\"\n    return cls(\n        document_type=cls._infer_document_type(local_path),\n        source=LocalFileSource(path=local_path),\n    )\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentMeta.from_source","title":"from_source  <code>async</code> <code>classmethod</code>","text":"<pre><code>from_source(source: Source) -&gt; DocumentMeta\n</code></pre> <p>Create a document metadata from a source.</p> PARAMETER DESCRIPTION <code>source</code> <p>The source from which the document is fetched.</p> <p> TYPE: <code>Source</code> </p> RETURNS DESCRIPTION <code>DocumentMeta</code> <p>The document metadata.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/documents/document.py</code> <pre><code>@classmethod\nasync def from_source(cls, source: Source) -&gt; \"DocumentMeta\":\n    \"\"\"\n    Create a document metadata from a source.\n\n    Args:\n        source: The source from which the document is fetched.\n\n    Returns:\n        The document metadata.\n    \"\"\"\n    path = await source.fetch()\n\n    return cls(\n        document_type=cls._infer_document_type(path),\n        source=source,\n    )\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType","title":"ragbits.document_search.documents.document.DocumentType","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Document types that can be parsed.</p>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.MD","title":"MD  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MD = 'md'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.TXT","title":"TXT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TXT = 'txt'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.PDF","title":"PDF  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PDF = 'pdf'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.CSV","title":"CSV  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CSV = 'csv'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.DOC","title":"DOC  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DOC = 'doc'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.DOCX","title":"DOCX  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DOCX = 'docx'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.HTML","title":"HTML  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HTML = 'html'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.EPUB","title":"EPUB  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>EPUB = 'epub'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.XLSX","title":"XLSX  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>XLSX = 'xlsx'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.XLS","title":"XLS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>XLS = 'xls'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.ORG","title":"ORG  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ORG = 'org'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.ODT","title":"ODT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ODT = 'odt'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.PPT","title":"PPT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PPT = 'ppt'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.PPTX","title":"PPTX  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PPTX = 'pptx'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.RST","title":"RST  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RST = 'rst'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.RTF","title":"RTF  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RTF = 'rtf'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.TSV","title":"TSV  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TSV = 'tsv'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.JSON","title":"JSON  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>JSON = 'json'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.JSONL","title":"JSONL  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>JSONL = 'jsonl'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.XML","title":"XML  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>XML = 'xml'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.JPG","title":"JPG  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>JPG = 'jpg'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.PNG","title":"PNG  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PNG = 'png'\n</code></pre>"},{"location":"api_reference/document_search/documents/documents/#ragbits.document_search.documents.document.DocumentType.UNKNOWN","title":"UNKNOWN  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>UNKNOWN = 'unknown'\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/","title":"Elements","text":""},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.Element","title":"ragbits.document_search.documents.element.Element","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>An object representing an element in a document.</p>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.Element.element_type","title":"element_type  <code>instance-attribute</code>","text":"<pre><code>element_type: str\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.Element.document_meta","title":"document_meta  <code>instance-attribute</code>","text":"<pre><code>document_meta: DocumentMeta\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.Element.location","title":"location  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>location: ElementLocation | None = None\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.Element.score","title":"score  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>score: float | None = None\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.Element.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Retrieve the ID of the element, primarily used to represent the element's data.</p> RETURNS DESCRIPTION <code>str</code> <p>string representing element</p> <p> TYPE: <code>str</code> </p>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.Element.key","title":"key  <code>property</code>","text":"<pre><code>key: str | None\n</code></pre> <p>Get the representation of the element for embedding.</p> RETURNS DESCRIPTION <code>str | None</code> <p>The representation for embedding.</p>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.Element.text_representation","title":"text_representation  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>text_representation: str | None\n</code></pre> <p>Get the text representation of the element.</p> RETURNS DESCRIPTION <code>str | None</code> <p>The text representation.</p>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.Element.image_representation","title":"image_representation  <code>property</code>","text":"<pre><code>image_representation: bytes | None\n</code></pre> <p>Get the image representation of the element.</p> RETURNS DESCRIPTION <code>bytes | None</code> <p>The image representation.</p>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.Element.get_id_components","title":"get_id_components","text":"<pre><code>get_id_components() -&gt; dict[str, str]\n</code></pre> <p>Creates a dictionary of key value pairs of id components</p> RETURNS DESCRIPTION <code>dict</code> <p>a dictionary</p> <p> TYPE: <code>dict[str, str]</code> </p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/documents/element.py</code> <pre><code>def get_id_components(self) -&gt; dict[str, str]:\n    \"\"\"\n    Creates a dictionary of key value pairs of id components\n\n    Returns:\n        dict: a dictionary\n    \"\"\"\n    id_components = {\n        \"meta\": self.document_meta.id,\n        \"type\": self.element_type,\n        \"key\": str(self.key),\n        \"text\": str(self.text_representation),\n        \"location\": str(self.location),\n    }\n    return id_components\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.Element.from_vector_db_entry","title":"from_vector_db_entry  <code>classmethod</code>","text":"<pre><code>from_vector_db_entry(db_entry: VectorStoreEntry, score: float | None = None) -&gt; Element\n</code></pre> <p>Create an element from a vector database entry.</p> PARAMETER DESCRIPTION <code>db_entry</code> <p>The vector database entry.</p> <p> TYPE: <code>VectorStoreEntry</code> </p> <code>score</code> <p>The score of the element retrieved from the vector database or reranker.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Element</code> <p>The element.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/documents/element.py</code> <pre><code>@classmethod\ndef from_vector_db_entry(cls, db_entry: VectorStoreEntry, score: float | None = None) -&gt; \"Element\":\n    \"\"\"\n    Create an element from a vector database entry.\n\n    Args:\n        db_entry: The vector database entry.\n        score: The score of the element retrieved from the vector database or reranker.\n\n    Returns:\n        The element.\n    \"\"\"\n    element_type = db_entry.metadata[\"element_type\"]\n    element_cls = Element._elements_registry[element_type]\n    if \"embedding_type\" in db_entry.metadata:\n        del db_entry.metadata[\"embedding_type\"]\n\n    element = element_cls(**db_entry.metadata)\n    element.score = score\n    return element\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.Element.to_vector_db_entry","title":"to_vector_db_entry","text":"<pre><code>to_vector_db_entry() -&gt; VectorStoreEntry\n</code></pre> <p>Create a vector database entry from the element.</p> RETURNS DESCRIPTION <code>VectorStoreEntry</code> <p>The vector database entry</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/documents/element.py</code> <pre><code>def to_vector_db_entry(self) -&gt; VectorStoreEntry:\n    \"\"\"\n    Create a vector database entry from the element.\n\n    Returns:\n        The vector database entry\n    \"\"\"\n    id_components = [\n        self.id,\n    ]\n    vector_store_entry_id = uuid.uuid5(uuid.NAMESPACE_OID, \";\".join(id_components))\n    metadata = self.model_dump(exclude={\"id\", \"key\"})\n    metadata[\"document_meta\"][\"source\"][\"id\"] = self.document_meta.source.id\n\n    return VectorStoreEntry(\n        id=vector_store_entry_id, text=self.key, image_bytes=self.image_representation, metadata=metadata\n    )\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.TextElement","title":"ragbits.document_search.documents.element.TextElement","text":"<p>               Bases: <code>Element</code></p> <p>An object representing a text element in a document.</p>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.TextElement.document_meta","title":"document_meta  <code>instance-attribute</code>","text":"<pre><code>document_meta: DocumentMeta\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.TextElement.location","title":"location  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>location: ElementLocation | None = None\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.TextElement.score","title":"score  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>score: float | None = None\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.TextElement.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Retrieve the ID of the element, primarily used to represent the element's data.</p> RETURNS DESCRIPTION <code>str</code> <p>string representing element</p> <p> TYPE: <code>str</code> </p>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.TextElement.key","title":"key  <code>property</code>","text":"<pre><code>key: str | None\n</code></pre> <p>Get the representation of the element for embedding.</p> RETURNS DESCRIPTION <code>str | None</code> <p>The representation for embedding.</p>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.TextElement.image_representation","title":"image_representation  <code>property</code>","text":"<pre><code>image_representation: bytes | None\n</code></pre> <p>Get the image representation of the element.</p> RETURNS DESCRIPTION <code>bytes | None</code> <p>The image representation.</p>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.TextElement.element_type","title":"element_type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>element_type: str = 'text'\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.TextElement.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: str\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.TextElement.text_representation","title":"text_representation  <code>property</code>","text":"<pre><code>text_representation: str\n</code></pre> <p>Get the text representation of the element.</p> RETURNS DESCRIPTION <code>str</code> <p>The text representation.</p>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.TextElement.get_id_components","title":"get_id_components","text":"<pre><code>get_id_components() -&gt; dict[str, str]\n</code></pre> <p>Creates a dictionary of key value pairs of id components</p> RETURNS DESCRIPTION <code>dict</code> <p>a dictionary</p> <p> TYPE: <code>dict[str, str]</code> </p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/documents/element.py</code> <pre><code>def get_id_components(self) -&gt; dict[str, str]:\n    \"\"\"\n    Creates a dictionary of key value pairs of id components\n\n    Returns:\n        dict: a dictionary\n    \"\"\"\n    id_components = {\n        \"meta\": self.document_meta.id,\n        \"type\": self.element_type,\n        \"key\": str(self.key),\n        \"text\": str(self.text_representation),\n        \"location\": str(self.location),\n    }\n    return id_components\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.TextElement.from_vector_db_entry","title":"from_vector_db_entry  <code>classmethod</code>","text":"<pre><code>from_vector_db_entry(db_entry: VectorStoreEntry, score: float | None = None) -&gt; Element\n</code></pre> <p>Create an element from a vector database entry.</p> PARAMETER DESCRIPTION <code>db_entry</code> <p>The vector database entry.</p> <p> TYPE: <code>VectorStoreEntry</code> </p> <code>score</code> <p>The score of the element retrieved from the vector database or reranker.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Element</code> <p>The element.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/documents/element.py</code> <pre><code>@classmethod\ndef from_vector_db_entry(cls, db_entry: VectorStoreEntry, score: float | None = None) -&gt; \"Element\":\n    \"\"\"\n    Create an element from a vector database entry.\n\n    Args:\n        db_entry: The vector database entry.\n        score: The score of the element retrieved from the vector database or reranker.\n\n    Returns:\n        The element.\n    \"\"\"\n    element_type = db_entry.metadata[\"element_type\"]\n    element_cls = Element._elements_registry[element_type]\n    if \"embedding_type\" in db_entry.metadata:\n        del db_entry.metadata[\"embedding_type\"]\n\n    element = element_cls(**db_entry.metadata)\n    element.score = score\n    return element\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.TextElement.to_vector_db_entry","title":"to_vector_db_entry","text":"<pre><code>to_vector_db_entry() -&gt; VectorStoreEntry\n</code></pre> <p>Create a vector database entry from the element.</p> RETURNS DESCRIPTION <code>VectorStoreEntry</code> <p>The vector database entry</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/documents/element.py</code> <pre><code>def to_vector_db_entry(self) -&gt; VectorStoreEntry:\n    \"\"\"\n    Create a vector database entry from the element.\n\n    Returns:\n        The vector database entry\n    \"\"\"\n    id_components = [\n        self.id,\n    ]\n    vector_store_entry_id = uuid.uuid5(uuid.NAMESPACE_OID, \";\".join(id_components))\n    metadata = self.model_dump(exclude={\"id\", \"key\"})\n    metadata[\"document_meta\"][\"source\"][\"id\"] = self.document_meta.source.id\n\n    return VectorStoreEntry(\n        id=vector_store_entry_id, text=self.key, image_bytes=self.image_representation, metadata=metadata\n    )\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.ImageElement","title":"ragbits.document_search.documents.element.ImageElement","text":"<p>               Bases: <code>Element</code></p> <p>An object representing an image element in a document.</p>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.ImageElement.document_meta","title":"document_meta  <code>instance-attribute</code>","text":"<pre><code>document_meta: DocumentMeta\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.ImageElement.location","title":"location  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>location: ElementLocation | None = None\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.ImageElement.score","title":"score  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>score: float | None = None\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.ImageElement.id","title":"id  <code>property</code>","text":"<pre><code>id: str\n</code></pre> <p>Retrieve the ID of the element, primarily used to represent the element's data.</p> RETURNS DESCRIPTION <code>str</code> <p>string representing element</p> <p> TYPE: <code>str</code> </p>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.ImageElement.key","title":"key  <code>property</code>","text":"<pre><code>key: str | None\n</code></pre> <p>Get the representation of the element for embedding.</p> RETURNS DESCRIPTION <code>str | None</code> <p>The representation for embedding.</p>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.ImageElement.element_type","title":"element_type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>element_type: str = 'image'\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.ImageElement.image_bytes","title":"image_bytes  <code>instance-attribute</code>","text":"<pre><code>image_bytes: SerializableBytes\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.ImageElement.description","title":"description  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>description: str | None = None\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.ImageElement.ocr_extracted_text","title":"ocr_extracted_text  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ocr_extracted_text: str | None = None\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.ImageElement.text_representation","title":"text_representation  <code>property</code>","text":"<pre><code>text_representation: str | None\n</code></pre> <p>Get the text representation of the element.</p> RETURNS DESCRIPTION <code>str | None</code> <p>The text representation.</p>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.ImageElement.image_representation","title":"image_representation  <code>property</code>","text":"<pre><code>image_representation: bytes\n</code></pre> <p>Get the image representation of the element.</p> RETURNS DESCRIPTION <code>bytes</code> <p>The image representation.</p>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.ImageElement.from_vector_db_entry","title":"from_vector_db_entry  <code>classmethod</code>","text":"<pre><code>from_vector_db_entry(db_entry: VectorStoreEntry, score: float | None = None) -&gt; Element\n</code></pre> <p>Create an element from a vector database entry.</p> PARAMETER DESCRIPTION <code>db_entry</code> <p>The vector database entry.</p> <p> TYPE: <code>VectorStoreEntry</code> </p> <code>score</code> <p>The score of the element retrieved from the vector database or reranker.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Element</code> <p>The element.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/documents/element.py</code> <pre><code>@classmethod\ndef from_vector_db_entry(cls, db_entry: VectorStoreEntry, score: float | None = None) -&gt; \"Element\":\n    \"\"\"\n    Create an element from a vector database entry.\n\n    Args:\n        db_entry: The vector database entry.\n        score: The score of the element retrieved from the vector database or reranker.\n\n    Returns:\n        The element.\n    \"\"\"\n    element_type = db_entry.metadata[\"element_type\"]\n    element_cls = Element._elements_registry[element_type]\n    if \"embedding_type\" in db_entry.metadata:\n        del db_entry.metadata[\"embedding_type\"]\n\n    element = element_cls(**db_entry.metadata)\n    element.score = score\n    return element\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.ImageElement.to_vector_db_entry","title":"to_vector_db_entry","text":"<pre><code>to_vector_db_entry() -&gt; VectorStoreEntry\n</code></pre> <p>Create a vector database entry from the element.</p> RETURNS DESCRIPTION <code>VectorStoreEntry</code> <p>The vector database entry</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/documents/element.py</code> <pre><code>def to_vector_db_entry(self) -&gt; VectorStoreEntry:\n    \"\"\"\n    Create a vector database entry from the element.\n\n    Returns:\n        The vector database entry\n    \"\"\"\n    id_components = [\n        self.id,\n    ]\n    vector_store_entry_id = uuid.uuid5(uuid.NAMESPACE_OID, \";\".join(id_components))\n    metadata = self.model_dump(exclude={\"id\", \"key\"})\n    metadata[\"document_meta\"][\"source\"][\"id\"] = self.document_meta.source.id\n\n    return VectorStoreEntry(\n        id=vector_store_entry_id, text=self.key, image_bytes=self.image_representation, metadata=metadata\n    )\n</code></pre>"},{"location":"api_reference/document_search/documents/elements/#ragbits.document_search.documents.element.ImageElement.get_id_components","title":"get_id_components","text":"<pre><code>get_id_components() -&gt; dict[str, str]\n</code></pre> <p>Creates a dictionary of key value pairs of id components</p> RETURNS DESCRIPTION <code>dict</code> <p>a dictionary</p> <p> TYPE: <code>dict[str, str]</code> </p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/documents/element.py</code> <pre><code>def get_id_components(self) -&gt; dict[str, str]:\n    \"\"\"\n    Creates a dictionary of key value pairs of id components\n\n    Returns:\n        dict: a dictionary\n    \"\"\"\n    id_components = super().get_id_components()\n    id_components[\"image_hash\"] = hashlib.sha256(self.image_bytes).hexdigest()\n    return id_components\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/","title":"Element Enrichers","text":""},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.router.ElementEnricherRouter","title":"ragbits.document_search.ingestion.enrichers.router.ElementEnricherRouter","text":"<pre><code>ElementEnricherRouter(enrichers: Mapping[type[Element], ElementEnricher] | None = None)\n</code></pre> <p>               Bases: <code>WithConstructionConfig</code></p> <p>The class responsible for routing the element to the correct enricher based on the element type.</p> <p>Initialize the ElementEnricherRouter instance.</p> PARAMETER DESCRIPTION <code>enrichers</code> <p>The mapping of element types and their enrichers. To override default enrichers.</p> <p> TYPE: <code>Mapping[type[Element], ElementEnricher] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/enrichers/router.py</code> <pre><code>def __init__(\n    self,\n    enrichers: Mapping[type[Element], ElementEnricher] | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the ElementEnricherRouter instance.\n\n    Args:\n        enrichers: The mapping of element types and their enrichers. To override default enrichers.\n    \"\"\"\n    self._enrichers = {**_DEFAULT_ENRICHERS, **enrichers} if enrichers else _DEFAULT_ENRICHERS\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.router.ElementEnricherRouter.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = None\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.router.ElementEnricherRouter.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'enricher_router'\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.router.ElementEnricherRouter.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.router.ElementEnricherRouter.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.router.ElementEnricherRouter.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.router.ElementEnricherRouter.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, ObjectConstructionConfig]) -&gt; Self\n</code></pre> <p>Initialize the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, ObjectConstructionConfig]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The ElementEnricherRouter.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If any of the provided parsers cannot be initialized.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/enrichers/router.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, ObjectConstructionConfig]) -&gt; Self:\n    \"\"\"\n    Initialize the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        The ElementEnricherRouter.\n\n    Raises:\n        InvalidConfigError: If any of the provided parsers cannot be initialized.\n    \"\"\"\n    enrichers: dict[type[Element], ElementEnricher] = {\n        import_by_path(element_type, element): ElementEnricher.subclass_from_config(enricher_config)\n        for element_type, enricher_config in config.items()\n    }\n    return super().from_config({\"enrichers\": enrichers})\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.router.ElementEnricherRouter.get","title":"get","text":"<pre><code>get(element_type: type[Element]) -&gt; ElementEnricher\n</code></pre> <p>Get the enricher for the element.</p> PARAMETER DESCRIPTION <code>element_type</code> <p>The element type.</p> <p> TYPE: <code>type[Element]</code> </p> RETURNS DESCRIPTION <code>ElementEnricher</code> <p>The enricher for processing the element.</p> RAISES DESCRIPTION <code>EnricherNotFoundError</code> <p>If no enricher is found for the element type.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/enrichers/router.py</code> <pre><code>def get(self, element_type: type[Element]) -&gt; ElementEnricher:\n    \"\"\"\n    Get the enricher for the element.\n\n    Args:\n        element_type: The element type.\n\n    Returns:\n        The enricher for processing the element.\n\n    Raises:\n        EnricherNotFoundError: If no enricher is found for the element type.\n    \"\"\"\n    enricher = self._enrichers.get(element_type)\n\n    if isinstance(enricher, ElementEnricher):\n        return enricher\n\n    raise EnricherNotFoundError(element_type)\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.base.ElementEnricher","title":"ragbits.document_search.ingestion.enrichers.base.ElementEnricher","text":"<p>               Bases: <code>Generic[ElementT]</code>, <code>WithConstructionConfig</code>, <code>ABC</code></p> <p>Base class for element enrichers, responsible for providing additional information about elements.</p> <p>Enrichers operate on raw elements and are used to fill in missing fields that could not be filled in during parsing. They usually deal with summarizing text or describing images.</p>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.base.ElementEnricher.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = enrichers\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.base.ElementEnricher.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'enricher'\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.base.ElementEnricher.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.base.ElementEnricher.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.base.ElementEnricher.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.base.ElementEnricher.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.base.ElementEnricher.enrich","title":"enrich  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>enrich(elements: list[ElementT]) -&gt; list[ElementT]\n</code></pre> <p>Enrich elements.</p> PARAMETER DESCRIPTION <code>elements</code> <p>The elements to be enriched.</p> <p> TYPE: <code>list[ElementT]</code> </p> RETURNS DESCRIPTION <code>list[ElementT]</code> <p>The list of enriched elements.</p> RAISES DESCRIPTION <code>EnricherError</code> <p>If the enrichment of the elements failed.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/enrichers/base.py</code> <pre><code>@abstractmethod\nasync def enrich(self, elements: list[ElementT]) -&gt; list[ElementT]:\n    \"\"\"\n    Enrich elements.\n\n    Args:\n        elements: The elements to be enriched.\n\n    Returns:\n        The list of enriched elements.\n\n    Raises:\n        EnricherError: If the enrichment of the elements failed.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.base.ElementEnricher.validate_element_type","title":"validate_element_type  <code>classmethod</code>","text":"<pre><code>validate_element_type(element_type: type[Element]) -&gt; None\n</code></pre> <p>Check if the enricher supports the element type.</p> PARAMETER DESCRIPTION <code>element_type</code> <p>The element type to validate against the enricher.</p> <p> TYPE: <code>type[Element]</code> </p> RAISES DESCRIPTION <code>EnricherElementNotSupportedError</code> <p>If the element type is not supported.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/enrichers/base.py</code> <pre><code>@classmethod\ndef validate_element_type(cls, element_type: type[Element]) -&gt; None:\n    \"\"\"\n    Check if the enricher supports the element type.\n\n    Args:\n        element_type: The element type to validate against the enricher.\n\n    Raises:\n        EnricherElementNotSupportedError: If the element type is not supported.\n    \"\"\"\n    expected_element_type = cls.__orig_bases__[0].__args__[0]  # type: ignore\n\n    # Check if expected_element_type is a Union and if element_type is in that Union\n    if (\n        (origin := get_origin(expected_element_type))\n        and origin == UnionType\n        and element_type in get_args(expected_element_type)\n    ):\n        return\n\n    # Check if element_type matches expected_element_type exactly\n    if element_type == expected_element_type:\n        return\n\n    raise EnricherElementNotSupportedError(enricher_name=cls.__name__, element_type=element_type)\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.image.ImageElementEnricher","title":"ragbits.document_search.ingestion.enrichers.image.ImageElementEnricher","text":"<pre><code>ImageElementEnricher(llm: LLM | None = None, prompt: type[Prompt[ImageDescriberInput, ImageDescriberOutput]] | None = None)\n</code></pre> <p>               Bases: <code>ElementEnricher[ImageElement]</code></p> <p>Enricher that describes image elements using LLM.</p> <p>Initialize the ImageElementEnricher instance.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The language model to use for describing images.</p> <p> TYPE: <code>LLM | None</code> DEFAULT: <code>None</code> </p> <code>prompt</code> <p>The prompt class to use.</p> <p> TYPE: <code>type[Prompt[ImageDescriberInput, ImageDescriberOutput]] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/enrichers/image.py</code> <pre><code>def __init__(\n    self,\n    llm: LLM | None = None,\n    prompt: type[Prompt[ImageDescriberInput, ImageDescriberOutput]] | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the ImageElementEnricher instance.\n\n    Args:\n        llm: The language model to use for describing images.\n        prompt: The prompt class to use.\n    \"\"\"\n    self._llm = llm or get_preferred_llm(llm_type=LLMType.VISION)\n    self._prompt = prompt or ImageDescriberPrompt\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.image.ImageElementEnricher.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = enrichers\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.image.ImageElementEnricher.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'enricher'\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.image.ImageElementEnricher.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.image.ImageElementEnricher.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.image.ImageElementEnricher.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.image.ImageElementEnricher.validate_element_type","title":"validate_element_type  <code>classmethod</code>","text":"<pre><code>validate_element_type(element_type: type[Element]) -&gt; None\n</code></pre> <p>Check if the enricher supports the element type.</p> PARAMETER DESCRIPTION <code>element_type</code> <p>The element type to validate against the enricher.</p> <p> TYPE: <code>type[Element]</code> </p> RAISES DESCRIPTION <code>EnricherElementNotSupportedError</code> <p>If the element type is not supported.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/enrichers/base.py</code> <pre><code>@classmethod\ndef validate_element_type(cls, element_type: type[Element]) -&gt; None:\n    \"\"\"\n    Check if the enricher supports the element type.\n\n    Args:\n        element_type: The element type to validate against the enricher.\n\n    Raises:\n        EnricherElementNotSupportedError: If the element type is not supported.\n    \"\"\"\n    expected_element_type = cls.__orig_bases__[0].__args__[0]  # type: ignore\n\n    # Check if expected_element_type is a Union and if element_type is in that Union\n    if (\n        (origin := get_origin(expected_element_type))\n        and origin == UnionType\n        and element_type in get_args(expected_element_type)\n    ):\n        return\n\n    # Check if element_type matches expected_element_type exactly\n    if element_type == expected_element_type:\n        return\n\n    raise EnricherElementNotSupportedError(enricher_name=cls.__name__, element_type=element_type)\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.image.ImageElementEnricher.enrich","title":"enrich  <code>async</code>","text":"<pre><code>enrich(elements: list[ImageElement]) -&gt; list[ImageElement]\n</code></pre> <p>Enrich image elements with additional description of the image.</p> PARAMETER DESCRIPTION <code>elements</code> <p>The elements to be enriched.</p> <p> TYPE: <code>list[ImageElement]</code> </p> RETURNS DESCRIPTION <code>list[ImageElement]</code> <p>The list of enriched elements.</p> RAISES DESCRIPTION <code>EnricherElementNotSupportedError</code> <p>If the element type is not supported.</p> <code>LLMError</code> <p>If LLM generation fails.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/enrichers/image.py</code> <pre><code>async def enrich(self, elements: list[ImageElement]) -&gt; list[ImageElement]:\n    \"\"\"\n    Enrich image elements with additional description of the image.\n\n    Args:\n        elements: The elements to be enriched.\n\n    Returns:\n        The list of enriched elements.\n\n    Raises:\n        EnricherElementNotSupportedError: If the element type is not supported.\n        LLMError: If LLM generation fails.\n    \"\"\"\n    responses: list[ImageDescriberOutput] = []\n    for element in elements:\n        self.validate_element_type(type(element))\n        image = Attachment(data=element.image_bytes)\n        prompt = self._prompt(ImageDescriberInput(image=image))\n        responses.append(await self._llm.generate(prompt))\n\n    return [\n        ImageElement(\n            document_meta=element.document_meta,\n            description=response.description,\n            image_bytes=element.image_bytes,\n            ocr_extracted_text=element.ocr_extracted_text,\n        )\n        for element, response in zip(elements, responses, strict=True)\n    ]\n</code></pre>"},{"location":"api_reference/document_search/ingest/enrichers/#ragbits.document_search.ingestion.enrichers.image.ImageElementEnricher.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; ImageElementEnricher\n</code></pre> <p>Create an <code>ImageElementEnricher</code> instance from a configuration dictionary.</p> PARAMETER DESCRIPTION <code>config</code> <p>The dictionary containing the configuration settings.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>ImageElementEnricher</code> <p>The initialized instance of <code>ImageElementEnricher</code>.</p> RAISES DESCRIPTION <code>ValidationError</code> <p>If the configuration doesn't follow the expected format.</p> <code>InvalidConfigError</code> <p>If llm or prompt can't be found or are not the correct type.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/enrichers/image.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; \"ImageElementEnricher\":\n    \"\"\"\n    Create an `ImageElementEnricher` instance from a configuration dictionary.\n\n    Args:\n        config: The dictionary containing the configuration settings.\n\n    Returns:\n        The initialized instance of `ImageElementEnricher`.\n\n    Raises:\n        ValidationError: If the configuration doesn't follow the expected format.\n        InvalidConfigError: If llm or prompt can't be found or are not the correct type.\n    \"\"\"\n    config[\"llm\"] = (\n        LLM.subclass_from_config(ObjectConstructionConfig.model_validate(config[\"llm\"]))\n        if \"llm\" in config\n        else None\n    )\n    config[\"prompt\"] = import_by_path(config[\"prompt\"]) if \"prompt\" in config else None\n    return super().from_config(config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/","title":"Document Parsers","text":""},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.router.DocumentParserRouter","title":"ragbits.document_search.ingestion.parsers.router.DocumentParserRouter","text":"<pre><code>DocumentParserRouter(parsers: Mapping[DocumentType, DocumentParser] | None = None)\n</code></pre> <p>               Bases: <code>WithConstructionConfig</code></p> <p>The class responsible for routing the document to the correct parser based on the document type.</p> <p>Initialize the DocumentParserRouter instance.</p> PARAMETER DESCRIPTION <code>parsers</code> <p>The mapping of document types and their parsers. To override default Unstructured parsers.</p> <p> TYPE: <code>Mapping[DocumentType, DocumentParser] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/parsers/router.py</code> <pre><code>def __init__(self, parsers: Mapping[DocumentType, DocumentParser] | None = None) -&gt; None:\n    \"\"\"\n    Initialize the DocumentParserRouter instance.\n\n    Args:\n        parsers: The mapping of document types and their parsers. To override default Unstructured parsers.\n    \"\"\"\n    self._parsers = {**self._get_default_parsers(), **parsers} if parsers else self._get_default_parsers()\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.router.DocumentParserRouter.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = None\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.router.DocumentParserRouter.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'parser_router'\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.router.DocumentParserRouter.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.router.DocumentParserRouter.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.router.DocumentParserRouter.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.router.DocumentParserRouter.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, ObjectConstructionConfig]) -&gt; Self\n</code></pre> <p>Initialize the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, ObjectConstructionConfig]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The DocumentParserRouter.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If any of the provided parsers cannot be initialized.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/parsers/router.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, ObjectConstructionConfig]) -&gt; Self:\n    \"\"\"\n    Initialize the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        The DocumentParserRouter.\n\n    Raises:\n        InvalidConfigError: If any of the provided parsers cannot be initialized.\n    \"\"\"\n    parsers = {\n        DocumentType(document_type): DocumentParser.subclass_from_config(parser_config)\n        for document_type, parser_config in config.items()\n    }\n    return super().from_config({\"parsers\": parsers})\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.router.DocumentParserRouter.get","title":"get","text":"<pre><code>get(document_type: DocumentType) -&gt; DocumentParser\n</code></pre> <p>Get the parser for the document.</p> PARAMETER DESCRIPTION <code>document_type</code> <p>The document type.</p> <p> TYPE: <code>DocumentType</code> </p> RETURNS DESCRIPTION <code>DocumentParser</code> <p>The parser for processing the document.</p> RAISES DESCRIPTION <code>ParserNotFoundError</code> <p>If no parser is found for the document type.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/parsers/router.py</code> <pre><code>def get(self, document_type: DocumentType) -&gt; DocumentParser:\n    \"\"\"\n    Get the parser for the document.\n\n    Args:\n        document_type: The document type.\n\n    Returns:\n        The parser for processing the document.\n\n    Raises:\n        ParserNotFoundError: If no parser is found for the document type.\n    \"\"\"\n    parser = self._parsers.get(document_type)\n\n    if isinstance(parser, DocumentParser):\n        return parser\n\n    raise ParserNotFoundError(document_type)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.DocumentParser","title":"ragbits.document_search.ingestion.parsers.base.DocumentParser","text":"<p>               Bases: <code>WithConstructionConfig</code>, <code>ABC</code></p> <p>Base class for document parsers, responsible for converting the document into a list of elements.</p>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.DocumentParser.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = parsers\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.DocumentParser.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'parser'\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.DocumentParser.supported_document_types","title":"supported_document_types  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>supported_document_types: set[DocumentType] = set()\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.DocumentParser.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.DocumentParser.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.DocumentParser.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.DocumentParser.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.DocumentParser.parse","title":"parse  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>parse(document: Document) -&gt; list[Element]\n</code></pre> <p>Parse the document.</p> PARAMETER DESCRIPTION <code>document</code> <p>The document to parse.</p> <p> TYPE: <code>Document</code> </p> RETURNS DESCRIPTION <code>list[Element]</code> <p>The list of elements extracted from the document.</p> RAISES DESCRIPTION <code>ParserError</code> <p>If the parsing of the document failed.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/parsers/base.py</code> <pre><code>@abstractmethod\nasync def parse(self, document: Document) -&gt; list[Element]:\n    \"\"\"\n    Parse the document.\n\n    Args:\n        document: The document to parse.\n\n    Returns:\n        The list of elements extracted from the document.\n\n    Raises:\n        ParserError: If the parsing of the document failed.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.DocumentParser.validate_document_type","title":"validate_document_type  <code>classmethod</code>","text":"<pre><code>validate_document_type(document_type: DocumentType) -&gt; None\n</code></pre> <p>Check if the parser supports the document type.</p> PARAMETER DESCRIPTION <code>document_type</code> <p>The document type to validate against the parser.</p> <p> TYPE: <code>DocumentType</code> </p> RAISES DESCRIPTION <code>ParserDocumentNotSupportedError</code> <p>If the document type is not supported.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/parsers/base.py</code> <pre><code>@classmethod\ndef validate_document_type(cls, document_type: DocumentType) -&gt; None:\n    \"\"\"\n    Check if the parser supports the document type.\n\n    Args:\n        document_type: The document type to validate against the parser.\n\n    Raises:\n        ParserDocumentNotSupportedError: If the document type is not supported.\n    \"\"\"\n    if document_type not in cls.supported_document_types:\n        raise ParserDocumentNotSupportedError(parser_name=cls.__name__, document_type=document_type)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.TextDocumentParser","title":"ragbits.document_search.ingestion.parsers.base.TextDocumentParser","text":"<p>               Bases: <code>DocumentParser</code></p> <p>Simple parser that maps a text to the text element.</p>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.TextDocumentParser.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = parsers\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.TextDocumentParser.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'parser'\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.TextDocumentParser.supported_document_types","title":"supported_document_types  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>supported_document_types = {TXT, MD}\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.TextDocumentParser.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.TextDocumentParser.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.TextDocumentParser.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.TextDocumentParser.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.TextDocumentParser.validate_document_type","title":"validate_document_type  <code>classmethod</code>","text":"<pre><code>validate_document_type(document_type: DocumentType) -&gt; None\n</code></pre> <p>Check if the parser supports the document type.</p> PARAMETER DESCRIPTION <code>document_type</code> <p>The document type to validate against the parser.</p> <p> TYPE: <code>DocumentType</code> </p> RAISES DESCRIPTION <code>ParserDocumentNotSupportedError</code> <p>If the document type is not supported.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/parsers/base.py</code> <pre><code>@classmethod\ndef validate_document_type(cls, document_type: DocumentType) -&gt; None:\n    \"\"\"\n    Check if the parser supports the document type.\n\n    Args:\n        document_type: The document type to validate against the parser.\n\n    Raises:\n        ParserDocumentNotSupportedError: If the document type is not supported.\n    \"\"\"\n    if document_type not in cls.supported_document_types:\n        raise ParserDocumentNotSupportedError(parser_name=cls.__name__, document_type=document_type)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.TextDocumentParser.parse","title":"parse  <code>async</code>","text":"<pre><code>parse(document: Document) -&gt; list[Element]\n</code></pre> <p>Parse the document.</p> PARAMETER DESCRIPTION <code>document</code> <p>The document to parse.</p> <p> TYPE: <code>Document</code> </p> RETURNS DESCRIPTION <code>list[Element]</code> <p>List with an text element with the text content.</p> RAISES DESCRIPTION <code>ParserDocumentNotSupportedError</code> <p>If the document type is not supported by the parser.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/parsers/base.py</code> <pre><code>async def parse(self, document: Document) -&gt; list[Element]:\n    \"\"\"\n    Parse the document.\n\n    Args:\n        document: The document to parse.\n\n    Returns:\n        List with an text element with the text content.\n\n    Raises:\n        ParserDocumentNotSupportedError: If the document type is not supported by the parser.\n    \"\"\"\n    self.validate_document_type(document.metadata.document_type)\n    return [TextElement(content=document.local_path.read_text(), document_meta=document.metadata)]\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.ImageDocumentParser","title":"ragbits.document_search.ingestion.parsers.base.ImageDocumentParser","text":"<p>               Bases: <code>DocumentParser</code></p> <p>Simple parser that maps an image to the image element.</p>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.ImageDocumentParser.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = parsers\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.ImageDocumentParser.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'parser'\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.ImageDocumentParser.supported_document_types","title":"supported_document_types  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>supported_document_types = {JPG, PNG}\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.ImageDocumentParser.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.ImageDocumentParser.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.ImageDocumentParser.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.ImageDocumentParser.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.ImageDocumentParser.validate_document_type","title":"validate_document_type  <code>classmethod</code>","text":"<pre><code>validate_document_type(document_type: DocumentType) -&gt; None\n</code></pre> <p>Check if the parser supports the document type.</p> PARAMETER DESCRIPTION <code>document_type</code> <p>The document type to validate against the parser.</p> <p> TYPE: <code>DocumentType</code> </p> RAISES DESCRIPTION <code>ParserDocumentNotSupportedError</code> <p>If the document type is not supported.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/parsers/base.py</code> <pre><code>@classmethod\ndef validate_document_type(cls, document_type: DocumentType) -&gt; None:\n    \"\"\"\n    Check if the parser supports the document type.\n\n    Args:\n        document_type: The document type to validate against the parser.\n\n    Raises:\n        ParserDocumentNotSupportedError: If the document type is not supported.\n    \"\"\"\n    if document_type not in cls.supported_document_types:\n        raise ParserDocumentNotSupportedError(parser_name=cls.__name__, document_type=document_type)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.base.ImageDocumentParser.parse","title":"parse  <code>async</code>","text":"<pre><code>parse(document: Document) -&gt; list[Element]\n</code></pre> <p>Parse the document.</p> PARAMETER DESCRIPTION <code>document</code> <p>The document to parse.</p> <p> TYPE: <code>Document</code> </p> RETURNS DESCRIPTION <code>list[Element]</code> <p>List with an image element with the image content.</p> RAISES DESCRIPTION <code>ParserDocumentNotSupportedError</code> <p>If the document type is not supported by the parser.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/parsers/base.py</code> <pre><code>async def parse(self, document: Document) -&gt; list[Element]:\n    \"\"\"\n    Parse the document.\n\n    Args:\n        document: The document to parse.\n\n    Returns:\n        List with an image element with the image content.\n\n    Raises:\n        ParserDocumentNotSupportedError: If the document type is not supported by the parser.\n    \"\"\"\n    self.validate_document_type(document.metadata.document_type)\n    return [ImageElement(image_bytes=document.local_path.read_bytes(), document_meta=document.metadata)]\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.docling.DoclingDocumentParser","title":"ragbits.document_search.ingestion.parsers.docling.DoclingDocumentParser","text":"<pre><code>DoclingDocumentParser(ignore_images: bool = False, num_threads: int = 1, chunker: BaseChunker | None = None, format_options: dict[InputFormat, FormatOption] | None = None)\n</code></pre> <p>               Bases: <code>DocumentParser</code></p> <p>Parser that uses the Docling to process the documents.</p> <p>Initialize the DoclingDocumentParser instance.</p> PARAMETER DESCRIPTION <code>ignore_images</code> <p>If True images will be skipped.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>num_threads</code> <p>The number of threads for parsing parallelism on CPU.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>chunker</code> <p>Custom chunker instance. If None, HierarchicalChunker will be used.</p> <p> TYPE: <code>BaseChunker | None</code> DEFAULT: <code>None</code> </p> <code>format_options</code> <p>Full format options configuration for DocumentConverter. If None, default format options will be used.</p> <p> TYPE: <code>dict[InputFormat, FormatOption] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/parsers/docling.py</code> <pre><code>def __init__(\n    self,\n    ignore_images: bool = False,\n    num_threads: int = 1,\n    chunker: BaseChunker | None = None,\n    format_options: dict[InputFormat, FormatOption] | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the DoclingDocumentParser instance.\n\n    Args:\n        ignore_images: If True images will be skipped.\n        num_threads: The number of threads for parsing parallelism on CPU.\n        chunker: Custom chunker instance. If None, HierarchicalChunker will be used.\n        format_options: Full format options configuration for DocumentConverter.\n            If None, default format options will be used.\n    \"\"\"\n    self.ignore_images = ignore_images\n    self.num_threads = num_threads\n    self.chunker = chunker\n    self.format_options = format_options\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.docling.DoclingDocumentParser.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = parsers\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.docling.DoclingDocumentParser.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'parser'\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.docling.DoclingDocumentParser.supported_document_types","title":"supported_document_types  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>supported_document_types = {DOCX, PPTX, XLSX, MD, PNG, JPG, HTML, TXT, PDF}\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.docling.DoclingDocumentParser.ignore_images","title":"ignore_images  <code>instance-attribute</code>","text":"<pre><code>ignore_images = ignore_images\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.docling.DoclingDocumentParser.num_threads","title":"num_threads  <code>instance-attribute</code>","text":"<pre><code>num_threads = num_threads\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.docling.DoclingDocumentParser.chunker","title":"chunker  <code>instance-attribute</code>","text":"<pre><code>chunker = chunker\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.docling.DoclingDocumentParser.format_options","title":"format_options  <code>instance-attribute</code>","text":"<pre><code>format_options = format_options\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.docling.DoclingDocumentParser.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.docling.DoclingDocumentParser.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.docling.DoclingDocumentParser.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.docling.DoclingDocumentParser.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.docling.DoclingDocumentParser.validate_document_type","title":"validate_document_type  <code>classmethod</code>","text":"<pre><code>validate_document_type(document_type: DocumentType) -&gt; None\n</code></pre> <p>Check if the parser supports the document type.</p> PARAMETER DESCRIPTION <code>document_type</code> <p>The document type to validate against the parser.</p> <p> TYPE: <code>DocumentType</code> </p> RAISES DESCRIPTION <code>ParserDocumentNotSupportedError</code> <p>If the document type is not supported.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/parsers/base.py</code> <pre><code>@classmethod\ndef validate_document_type(cls, document_type: DocumentType) -&gt; None:\n    \"\"\"\n    Check if the parser supports the document type.\n\n    Args:\n        document_type: The document type to validate against the parser.\n\n    Raises:\n        ParserDocumentNotSupportedError: If the document type is not supported.\n    \"\"\"\n    if document_type not in cls.supported_document_types:\n        raise ParserDocumentNotSupportedError(parser_name=cls.__name__, document_type=document_type)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.docling.DoclingDocumentParser.parse","title":"parse  <code>async</code>","text":"<pre><code>parse(document: Document) -&gt; list[Element]\n</code></pre> <p>Parse the document using the Docling API.</p> PARAMETER DESCRIPTION <code>document</code> <p>The document to parse.</p> <p> TYPE: <code>Document</code> </p> RETURNS DESCRIPTION <code>list[Element]</code> <p>The list of elements extracted from the document.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/parsers/docling.py</code> <pre><code>async def parse(self, document: Document) -&gt; list[Element]:\n    \"\"\"\n    Parse the document using the Docling API.\n\n    Args:\n        document: The document to parse.\n\n    Returns:\n        The list of elements extracted from the document.\n    \"\"\"\n    self.validate_document_type(document.metadata.document_type)\n    partitioned_document = await self._partition(document)\n    return self._chunk(partitioned_document, document)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.unstructured.UnstructuredDocumentParser","title":"ragbits.document_search.ingestion.parsers.unstructured.UnstructuredDocumentParser","text":"<pre><code>UnstructuredDocumentParser(partition_kwargs: dict | None = None, chunking_kwargs: dict | None = None, api_key: str | None = None, api_server: str | None = None, use_api: bool = False, ignore_images: bool = False)\n</code></pre> <p>               Bases: <code>DocumentParser</code></p> <p>Parser that uses the Unstructured API or local SDK to process the documents.</p> <p>Initialize the UnstructuredDocumentParser instance.</p> PARAMETER DESCRIPTION <code>partition_kwargs</code> <p>The additional arguments for the partitioning. Refer to the Unstructured API documentation for the available options: https://docs.unstructured.io/api-reference/api-services/api-parameters</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>chunking_kwargs</code> <p>The additional arguments for the chunking.</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>api_key</code> <p>The API key to use for the Unstructured API. If not specified, the UNSTRUCTURED_API_KEY environment variable will be used.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>api_server</code> <p>The API server URL to use for the Unstructured API. If not specified, the UNSTRUCTURED_SERVER_URL environment variable will be used.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>use_api</code> <p>whether to use Unstructured API, otherwise use local version of Unstructured library</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>ignore_images</code> <p>if True images will be skipped</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/parsers/unstructured.py</code> <pre><code>def __init__(\n    self,\n    partition_kwargs: dict | None = None,\n    chunking_kwargs: dict | None = None,\n    api_key: str | None = None,\n    api_server: str | None = None,\n    use_api: bool = False,\n    ignore_images: bool = False,\n) -&gt; None:\n    \"\"\"\n    Initialize the UnstructuredDocumentParser instance.\n\n    Args:\n        partition_kwargs: The additional arguments for the partitioning. Refer to the Unstructured API documentation\n            for the available options: https://docs.unstructured.io/api-reference/api-services/api-parameters\n        chunking_kwargs: The additional arguments for the chunking.\n        api_key: The API key to use for the Unstructured API. If not specified, the UNSTRUCTURED_API_KEY environment\n            variable will be used.\n        api_server: The API server URL to use for the Unstructured API. If not specified, the\n            UNSTRUCTURED_SERVER_URL environment variable will be used.\n        use_api: whether to use Unstructured API, otherwise use local version of Unstructured library\n        ignore_images: if True images will be skipped\n    \"\"\"\n    self.partition_kwargs = partition_kwargs or {}\n    self.chunking_kwargs = chunking_kwargs or {}\n    self.api_key = api_key or os.getenv(UNSTRUCTURED_API_KEY_ENV)\n    self.api_server = api_server or os.getenv(UNSTRUCTURED_SERVER_URL_ENV)\n    self.use_api = use_api\n    self.ignore_images = ignore_images\n    self._client = UnstructuredClient(api_key_auth=self.api_key, server_url=self.api_server)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.unstructured.UnstructuredDocumentParser.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = parsers\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.unstructured.UnstructuredDocumentParser.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'parser'\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.unstructured.UnstructuredDocumentParser.supported_document_types","title":"supported_document_types  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>supported_document_types = {TXT, MD, PDF, DOCX, DOC, PPTX, PPT, XLSX, XLS, CSV, HTML, EPUB, ORG, ODT, RST, RTF, TSV, JSON, XML, JPG, PNG}\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.unstructured.UnstructuredDocumentParser.partition_kwargs","title":"partition_kwargs  <code>instance-attribute</code>","text":"<pre><code>partition_kwargs = partition_kwargs or {}\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.unstructured.UnstructuredDocumentParser.chunking_kwargs","title":"chunking_kwargs  <code>instance-attribute</code>","text":"<pre><code>chunking_kwargs = chunking_kwargs or {}\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.unstructured.UnstructuredDocumentParser.api_key","title":"api_key  <code>instance-attribute</code>","text":"<pre><code>api_key = api_key or getenv(UNSTRUCTURED_API_KEY_ENV)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.unstructured.UnstructuredDocumentParser.api_server","title":"api_server  <code>instance-attribute</code>","text":"<pre><code>api_server = api_server or getenv(UNSTRUCTURED_SERVER_URL_ENV)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.unstructured.UnstructuredDocumentParser.use_api","title":"use_api  <code>instance-attribute</code>","text":"<pre><code>use_api = use_api\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.unstructured.UnstructuredDocumentParser.ignore_images","title":"ignore_images  <code>instance-attribute</code>","text":"<pre><code>ignore_images = ignore_images\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.unstructured.UnstructuredDocumentParser.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.unstructured.UnstructuredDocumentParser.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.unstructured.UnstructuredDocumentParser.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.unstructured.UnstructuredDocumentParser.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.unstructured.UnstructuredDocumentParser.validate_document_type","title":"validate_document_type  <code>classmethod</code>","text":"<pre><code>validate_document_type(document_type: DocumentType) -&gt; None\n</code></pre> <p>Check if the parser supports the document type.</p> PARAMETER DESCRIPTION <code>document_type</code> <p>The document type to validate against the parser.</p> <p> TYPE: <code>DocumentType</code> </p> RAISES DESCRIPTION <code>ParserDocumentNotSupportedError</code> <p>If the document type is not supported.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/parsers/base.py</code> <pre><code>@classmethod\ndef validate_document_type(cls, document_type: DocumentType) -&gt; None:\n    \"\"\"\n    Check if the parser supports the document type.\n\n    Args:\n        document_type: The document type to validate against the parser.\n\n    Raises:\n        ParserDocumentNotSupportedError: If the document type is not supported.\n    \"\"\"\n    if document_type not in cls.supported_document_types:\n        raise ParserDocumentNotSupportedError(parser_name=cls.__name__, document_type=document_type)\n</code></pre>"},{"location":"api_reference/document_search/ingest/parsers/#ragbits.document_search.ingestion.parsers.unstructured.UnstructuredDocumentParser.parse","title":"parse  <code>async</code>","text":"<pre><code>parse(document: Document) -&gt; list[Element]\n</code></pre> <p>Parse the document using the Unstructured API.</p> PARAMETER DESCRIPTION <code>document</code> <p>The document to parse.</p> <p> TYPE: <code>Document</code> </p> RETURNS DESCRIPTION <code>list[Element]</code> <p>The list of elements extracted from the document.</p> RAISES DESCRIPTION <code>ParserDocumentNotSupportedError</code> <p>If the document type is not supported by the parser.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/parsers/unstructured.py</code> <pre><code>@traceable\nasync def parse(self, document: Document) -&gt; list[Element]:\n    \"\"\"\n    Parse the document using the Unstructured API.\n\n    Args:\n        document: The document to parse.\n\n    Returns:\n        The list of elements extracted from the document.\n\n    Raises:\n        ParserDocumentNotSupportedError: If the document type is not supported by the parser.\n    \"\"\"\n    self.validate_document_type(document.metadata.document_type)\n    elements = await self._partition(document)\n    return self._chunk(elements, document)\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/","title":"Ingest Strategies","text":""},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.base.IngestStrategy","title":"ragbits.document_search.ingestion.strategies.base.IngestStrategy","text":"<pre><code>IngestStrategy(num_retries: int = 3, backoff_multiplier: int = 1, backoff_max: int = 60)\n</code></pre> <p>               Bases: <code>WithConstructionConfig</code>, <code>ABC</code></p> <p>Base class for ingest strategies, responsible for orchiesting the tasks required to index the document.</p> <p>Initialize the IngestStrategy instance.</p> PARAMETER DESCRIPTION <code>num_retries</code> <p>The number of retries per document ingest task error.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> <code>backoff_multiplier</code> <p>The base delay multiplier for exponential backoff (in seconds).</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>backoff_max</code> <p>The maximum allowed delay (in seconds) between retries.</p> <p> TYPE: <code>int</code> DEFAULT: <code>60</code> </p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/strategies/base.py</code> <pre><code>def __init__(self, num_retries: int = 3, backoff_multiplier: int = 1, backoff_max: int = 60) -&gt; None:\n    \"\"\"\n    Initialize the IngestStrategy instance.\n\n    Args:\n        num_retries: The number of retries per document ingest task error.\n        backoff_multiplier: The base delay multiplier for exponential backoff (in seconds).\n        backoff_max: The maximum allowed delay (in seconds) between retries.\n    \"\"\"\n    self.num_retries = num_retries\n    self.backoff_multiplier = backoff_multiplier\n    self.backoff_max = backoff_max\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.base.IngestStrategy.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = strategies\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.base.IngestStrategy.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'ingest_strategy'\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.base.IngestStrategy.num_retries","title":"num_retries  <code>instance-attribute</code>","text":"<pre><code>num_retries = num_retries\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.base.IngestStrategy.backoff_multiplier","title":"backoff_multiplier  <code>instance-attribute</code>","text":"<pre><code>backoff_multiplier = backoff_multiplier\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.base.IngestStrategy.backoff_max","title":"backoff_max  <code>instance-attribute</code>","text":"<pre><code>backoff_max = backoff_max\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.base.IngestStrategy.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.base.IngestStrategy.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.base.IngestStrategy.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.base.IngestStrategy.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.sequential.SequentialIngestStrategy","title":"ragbits.document_search.ingestion.strategies.sequential.SequentialIngestStrategy","text":"<pre><code>SequentialIngestStrategy(num_retries: int = 0, backoff_multiplier: int = 1, backoff_max: int = 60)\n</code></pre> <p>               Bases: <code>BatchedIngestStrategy</code></p> <p>Ingest strategy that processes documents in sequence, one at a time.</p> <p>Initialize the SequentialIngestStrategy instance.</p> PARAMETER DESCRIPTION <code>num_retries</code> <p>The number of retries per document ingest task error.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>backoff_multiplier</code> <p>The base delay multiplier for exponential backoff (in seconds).</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>backoff_max</code> <p>The maximum allowed delay (in seconds) between retries.</p> <p> TYPE: <code>int</code> DEFAULT: <code>60</code> </p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/strategies/sequential.py</code> <pre><code>def __init__(self, num_retries: int = 0, backoff_multiplier: int = 1, backoff_max: int = 60) -&gt; None:\n    \"\"\"\n    Initialize the SequentialIngestStrategy instance.\n\n    Args:\n        num_retries: The number of retries per document ingest task error.\n        backoff_multiplier: The base delay multiplier for exponential backoff (in seconds).\n        backoff_max: The maximum allowed delay (in seconds) between retries.\n    \"\"\"\n    super().__init__(\n        batch_size=1,\n        num_retries=num_retries,\n        backoff_multiplier=backoff_multiplier,\n        backoff_max=backoff_max,\n    )\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.sequential.SequentialIngestStrategy.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = strategies\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.sequential.SequentialIngestStrategy.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'ingest_strategy'\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.sequential.SequentialIngestStrategy.num_retries","title":"num_retries  <code>instance-attribute</code>","text":"<pre><code>num_retries = num_retries\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.sequential.SequentialIngestStrategy.backoff_multiplier","title":"backoff_multiplier  <code>instance-attribute</code>","text":"<pre><code>backoff_multiplier = backoff_multiplier\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.sequential.SequentialIngestStrategy.backoff_max","title":"backoff_max  <code>instance-attribute</code>","text":"<pre><code>backoff_max = backoff_max\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.sequential.SequentialIngestStrategy.batch_size","title":"batch_size  <code>instance-attribute</code>","text":"<pre><code>batch_size = batch_size\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.sequential.SequentialIngestStrategy.enrich_batch_size","title":"enrich_batch_size  <code>instance-attribute</code>","text":"<pre><code>enrich_batch_size = enrich_batch_size\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.sequential.SequentialIngestStrategy.index_batch_size","title":"index_batch_size  <code>instance-attribute</code>","text":"<pre><code>index_batch_size = index_batch_size\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.sequential.SequentialIngestStrategy.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.sequential.SequentialIngestStrategy.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.sequential.SequentialIngestStrategy.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.sequential.SequentialIngestStrategy.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.batched.BatchedIngestStrategy","title":"ragbits.document_search.ingestion.strategies.batched.BatchedIngestStrategy","text":"<pre><code>BatchedIngestStrategy(batch_size: int | None = None, enrich_batch_size: int | None = None, index_batch_size: int | None = None, num_retries: int = 3, backoff_multiplier: int = 1, backoff_max: int = 60)\n</code></pre> <p>               Bases: <code>IngestStrategy</code></p> <p>Ingest strategy that processes documents in batches.</p> <p>Initialize the BatchedIngestStrategy instance.</p> PARAMETER DESCRIPTION <code>batch_size</code> <p>The batch size for parsing documents. Describes the maximum number of documents to parse at once. If None, all documents are parsed at once.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>enrich_batch_size</code> <p>The batch size for enriching elements. Describes the maximum number of document elements to enrich at once. If None, all elements are enriched at once.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>index_batch_size</code> <p>The batch size for indexing elements. Describes the maximum number of document elements to index at once. If None, all elements are indexed at once.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>num_retries</code> <p>The number of retries per document ingest task error.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> <code>backoff_multiplier</code> <p>The base delay multiplier for exponential backoff (in seconds).</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>backoff_max</code> <p>The maximum allowed delay (in seconds) between retries.</p> <p> TYPE: <code>int</code> DEFAULT: <code>60</code> </p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/strategies/batched.py</code> <pre><code>def __init__(\n    self,\n    batch_size: int | None = None,\n    enrich_batch_size: int | None = None,\n    index_batch_size: int | None = None,\n    num_retries: int = 3,\n    backoff_multiplier: int = 1,\n    backoff_max: int = 60,\n) -&gt; None:\n    \"\"\"\n    Initialize the BatchedIngestStrategy instance.\n\n    Args:\n        batch_size: The batch size for parsing documents.\n            Describes the maximum number of documents to parse at once. If None, all documents are parsed at once.\n        enrich_batch_size: The batch size for enriching elements.\n            Describes the maximum number of document elements to enrich at once.\n            If None, all elements are enriched at once.\n        index_batch_size: The batch size for indexing elements.\n            Describes the maximum number of document elements to index at once.\n            If None, all elements are indexed at once.\n        num_retries: The number of retries per document ingest task error.\n        backoff_multiplier: The base delay multiplier for exponential backoff (in seconds).\n        backoff_max: The maximum allowed delay (in seconds) between retries.\n    \"\"\"\n    super().__init__(num_retries=num_retries, backoff_multiplier=backoff_multiplier, backoff_max=backoff_max)\n    self.batch_size = batch_size\n    self.enrich_batch_size = enrich_batch_size\n    self.index_batch_size = index_batch_size\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.batched.BatchedIngestStrategy.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = strategies\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.batched.BatchedIngestStrategy.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'ingest_strategy'\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.batched.BatchedIngestStrategy.num_retries","title":"num_retries  <code>instance-attribute</code>","text":"<pre><code>num_retries = num_retries\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.batched.BatchedIngestStrategy.backoff_multiplier","title":"backoff_multiplier  <code>instance-attribute</code>","text":"<pre><code>backoff_multiplier = backoff_multiplier\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.batched.BatchedIngestStrategy.backoff_max","title":"backoff_max  <code>instance-attribute</code>","text":"<pre><code>backoff_max = backoff_max\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.batched.BatchedIngestStrategy.batch_size","title":"batch_size  <code>instance-attribute</code>","text":"<pre><code>batch_size = batch_size\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.batched.BatchedIngestStrategy.enrich_batch_size","title":"enrich_batch_size  <code>instance-attribute</code>","text":"<pre><code>enrich_batch_size = enrich_batch_size\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.batched.BatchedIngestStrategy.index_batch_size","title":"index_batch_size  <code>instance-attribute</code>","text":"<pre><code>index_batch_size = index_batch_size\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.batched.BatchedIngestStrategy.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.batched.BatchedIngestStrategy.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.batched.BatchedIngestStrategy.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.batched.BatchedIngestStrategy.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.ray.RayDistributedIngestStrategy","title":"ragbits.document_search.ingestion.strategies.ray.RayDistributedIngestStrategy","text":"<pre><code>RayDistributedIngestStrategy(batch_size: int = 1, enrich_batch_size: int | None = None, index_batch_size: int | None = None, parse_memory: float | None = None, processing_memory: float | None = None, num_retries: int = 3, backoff_multiplier: int = 1, backoff_max: int = 60)\n</code></pre> <p>               Bases: <code>BatchedIngestStrategy</code></p> <p>Ingest strategy that processes documents on a cluster, using Ray.</p> <p>Initialize the RayDistributedIngestStrategy instance.</p> PARAMETER DESCRIPTION <code>batch_size</code> <p>The batch size for parsing documents.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>enrich_batch_size</code> <p>The batch size for enriching elements. Describes the maximum number of document elements to enrich at once. If None, all elements are enriched at once.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>index_batch_size</code> <p>The batch size for indexing elements. Describes the maximum number of document elements to index at once. If None, all elements are indexed at once.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>parse_memory</code> <p>The heap memory in bytes to reserve for each parallel parsing tasks.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>processing_memory</code> <p>The heap memory in bytes to reserve for each parallel elements processing tasks.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>num_retries</code> <p>The number of retries per document ingest task error.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> <code>backoff_multiplier</code> <p>The base delay multiplier for exponential backoff (in seconds).</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>backoff_max</code> <p>The maximum allowed delay (in seconds) between retries.</p> <p> TYPE: <code>int</code> DEFAULT: <code>60</code> </p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/ingestion/strategies/ray.py</code> <pre><code>def __init__(\n    self,\n    batch_size: int = 1,\n    enrich_batch_size: int | None = None,\n    index_batch_size: int | None = None,\n    parse_memory: float | None = None,\n    processing_memory: float | None = None,\n    num_retries: int = 3,\n    backoff_multiplier: int = 1,\n    backoff_max: int = 60,\n) -&gt; None:\n    \"\"\"\n    Initialize the RayDistributedIngestStrategy instance.\n\n    Args:\n        batch_size: The batch size for parsing documents.\n        enrich_batch_size: The batch size for enriching elements.\n            Describes the maximum number of document elements to enrich at once.\n            If None, all elements are enriched at once.\n        index_batch_size: The batch size for indexing elements.\n            Describes the maximum number of document elements to index at once.\n            If None, all elements are indexed at once.\n        parse_memory: The heap memory in bytes to reserve for each parallel parsing tasks.\n        processing_memory: The heap memory in bytes to reserve for each parallel elements processing tasks.\n        num_retries: The number of retries per document ingest task error.\n        backoff_multiplier: The base delay multiplier for exponential backoff (in seconds).\n        backoff_max: The maximum allowed delay (in seconds) between retries.\n    \"\"\"\n    super().__init__(\n        batch_size=batch_size,\n        enrich_batch_size=enrich_batch_size,\n        index_batch_size=index_batch_size,\n        num_retries=num_retries,\n        backoff_multiplier=backoff_multiplier,\n        backoff_max=backoff_max,\n    )\n    self.parse_memory = parse_memory\n    self.processing_memory = processing_memory\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.ray.RayDistributedIngestStrategy.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = strategies\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.ray.RayDistributedIngestStrategy.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'ingest_strategy'\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.ray.RayDistributedIngestStrategy.num_retries","title":"num_retries  <code>instance-attribute</code>","text":"<pre><code>num_retries = num_retries\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.ray.RayDistributedIngestStrategy.backoff_multiplier","title":"backoff_multiplier  <code>instance-attribute</code>","text":"<pre><code>backoff_multiplier = backoff_multiplier\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.ray.RayDistributedIngestStrategy.backoff_max","title":"backoff_max  <code>instance-attribute</code>","text":"<pre><code>backoff_max = backoff_max\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.ray.RayDistributedIngestStrategy.batch_size","title":"batch_size  <code>instance-attribute</code>","text":"<pre><code>batch_size = batch_size\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.ray.RayDistributedIngestStrategy.enrich_batch_size","title":"enrich_batch_size  <code>instance-attribute</code>","text":"<pre><code>enrich_batch_size = enrich_batch_size\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.ray.RayDistributedIngestStrategy.index_batch_size","title":"index_batch_size  <code>instance-attribute</code>","text":"<pre><code>index_batch_size = index_batch_size\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.ray.RayDistributedIngestStrategy.parse_memory","title":"parse_memory  <code>instance-attribute</code>","text":"<pre><code>parse_memory = parse_memory\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.ray.RayDistributedIngestStrategy.processing_memory","title":"processing_memory  <code>instance-attribute</code>","text":"<pre><code>processing_memory = processing_memory\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.ray.RayDistributedIngestStrategy.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.ray.RayDistributedIngestStrategy.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.ray.RayDistributedIngestStrategy.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/ingest/strategies/#ragbits.document_search.ingestion.strategies.ray.RayDistributedIngestStrategy.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/","title":"Query Rephrasers","text":""},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.base.QueryRephraserOptions","title":"ragbits.document_search.retrieval.rephrasers.base.QueryRephraserOptions","text":"<p>               Bases: <code>Options</code></p> <p>Object representing the options for the rephraser.</p>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.base.QueryRephraserOptions.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(extra='allow', arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.base.QueryRephraserOptions.dict","title":"dict","text":"<pre><code>dict() -&gt; dict[str, Any]\n</code></pre> <p>Creates a dictionary representation of the Options instance. If a value is None, it will be replaced with a provider-specific not-given sentinel.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>A dictionary representation of the Options instance.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/options.py</code> <pre><code>def dict(self) -&gt; dict[str, Any]:  # type: ignore # mypy complains about overriding BaseModel.dict\n    \"\"\"\n    Creates a dictionary representation of the Options instance.\n    If a value is None, it will be replaced with a provider-specific not-given sentinel.\n\n    Returns:\n        A dictionary representation of the Options instance.\n    \"\"\"\n    options = self.model_dump()\n\n    return {\n        key: self._not_given if value is None or isinstance(value, NotGiven) else value\n        for key, value in options.items()\n    }\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.llm.LLMQueryRephraserOptions","title":"ragbits.document_search.retrieval.rephrasers.llm.LLMQueryRephraserOptions","text":"<p>               Bases: <code>QueryRephraserOptions</code>, <code>Generic[LLMClientOptionsT]</code></p> <p>Object representing the options for the LLM query rephraser.</p> ATTRIBUTE DESCRIPTION <code>n</code> <p>The number of rephrasings to generate. Any number below 2 will generate only one rephrasing.</p> <p> TYPE: <code>int | None | NotGiven</code> </p> <code>llm_options</code> <p>The options for the LLM.</p> <p> TYPE: <code>LLMClientOptionsT | None | NotGiven</code> </p>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.llm.LLMQueryRephraserOptions.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(extra='allow', arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.llm.LLMQueryRephraserOptions.n","title":"n  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>n: int | None | NotGiven = NOT_GIVEN\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.llm.LLMQueryRephraserOptions.llm_options","title":"llm_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>llm_options: LLMClientOptionsT | None | NotGiven = NOT_GIVEN\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.llm.LLMQueryRephraserOptions.dict","title":"dict","text":"<pre><code>dict() -&gt; dict[str, Any]\n</code></pre> <p>Creates a dictionary representation of the Options instance. If a value is None, it will be replaced with a provider-specific not-given sentinel.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>A dictionary representation of the Options instance.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/options.py</code> <pre><code>def dict(self) -&gt; dict[str, Any]:  # type: ignore # mypy complains about overriding BaseModel.dict\n    \"\"\"\n    Creates a dictionary representation of the Options instance.\n    If a value is None, it will be replaced with a provider-specific not-given sentinel.\n\n    Returns:\n        A dictionary representation of the Options instance.\n    \"\"\"\n    options = self.model_dump()\n\n    return {\n        key: self._not_given if value is None or isinstance(value, NotGiven) else value\n        for key, value in options.items()\n    }\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.base.QueryRephraser","title":"ragbits.document_search.retrieval.rephrasers.base.QueryRephraser","text":"<pre><code>QueryRephraser(default_options: OptionsT | None = None)\n</code></pre> <p>               Bases: <code>ConfigurableComponent[QueryRephraserOptionsT]</code>, <code>ABC</code></p> <p>Rephrases a query. Can provide multiple rephrased queries from one sentence / question.</p> <p>Constructs a new ConfigurableComponent instance.</p> PARAMETER DESCRIPTION <code>default_options</code> <p>The default options for the component.</p> <p> TYPE: <code>OptionsT | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>def __init__(self, default_options: OptionsT | None = None) -&gt; None:\n    \"\"\"\n    Constructs a new ConfigurableComponent instance.\n\n    Args:\n        default_options: The default options for the component.\n    \"\"\"\n    self.default_options: OptionsT = default_options or self.options_cls()\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.base.QueryRephraser.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.base.QueryRephraser.options_cls","title":"options_cls  <code>instance-attribute</code>","text":"<pre><code>options_cls: type[QueryRephraserOptionsT]\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.base.QueryRephraser.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = rephrasers\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.base.QueryRephraser.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'rephraser'\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.base.QueryRephraser.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.base.QueryRephraser.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.base.QueryRephraser.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.base.QueryRephraser.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.base.QueryRephraser.rephrase","title":"rephrase  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>rephrase(query: str, options: QueryRephraserOptionsT | None = None) -&gt; Iterable[str]\n</code></pre> <p>Rephrase a query.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to rephrase.</p> <p> TYPE: <code>str</code> </p> <code>options</code> <p>The options for the rephraser.</p> <p> TYPE: <code>QueryRephraserOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Iterable[str]</code> <p>The rephrased queries.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/retrieval/rephrasers/base.py</code> <pre><code>@abstractmethod\nasync def rephrase(self, query: str, options: QueryRephraserOptionsT | None = None) -&gt; Iterable[str]:\n    \"\"\"\n    Rephrase a query.\n\n    Args:\n        query: The query to rephrase.\n        options: The options for the rephraser.\n\n    Returns:\n        The rephrased queries.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.llm.LLMQueryRephraser","title":"ragbits.document_search.retrieval.rephrasers.llm.LLMQueryRephraser","text":"<pre><code>LLMQueryRephraser(llm: LLM[LLMClientOptionsT], prompt: type[Prompt[LLMQueryRephraserPromptInput, list[str]]] | None = None, default_options: LLMQueryRephraserOptions[LLMClientOptionsT] | None = None)\n</code></pre> <p>               Bases: <code>QueryRephraser[LLMQueryRephraserOptions[LLMClientOptionsT]]</code></p> <p>A rephraser class that uses a LLM to rephrase queries.</p> <p>Initialize the LLMQueryRephraser with a LLM.</p> PARAMETER DESCRIPTION <code>llm</code> <p>A LLM instance to handle query rephrasing.</p> <p> TYPE: <code>LLM[LLMClientOptionsT]</code> </p> <code>prompt</code> <p>The prompt to use for rephrasing queries.</p> <p> TYPE: <code>type[Prompt[LLMQueryRephraserPromptInput, list[str]]] | None</code> DEFAULT: <code>None</code> </p> <code>default_options</code> <p>The default options for the rephraser.</p> <p> TYPE: <code>LLMQueryRephraserOptions[LLMClientOptionsT] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/retrieval/rephrasers/llm.py</code> <pre><code>def __init__(\n    self,\n    llm: LLM[LLMClientOptionsT],\n    prompt: type[Prompt[LLMQueryRephraserPromptInput, list[str]]] | None = None,\n    default_options: LLMQueryRephraserOptions[LLMClientOptionsT] | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the LLMQueryRephraser with a LLM.\n\n    Args:\n        llm: A LLM instance to handle query rephrasing.\n        prompt: The prompt to use for rephrasing queries.\n        default_options: The default options for the rephraser.\n    \"\"\"\n    super().__init__(default_options=default_options)\n    self._llm = llm\n    self._prompt = prompt or LLMQueryRephraserPrompt\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.llm.LLMQueryRephraser.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = rephrasers\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.llm.LLMQueryRephraser.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'rephraser'\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.llm.LLMQueryRephraser.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.llm.LLMQueryRephraser.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls: type[LLMQueryRephraserOptions] = LLMQueryRephraserOptions\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.llm.LLMQueryRephraser.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.llm.LLMQueryRephraser.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.llm.LLMQueryRephraser.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.llm.LLMQueryRephraser.rephrase","title":"rephrase  <code>async</code>","text":"<pre><code>rephrase(query: str, options: LLMQueryRephraserOptions[LLMClientOptionsT] | None = None) -&gt; Iterable[str]\n</code></pre> <p>Rephrase a given query using the LLM.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to be rephrased. If not provided, a custom prompt must be given.</p> <p> TYPE: <code>str</code> </p> <code>options</code> <p>The options for the rephraser.</p> <p> TYPE: <code>LLMQueryRephraserOptions[LLMClientOptionsT] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Iterable[str]</code> <p>A list containing the rephrased query.</p> RAISES DESCRIPTION <code>LLMConnectionError</code> <p>If there is a connection error with the LLM API.</p> <code>LLMStatusError</code> <p>If the LLM API returns an error status code.</p> <code>LLMResponseError</code> <p>If the LLM API response is invalid.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/retrieval/rephrasers/llm.py</code> <pre><code>@traceable\nasync def rephrase(\n    self,\n    query: str,\n    options: LLMQueryRephraserOptions[LLMClientOptionsT] | None = None,\n) -&gt; Iterable[str]:\n    \"\"\"\n    Rephrase a given query using the LLM.\n\n    Args:\n        query: The query to be rephrased. If not provided, a custom prompt must be given.\n        options: The options for the rephraser.\n\n    Returns:\n        A list containing the rephrased query.\n\n    Raises:\n        LLMConnectionError: If there is a connection error with the LLM API.\n        LLMStatusError: If the LLM API returns an error status code.\n        LLMResponseError: If the LLM API response is invalid.\n    \"\"\"\n    merged_options = (self.default_options | options) if options else self.default_options\n    llm_options = merged_options.llm_options or None\n    prompt = self._prompt(LLMQueryRephraserPromptInput(query=query, n=merged_options.n or None))\n    return await self._llm.generate(prompt, options=llm_options)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.llm.LLMQueryRephraser.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Create an instance of <code>LLMQueryRephraser</code> from a configuration dictionary.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration settings for the rephraser.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the rephraser class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>ValidationError</code> <p>If the LLM or prompt configuration doesn't follow the expected format.</p> <code>InvalidConfigError</code> <p>If an LLM or prompt class can't be found or is not the correct type.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/retrieval/rephrasers/llm.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Create an instance of `LLMQueryRephraser` from a configuration dictionary.\n\n    Args:\n        config: A dictionary containing configuration settings for the rephraser.\n\n    Returns:\n        An instance of the rephraser class initialized with the provided configuration.\n\n    Raises:\n       ValidationError: If the LLM or prompt configuration doesn't follow the expected format.\n       InvalidConfigError: If an LLM or prompt class can't be found or is not the correct type.\n    \"\"\"\n    config[\"llm\"] = LLM.subclass_from_config(ObjectConstructionConfig.model_validate(config[\"llm\"]))\n    config[\"prompt\"] = (\n        import_by_path(ObjectConstructionConfig.model_validate(config[\"prompt\"]).type)\n        if \"prompt\" in config\n        else None\n    )\n    return super().from_config(config)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.noop.NoopQueryRephraser","title":"ragbits.document_search.retrieval.rephrasers.noop.NoopQueryRephraser","text":"<pre><code>NoopQueryRephraser(default_options: OptionsT | None = None)\n</code></pre> <p>               Bases: <code>QueryRephraser[QueryRephraserOptions]</code></p> <p>A no-op query paraphraser that does not change the query.</p> <p>Constructs a new ConfigurableComponent instance.</p> PARAMETER DESCRIPTION <code>default_options</code> <p>The default options for the component.</p> <p> TYPE: <code>OptionsT | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>def __init__(self, default_options: OptionsT | None = None) -&gt; None:\n    \"\"\"\n    Constructs a new ConfigurableComponent instance.\n\n    Args:\n        default_options: The default options for the component.\n    \"\"\"\n    self.default_options: OptionsT = default_options or self.options_cls()\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.noop.NoopQueryRephraser.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = rephrasers\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.noop.NoopQueryRephraser.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'rephraser'\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.noop.NoopQueryRephraser.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.noop.NoopQueryRephraser.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls: type[QueryRephraserOptions] = QueryRephraserOptions\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.noop.NoopQueryRephraser.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.noop.NoopQueryRephraser.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.noop.NoopQueryRephraser.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.noop.NoopQueryRephraser.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rephrasers/#ragbits.document_search.retrieval.rephrasers.noop.NoopQueryRephraser.rephrase","title":"rephrase  <code>async</code>","text":"<pre><code>rephrase(query: str, options: QueryRephraserOptions | None = None) -&gt; Iterable[str]\n</code></pre> <p>Mock implementation which outputs the same query as in input.</p> PARAMETER DESCRIPTION <code>query</code> <p>The query to rephrase.</p> <p> TYPE: <code>str</code> </p> <code>options</code> <p>The options for the rephraser.</p> <p> TYPE: <code>QueryRephraserOptions | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Iterable[str]</code> <p>The list with non-transformed query.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/retrieval/rephrasers/noop.py</code> <pre><code>@traceable\nasync def rephrase(self, query: str, options: QueryRephraserOptions | None = None) -&gt; Iterable[str]:  # noqa: PLR6301\n    \"\"\"\n    Mock implementation which outputs the same query as in input.\n\n    Args:\n        query: The query to rephrase.\n        options: The options for the rephraser.\n\n    Returns:\n        The list with non-transformed query.\n    \"\"\"\n    return [query]\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/","title":"Rerankers","text":""},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.base.RerankerOptions","title":"ragbits.document_search.retrieval.rerankers.base.RerankerOptions","text":"<p>               Bases: <code>Options</code></p> <p>Object representing the options for the reranker.</p> ATTRIBUTE DESCRIPTION <code>top_n</code> <p>The number of entries to return.</p> <p> TYPE: <code>int | None | NotGiven</code> </p> <code>score_threshold</code> <p>The minimum relevance score for an entry to be returned.</p> <p> TYPE: <code>float | None | NotGiven</code> </p> <code>override_score</code> <p>If True reranking will override element score.</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.base.RerankerOptions.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(extra='allow', arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.base.RerankerOptions.top_n","title":"top_n  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>top_n: int | None | NotGiven = NOT_GIVEN\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.base.RerankerOptions.score_threshold","title":"score_threshold  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>score_threshold: float | None | NotGiven = NOT_GIVEN\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.base.RerankerOptions.override_score","title":"override_score  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>override_score: bool = True\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.base.RerankerOptions.dict","title":"dict","text":"<pre><code>dict() -&gt; dict[str, Any]\n</code></pre> <p>Creates a dictionary representation of the Options instance. If a value is None, it will be replaced with a provider-specific not-given sentinel.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>A dictionary representation of the Options instance.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/options.py</code> <pre><code>def dict(self) -&gt; dict[str, Any]:  # type: ignore # mypy complains about overriding BaseModel.dict\n    \"\"\"\n    Creates a dictionary representation of the Options instance.\n    If a value is None, it will be replaced with a provider-specific not-given sentinel.\n\n    Returns:\n        A dictionary representation of the Options instance.\n    \"\"\"\n    options = self.model_dump()\n\n    return {\n        key: self._not_given if value is None or isinstance(value, NotGiven) else value\n        for key, value in options.items()\n    }\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMRerankerOptions","title":"ragbits.document_search.retrieval.rerankers.litellm.LiteLLMRerankerOptions","text":"<p>               Bases: <code>RerankerOptions</code></p> <p>Object representing the options for the litellm reranker.</p> ATTRIBUTE DESCRIPTION <code>top_n</code> <p>The number of entries to return.</p> <p> TYPE: <code>int | None | NotGiven</code> </p> <code>score_threshold</code> <p>The minimum relevance score for an entry to be returned.</p> <p> TYPE: <code>float | None | NotGiven</code> </p> <code>override_score</code> <p>If True reranking will override element score.</p> <p> TYPE: <code>bool</code> </p> <code>max_chunks_per_doc</code> <p>The maximum amount of tokens a document can have before truncation.</p> <p> TYPE: <code>int | None | NotGiven</code> </p>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMRerankerOptions.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(extra='allow', arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMRerankerOptions.top_n","title":"top_n  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>top_n: int | None | NotGiven = NOT_GIVEN\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMRerankerOptions.score_threshold","title":"score_threshold  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>score_threshold: float | None | NotGiven = NOT_GIVEN\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMRerankerOptions.override_score","title":"override_score  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>override_score: bool = True\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMRerankerOptions.max_chunks_per_doc","title":"max_chunks_per_doc  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>max_chunks_per_doc: int | None | NotGiven = NOT_GIVEN\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMRerankerOptions.dict","title":"dict","text":"<pre><code>dict() -&gt; dict[str, Any]\n</code></pre> <p>Creates a dictionary representation of the Options instance. If a value is None, it will be replaced with a provider-specific not-given sentinel.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>A dictionary representation of the Options instance.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/options.py</code> <pre><code>def dict(self) -&gt; dict[str, Any]:  # type: ignore # mypy complains about overriding BaseModel.dict\n    \"\"\"\n    Creates a dictionary representation of the Options instance.\n    If a value is None, it will be replaced with a provider-specific not-given sentinel.\n\n    Returns:\n        A dictionary representation of the Options instance.\n    \"\"\"\n    options = self.model_dump()\n\n    return {\n        key: self._not_given if value is None or isinstance(value, NotGiven) else value\n        for key, value in options.items()\n    }\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.llm.LLMRerankerOptions","title":"ragbits.document_search.retrieval.rerankers.llm.LLMRerankerOptions","text":"<p>               Bases: <code>RerankerOptions</code></p> <p>Object representing the options for the llm reranker.</p> ATTRIBUTE DESCRIPTION <code>top_n</code> <p>The number of entries to return.</p> <p> TYPE: <code>int | None | NotGiven</code> </p> <code>score_threshold</code> <p>The minimum relevance score for an entry to be returned.</p> <p> TYPE: <code>float | None | NotGiven</code> </p> <code>override_score</code> <p>If True reranking will override element score.</p> <p> TYPE: <code>bool</code> </p> <code>llm_options</code> <p>The options for the LLM.</p> <p> TYPE: <code>LiteLLMOptions | None | NotGiven</code> </p>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.llm.LLMRerankerOptions.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(extra='allow', arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.llm.LLMRerankerOptions.top_n","title":"top_n  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>top_n: int | None | NotGiven = NOT_GIVEN\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.llm.LLMRerankerOptions.score_threshold","title":"score_threshold  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>score_threshold: float | None | NotGiven = NOT_GIVEN\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.llm.LLMRerankerOptions.override_score","title":"override_score  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>override_score: bool = True\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.llm.LLMRerankerOptions.llm_options","title":"llm_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>llm_options: LiteLLMOptions | None | NotGiven = NOT_GIVEN\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.llm.LLMRerankerOptions.dict","title":"dict","text":"<pre><code>dict() -&gt; dict[str, Any]\n</code></pre> <p>Creates a dictionary representation of the Options instance. If a value is None, it will be replaced with a provider-specific not-given sentinel.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>A dictionary representation of the Options instance.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/options.py</code> <pre><code>def dict(self) -&gt; dict[str, Any]:  # type: ignore # mypy complains about overriding BaseModel.dict\n    \"\"\"\n    Creates a dictionary representation of the Options instance.\n    If a value is None, it will be replaced with a provider-specific not-given sentinel.\n\n    Returns:\n        A dictionary representation of the Options instance.\n    \"\"\"\n    options = self.model_dump()\n\n    return {\n        key: self._not_given if value is None or isinstance(value, NotGiven) else value\n        for key, value in options.items()\n    }\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.base.Reranker","title":"ragbits.document_search.retrieval.rerankers.base.Reranker","text":"<pre><code>Reranker(default_options: OptionsT | None = None)\n</code></pre> <p>               Bases: <code>ConfigurableComponent[RerankerOptionsT]</code>, <code>ABC</code></p> <p>Reranks elements retrieved from vector store.</p> <p>Constructs a new ConfigurableComponent instance.</p> PARAMETER DESCRIPTION <code>default_options</code> <p>The default options for the component.</p> <p> TYPE: <code>OptionsT | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>def __init__(self, default_options: OptionsT | None = None) -&gt; None:\n    \"\"\"\n    Constructs a new ConfigurableComponent instance.\n\n    Args:\n        default_options: The default options for the component.\n    \"\"\"\n    self.default_options: OptionsT = default_options or self.options_cls()\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.base.Reranker.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.base.Reranker.options_cls","title":"options_cls  <code>instance-attribute</code>","text":"<pre><code>options_cls: type[RerankerOptionsT]\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.base.Reranker.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = rerankers\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.base.Reranker.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'reranker'\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.base.Reranker.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.base.Reranker.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.base.Reranker.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.base.Reranker.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.base.Reranker.rerank","title":"rerank  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>rerank(elements: Sequence[Sequence[Element]], query: str, options: RerankerOptionsT | None = None) -&gt; Sequence[Element]\n</code></pre> <p>Rerank elements.</p> PARAMETER DESCRIPTION <code>elements</code> <p>The elements to rerank.</p> <p> TYPE: <code>Sequence[Sequence[Element]]</code> </p> <code>query</code> <p>The query to rerank the elements against.</p> <p> TYPE: <code>str</code> </p> <code>options</code> <p>The options for reranking.</p> <p> TYPE: <code>RerankerOptionsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Sequence[Element]</code> <p>The reranked elements.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/retrieval/rerankers/base.py</code> <pre><code>@abstractmethod\nasync def rerank(\n    self,\n    elements: Sequence[Sequence[Element]],\n    query: str,\n    options: RerankerOptionsT | None = None,\n) -&gt; Sequence[Element]:\n    \"\"\"\n    Rerank elements.\n\n    Args:\n        elements: The elements to rerank.\n        query: The query to rerank the elements against.\n        options: The options for reranking.\n\n    Returns:\n        The reranked elements.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.answerai.AnswerAIReranker","title":"ragbits.document_search.retrieval.rerankers.answerai.AnswerAIReranker","text":"<pre><code>AnswerAIReranker(model: str, default_options: RerankerOptions | None = None, **rerankers_kwargs: Any)\n</code></pre> <p>               Bases: <code>Reranker[RerankerOptions]</code></p> <p>A rerankers re-ranker covering most popular re-ranking methods.</p> <p>Initialize the AnswerAIReranker instance.</p> PARAMETER DESCRIPTION <code>model</code> <p>The reranker model to use.</p> <p> TYPE: <code>str</code> </p> <code>default_options</code> <p>The default options for reranking.</p> <p> TYPE: <code>RerankerOptions | None</code> DEFAULT: <code>None</code> </p> <code>**rerankers_kwargs</code> <p>Additional keyword arguments native to rerankers lib.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/retrieval/rerankers/answerai.py</code> <pre><code>def __init__(\n    self,\n    model: str,\n    default_options: RerankerOptions | None = None,\n    **rerankers_kwargs: Any,  # noqa: ANN401\n) -&gt; None:\n    \"\"\"\n    Initialize the AnswerAIReranker instance.\n\n    Args:\n        model: The reranker model to use.\n        default_options: The default options for reranking.\n        **rerankers_kwargs: Additional keyword arguments native to rerankers lib.\n    \"\"\"\n    super().__init__(default_options=default_options)\n    self.model = model\n    self.ranker = AnswerReranker(self.model, **rerankers_kwargs)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.answerai.AnswerAIReranker.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = rerankers\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.answerai.AnswerAIReranker.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'reranker'\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.answerai.AnswerAIReranker.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.answerai.AnswerAIReranker.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls: type[RerankerOptions] = RerankerOptions\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.answerai.AnswerAIReranker.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model = model\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.answerai.AnswerAIReranker.ranker","title":"ranker  <code>instance-attribute</code>","text":"<pre><code>ranker = Reranker(model, **rerankers_kwargs)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.answerai.AnswerAIReranker.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.answerai.AnswerAIReranker.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.answerai.AnswerAIReranker.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.answerai.AnswerAIReranker.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.answerai.AnswerAIReranker.rerank","title":"rerank  <code>async</code>","text":"<pre><code>rerank(elements: Sequence[Sequence[Element]], query: str, options: RerankerOptions | None = None) -&gt; Sequence[Element]\n</code></pre> <p>Rerank elements.</p> PARAMETER DESCRIPTION <code>elements</code> <p>The elements to rerank.</p> <p> TYPE: <code>Sequence[Sequence[Element]]</code> </p> <code>query</code> <p>The query to rerank the elements against.</p> <p> TYPE: <code>str</code> </p> <code>options</code> <p>The options for reranking.</p> <p> TYPE: <code>RerankerOptions | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Sequence[Element]</code> <p>The reranked elements.</p> RAISES DESCRIPTION <code>ValueError</code> <p>Raised if the input query is empty or if the list of candidate documents is empty.</p> <code>TypeError</code> <p>Raised if the input types are incorrect, such as if the query is not a string, or List[str].</p> <code>IndexError</code> <p>Raised if docs is an empty List.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/retrieval/rerankers/answerai.py</code> <pre><code>async def rerank(\n    self,\n    elements: Sequence[Sequence[Element]],\n    query: str,\n    options: RerankerOptions | None = None,\n) -&gt; Sequence[Element]:\n    \"\"\"\n    Rerank elements.\n\n    Args:\n        elements: The elements to rerank.\n        query: The query to rerank the elements against.\n        options: The options for reranking.\n\n    Returns:\n        The reranked elements.\n\n    Raises:\n        ValueError: Raised if the input query is empty or if the list of candidate documents is empty.\n        TypeError: Raised if the input types are incorrect, such as if the query is not a string, or List[str].\n        IndexError: Raised if docs is an empty List.\n    \"\"\"\n    merged_options = (self.default_options | options) if options else self.default_options\n    flat_elements = list(chain.from_iterable(elements))\n    documents = [element.text_representation or \"\" for element in flat_elements]\n\n    with trace(\n        query=query, documents=documents, elements=elements, model=self.model, options=merged_options\n    ) as outputs:\n        response = self.ranker.rank(\n            query=query,\n            docs=documents,\n        )\n        if merged_options.top_n:\n            response = response.top_k(merged_options.top_n)\n\n        results = []\n        for result in response:\n            if not merged_options.score_threshold or result.score &gt;= merged_options.score_threshold:\n                if merged_options.override_score:\n                    flat_elements[result.document.doc_id].score = result.score\n                results.append(flat_elements[result.document.doc_id])\n\n        outputs.results = results\n\n    return outputs.results\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMReranker","title":"ragbits.document_search.retrieval.rerankers.litellm.LiteLLMReranker","text":"<pre><code>LiteLLMReranker(model: str, default_options: LiteLLMRerankerOptions | None = None)\n</code></pre> <p>               Bases: <code>Reranker[LiteLLMRerankerOptions]</code></p> <p>A LiteLLM reranker for providers such as Cohere, Together AI, Azure AI.</p> <p>Initialize the LiteLLMReranker instance.</p> PARAMETER DESCRIPTION <code>model</code> <p>The reranker model to use.</p> <p> TYPE: <code>str</code> </p> <code>default_options</code> <p>The default options for reranking.</p> <p> TYPE: <code>LiteLLMRerankerOptions | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/retrieval/rerankers/litellm.py</code> <pre><code>def __init__(\n    self,\n    model: str,\n    default_options: LiteLLMRerankerOptions | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the LiteLLMReranker instance.\n\n    Args:\n        model: The reranker model to use.\n        default_options: The default options for reranking.\n    \"\"\"\n    super().__init__(default_options=default_options)\n    self.model = model\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMReranker.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = rerankers\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMReranker.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'reranker'\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMReranker.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMReranker.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls: type[LiteLLMRerankerOptions] = LiteLLMRerankerOptions\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMReranker.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model = model\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMReranker.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMReranker.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMReranker.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMReranker.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.litellm.LiteLLMReranker.rerank","title":"rerank  <code>async</code>","text":"<pre><code>rerank(elements: Sequence[Sequence[Element]], query: str, options: LiteLLMRerankerOptions | None = None) -&gt; Sequence[Element]\n</code></pre> <p>Rerank elements with LiteLLM API.</p> PARAMETER DESCRIPTION <code>elements</code> <p>The elements to rerank.</p> <p> TYPE: <code>Sequence[Sequence[Element]]</code> </p> <code>query</code> <p>The query to rerank the elements against.</p> <p> TYPE: <code>str</code> </p> <code>options</code> <p>The options for reranking.</p> <p> TYPE: <code>LiteLLMRerankerOptions | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Sequence[Element]</code> <p>The reranked elements.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/retrieval/rerankers/litellm.py</code> <pre><code>@traceable\nasync def rerank(\n    self,\n    elements: Sequence[Sequence[Element]],\n    query: str,\n    options: LiteLLMRerankerOptions | None = None,\n) -&gt; Sequence[Element]:\n    \"\"\"\n    Rerank elements with LiteLLM API.\n\n    Args:\n        elements: The elements to rerank.\n        query: The query to rerank the elements against.\n        options: The options for reranking.\n\n    Returns:\n        The reranked elements.\n    \"\"\"\n    merged_options = (self.default_options | options) if options else self.default_options\n    flat_elements = list(chain.from_iterable(elements))\n    documents = [element.text_representation or \"\" for element in flat_elements]\n\n    response = await litellm.arerank(\n        model=self.model,\n        query=query,\n        documents=documents,\n        top_n=merged_options.top_n or None,\n        max_chunks_per_doc=merged_options.max_chunks_per_doc or None,\n    )\n\n    results = []\n    for result in response.results:\n        if not merged_options.score_threshold or result[\"relevance_score\"] &gt;= merged_options.score_threshold:\n            if merged_options.override_score:\n                flat_elements[result[\"index\"]].score = result[\"relevance_score\"]\n            results.append(flat_elements[result[\"index\"]])\n\n    return results\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.llm.LLMReranker","title":"ragbits.document_search.retrieval.rerankers.llm.LLMReranker","text":"<pre><code>LLMReranker(llm: LiteLLM, *, prompt: type[Prompt[RerankerInput, str]] | None = None, default_options: LLMRerankerOptions | None = None)\n</code></pre> <p>               Bases: <code>Reranker[LLMRerankerOptions]</code></p> <p>Reranker based on LLM.</p> <p>Initialize the LLMReranker instance.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The LLM instance to handle reranking.</p> <p> TYPE: <code>LiteLLM</code> </p> <code>prompt</code> <p>The prompt to use for reranking elements.</p> <p> TYPE: <code>type[Prompt[RerankerInput, str]] | None</code> DEFAULT: <code>None</code> </p> <code>default_options</code> <p>The default options for reranking.</p> <p> TYPE: <code>LLMRerankerOptions | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/retrieval/rerankers/llm.py</code> <pre><code>def __init__(\n    self,\n    llm: LiteLLM,\n    *,\n    prompt: type[Prompt[RerankerInput, str]] | None = None,\n    default_options: LLMRerankerOptions | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the LLMReranker instance.\n\n    Args:\n        llm: The LLM instance to handle reranking.\n        prompt: The prompt to use for reranking elements.\n        default_options: The default options for reranking.\n    \"\"\"\n    super().__init__(default_options=default_options)\n    self._llm = llm\n    self._prompt = prompt or RerankerPrompt\n    self._llm_options = LiteLLMOptions(\n        temperature=0.0,\n        logprobs=True,\n        max_tokens=1,\n        logit_bias={\n            self._llm.get_token_id(\" Yes\"): 1,\n            self._llm.get_token_id(\" No\"): 1,\n        },\n    )\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.llm.LLMReranker.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = rerankers\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.llm.LLMReranker.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'reranker'\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.llm.LLMReranker.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.llm.LLMReranker.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls: type[LLMRerankerOptions] = LLMRerankerOptions\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.llm.LLMReranker.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.llm.LLMReranker.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.llm.LLMReranker.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.llm.LLMReranker.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initialize the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The initialized instance of LLMReranker.</p> RAISES DESCRIPTION <code>ValidationError</code> <p>If the configuration doesn't follow the expected format.</p> <code>InvalidConfigError</code> <p>If llm or prompt can't be found or are not the correct type.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/retrieval/rerankers/llm.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initialize the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        The initialized instance of LLMReranker.\n\n    Raises:\n        ValidationError: If the configuration doesn't follow the expected format.\n        InvalidConfigError: If llm or prompt can't be found or are not the correct type.\n    \"\"\"\n    config[\"llm\"] = LLM.subclass_from_config(ObjectConstructionConfig.model_validate(config[\"llm\"]))\n    config[\"prompt\"] = import_by_path(config[\"prompt\"]) if \"prompt\" in config else None\n    return super().from_config(config)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.llm.LLMReranker.rerank","title":"rerank  <code>async</code>","text":"<pre><code>rerank(elements: Sequence[Sequence[Element]], query: str, options: LLMRerankerOptions | None = None) -&gt; Sequence[Element]\n</code></pre> <p>Rerank elements with LLM.</p> PARAMETER DESCRIPTION <code>elements</code> <p>The elements to rerank.</p> <p> TYPE: <code>Sequence[Sequence[Element]]</code> </p> <code>query</code> <p>The query to rerank the elements against.</p> <p> TYPE: <code>str</code> </p> <code>options</code> <p>The options for reranking.</p> <p> TYPE: <code>LLMRerankerOptions | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Sequence[Element]</code> <p>The reranked elements.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/retrieval/rerankers/llm.py</code> <pre><code>@traceable\nasync def rerank(\n    self,\n    elements: Sequence[Sequence[Element]],\n    query: str,\n    options: LLMRerankerOptions | None = None,\n) -&gt; Sequence[Element]:\n    \"\"\"\n    Rerank elements with LLM.\n\n    Args:\n        elements: The elements to rerank.\n        query: The query to rerank the elements against.\n        options: The options for reranking.\n\n    Returns:\n        The reranked elements.\n    \"\"\"\n    merged_options = (self.default_options | options) if options else self.default_options\n    llm_options = (\n        self._llm_options | merged_options.llm_options if merged_options.llm_options else self._llm_options\n    )\n\n    flat_elements = list(chain.from_iterable(elements))\n    scores = await self._score_elements(flat_elements, query, llm_options)\n\n    scored_elements = list(zip(flat_elements, scores, strict=True))\n    scored_elements.sort(key=lambda x: x[1], reverse=True)\n\n    results = []\n    for element, score in scored_elements[: merged_options.top_n or None]:\n        if not merged_options.score_threshold or score &gt;= merged_options.score_threshold:\n            if merged_options.override_score:\n                element.score = score\n            results.append(element)\n    return results\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.noop.NoopReranker","title":"ragbits.document_search.retrieval.rerankers.noop.NoopReranker","text":"<pre><code>NoopReranker(default_options: OptionsT | None = None)\n</code></pre> <p>               Bases: <code>Reranker[RerankerOptions]</code></p> <p>A no-op reranker that does not change the order of the elements.</p> <p>Constructs a new ConfigurableComponent instance.</p> PARAMETER DESCRIPTION <code>default_options</code> <p>The default options for the component.</p> <p> TYPE: <code>OptionsT | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>def __init__(self, default_options: OptionsT | None = None) -&gt; None:\n    \"\"\"\n    Constructs a new ConfigurableComponent instance.\n\n    Args:\n        default_options: The default options for the component.\n    \"\"\"\n    self.default_options: OptionsT = default_options or self.options_cls()\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.noop.NoopReranker.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = rerankers\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.noop.NoopReranker.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'reranker'\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.noop.NoopReranker.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.noop.NoopReranker.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls: type[RerankerOptions] = RerankerOptions\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.noop.NoopReranker.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.noop.NoopReranker.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.noop.NoopReranker.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.noop.NoopReranker.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.noop.NoopReranker.rerank","title":"rerank  <code>async</code>","text":"<pre><code>rerank(elements: Sequence[Sequence[Element]], query: str, options: RerankerOptions | None = None) -&gt; Sequence[Element]\n</code></pre> <p>No reranking, returning the elements in the same order.</p> PARAMETER DESCRIPTION <code>elements</code> <p>The elements to rerank.</p> <p> TYPE: <code>Sequence[Sequence[Element]]</code> </p> <code>query</code> <p>The query to rerank the elements against.</p> <p> TYPE: <code>str</code> </p> <code>options</code> <p>The options for reranking.</p> <p> TYPE: <code>RerankerOptions | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Sequence[Element]</code> <p>The reranked elements.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/retrieval/rerankers/noop.py</code> <pre><code>@traceable\nasync def rerank(  # noqa: PLR6301\n    self,\n    elements: Sequence[Sequence[Element]],\n    query: str,\n    options: RerankerOptions | None = None,\n) -&gt; Sequence[Element]:\n    \"\"\"\n    No reranking, returning the elements in the same order.\n\n    Args:\n        elements: The elements to rerank.\n        query: The query to rerank the elements against.\n        options: The options for reranking.\n\n    Returns:\n        The reranked elements.\n    \"\"\"\n    return [*{element.id: element for element in chain.from_iterable(elements)}.values()]\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.rrf.ReciprocalRankFusionReranker","title":"ragbits.document_search.retrieval.rerankers.rrf.ReciprocalRankFusionReranker","text":"<pre><code>ReciprocalRankFusionReranker(default_options: OptionsT | None = None)\n</code></pre> <p>               Bases: <code>Reranker[RerankerOptions]</code></p> <p>A reranker that implements the Reciprocal Rank Fusion (RRF) algorithm to combine multiple ranked result sets into a single reranked list.</p> <p>RRF is a method that assigns scores to documents based on their positions in multiple ranked lists, allowing for fusion of diverse ranking sources without the need for tuning.</p> <p>The score for each document is calculated using the formula:</p> <pre><code>score = sum(1.0 / (k + rank(q, d)))\n</code></pre> where <ul> <li>k is a ranking constant (1 is used here)</li> <li>q is a query in the set of queries</li> <li>d is a document in the result set</li> <li>rank(q, d) is the position of d in the ranking list for q (starting from 1)</li> </ul> <p>Constructs a new ConfigurableComponent instance.</p> PARAMETER DESCRIPTION <code>default_options</code> <p>The default options for the component.</p> <p> TYPE: <code>OptionsT | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>def __init__(self, default_options: OptionsT | None = None) -&gt; None:\n    \"\"\"\n    Constructs a new ConfigurableComponent instance.\n\n    Args:\n        default_options: The default options for the component.\n    \"\"\"\n    self.default_options: OptionsT = default_options or self.options_cls()\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.rrf.ReciprocalRankFusionReranker.default_module","title":"default_module  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_module: ClassVar = rerankers\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.rrf.ReciprocalRankFusionReranker.configuration_key","title":"configuration_key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>configuration_key: ClassVar = 'reranker'\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.rrf.ReciprocalRankFusionReranker.default_options","title":"default_options  <code>instance-attribute</code>","text":"<pre><code>default_options: OptionsT = default_options or options_cls()\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.rrf.ReciprocalRankFusionReranker.options_cls","title":"options_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options_cls: type[RerankerOptions] = RerankerOptions\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.rrf.ReciprocalRankFusionReranker.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.rrf.ReciprocalRankFusionReranker.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.rrf.ReciprocalRankFusionReranker.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.rrf.ReciprocalRankFusionReranker.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict[str, Any]) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict[str, Any]) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    default_options = config.pop(\"default_options\", None)\n    options = cls.options_cls(**default_options) if default_options else None\n    return cls(**config, default_options=options)\n</code></pre>"},{"location":"api_reference/document_search/retrieval/rerankers/#ragbits.document_search.retrieval.rerankers.rrf.ReciprocalRankFusionReranker.rerank","title":"rerank  <code>async</code>","text":"<pre><code>rerank(elements: Sequence[Sequence[Element]], query: str, options: RerankerOptions | None = None) -&gt; Sequence[Element]\n</code></pre> <p>Reranks elements using the Reciprocal Rank Fusion (RRF) algorithm.</p> PARAMETER DESCRIPTION <code>elements</code> <p>A list of ranked lists of elements to be fused.</p> <p> TYPE: <code>Sequence[Sequence[Element]]</code> </p> <code>query</code> <p>The query string for reranking.</p> <p> TYPE: <code>str</code> </p> <code>options</code> <p>The options for reranking.</p> <p> TYPE: <code>RerankerOptions | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Sequence[Element]</code> <p>The reranked elements.</p> Source code in <code>packages/ragbits-document-search/src/ragbits/document_search/retrieval/rerankers/rrf.py</code> <pre><code>@traceable\nasync def rerank(\n    self,\n    elements: Sequence[Sequence[Element]],\n    query: str,\n    options: RerankerOptions | None = None,\n) -&gt; Sequence[Element]:\n    \"\"\"\n    Reranks elements using the Reciprocal Rank Fusion (RRF) algorithm.\n\n    Args:\n        elements: A list of ranked lists of elements to be fused.\n        query: The query string for reranking.\n        options: The options for reranking.\n\n    Returns:\n        The reranked elements.\n    \"\"\"\n    if len(elements) == 1:\n        return elements[0]\n\n    merged_options = (self.default_options | options) if options else self.default_options\n\n    scores: dict[str, float] = defaultdict(float)\n    elements_map: dict[str, Element] = {}\n\n    for query_elements in elements:\n        for rank, element in enumerate(query_elements):\n            if not element.key:\n                continue\n            scores[element.key] += 1 / (rank + 1 + 1)\n            elements_map[element.key] = element\n\n    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n\n    results = []\n    for element_id, score in sorted_scores[: merged_options.top_n or None]:\n        if not merged_options.score_threshold or score &gt;= merged_options.score_threshold:\n            if merged_options.override_score:\n                elements_map[element_id].score = score\n            results.append(elements_map[element_id])\n\n    return results\n</code></pre>"},{"location":"api_reference/evaluate/","title":"Evaluate","text":""},{"location":"api_reference/evaluate/#ragbits.evaluate.evaluator.Evaluator","title":"ragbits.evaluate.evaluator.Evaluator","text":"<pre><code>Evaluator(batch_size: int = 10, num_retries: int = 3, backoff_multiplier: int = 1, backoff_max: int = 60, parallelize_batches: bool = False)\n</code></pre> <p>               Bases: <code>WithConstructionConfig</code></p> <p>Evaluator class.</p> <p>Initialize the Evaluator instance.</p> PARAMETER DESCRIPTION <code>batch_size</code> <p>batch size for the evaluation pipeline inference.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>num_retries</code> <p>The number of retries per evaluation pipeline inference error.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> <code>backoff_multiplier</code> <p>The base delay multiplier for exponential backoff (in seconds).</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>backoff_max</code> <p>The maximum allowed delay (in seconds) between retries.</p> <p> TYPE: <code>int</code> DEFAULT: <code>60</code> </p> <code>parallelize_batches</code> <p>Whether to process samples within each batch in parallel (asyncio.gather).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/evaluator.py</code> <pre><code>def __init__(\n    self,\n    batch_size: int = 10,\n    num_retries: int = 3,\n    backoff_multiplier: int = 1,\n    backoff_max: int = 60,\n    parallelize_batches: bool = False,\n) -&gt; None:\n    \"\"\"\n    Initialize the Evaluator instance.\n\n    Args:\n        batch_size: batch size for the evaluation pipeline inference.\n        num_retries: The number of retries per evaluation pipeline inference error.\n        backoff_multiplier: The base delay multiplier for exponential backoff (in seconds).\n        backoff_max: The maximum allowed delay (in seconds) between retries.\n        parallelize_batches: Whether to process samples within each batch in parallel (asyncio.gather).\n    \"\"\"\n    self.batch_size = batch_size\n    self.num_retries = num_retries\n    self.backoff_multiplier = backoff_multiplier\n    self.backoff_max = backoff_max\n    self.parallelize_batches = parallelize_batches\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.evaluator.Evaluator.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = None\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.evaluator.Evaluator.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.evaluator.Evaluator.batch_size","title":"batch_size  <code>instance-attribute</code>","text":"<pre><code>batch_size = batch_size\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.evaluator.Evaluator.num_retries","title":"num_retries  <code>instance-attribute</code>","text":"<pre><code>num_retries = num_retries\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.evaluator.Evaluator.backoff_multiplier","title":"backoff_multiplier  <code>instance-attribute</code>","text":"<pre><code>backoff_multiplier = backoff_multiplier\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.evaluator.Evaluator.backoff_max","title":"backoff_max  <code>instance-attribute</code>","text":"<pre><code>backoff_max = backoff_max\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.evaluator.Evaluator.parallelize_batches","title":"parallelize_batches  <code>instance-attribute</code>","text":"<pre><code>parallelize_batches = parallelize_batches\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.evaluator.Evaluator.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.evaluator.Evaluator.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.evaluator.Evaluator.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.evaluator.Evaluator.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.evaluator.Evaluator.run_from_config","title":"run_from_config  <code>async</code> <code>classmethod</code>","text":"<pre><code>run_from_config(config: dict) -&gt; EvaluatorResult\n</code></pre> <p>Run the evaluation based on configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>Evaluation config.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>EvaluatorResult</code> <p>The evaluation results.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/evaluator.py</code> <pre><code>@classmethod\nasync def run_from_config(cls, config: dict) -&gt; EvaluatorResult:\n    \"\"\"\n    Run the evaluation based on configuration.\n\n    Args:\n        config: Evaluation config.\n\n    Returns:\n        The evaluation results.\n    \"\"\"\n    evaluator_config = EvaluatorConfig.model_validate(config)\n    evaluation_config = EvaluationConfig.model_validate(evaluator_config.evaluation)\n    pipeline: EvaluationPipeline = EvaluationPipeline.subclass_from_config(evaluation_config.pipeline)\n    dataloader: DataLoader = DataLoader.subclass_from_config(evaluation_config.dataloader)\n    metricset: MetricSet = MetricSet.from_config(evaluation_config.metrics)\n\n    evaluator = cls.from_config(evaluator_config.evaluator or {})\n    return await evaluator.compute(\n        pipeline=pipeline,\n        dataloader=dataloader,\n        metricset=metricset,\n    )\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.evaluator.Evaluator.compute","title":"compute  <code>async</code>","text":"<pre><code>compute(pipeline: EvaluationPipeline[EvaluationTargetT, EvaluationDataT, EvaluationResultT], dataloader: DataLoader[EvaluationDataT], metricset: MetricSet[EvaluationResultT]) -&gt; EvaluatorResult[EvaluationResultT]\n</code></pre> <p>Compute the evaluation results for the given pipeline and data.</p> PARAMETER DESCRIPTION <code>pipeline</code> <p>The pipeline to be evaluated.</p> <p> TYPE: <code>EvaluationPipeline[EvaluationTargetT, EvaluationDataT, EvaluationResultT]</code> </p> <code>dataloader</code> <p>The dataloader to load the data.</p> <p> TYPE: <code>DataLoader[EvaluationDataT]</code> </p> <code>metricset</code> <p>The metrics to be computed.</p> <p> TYPE: <code>MetricSet[EvaluationResultT]</code> </p> RETURNS DESCRIPTION <code>EvaluatorResult[EvaluationResultT]</code> <p>The evaluation results.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/evaluator.py</code> <pre><code>async def compute(\n    self,\n    pipeline: EvaluationPipeline[EvaluationTargetT, EvaluationDataT, EvaluationResultT],\n    dataloader: DataLoader[EvaluationDataT],\n    metricset: MetricSet[EvaluationResultT],\n) -&gt; EvaluatorResult[EvaluationResultT]:\n    \"\"\"\n    Compute the evaluation results for the given pipeline and data.\n\n    Args:\n        pipeline: The pipeline to be evaluated.\n        dataloader: The dataloader to load the data.\n        metricset: The metrics to be computed.\n\n    Returns:\n        The evaluation results.\n    \"\"\"\n    await pipeline.prepare()\n\n    dataset = await dataloader.load()\n    results, errors, time_perf = await self._call_pipeline(pipeline, dataset)\n    metrics = await metricset.compute(results)\n\n    return EvaluatorResult(\n        metrics=metrics,\n        results=results,\n        errors=errors,\n        time_perf=time_perf,\n    )\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.optimizer.Optimizer","title":"ragbits.evaluate.optimizer.Optimizer","text":"<pre><code>Optimizer(direction: str = 'maximize', n_trials: int = 10, max_retries_for_trial: int = 1)\n</code></pre> <p>               Bases: <code>WithConstructionConfig</code></p> <p>Optimizer class.</p> <p>Initialize the pipeline optimizer.</p> PARAMETER DESCRIPTION <code>direction</code> <p>Direction of optimization.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'maximize'</code> </p> <code>n_trials</code> <p>The number of trials for each process.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>max_retries_for_trial</code> <p>The number of retires for single process.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/optimizer.py</code> <pre><code>def __init__(self, direction: str = \"maximize\", n_trials: int = 10, max_retries_for_trial: int = 1) -&gt; None:\n    \"\"\"\n    Initialize the pipeline optimizer.\n\n    Args:\n        direction: Direction of optimization.\n        n_trials: The number of trials for each process.\n        max_retries_for_trial: The number of retires for single process.\n    \"\"\"\n    self.direction = direction\n    self.n_trials = n_trials\n    self.max_retries_for_trial = max_retries_for_trial\n    # workaround for optuna not allowing different choices for different trials\n    # TODO check how optuna handles parallelism. discuss if we want to have parallel studies\n    self._choices_cache: dict[str, list] = {}\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.optimizer.Optimizer.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = None\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.optimizer.Optimizer.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.optimizer.Optimizer.direction","title":"direction  <code>instance-attribute</code>","text":"<pre><code>direction = direction\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.optimizer.Optimizer.n_trials","title":"n_trials  <code>instance-attribute</code>","text":"<pre><code>n_trials = n_trials\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.optimizer.Optimizer.max_retries_for_trial","title":"max_retries_for_trial  <code>instance-attribute</code>","text":"<pre><code>max_retries_for_trial = max_retries_for_trial\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.optimizer.Optimizer.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.optimizer.Optimizer.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.optimizer.Optimizer.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.optimizer.Optimizer.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.optimizer.Optimizer.run_from_config","title":"run_from_config  <code>classmethod</code>","text":"<pre><code>run_from_config(config: dict) -&gt; list[tuple[dict, float, dict[str, float]]]\n</code></pre> <p>Run the optimization process configured with a config object.</p> PARAMETER DESCRIPTION <code>config</code> <p>Optimizer config.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>list[tuple[dict, float, dict[str, float]]]</code> <p>List of tested configs with associated scores and metrics.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/optimizer.py</code> <pre><code>@classmethod\ndef run_from_config(cls, config: dict) -&gt; list[tuple[dict, float, dict[str, float]]]:\n    \"\"\"\n    Run the optimization process configured with a config object.\n\n    Args:\n        config: Optimizer config.\n\n    Returns:\n        List of tested configs with associated scores and metrics.\n    \"\"\"\n    optimizer_config = OptimizerConfig.model_validate(config)\n    evaluator_config = EvaluatorConfig.model_validate(optimizer_config.evaluator)\n\n    dataloader: DataLoader = DataLoader.subclass_from_config(evaluator_config.evaluation.dataloader)\n    metricset: MetricSet = MetricSet.from_config(evaluator_config.evaluation.metrics)\n\n    pipeline_class = import_by_path(evaluator_config.evaluation.pipeline.type)\n    pipeline_config = dict(evaluator_config.evaluation.pipeline.config)\n    callbacks = [setup_optuna_neptune_callback()] if optimizer_config.neptune_callback else []\n\n    optimizer = cls.from_config(optimizer_config.optimizer or {})\n    return optimizer.optimize(\n        pipeline_class=pipeline_class,\n        pipeline_config=pipeline_config,\n        metricset=metricset,\n        dataloader=dataloader,\n        callbacks=callbacks,\n    )\n</code></pre>"},{"location":"api_reference/evaluate/#ragbits.evaluate.optimizer.Optimizer.optimize","title":"optimize","text":"<pre><code>optimize(pipeline_class: type[EvaluationPipeline], pipeline_config: dict, dataloader: DataLoader, metricset: MetricSet, callbacks: list[Callable] | None = None) -&gt; list[tuple[dict, float, dict[str, float]]]\n</code></pre> <p>Run the optimization process for given parameters.</p> PARAMETER DESCRIPTION <code>pipeline_class</code> <p>Pipeline to be optimized.</p> <p> TYPE: <code>type[EvaluationPipeline]</code> </p> <code>pipeline_config</code> <p>Configuration defining the optimization process.</p> <p> TYPE: <code>dict</code> </p> <code>dataloader</code> <p>Data loader.</p> <p> TYPE: <code>DataLoader</code> </p> <code>metricset</code> <p>Metrics to be optimized.</p> <p> TYPE: <code>MetricSet</code> </p> <code>callbacks</code> <p>Experiment callbacks.</p> <p> TYPE: <code>list[Callable] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[tuple[dict, float, dict[str, float]]]</code> <p>List of tested configs with associated scores and metrics.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/optimizer.py</code> <pre><code>def optimize(\n    self,\n    pipeline_class: type[EvaluationPipeline],\n    pipeline_config: dict,\n    dataloader: DataLoader,\n    metricset: MetricSet,\n    callbacks: list[Callable] | None = None,\n) -&gt; list[tuple[dict, float, dict[str, float]]]:\n    \"\"\"\n    Run the optimization process for given parameters.\n\n    Args:\n        pipeline_class: Pipeline to be optimized.\n        pipeline_config: Configuration defining the optimization process.\n        dataloader: Data loader.\n        metricset: Metrics to be optimized.\n        callbacks: Experiment callbacks.\n\n    Returns:\n        List of tested configs with associated scores and metrics.\n    \"\"\"\n\n    def objective(trial: Trial) -&gt; float:\n        return self._objective(\n            trial=trial,\n            pipeline_class=pipeline_class,\n            pipeline_config=pipeline_config,\n            dataloader=dataloader,\n            metricset=metricset,\n        )\n\n    study = optuna.create_study(direction=self.direction)\n    study.optimize(\n        func=objective,\n        n_trials=self.n_trials,\n        callbacks=callbacks,\n    )\n    return sorted(\n        [\n            (\n                trial.user_attrs[\"config\"],\n                trial.user_attrs[\"score\"],\n                trial.user_attrs[\"metrics\"],\n            )\n            for trial in study.get_trials()\n        ],\n        key=lambda x: -x[1] if self.direction == \"maximize\" else x[1],\n    )\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/","title":"Data Loaders","text":""},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.base.DataLoader","title":"ragbits.evaluate.dataloaders.base.DataLoader","text":"<pre><code>DataLoader(source: Source, *, split: str = 'data', required_keys: set[str] | None = None)\n</code></pre> <p>               Bases: <code>WithConstructionConfig</code>, <code>Generic[EvaluationDataT]</code>, <code>ABC</code></p> <p>Evaluation data loader.</p> <p>Initialize the data loader.</p> PARAMETER DESCRIPTION <code>source</code> <p>The source to load the evaluation data from.</p> <p> TYPE: <code>Source</code> </p> <code>split</code> <p>The split to load the data from. Split is fixed for data loaders to \"data\", but you can slice it using the Hugging Face API.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'data'</code> </p> <code>required_keys</code> <p>The required columns for the evaluation data.</p> <p> TYPE: <code>set[str] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/dataloaders/base.py</code> <pre><code>def __init__(self, source: Source, *, split: str = \"data\", required_keys: set[str] | None = None) -&gt; None:\n    \"\"\"\n    Initialize the data loader.\n\n    Args:\n        source: The source to load the evaluation data from.\n        split: The split to load the data from. Split is fixed for data loaders to \"data\",\n            but you can slice it using the [Hugging Face API](https://huggingface.co/docs/datasets/v1.11.0/splits.html#slicing-api).\n        required_keys: The required columns for the evaluation data.\n    \"\"\"\n    self.source = source\n    self.split = split\n    self.required_keys = required_keys or set()\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.base.DataLoader.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = dataloaders\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.base.DataLoader.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'dataloader'\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.base.DataLoader.source","title":"source  <code>instance-attribute</code>","text":"<pre><code>source = source\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.base.DataLoader.split","title":"split  <code>instance-attribute</code>","text":"<pre><code>split = split\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.base.DataLoader.required_keys","title":"required_keys  <code>instance-attribute</code>","text":"<pre><code>required_keys = required_keys or set()\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.base.DataLoader.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.base.DataLoader.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.base.DataLoader.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.base.DataLoader.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Create an instance of <code>DataLoader</code> from a configuration dictionary.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration settings for the data loader.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the data loader class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/dataloaders/base.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Create an instance of `DataLoader` from a configuration dictionary.\n\n    Args:\n        config: A dictionary containing configuration settings for the data loader.\n\n    Returns:\n        An instance of the data loader class initialized with the provided configuration.\n    \"\"\"\n    dataloader_config = DataLoaderConfig.model_validate(config)\n    config[\"source\"] = Source.subclass_from_config(dataloader_config.source)\n    return super().from_config(config)\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.base.DataLoader.load","title":"load  <code>async</code>","text":"<pre><code>load() -&gt; Iterable[EvaluationDataT]\n</code></pre> <p>Load the data.</p> RETURNS DESCRIPTION <code>Iterable[EvaluationDataT]</code> <p>The loaded evaluation data.</p> RAISES DESCRIPTION <code>DataLoaderIncorrectFormatDataError</code> <p>If evaluation dataset is incorrectly formatted.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/dataloaders/base.py</code> <pre><code>async def load(self) -&gt; Iterable[EvaluationDataT]:\n    \"\"\"\n    Load the data.\n\n    Returns:\n        The loaded evaluation data.\n\n    Raises:\n        DataLoaderIncorrectFormatDataError: If evaluation dataset is incorrectly formatted.\n    \"\"\"\n    data_path = await self.source.fetch()\n    dataset = load_dataset(\n        path=str(data_path.parent),\n        data_files={\"data\": str(data_path.name)},\n        split=self.split,\n    )\n    if not self.required_keys.issubset(dataset.features):\n        raise DataLoaderIncorrectFormatDataError(\n            required_features=list(self.required_keys),\n            data_path=data_path,\n        )\n    return await self.map(dataset.to_list())\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.base.DataLoader.map","title":"map  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>map(dataset: Iterable[dict]) -&gt; Iterable[EvaluationDataT]\n</code></pre> <p>Map the dataset to the evaluation data.</p> PARAMETER DESCRIPTION <code>dataset</code> <p>The dataset to map.</p> <p> TYPE: <code>Iterable[dict]</code> </p> RETURNS DESCRIPTION <code>Iterable[EvaluationDataT]</code> <p>The evaluation data.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/dataloaders/base.py</code> <pre><code>@abstractmethod\nasync def map(self, dataset: Iterable[dict]) -&gt; Iterable[EvaluationDataT]:\n    \"\"\"\n    Map the dataset to the evaluation data.\n\n    Args:\n        dataset: The dataset to map.\n\n    Returns:\n        The evaluation data.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.document_search.DocumentSearchDataLoader","title":"ragbits.evaluate.dataloaders.document_search.DocumentSearchDataLoader","text":"<pre><code>DocumentSearchDataLoader(source: Source, *, split: str = 'data', question_key: str = 'question', document_ids_key: str = 'document_ids', passages_key: str = 'passages', page_numbers_key: str = 'page_numbers')\n</code></pre> <p>               Bases: <code>DataLoader[DocumentSearchData]</code></p> <p>Document search evaluation data loader.</p> <p>The source used for this data loader should point to a file that can be loaded by Hugging Face.</p> <p>Initialize the document search data loader.</p> PARAMETER DESCRIPTION <code>source</code> <p>The source to load the data from.</p> <p> TYPE: <code>Source</code> </p> <code>split</code> <p>The split to load the data from. Split is fixed for data loaders to \"data\", but you can slice it using the Hugging Face API.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'data'</code> </p> <code>question_key</code> <p>The dataset column name that contains the question.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'question'</code> </p> <code>document_ids_key</code> <p>The dataset column name that contains the document ids. Document ids are optional.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'document_ids'</code> </p> <code>passages_key</code> <p>The dataset column name that contains the passages. Passages are optional.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'passages'</code> </p> <code>page_numbers_key</code> <p>The dataset column name that contains the page numbers. Page numbers are optional.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'page_numbers'</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/dataloaders/document_search.py</code> <pre><code>def __init__(\n    self,\n    source: Source,\n    *,\n    split: str = \"data\",\n    question_key: str = \"question\",\n    document_ids_key: str = \"document_ids\",\n    passages_key: str = \"passages\",\n    page_numbers_key: str = \"page_numbers\",\n) -&gt; None:\n    \"\"\"\n    Initialize the document search data loader.\n\n    Args:\n        source: The source to load the data from.\n        split: The split to load the data from. Split is fixed for data loaders to \"data\",\n            but you can slice it using the [Hugging Face API](https://huggingface.co/docs/datasets/v1.11.0/splits.html#slicing-api).\n        question_key: The dataset column name that contains the question.\n        document_ids_key: The dataset column name that contains the document ids. Document ids are optional.\n        passages_key: The dataset column name that contains the passages. Passages are optional.\n        page_numbers_key: The dataset column name that contains the page numbers. Page numbers are optional.\n    \"\"\"\n    super().__init__(source=source, split=split, required_keys={question_key})\n    self.question_key = question_key\n    self.document_ids_key = document_ids_key\n    self.passages_key = passages_key\n    self.page_numbers_key = page_numbers_key\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.document_search.DocumentSearchDataLoader.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = dataloaders\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.document_search.DocumentSearchDataLoader.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'dataloader'\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.document_search.DocumentSearchDataLoader.source","title":"source  <code>instance-attribute</code>","text":"<pre><code>source = source\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.document_search.DocumentSearchDataLoader.split","title":"split  <code>instance-attribute</code>","text":"<pre><code>split = split\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.document_search.DocumentSearchDataLoader.required_keys","title":"required_keys  <code>instance-attribute</code>","text":"<pre><code>required_keys = required_keys or set()\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.document_search.DocumentSearchDataLoader.question_key","title":"question_key  <code>instance-attribute</code>","text":"<pre><code>question_key = question_key\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.document_search.DocumentSearchDataLoader.document_ids_key","title":"document_ids_key  <code>instance-attribute</code>","text":"<pre><code>document_ids_key = document_ids_key\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.document_search.DocumentSearchDataLoader.passages_key","title":"passages_key  <code>instance-attribute</code>","text":"<pre><code>passages_key = passages_key\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.document_search.DocumentSearchDataLoader.page_numbers_key","title":"page_numbers_key  <code>instance-attribute</code>","text":"<pre><code>page_numbers_key = page_numbers_key\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.document_search.DocumentSearchDataLoader.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.document_search.DocumentSearchDataLoader.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.document_search.DocumentSearchDataLoader.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.document_search.DocumentSearchDataLoader.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Create an instance of <code>DataLoader</code> from a configuration dictionary.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration settings for the data loader.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the data loader class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/dataloaders/base.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Create an instance of `DataLoader` from a configuration dictionary.\n\n    Args:\n        config: A dictionary containing configuration settings for the data loader.\n\n    Returns:\n        An instance of the data loader class initialized with the provided configuration.\n    \"\"\"\n    dataloader_config = DataLoaderConfig.model_validate(config)\n    config[\"source\"] = Source.subclass_from_config(dataloader_config.source)\n    return super().from_config(config)\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.document_search.DocumentSearchDataLoader.load","title":"load  <code>async</code>","text":"<pre><code>load() -&gt; Iterable[EvaluationDataT]\n</code></pre> <p>Load the data.</p> RETURNS DESCRIPTION <code>Iterable[EvaluationDataT]</code> <p>The loaded evaluation data.</p> RAISES DESCRIPTION <code>DataLoaderIncorrectFormatDataError</code> <p>If evaluation dataset is incorrectly formatted.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/dataloaders/base.py</code> <pre><code>async def load(self) -&gt; Iterable[EvaluationDataT]:\n    \"\"\"\n    Load the data.\n\n    Returns:\n        The loaded evaluation data.\n\n    Raises:\n        DataLoaderIncorrectFormatDataError: If evaluation dataset is incorrectly formatted.\n    \"\"\"\n    data_path = await self.source.fetch()\n    dataset = load_dataset(\n        path=str(data_path.parent),\n        data_files={\"data\": str(data_path.name)},\n        split=self.split,\n    )\n    if not self.required_keys.issubset(dataset.features):\n        raise DataLoaderIncorrectFormatDataError(\n            required_features=list(self.required_keys),\n            data_path=data_path,\n        )\n    return await self.map(dataset.to_list())\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.document_search.DocumentSearchDataLoader.map","title":"map  <code>async</code>","text":"<pre><code>map(dataset: Iterable[dict]) -&gt; Iterable[DocumentSearchData]\n</code></pre> <p>Map the dataset to the document search data schema.</p> PARAMETER DESCRIPTION <code>dataset</code> <p>The dataset to map.</p> <p> TYPE: <code>Iterable[dict]</code> </p> RETURNS DESCRIPTION <code>Iterable[DocumentSearchData]</code> <p>The document search data.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/dataloaders/document_search.py</code> <pre><code>async def map(self, dataset: Iterable[dict]) -&gt; Iterable[DocumentSearchData]:\n    \"\"\"\n    Map the dataset to the document search data schema.\n\n    Args:\n        dataset: The dataset to map.\n\n    Returns:\n        The document search data.\n    \"\"\"\n    return [\n        DocumentSearchData(\n            question=data.get(self.question_key, \"\"),\n            reference_document_ids=data.get(self.document_ids_key),\n            reference_passages=data.get(self.passages_key),\n            reference_page_numbers=data.get(self.page_numbers_key),\n        )\n        for data in dataset\n    ]\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.question_answer.QuestionAnswerDataLoader","title":"ragbits.evaluate.dataloaders.question_answer.QuestionAnswerDataLoader","text":"<pre><code>QuestionAnswerDataLoader(source: Source, *, split: str = 'data', question_key: str = 'question', answer_key: str = 'answer', context_key: str = 'context')\n</code></pre> <p>               Bases: <code>DataLoader[QuestionAnswerData]</code></p> <p>Question answer evaluation data loader.</p> <p>The source used for this data loader should point to a file that can be loaded by Hugging Face.</p> <p>Initialize the question answer data loader.</p> PARAMETER DESCRIPTION <code>source</code> <p>The source to load the data from.</p> <p> TYPE: <code>Source</code> </p> <code>split</code> <p>The split to load the data from.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'data'</code> </p> <code>question_key</code> <p>The dataset column name that contains the question.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'question'</code> </p> <code>answer_key</code> <p>The dataset column name that contains the answer.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'answer'</code> </p> <code>context_key</code> <p>The dataset column name that contains the context. Context is optional.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'context'</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/dataloaders/question_answer.py</code> <pre><code>def __init__(\n    self,\n    source: Source,\n    *,\n    split: str = \"data\",\n    question_key: str = \"question\",\n    answer_key: str = \"answer\",\n    context_key: str = \"context\",\n) -&gt; None:\n    \"\"\"\n    Initialize the question answer data loader.\n\n    Args:\n        source: The source to load the data from.\n        split: The split to load the data from.\n        question_key: The dataset column name that contains the question.\n        answer_key: The dataset column name that contains the answer.\n        context_key: The dataset column name that contains the context. Context is optional.\n    \"\"\"\n    super().__init__(source=source, split=split, required_keys={question_key, answer_key})\n    self.question_key = question_key\n    self.answer_key = answer_key\n    self.context_key = context_key\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.question_answer.QuestionAnswerDataLoader.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = dataloaders\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.question_answer.QuestionAnswerDataLoader.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'dataloader'\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.question_answer.QuestionAnswerDataLoader.source","title":"source  <code>instance-attribute</code>","text":"<pre><code>source = source\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.question_answer.QuestionAnswerDataLoader.split","title":"split  <code>instance-attribute</code>","text":"<pre><code>split = split\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.question_answer.QuestionAnswerDataLoader.required_keys","title":"required_keys  <code>instance-attribute</code>","text":"<pre><code>required_keys = required_keys or set()\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.question_answer.QuestionAnswerDataLoader.question_key","title":"question_key  <code>instance-attribute</code>","text":"<pre><code>question_key = question_key\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.question_answer.QuestionAnswerDataLoader.answer_key","title":"answer_key  <code>instance-attribute</code>","text":"<pre><code>answer_key = answer_key\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.question_answer.QuestionAnswerDataLoader.context_key","title":"context_key  <code>instance-attribute</code>","text":"<pre><code>context_key = context_key\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.question_answer.QuestionAnswerDataLoader.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.question_answer.QuestionAnswerDataLoader.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.question_answer.QuestionAnswerDataLoader.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.question_answer.QuestionAnswerDataLoader.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Create an instance of <code>DataLoader</code> from a configuration dictionary.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration settings for the data loader.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the data loader class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/dataloaders/base.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Create an instance of `DataLoader` from a configuration dictionary.\n\n    Args:\n        config: A dictionary containing configuration settings for the data loader.\n\n    Returns:\n        An instance of the data loader class initialized with the provided configuration.\n    \"\"\"\n    dataloader_config = DataLoaderConfig.model_validate(config)\n    config[\"source\"] = Source.subclass_from_config(dataloader_config.source)\n    return super().from_config(config)\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.question_answer.QuestionAnswerDataLoader.load","title":"load  <code>async</code>","text":"<pre><code>load() -&gt; Iterable[EvaluationDataT]\n</code></pre> <p>Load the data.</p> RETURNS DESCRIPTION <code>Iterable[EvaluationDataT]</code> <p>The loaded evaluation data.</p> RAISES DESCRIPTION <code>DataLoaderIncorrectFormatDataError</code> <p>If evaluation dataset is incorrectly formatted.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/dataloaders/base.py</code> <pre><code>async def load(self) -&gt; Iterable[EvaluationDataT]:\n    \"\"\"\n    Load the data.\n\n    Returns:\n        The loaded evaluation data.\n\n    Raises:\n        DataLoaderIncorrectFormatDataError: If evaluation dataset is incorrectly formatted.\n    \"\"\"\n    data_path = await self.source.fetch()\n    dataset = load_dataset(\n        path=str(data_path.parent),\n        data_files={\"data\": str(data_path.name)},\n        split=self.split,\n    )\n    if not self.required_keys.issubset(dataset.features):\n        raise DataLoaderIncorrectFormatDataError(\n            required_features=list(self.required_keys),\n            data_path=data_path,\n        )\n    return await self.map(dataset.to_list())\n</code></pre>"},{"location":"api_reference/evaluate/dataloaders/#ragbits.evaluate.dataloaders.question_answer.QuestionAnswerDataLoader.map","title":"map  <code>async</code>","text":"<pre><code>map(dataset: Iterable[dict]) -&gt; Iterable[QuestionAnswerData]\n</code></pre> <p>Map the dataset to the question answer data schema.</p> PARAMETER DESCRIPTION <code>dataset</code> <p>The dataset to map.</p> <p> TYPE: <code>Iterable[dict]</code> </p> RETURNS DESCRIPTION <code>Iterable[QuestionAnswerData]</code> <p>The question answer data.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/dataloaders/question_answer.py</code> <pre><code>async def map(self, dataset: Iterable[dict]) -&gt; Iterable[QuestionAnswerData]:\n    \"\"\"\n    Map the dataset to the question answer data schema.\n\n    Args:\n        dataset: The dataset to map.\n\n    Returns:\n        The question answer data.\n    \"\"\"\n    return [\n        QuestionAnswerData(\n            question=data.get(self.question_key, \"\"),\n            reference_answer=data.get(self.answer_key, \"\"),\n            reference_context=data.get(self.context_key),\n        )\n        for data in dataset\n    ]\n</code></pre>"},{"location":"api_reference/evaluate/metrics/","title":"Metrics","text":""},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.MetricSet","title":"ragbits.evaluate.metrics.base.MetricSet","text":"<pre><code>MetricSet(*metrics: Metric[EvaluationResultT])\n</code></pre> <p>               Bases: <code>WithConstructionConfig</code>, <code>Generic[EvaluationResultT]</code></p> <p>Represents a set of metrics.</p> <p>Initialize the metric set.</p> PARAMETER DESCRIPTION <code>metrics</code> <p>The metrics.</p> <p> TYPE: <code>Metric[EvaluationResultT]</code> DEFAULT: <code>()</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/base.py</code> <pre><code>def __init__(self, *metrics: Metric[EvaluationResultT]) -&gt; None:\n    \"\"\"\n    Initialize the metric set.\n\n    Args:\n        metrics: The metrics.\n    \"\"\"\n    self.metrics = metrics\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.MetricSet.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'metrics'\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.MetricSet.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = metrics\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.MetricSet.metrics","title":"metrics  <code>instance-attribute</code>","text":"<pre><code>metrics = metrics\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.MetricSet.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.MetricSet.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.MetricSet.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.MetricSet.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Create an instance of <code>MetricSet</code> from a configuration dictionary.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration settings for the metric set.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the metric set class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/base.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Create an instance of `MetricSet` from a configuration dictionary.\n\n    Args:\n        config: A dictionary containing configuration settings for the metric set.\n\n    Returns:\n        An instance of the metric set class initialized with the provided configuration.\n    \"\"\"\n    return cls(*[Metric.subclass_from_config(metric_config) for metric_config in config.values()])\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.MetricSet.compute","title":"compute  <code>async</code>","text":"<pre><code>compute(results: list[EvaluationResultT]) -&gt; dict\n</code></pre> <p>Compute the metrics.</p> PARAMETER DESCRIPTION <code>results</code> <p>The evaluation results.</p> <p> TYPE: <code>list[EvaluationResultT]</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>The computed metrics.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/base.py</code> <pre><code>async def compute(self, results: list[EvaluationResultT]) -&gt; dict:\n    \"\"\"\n    Compute the metrics.\n\n    Args:\n        results: The evaluation results.\n\n    Returns:\n        The computed metrics.\n    \"\"\"\n    metric_results = await asyncio.gather(*[metric.compute(results) for metric in self.metrics])\n    return {\n        name: metric.weight * value\n        for metric, result in zip(self.metrics, metric_results, strict=False)\n        for name, value in result.items()\n    }\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.Metric","title":"ragbits.evaluate.metrics.base.Metric","text":"<pre><code>Metric(weight: float = 1.0)\n</code></pre> <p>               Bases: <code>WithConstructionConfig</code>, <code>Generic[EvaluationResultT]</code>, <code>ABC</code></p> <p>Base class for metrics.</p> <p>Initialize the metric.</p> PARAMETER DESCRIPTION <code>weight</code> <p>Metric value weight in the final score, used during optimization.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/base.py</code> <pre><code>def __init__(self, weight: float = 1.0) -&gt; None:\n    \"\"\"\n    Initialize the metric.\n\n    Args:\n        weight: Metric value weight in the final score, used during optimization.\n    \"\"\"\n    super().__init__()\n    self.weight = weight\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.Metric.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = metrics\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.Metric.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'metric'\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.Metric.weight","title":"weight  <code>instance-attribute</code>","text":"<pre><code>weight = weight\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.Metric.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.Metric.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.Metric.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.Metric.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.base.Metric.compute","title":"compute  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>compute(results: list[EvaluationResultT]) -&gt; dict\n</code></pre> <p>Compute the metric.</p> PARAMETER DESCRIPTION <code>results</code> <p>The evaluation results.</p> <p> TYPE: <code>list[EvaluationResultT]</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>The computed metric.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/base.py</code> <pre><code>@abstractmethod\nasync def compute(self, results: list[EvaluationResultT]) -&gt; dict:\n    \"\"\"\n    Compute the metric.\n\n    Args:\n        results: The evaluation results.\n\n    Returns:\n        The computed metric.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchMetric","title":"ragbits.evaluate.metrics.document_search.DocumentSearchMetric","text":"<pre><code>DocumentSearchMetric(matching_strategy: MatchingStrategy, weight: float = 1.0)\n</code></pre> <p>               Bases: <code>Metric[DocumentSearchResult]</code>, <code>ABC</code></p> <p>Metric for document search evaluation based on Relari backend. More details can be found here.</p> <p>Initialize the document search metric.</p> PARAMETER DESCRIPTION <code>matching_strategy</code> <p>Matching strategys that determine relevance.</p> <p> TYPE: <code>MatchingStrategy</code> </p> <code>weight</code> <p>Metric value weight in the final score, used during optimization.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/document_search.py</code> <pre><code>def __init__(self, matching_strategy: MatchingStrategy, weight: float = 1.0) -&gt; None:\n    \"\"\"\n    Initialize the document search metric.\n\n    Args:\n        matching_strategy: Matching strategys that determine relevance.\n        weight: Metric value weight in the final score, used during optimization.\n    \"\"\"\n    super().__init__(weight=weight)\n    self.metric = self.metric_cls(matching_strategy)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchMetric.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = metrics\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchMetric.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'metric'\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchMetric.weight","title":"weight  <code>instance-attribute</code>","text":"<pre><code>weight = weight\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchMetric.metric_cls","title":"metric_cls  <code>instance-attribute</code>","text":"<pre><code>metric_cls: type[PrecisionRecallF1 | RankedRetrievalMetrics]\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchMetric.metric","title":"metric  <code>instance-attribute</code>","text":"<pre><code>metric = metric_cls(matching_strategy)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchMetric.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchMetric.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchMetric.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchMetric.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Create an instance of <code>DocumentSearchMetric</code> from a configuration dictionary.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration settings for the metric.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the metric class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/document_search.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Create an instance of `DocumentSearchMetric` from a configuration dictionary.\n\n    Args:\n        config: A dictionary containing configuration settings for the metric.\n\n    Returns:\n        An instance of the metric class initialized with the provided configuration.\n    \"\"\"\n    matching_strategy_cls = getattr(\n        importlib.import_module(\"continuous_eval.metrics.retrieval.matching_strategy\"),\n        config[\"matching_strategy\"][\"type\"],\n    )\n    matching_strategy = matching_strategy_cls(**config[\"matching_strategy\"][\"config\"])\n    return cls(matching_strategy=matching_strategy, weight=config.get(\"weight\", 1.0))\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchMetric.compute","title":"compute  <code>async</code>","text":"<pre><code>compute(results: list[DocumentSearchResult]) -&gt; dict\n</code></pre> <p>Compute the metric.</p> PARAMETER DESCRIPTION <code>results</code> <p>The evaluation results.</p> <p> TYPE: <code>list[DocumentSearchResult]</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>The computed metric.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/document_search.py</code> <pre><code>async def compute(self, results: list[DocumentSearchResult]) -&gt; dict:\n    \"\"\"\n    Compute the metric.\n\n    Args:\n        results: The evaluation results.\n\n    Returns:\n        The computed metric.\n    \"\"\"\n    return self.metric.aggregate(\n        [\n            self.metric(\n                [\n                    element.text_representation\n                    for element in result.predicted_elements\n                    if element.text_representation\n                ],\n                result.reference_passages,\n            )\n            for result in results\n            if result.reference_passages is not None\n        ]\n    )\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchPrecisionRecallF1","title":"ragbits.evaluate.metrics.document_search.DocumentSearchPrecisionRecallF1","text":"<pre><code>DocumentSearchPrecisionRecallF1(matching_strategy: MatchingStrategy, weight: float = 1.0)\n</code></pre> <p>               Bases: <code>DocumentSearchMetric</code></p> <p>Precision, recall, and F1 score for context retrieval. More details can be found here.</p> <p>Initialize the document search metric.</p> PARAMETER DESCRIPTION <code>matching_strategy</code> <p>Matching strategys that determine relevance.</p> <p> TYPE: <code>MatchingStrategy</code> </p> <code>weight</code> <p>Metric value weight in the final score, used during optimization.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/document_search.py</code> <pre><code>def __init__(self, matching_strategy: MatchingStrategy, weight: float = 1.0) -&gt; None:\n    \"\"\"\n    Initialize the document search metric.\n\n    Args:\n        matching_strategy: Matching strategys that determine relevance.\n        weight: Metric value weight in the final score, used during optimization.\n    \"\"\"\n    super().__init__(weight=weight)\n    self.metric = self.metric_cls(matching_strategy)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchPrecisionRecallF1.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = metrics\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchPrecisionRecallF1.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'metric'\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchPrecisionRecallF1.weight","title":"weight  <code>instance-attribute</code>","text":"<pre><code>weight = weight\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchPrecisionRecallF1.metric","title":"metric  <code>instance-attribute</code>","text":"<pre><code>metric = metric_cls(matching_strategy)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchPrecisionRecallF1.metric_cls","title":"metric_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metric_cls = PrecisionRecallF1\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchPrecisionRecallF1.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchPrecisionRecallF1.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchPrecisionRecallF1.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchPrecisionRecallF1.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Create an instance of <code>DocumentSearchMetric</code> from a configuration dictionary.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration settings for the metric.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the metric class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/document_search.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Create an instance of `DocumentSearchMetric` from a configuration dictionary.\n\n    Args:\n        config: A dictionary containing configuration settings for the metric.\n\n    Returns:\n        An instance of the metric class initialized with the provided configuration.\n    \"\"\"\n    matching_strategy_cls = getattr(\n        importlib.import_module(\"continuous_eval.metrics.retrieval.matching_strategy\"),\n        config[\"matching_strategy\"][\"type\"],\n    )\n    matching_strategy = matching_strategy_cls(**config[\"matching_strategy\"][\"config\"])\n    return cls(matching_strategy=matching_strategy, weight=config.get(\"weight\", 1.0))\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchPrecisionRecallF1.compute","title":"compute  <code>async</code>","text":"<pre><code>compute(results: list[DocumentSearchResult]) -&gt; dict\n</code></pre> <p>Compute the metric.</p> PARAMETER DESCRIPTION <code>results</code> <p>The evaluation results.</p> <p> TYPE: <code>list[DocumentSearchResult]</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>The computed metric.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/document_search.py</code> <pre><code>async def compute(self, results: list[DocumentSearchResult]) -&gt; dict:\n    \"\"\"\n    Compute the metric.\n\n    Args:\n        results: The evaluation results.\n\n    Returns:\n        The computed metric.\n    \"\"\"\n    return self.metric.aggregate(\n        [\n            self.metric(\n                [\n                    element.text_representation\n                    for element in result.predicted_elements\n                    if element.text_representation\n                ],\n                result.reference_passages,\n            )\n            for result in results\n            if result.reference_passages is not None\n        ]\n    )\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchRankedRetrievalMetrics","title":"ragbits.evaluate.metrics.document_search.DocumentSearchRankedRetrievalMetrics","text":"<pre><code>DocumentSearchRankedRetrievalMetrics(matching_strategy: MatchingStrategy, weight: float = 1.0)\n</code></pre> <p>               Bases: <code>DocumentSearchMetric</code></p> <p>Rank-aware metrics takes into account the order in which the contexts are retrieved. More details can be found here.</p> <p>Initialize the document search metric.</p> PARAMETER DESCRIPTION <code>matching_strategy</code> <p>Matching strategys that determine relevance.</p> <p> TYPE: <code>MatchingStrategy</code> </p> <code>weight</code> <p>Metric value weight in the final score, used during optimization.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/document_search.py</code> <pre><code>def __init__(self, matching_strategy: MatchingStrategy, weight: float = 1.0) -&gt; None:\n    \"\"\"\n    Initialize the document search metric.\n\n    Args:\n        matching_strategy: Matching strategys that determine relevance.\n        weight: Metric value weight in the final score, used during optimization.\n    \"\"\"\n    super().__init__(weight=weight)\n    self.metric = self.metric_cls(matching_strategy)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchRankedRetrievalMetrics.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = metrics\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchRankedRetrievalMetrics.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'metric'\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchRankedRetrievalMetrics.weight","title":"weight  <code>instance-attribute</code>","text":"<pre><code>weight = weight\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchRankedRetrievalMetrics.metric","title":"metric  <code>instance-attribute</code>","text":"<pre><code>metric = metric_cls(matching_strategy)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchRankedRetrievalMetrics.metric_cls","title":"metric_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metric_cls = RankedRetrievalMetrics\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchRankedRetrievalMetrics.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchRankedRetrievalMetrics.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchRankedRetrievalMetrics.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchRankedRetrievalMetrics.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Create an instance of <code>DocumentSearchMetric</code> from a configuration dictionary.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration settings for the metric.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the metric class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/document_search.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Create an instance of `DocumentSearchMetric` from a configuration dictionary.\n\n    Args:\n        config: A dictionary containing configuration settings for the metric.\n\n    Returns:\n        An instance of the metric class initialized with the provided configuration.\n    \"\"\"\n    matching_strategy_cls = getattr(\n        importlib.import_module(\"continuous_eval.metrics.retrieval.matching_strategy\"),\n        config[\"matching_strategy\"][\"type\"],\n    )\n    matching_strategy = matching_strategy_cls(**config[\"matching_strategy\"][\"config\"])\n    return cls(matching_strategy=matching_strategy, weight=config.get(\"weight\", 1.0))\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.document_search.DocumentSearchRankedRetrievalMetrics.compute","title":"compute  <code>async</code>","text":"<pre><code>compute(results: list[DocumentSearchResult]) -&gt; dict\n</code></pre> <p>Compute the metric.</p> PARAMETER DESCRIPTION <code>results</code> <p>The evaluation results.</p> <p> TYPE: <code>list[DocumentSearchResult]</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>The computed metric.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/document_search.py</code> <pre><code>async def compute(self, results: list[DocumentSearchResult]) -&gt; dict:\n    \"\"\"\n    Compute the metric.\n\n    Args:\n        results: The evaluation results.\n\n    Returns:\n        The computed metric.\n    \"\"\"\n    return self.metric.aggregate(\n        [\n            self.metric(\n                [\n                    element.text_representation\n                    for element in result.predicted_elements\n                    if element.text_representation\n                ],\n                result.reference_passages,\n            )\n            for result in results\n            if result.reference_passages is not None\n        ]\n    )\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerMetric","title":"ragbits.evaluate.metrics.question_answer.QuestionAnswerMetric","text":"<pre><code>QuestionAnswerMetric(llm: LLM, batch_size: int = 15, weight: float = 1.0)\n</code></pre> <p>               Bases: <code>Generic[MetricT]</code>, <code>Metric[QuestionAnswerResult]</code>, <code>ABC</code></p> <p>Metric for question answer evaluation based on Relari backend. More details can be found here.</p> <p>Initialize the agent metric.</p> PARAMETER DESCRIPTION <code>llm</code> <p>Judge LLM instance.</p> <p> TYPE: <code>LLM</code> </p> <code>batch_size</code> <p>Batch size for metric computation.</p> <p> TYPE: <code>int</code> DEFAULT: <code>15</code> </p> <code>weight</code> <p>Metric value weight in the final score, used during optimization.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/question_answer.py</code> <pre><code>def __init__(self, llm: LLM, batch_size: int = 15, weight: float = 1.0) -&gt; None:\n    \"\"\"\n    Initialize the agent metric.\n\n    Args:\n        llm: Judge LLM instance.\n        batch_size: Batch size for metric computation.\n        weight: Metric value weight in the final score, used during optimization.\n    \"\"\"\n    super().__init__(weight=weight)\n    self.llm = llm\n    self.batch_size = batch_size\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerMetric.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = metrics\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerMetric.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'metric'\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerMetric.weight","title":"weight  <code>instance-attribute</code>","text":"<pre><code>weight = weight\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerMetric.metric_cls","title":"metric_cls  <code>instance-attribute</code>","text":"<pre><code>metric_cls: type[MetricT]\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerMetric.llm","title":"llm  <code>instance-attribute</code>","text":"<pre><code>llm = llm\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerMetric.batch_size","title":"batch_size  <code>instance-attribute</code>","text":"<pre><code>batch_size = batch_size\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerMetric.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerMetric.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerMetric.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerMetric.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Create an instance of <code>QuestionAnswerMetric</code> from a configuration dictionary.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration settings for the metric.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the metric class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/question_answer.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Create an instance of `QuestionAnswerMetric` from a configuration dictionary.\n\n    Args:\n        config: A dictionary containing configuration settings for the metric.\n\n    Returns:\n        An instance of the metric class initialized with the provided configuration.\n    \"\"\"\n    config[\"llm\"] = LLM.from_config(config[\"llm\"])\n    config[\"batch_size\"] = config.get(\"batch_size\", 15)\n    config[\"weight\"] = config.get(\"weight\", 1.0)\n    return super().from_config(config)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerMetric.compute","title":"compute  <code>async</code>","text":"<pre><code>compute(results: list[QuestionAnswerResult[QuestionAnswerPromptOutputT]]) -&gt; dict\n</code></pre> <p>Compute the metric.</p> PARAMETER DESCRIPTION <code>results</code> <p>The evaluation results.</p> <p> TYPE: <code>list[QuestionAnswerResult[QuestionAnswerPromptOutputT]]</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>The computed metric.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/question_answer.py</code> <pre><code>async def compute(self, results: list[QuestionAnswerResult[QuestionAnswerPromptOutputT]]) -&gt; dict:\n    \"\"\"\n    Compute the metric.\n\n    Args:\n        results: The evaluation results.\n\n    Returns:\n        The computed metric.\n    \"\"\"\n    metric = self.metric_cls(_MetricLMM(self.llm, loop=asyncio.get_running_loop()))\n    metric_results = chain.from_iterable(\n        [\n            await asyncio.gather(*[asyncio.to_thread(self._call_metric, metric, result) for result in batch])\n            for batch in batched(results, self.batch_size)\n        ]\n    )\n    return metric.aggregate(list(metric_results))\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerCorrectness","title":"ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerCorrectness","text":"<pre><code>QuestionAnswerAnswerCorrectness(llm: LLM, batch_size: int = 15, weight: float = 1.0)\n</code></pre> <p>               Bases: <code>QuestionAnswerMetric[AnswerCorrectness]</code></p> <p>Metric checking answer correctness based on LLM. More details can be found here.</p> <p>Initialize the agent metric.</p> PARAMETER DESCRIPTION <code>llm</code> <p>Judge LLM instance.</p> <p> TYPE: <code>LLM</code> </p> <code>batch_size</code> <p>Batch size for metric computation.</p> <p> TYPE: <code>int</code> DEFAULT: <code>15</code> </p> <code>weight</code> <p>Metric value weight in the final score, used during optimization.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/question_answer.py</code> <pre><code>def __init__(self, llm: LLM, batch_size: int = 15, weight: float = 1.0) -&gt; None:\n    \"\"\"\n    Initialize the agent metric.\n\n    Args:\n        llm: Judge LLM instance.\n        batch_size: Batch size for metric computation.\n        weight: Metric value weight in the final score, used during optimization.\n    \"\"\"\n    super().__init__(weight=weight)\n    self.llm = llm\n    self.batch_size = batch_size\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerCorrectness.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = metrics\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerCorrectness.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'metric'\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerCorrectness.weight","title":"weight  <code>instance-attribute</code>","text":"<pre><code>weight = weight\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerCorrectness.llm","title":"llm  <code>instance-attribute</code>","text":"<pre><code>llm = llm\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerCorrectness.batch_size","title":"batch_size  <code>instance-attribute</code>","text":"<pre><code>batch_size = batch_size\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerCorrectness.metric_cls","title":"metric_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metric_cls: type[AnswerCorrectness] = AnswerCorrectness\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerCorrectness.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerCorrectness.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerCorrectness.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerCorrectness.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Create an instance of <code>QuestionAnswerMetric</code> from a configuration dictionary.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration settings for the metric.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the metric class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/question_answer.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Create an instance of `QuestionAnswerMetric` from a configuration dictionary.\n\n    Args:\n        config: A dictionary containing configuration settings for the metric.\n\n    Returns:\n        An instance of the metric class initialized with the provided configuration.\n    \"\"\"\n    config[\"llm\"] = LLM.from_config(config[\"llm\"])\n    config[\"batch_size\"] = config.get(\"batch_size\", 15)\n    config[\"weight\"] = config.get(\"weight\", 1.0)\n    return super().from_config(config)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerCorrectness.compute","title":"compute  <code>async</code>","text":"<pre><code>compute(results: list[QuestionAnswerResult[QuestionAnswerPromptOutputT]]) -&gt; dict\n</code></pre> <p>Compute the metric.</p> PARAMETER DESCRIPTION <code>results</code> <p>The evaluation results.</p> <p> TYPE: <code>list[QuestionAnswerResult[QuestionAnswerPromptOutputT]]</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>The computed metric.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/question_answer.py</code> <pre><code>async def compute(self, results: list[QuestionAnswerResult[QuestionAnswerPromptOutputT]]) -&gt; dict:\n    \"\"\"\n    Compute the metric.\n\n    Args:\n        results: The evaluation results.\n\n    Returns:\n        The computed metric.\n    \"\"\"\n    metric = self.metric_cls(_MetricLMM(self.llm, loop=asyncio.get_running_loop()))\n    metric_results = chain.from_iterable(\n        [\n            await asyncio.gather(*[asyncio.to_thread(self._call_metric, metric, result) for result in batch])\n            for batch in batched(results, self.batch_size)\n        ]\n    )\n    return metric.aggregate(list(metric_results))\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerFaithfulness","title":"ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerFaithfulness","text":"<pre><code>QuestionAnswerAnswerFaithfulness(llm: LLM, batch_size: int = 15, weight: float = 1.0)\n</code></pre> <p>               Bases: <code>QuestionAnswerMetric[Faithfulness]</code></p> <p>Metric checking answer faithfulness based on LLM. More details can be found here.</p> <p>Initialize the agent metric.</p> PARAMETER DESCRIPTION <code>llm</code> <p>Judge LLM instance.</p> <p> TYPE: <code>LLM</code> </p> <code>batch_size</code> <p>Batch size for metric computation.</p> <p> TYPE: <code>int</code> DEFAULT: <code>15</code> </p> <code>weight</code> <p>Metric value weight in the final score, used during optimization.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/question_answer.py</code> <pre><code>def __init__(self, llm: LLM, batch_size: int = 15, weight: float = 1.0) -&gt; None:\n    \"\"\"\n    Initialize the agent metric.\n\n    Args:\n        llm: Judge LLM instance.\n        batch_size: Batch size for metric computation.\n        weight: Metric value weight in the final score, used during optimization.\n    \"\"\"\n    super().__init__(weight=weight)\n    self.llm = llm\n    self.batch_size = batch_size\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerFaithfulness.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = metrics\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerFaithfulness.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'metric'\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerFaithfulness.weight","title":"weight  <code>instance-attribute</code>","text":"<pre><code>weight = weight\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerFaithfulness.llm","title":"llm  <code>instance-attribute</code>","text":"<pre><code>llm = llm\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerFaithfulness.batch_size","title":"batch_size  <code>instance-attribute</code>","text":"<pre><code>batch_size = batch_size\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerFaithfulness.metric_cls","title":"metric_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metric_cls: type[Faithfulness] = Faithfulness\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerFaithfulness.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerFaithfulness.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerFaithfulness.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerFaithfulness.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Create an instance of <code>QuestionAnswerMetric</code> from a configuration dictionary.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration settings for the metric.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the metric class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/question_answer.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Create an instance of `QuestionAnswerMetric` from a configuration dictionary.\n\n    Args:\n        config: A dictionary containing configuration settings for the metric.\n\n    Returns:\n        An instance of the metric class initialized with the provided configuration.\n    \"\"\"\n    config[\"llm\"] = LLM.from_config(config[\"llm\"])\n    config[\"batch_size\"] = config.get(\"batch_size\", 15)\n    config[\"weight\"] = config.get(\"weight\", 1.0)\n    return super().from_config(config)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerFaithfulness.compute","title":"compute  <code>async</code>","text":"<pre><code>compute(results: list[QuestionAnswerResult[QuestionAnswerPromptOutputT]]) -&gt; dict\n</code></pre> <p>Compute the metric.</p> PARAMETER DESCRIPTION <code>results</code> <p>The evaluation results.</p> <p> TYPE: <code>list[QuestionAnswerResult[QuestionAnswerPromptOutputT]]</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>The computed metric.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/question_answer.py</code> <pre><code>async def compute(self, results: list[QuestionAnswerResult[QuestionAnswerPromptOutputT]]) -&gt; dict:\n    \"\"\"\n    Compute the metric.\n\n    Args:\n        results: The evaluation results.\n\n    Returns:\n        The computed metric.\n    \"\"\"\n    metric = self.metric_cls(_MetricLMM(self.llm, loop=asyncio.get_running_loop()))\n    metric_results = chain.from_iterable(\n        [\n            await asyncio.gather(*[asyncio.to_thread(self._call_metric, metric, result) for result in batch])\n            for batch in batched(results, self.batch_size)\n        ]\n    )\n    return metric.aggregate(list(metric_results))\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerRelevance","title":"ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerRelevance","text":"<pre><code>QuestionAnswerAnswerRelevance(llm: LLM, batch_size: int = 15, weight: float = 1.0)\n</code></pre> <p>               Bases: <code>QuestionAnswerMetric[AnswerRelevance]</code></p> <p>Metric checking answer relevance based on LLM. More details can be found here.</p> <p>Initialize the agent metric.</p> PARAMETER DESCRIPTION <code>llm</code> <p>Judge LLM instance.</p> <p> TYPE: <code>LLM</code> </p> <code>batch_size</code> <p>Batch size for metric computation.</p> <p> TYPE: <code>int</code> DEFAULT: <code>15</code> </p> <code>weight</code> <p>Metric value weight in the final score, used during optimization.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/question_answer.py</code> <pre><code>def __init__(self, llm: LLM, batch_size: int = 15, weight: float = 1.0) -&gt; None:\n    \"\"\"\n    Initialize the agent metric.\n\n    Args:\n        llm: Judge LLM instance.\n        batch_size: Batch size for metric computation.\n        weight: Metric value weight in the final score, used during optimization.\n    \"\"\"\n    super().__init__(weight=weight)\n    self.llm = llm\n    self.batch_size = batch_size\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerRelevance.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = metrics\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerRelevance.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'metric'\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerRelevance.weight","title":"weight  <code>instance-attribute</code>","text":"<pre><code>weight = weight\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerRelevance.llm","title":"llm  <code>instance-attribute</code>","text":"<pre><code>llm = llm\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerRelevance.batch_size","title":"batch_size  <code>instance-attribute</code>","text":"<pre><code>batch_size = batch_size\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerRelevance.metric_cls","title":"metric_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metric_cls: type[AnswerRelevance] = AnswerRelevance\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerRelevance.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerRelevance.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerRelevance.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerRelevance.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Create an instance of <code>QuestionAnswerMetric</code> from a configuration dictionary.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration settings for the metric.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the metric class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/question_answer.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Create an instance of `QuestionAnswerMetric` from a configuration dictionary.\n\n    Args:\n        config: A dictionary containing configuration settings for the metric.\n\n    Returns:\n        An instance of the metric class initialized with the provided configuration.\n    \"\"\"\n    config[\"llm\"] = LLM.from_config(config[\"llm\"])\n    config[\"batch_size\"] = config.get(\"batch_size\", 15)\n    config[\"weight\"] = config.get(\"weight\", 1.0)\n    return super().from_config(config)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerRelevance.compute","title":"compute  <code>async</code>","text":"<pre><code>compute(results: list[QuestionAnswerResult[QuestionAnswerPromptOutputT]]) -&gt; dict\n</code></pre> <p>Compute the metric.</p> PARAMETER DESCRIPTION <code>results</code> <p>The evaluation results.</p> <p> TYPE: <code>list[QuestionAnswerResult[QuestionAnswerPromptOutputT]]</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>The computed metric.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/question_answer.py</code> <pre><code>async def compute(self, results: list[QuestionAnswerResult[QuestionAnswerPromptOutputT]]) -&gt; dict:\n    \"\"\"\n    Compute the metric.\n\n    Args:\n        results: The evaluation results.\n\n    Returns:\n        The computed metric.\n    \"\"\"\n    metric = self.metric_cls(_MetricLMM(self.llm, loop=asyncio.get_running_loop()))\n    metric_results = chain.from_iterable(\n        [\n            await asyncio.gather(*[asyncio.to_thread(self._call_metric, metric, result) for result in batch])\n            for batch in batched(results, self.batch_size)\n        ]\n    )\n    return metric.aggregate(list(metric_results))\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerConsistency","title":"ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerConsistency","text":"<pre><code>QuestionAnswerAnswerConsistency(llm: LLM, batch_size: int = 15, weight: float = 1.0)\n</code></pre> <p>               Bases: <code>QuestionAnswerMetric[StyleConsistency]</code></p> <p>Metric checking answer relevance based on LLM. More details can be found here.</p> <p>Initialize the agent metric.</p> PARAMETER DESCRIPTION <code>llm</code> <p>Judge LLM instance.</p> <p> TYPE: <code>LLM</code> </p> <code>batch_size</code> <p>Batch size for metric computation.</p> <p> TYPE: <code>int</code> DEFAULT: <code>15</code> </p> <code>weight</code> <p>Metric value weight in the final score, used during optimization.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/question_answer.py</code> <pre><code>def __init__(self, llm: LLM, batch_size: int = 15, weight: float = 1.0) -&gt; None:\n    \"\"\"\n    Initialize the agent metric.\n\n    Args:\n        llm: Judge LLM instance.\n        batch_size: Batch size for metric computation.\n        weight: Metric value weight in the final score, used during optimization.\n    \"\"\"\n    super().__init__(weight=weight)\n    self.llm = llm\n    self.batch_size = batch_size\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerConsistency.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = metrics\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerConsistency.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'metric'\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerConsistency.weight","title":"weight  <code>instance-attribute</code>","text":"<pre><code>weight = weight\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerConsistency.llm","title":"llm  <code>instance-attribute</code>","text":"<pre><code>llm = llm\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerConsistency.batch_size","title":"batch_size  <code>instance-attribute</code>","text":"<pre><code>batch_size = batch_size\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerConsistency.metric_cls","title":"metric_cls  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metric_cls: type[StyleConsistency] = StyleConsistency\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerConsistency.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerConsistency.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerConsistency.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerConsistency.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Create an instance of <code>QuestionAnswerMetric</code> from a configuration dictionary.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration settings for the metric.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the metric class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/question_answer.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Create an instance of `QuestionAnswerMetric` from a configuration dictionary.\n\n    Args:\n        config: A dictionary containing configuration settings for the metric.\n\n    Returns:\n        An instance of the metric class initialized with the provided configuration.\n    \"\"\"\n    config[\"llm\"] = LLM.from_config(config[\"llm\"])\n    config[\"batch_size\"] = config.get(\"batch_size\", 15)\n    config[\"weight\"] = config.get(\"weight\", 1.0)\n    return super().from_config(config)\n</code></pre>"},{"location":"api_reference/evaluate/metrics/#ragbits.evaluate.metrics.question_answer.QuestionAnswerAnswerConsistency.compute","title":"compute  <code>async</code>","text":"<pre><code>compute(results: list[QuestionAnswerResult[QuestionAnswerPromptOutputT]]) -&gt; dict\n</code></pre> <p>Compute the metric.</p> PARAMETER DESCRIPTION <code>results</code> <p>The evaluation results.</p> <p> TYPE: <code>list[QuestionAnswerResult[QuestionAnswerPromptOutputT]]</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>The computed metric.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/metrics/question_answer.py</code> <pre><code>async def compute(self, results: list[QuestionAnswerResult[QuestionAnswerPromptOutputT]]) -&gt; dict:\n    \"\"\"\n    Compute the metric.\n\n    Args:\n        results: The evaluation results.\n\n    Returns:\n        The computed metric.\n    \"\"\"\n    metric = self.metric_cls(_MetricLMM(self.llm, loop=asyncio.get_running_loop()))\n    metric_results = chain.from_iterable(\n        [\n            await asyncio.gather(*[asyncio.to_thread(self._call_metric, metric, result) for result in batch])\n            for batch in batched(results, self.batch_size)\n        ]\n    )\n    return metric.aggregate(list(metric_results))\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/","title":"Pipelines","text":""},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.base.EvaluationPipeline","title":"ragbits.evaluate.pipelines.base.EvaluationPipeline","text":"<pre><code>EvaluationPipeline(evaluation_target: EvaluationTargetT)\n</code></pre> <p>               Bases: <code>WithConstructionConfig</code>, <code>Generic[EvaluationTargetT, EvaluationDataT, EvaluationResultT]</code>, <code>ABC</code></p> <p>Evaluation pipeline.</p> <p>Initialize the evaluation pipeline.</p> PARAMETER DESCRIPTION <code>evaluation_target</code> <p>Evaluation target instance.</p> <p> TYPE: <code>EvaluationTargetT</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/pipelines/base.py</code> <pre><code>def __init__(self, evaluation_target: EvaluationTargetT) -&gt; None:\n    \"\"\"\n    Initialize the evaluation pipeline.\n\n    Args:\n        evaluation_target: Evaluation target instance.\n    \"\"\"\n    super().__init__()\n    self.evaluation_target = evaluation_target\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.base.EvaluationPipeline.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = pipelines\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.base.EvaluationPipeline.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'pipeline'\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.base.EvaluationPipeline.evaluation_target","title":"evaluation_target  <code>instance-attribute</code>","text":"<pre><code>evaluation_target = evaluation_target\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.base.EvaluationPipeline.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.base.EvaluationPipeline.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.base.EvaluationPipeline.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.base.EvaluationPipeline.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration details for the class.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration.\n\n    Args:\n        config: A dictionary containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n    \"\"\"\n    return cls(**config)\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.base.EvaluationPipeline.prepare","title":"prepare  <code>async</code>","text":"<pre><code>prepare() -&gt; None\n</code></pre> <p>Prepare pipeline for evaluation. Optional step.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/pipelines/base.py</code> <pre><code>async def prepare(self) -&gt; None:\n    \"\"\"\n    Prepare pipeline for evaluation. Optional step.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.document_search.DocumentSearchPipeline","title":"ragbits.evaluate.pipelines.document_search.DocumentSearchPipeline","text":"<pre><code>DocumentSearchPipeline(evaluation_target: DocumentSearch, source: dict | None = None)\n</code></pre> <p>               Bases: <code>EvaluationPipeline[DocumentSearch, DocumentSearchData, DocumentSearchResult]</code></p> <p>Document search evaluation pipeline.</p> <p>Initialize the document search evaluation pipeline.</p> PARAMETER DESCRIPTION <code>evaluation_target</code> <p>Document Search instance.</p> <p> TYPE: <code>DocumentSearch</code> </p> <code>source</code> <p>Source data config for ingest.</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/pipelines/document_search.py</code> <pre><code>def __init__(self, evaluation_target: DocumentSearch, source: dict | None = None) -&gt; None:\n    \"\"\"\n    Initialize the document search evaluation pipeline.\n\n    Args:\n        evaluation_target: Document Search instance.\n        source: Source data config for ingest.\n    \"\"\"\n    super().__init__(evaluation_target=evaluation_target)\n    self.source = source or {}\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.document_search.DocumentSearchPipeline.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = pipelines\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.document_search.DocumentSearchPipeline.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'pipeline'\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.document_search.DocumentSearchPipeline.evaluation_target","title":"evaluation_target  <code>instance-attribute</code>","text":"<pre><code>evaluation_target = evaluation_target\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.document_search.DocumentSearchPipeline.source","title":"source  <code>instance-attribute</code>","text":"<pre><code>source = source or {}\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.document_search.DocumentSearchPipeline.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.document_search.DocumentSearchPipeline.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.document_search.DocumentSearchPipeline.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.document_search.DocumentSearchPipeline.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Create an instance of <code>DocumentSearchPipeline</code> from a configuration dictionary.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration settings for the pipeline.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the pipeline class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/pipelines/document_search.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Create an instance of `DocumentSearchPipeline` from a configuration dictionary.\n\n    Args:\n        config: A dictionary containing configuration settings for the pipeline.\n\n    Returns:\n        An instance of the pipeline class initialized with the provided configuration.\n    \"\"\"\n    # At this point, we assume that if the source is set, the pipeline is run in experimental mode\n    # and create random indexes for testing\n    # TODO: optimize this for cases with duplicated document search configs between runs\n    if config.get(\"source\"):\n        config[\"vector_store\"][\"config\"][\"index_name\"] = str(uuid4())\n    evaluation_target: DocumentSearch = DocumentSearch.from_config(config)\n    return cls(evaluation_target=evaluation_target, source=config.get(\"source\"))\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.document_search.DocumentSearchPipeline.prepare","title":"prepare  <code>async</code>","text":"<pre><code>prepare() -&gt; None\n</code></pre> <p>Ingest corpus data for evaluation.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/pipelines/document_search.py</code> <pre><code>async def prepare(self) -&gt; None:\n    \"\"\"\n    Ingest corpus data for evaluation.\n    \"\"\"\n    if self.source:\n        # For now we only support HF sources for pre-evaluation ingest\n        # TODO: Make it generic to any data source\n        sources = await HuggingFaceSource.list_sources(\n            path=self.source[\"config\"][\"path\"],\n            split=self.source[\"config\"][\"split\"],\n        )\n        await self.evaluation_target.ingest(sources)\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.question_answer.QuestionAnswerPipeline","title":"ragbits.evaluate.pipelines.question_answer.QuestionAnswerPipeline","text":"<pre><code>QuestionAnswerPipeline(evaluation_target: EvaluationTargetT)\n</code></pre> <p>               Bases: <code>EvaluationPipeline[QuestionAnswerAgent[LLMClientOptionsT, QuestionAnswerPromptInput, QuestionAnswerPromptOutputT], QuestionAnswerData, QuestionAnswerResult]</code></p> <p>Question answer evaluation pipeline.</p> <p>Initialize the evaluation pipeline.</p> PARAMETER DESCRIPTION <code>evaluation_target</code> <p>Evaluation target instance.</p> <p> TYPE: <code>EvaluationTargetT</code> </p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/pipelines/base.py</code> <pre><code>def __init__(self, evaluation_target: EvaluationTargetT) -&gt; None:\n    \"\"\"\n    Initialize the evaluation pipeline.\n\n    Args:\n        evaluation_target: Evaluation target instance.\n    \"\"\"\n    super().__init__()\n    self.evaluation_target = evaluation_target\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.question_answer.QuestionAnswerPipeline.default_module","title":"default_module  <code>class-attribute</code>","text":"<pre><code>default_module: ModuleType | None = pipelines\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.question_answer.QuestionAnswerPipeline.configuration_key","title":"configuration_key  <code>class-attribute</code>","text":"<pre><code>configuration_key: str = 'pipeline'\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.question_answer.QuestionAnswerPipeline.evaluation_target","title":"evaluation_target  <code>instance-attribute</code>","text":"<pre><code>evaluation_target = evaluation_target\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.question_answer.QuestionAnswerPipeline.subclass_from_config","title":"subclass_from_config  <code>classmethod</code>","text":"<pre><code>subclass_from_config(config: ObjectConstructionConfig) -&gt; Self\n</code></pre> <p>Initializes the class with the provided configuration. May return a subclass of the class, if requested by the configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A model containing configuration details for the class.</p> <p> TYPE: <code>ObjectConstructionConfig</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided configuration.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The class can't be found or is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_config(cls, config: ObjectConstructionConfig) -&gt; Self:\n    \"\"\"\n    Initializes the class with the provided configuration. May return a subclass of the class,\n    if requested by the configuration.\n\n    Args:\n        config: A model containing configuration details for the class.\n\n    Returns:\n        An instance of the class initialized with the provided configuration.\n\n    Raises:\n        InvalidConfigError: The class can't be found or is not a subclass of the current class.\n    \"\"\"\n    subclass = import_by_path(config.type, cls.default_module)\n    if not issubclass(subclass, cls):\n        raise InvalidConfigError(f\"{subclass} is not a subclass of {cls}\")\n\n    return subclass.from_config(config.config)\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.question_answer.QuestionAnswerPipeline.subclass_from_factory","title":"subclass_from_factory  <code>classmethod</code>","text":"<pre><code>subclass_from_factory(factory_path: str) -&gt; Self\n</code></pre> <p>Creates the class using the provided factory function. May return a subclass of the class, if requested by the factory. Supports both synchronous and asynchronous factory functions.</p> PARAMETER DESCRIPTION <code>factory_path</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the class initialized with the provided factory function.</p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>The factory can't be found or the object returned is not a subclass of the current class.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef subclass_from_factory(cls, factory_path: str) -&gt; Self:\n    \"\"\"\n    Creates the class using the provided factory function. May return a subclass of the class,\n    if requested by the factory. Supports both synchronous and asynchronous factory functions.\n\n    Args:\n        factory_path: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n\n    Returns:\n        An instance of the class initialized with the provided factory function.\n\n    Raises:\n        InvalidConfigError: The factory can't be found or the object returned\n            is not a subclass of the current class.\n    \"\"\"\n    factory = import_by_path(factory_path, cls.default_module)\n\n    if asyncio.iscoroutinefunction(factory):\n        try:\n            loop = asyncio.get_running_loop()\n            obj = asyncio.run_coroutine_threadsafe(factory, loop).result()\n        except RuntimeError:\n            obj = asyncio.run(factory())\n    else:\n        obj = factory()\n\n    if not isinstance(obj, cls):\n        raise InvalidConfigError(f\"The object returned by factory {factory_path} is not an instance of {cls}\")\n\n    return obj\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.question_answer.QuestionAnswerPipeline.preferred_subclass","title":"preferred_subclass  <code>classmethod</code>","text":"<pre><code>preferred_subclass(config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None) -&gt; Self\n</code></pre> <p>Tries to create an instance by looking at project's component preferences, either from YAML or from the factory. Takes optional overrides for both, which takes a higher precedence.</p> PARAMETER DESCRIPTION <code>config</code> <p>The CoreConfig instance containing preferred factory and configuration details.</p> <p> TYPE: <code>CoreConfig</code> </p> <code>factory_path_override</code> <p>A string representing the path to the factory function in the format of \"module.submodule:factory_name\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>yaml_path_override</code> <p>A string representing the path to the YAML file containing the Ragstack instance configuration.</p> <p> TYPE: <code>Path | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>InvalidConfigError</code> <p>If the default factory or configuration can't be found.</p> Source code in <code>packages/ragbits-core/src/ragbits/core/utils/config_handling.py</code> <pre><code>@classmethod\ndef preferred_subclass(\n    cls, config: CoreConfig, factory_path_override: str | None = None, yaml_path_override: Path | None = None\n) -&gt; Self:\n    \"\"\"\n    Tries to create an instance by looking at project's component preferences, either from YAML\n    or from the factory. Takes optional overrides for both, which takes a higher precedence.\n\n    Args:\n        config: The CoreConfig instance containing preferred factory and configuration details.\n        factory_path_override: A string representing the path to the factory function\n            in the format of \"module.submodule:factory_name\".\n        yaml_path_override: A string representing the path to the YAML file containing\n            the Ragstack instance configuration.\n\n    Raises:\n        InvalidConfigError: If the default factory or configuration can't be found.\n    \"\"\"\n    if yaml_path_override:\n        preferences = get_config_from_yaml(yaml_path_override)\n        if type_config := preferences.get(cls.configuration_key):\n            return cls.subclass_from_config(ObjectConstructionConfig.model_validate(type_config))\n\n    if factory_path_override:\n        return cls.subclass_from_factory(factory_path_override)\n\n    if preferred_factory := config.component_preference_factories.get(cls.configuration_key):\n        return cls.subclass_from_factory(preferred_factory)\n\n    if preferred_config := config.preferred_instances_config.get(cls.configuration_key):\n        return cls.subclass_from_config(ObjectConstructionConfig.model_validate(preferred_config))\n\n    raise NoPreferredConfigError(f\"Could not find preferred factory or configuration for {cls.configuration_key}\")\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.question_answer.QuestionAnswerPipeline.prepare","title":"prepare  <code>async</code>","text":"<pre><code>prepare() -&gt; None\n</code></pre> <p>Prepare pipeline for evaluation. Optional step.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/pipelines/base.py</code> <pre><code>async def prepare(self) -&gt; None:\n    \"\"\"\n    Prepare pipeline for evaluation. Optional step.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api_reference/evaluate/pipelines/#ragbits.evaluate.pipelines.question_answer.QuestionAnswerPipeline.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config: dict) -&gt; Self\n</code></pre> <p>Create an instance of <code>QuestionAnswerPipeline</code> from a configuration dictionary.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing configuration settings for the pipeline.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>An instance of the pipeline class initialized with the provided configuration.</p> Source code in <code>packages/ragbits-evaluate/src/ragbits/evaluate/pipelines/question_answer.py</code> <pre><code>@classmethod\ndef from_config(cls, config: dict) -&gt; Self:\n    \"\"\"\n    Create an instance of `QuestionAnswerPipeline` from a configuration dictionary.\n\n    Args:\n        config: A dictionary containing configuration settings for the pipeline.\n\n    Returns:\n        An instance of the pipeline class initialized with the provided configuration.\n    \"\"\"\n    config[\"evaluation_target\"] = QuestionAnswerAgent.from_config(config)\n    return super().from_config(config)\n</code></pre>"},{"location":"api_reference/guardrails/","title":"Guardrails","text":""},{"location":"api_reference/guardrails/#ragbits.guardrails.base.Guardrail","title":"ragbits.guardrails.base.Guardrail","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract class representing guardrail</p>"},{"location":"api_reference/guardrails/#ragbits.guardrails.base.Guardrail.verify","title":"verify  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>verify(input_to_verify: Prompt | str) -&gt; GuardrailVerificationResult\n</code></pre> <p>Verifies whether provided input meets certain criteria</p> PARAMETER DESCRIPTION <code>input_to_verify</code> <p>prompt or output of the model to check</p> <p> TYPE: <code>Prompt | str</code> </p> RETURNS DESCRIPTION <code>GuardrailVerificationResult</code> <p>verification result</p> Source code in <code>packages/ragbits-guardrails/src/ragbits/guardrails/base.py</code> <pre><code>@abstractmethod\nasync def verify(self, input_to_verify: Prompt | str) -&gt; GuardrailVerificationResult:\n    \"\"\"\n    Verifies whether provided input meets certain criteria\n\n    Args:\n        input_to_verify: prompt or output of the model to check\n\n    Returns:\n        verification result\n    \"\"\"\n</code></pre>"},{"location":"api_reference/guardrails/#ragbits.guardrails.base.GuardrailManager","title":"ragbits.guardrails.base.GuardrailManager","text":"<pre><code>GuardrailManager(guardrails: list[Guardrail])\n</code></pre> <p>Class responsible for running guardrails</p> Source code in <code>packages/ragbits-guardrails/src/ragbits/guardrails/base.py</code> <pre><code>def __init__(self, guardrails: list[Guardrail]):\n    self._guardrails = guardrails\n</code></pre>"},{"location":"api_reference/guardrails/#ragbits.guardrails.base.GuardrailManager.verify","title":"verify  <code>async</code>","text":"<pre><code>verify(input_to_verify: Prompt | str) -&gt; list[GuardrailVerificationResult]\n</code></pre> <p>Verifies whether provided input meets certain criteria</p> PARAMETER DESCRIPTION <code>input_to_verify</code> <p>prompt or output of the model to check</p> <p> TYPE: <code>Prompt | str</code> </p> RETURNS DESCRIPTION <code>list[GuardrailVerificationResult]</code> <p>list of verification result</p> Source code in <code>packages/ragbits-guardrails/src/ragbits/guardrails/base.py</code> <pre><code>async def verify(self, input_to_verify: Prompt | str) -&gt; list[GuardrailVerificationResult]:\n    \"\"\"\n    Verifies whether provided input meets certain criteria\n\n    Args:\n        input_to_verify: prompt or output of the model to check\n\n    Returns:\n        list of verification result\n    \"\"\"\n    return [await guardrail.verify(input_to_verify) for guardrail in self._guardrails]\n</code></pre>"},{"location":"api_reference/guardrails/#ragbits.guardrails.base.GuardrailVerificationResult","title":"ragbits.guardrails.base.GuardrailVerificationResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Class representing result of guardrail verification</p>"},{"location":"api_reference/guardrails/#ragbits.guardrails.base.GuardrailVerificationResult.guardrail_name","title":"guardrail_name  <code>instance-attribute</code>","text":"<pre><code>guardrail_name: str\n</code></pre>"},{"location":"api_reference/guardrails/#ragbits.guardrails.base.GuardrailVerificationResult.succeeded","title":"succeeded  <code>instance-attribute</code>","text":"<pre><code>succeeded: bool\n</code></pre>"},{"location":"api_reference/guardrails/#ragbits.guardrails.base.GuardrailVerificationResult.fail_reason","title":"fail_reason  <code>instance-attribute</code>","text":"<pre><code>fail_reason: str | None\n</code></pre>"},{"location":"api_reference/guardrails/#ragbits.guardrails.openai_moderation.OpenAIModerationGuardrail","title":"ragbits.guardrails.openai_moderation.OpenAIModerationGuardrail","text":"<pre><code>OpenAIModerationGuardrail(moderation_model: str = 'omni-moderation-latest')\n</code></pre> <p>               Bases: <code>Guardrail</code></p> <p>Guardrail based on OpenAI moderation</p> Source code in <code>packages/ragbits-guardrails/src/ragbits/guardrails/openai_moderation.py</code> <pre><code>def __init__(self, moderation_model: str = \"omni-moderation-latest\"):\n    self._openai_client = AsyncOpenAI()\n    self._moderation_model = moderation_model\n</code></pre>"},{"location":"api_reference/guardrails/#ragbits.guardrails.openai_moderation.OpenAIModerationGuardrail.verify","title":"verify  <code>async</code>","text":"<pre><code>verify(input_to_verify: Prompt | str) -&gt; GuardrailVerificationResult\n</code></pre> <p>Verifies whether provided input meets certain criteria</p> PARAMETER DESCRIPTION <code>input_to_verify</code> <p>prompt or output of the model to check</p> <p> TYPE: <code>Prompt | str</code> </p> RETURNS DESCRIPTION <code>GuardrailVerificationResult</code> <p>verification result</p> Source code in <code>packages/ragbits-guardrails/src/ragbits/guardrails/openai_moderation.py</code> <pre><code>async def verify(self, input_to_verify: Prompt | str) -&gt; GuardrailVerificationResult:\n    \"\"\"\n    Verifies whether provided input meets certain criteria\n\n    Args:\n        input_to_verify: prompt or output of the model to check\n\n    Returns:\n        verification result\n    \"\"\"\n    if isinstance(input_to_verify, Prompt):\n        inputs = [{\"type\": \"text\", \"text\": input_to_verify.rendered_user_prompt}]\n\n        if input_to_verify.rendered_system_prompt is not None:\n            inputs.append({\"type\": \"text\", \"text\": input_to_verify.rendered_system_prompt})\n\n        if attachments := input_to_verify.attachments:\n            messages = [input_to_verify.create_message_with_attachment(attachment) for attachment in attachments]\n            inputs.extend(messages)\n    else:\n        inputs = [{\"type\": \"text\", \"text\": input_to_verify}]\n    response = await self._openai_client.moderations.create(model=self._moderation_model, input=inputs)  # type: ignore\n\n    fail_reasons = [result for result in response.results if result.flagged]\n    return GuardrailVerificationResult(\n        guardrail_name=self.__class__.__name__,\n        succeeded=len(fail_reasons) == 0,\n        fail_reason=None if len(fail_reasons) == 0 else str(fail_reasons),\n    )\n</code></pre>"},{"location":"cli/main/","title":"Ragbits CLI","text":"<p>Ragbits comes with a command-line interface (CLI) that provides several commands for working with the Ragbits platform. It can be accessed by running the <code>ragbits</code> command in your terminal.</p> <p>Commands that operate on Ragbits components, such as <code>ragbits vector-store</code>, use the project's preferred component implementations if a component configuration is not explicitly provided. To learn how to set component preferences in your project, see the How-To: Set preferred components in Ragbits project guide.</p>"},{"location":"cli/main/#ragbits","title":"ragbits","text":"<p>Common CLI arguments for all ragbits commands.</p> <p>Usage:</p> <pre><code>ragbits [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--output</code>, <code>-o</code> choice (<code>text</code> | <code>json</code>) Set the output type (text or json) <code>text</code> <code>--verbose</code>, <code>-v</code> boolean Print additional information <code>False</code> <code>--install-completion</code> boolean Install completion for the current shell. None <code>--show-completion</code> boolean Show completion for the current shell, to copy it or customize the installation. None <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>agents: Commands for managing and running agents</li> <li>api: Commands for running API service</li> <li>document-search: Commands for interacting with the document search</li> <li>evaluate: Commands for interacting with ragbits evaluate module</li> <li>prompts: Commands for managing prompts</li> <li>vector-store: Commands for managing vector stores</li> </ul>"},{"location":"cli/main/#ragbits-agents","title":"ragbits agents","text":"<p>Commands for managing and running agents</p> <p>Usage:</p> <pre><code>ragbits agents [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>exec: Execute a single input against an agent and return the result.</li> <li>run: Run an agent interactively or in batch mode.</li> </ul>"},{"location":"cli/main/#ragbits-agents-exec","title":"ragbits agents exec","text":"<p>Execute a single input against an agent and return the result.</p> <p>This runs the agent once with the provided input and outputs the result.</p> <p>Usage:</p> <pre><code>ragbits agents exec [OPTIONS] AGENT_PATH INPUT_TEXT\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/main/#ragbits-agents-run","title":"ragbits agents run","text":"<p>Run an agent interactively or in batch mode.</p> <p>AGENT_PATH should be in format 'module.path:agent_variable' Example: 'examples.city_explorer:city_explorer_agent'</p> <p>Usage:</p> <pre><code>ragbits agents run [OPTIONS] AGENT_PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--interactive</code>, <code>-i</code> / <code>--no-interactive</code> boolean Run in interactive mode with TUI <code>True</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/main/#ragbits-api","title":"ragbits api","text":"<p>Commands for running API service</p> <p>Usage:</p> <pre><code>ragbits api [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>run: Run API service with UI demo</li> </ul>"},{"location":"cli/main/#ragbits-api-run","title":"ragbits api run","text":"<p>Run API service with UI demo</p> <p>Usage:</p> <pre><code>ragbits api run [OPTIONS] CHAT_INTERFACE\n</code></pre> <p>Options:</p> Name Type Description Default <code>--host</code> text Host to bind the API server to <code>127.0.0.1</code> <code>--port</code> integer Port to bind the API server to <code>8000</code> <code>--cors-origin</code> text Allowed CORS origins. Can be specified multiple times. None <code>--ui-build-dir</code> text Path to a custom UI build directory. If not specified, uses the default package UI. None <code>--debug</code> boolean Flag enabling debug tools in the default UI <code>False</code> <code>--auth</code> text Path to a module with Authentication Backend None <code>--theme</code> text Path to a HeroUI theme JSON file from heroui.com/themes None <code>--reload</code> boolean Enable auto-reload on code changes for debugging <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/main/#ragbits-document-search","title":"ragbits document-search","text":"<p>Commands for interacting with the document search</p> <p>Usage:</p> <pre><code>ragbits document-search [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--factory-path</code> text Python path to a function that creates a document search object, in a 'module.submodule:function' format None <code>--yaml-path</code> path Path to a YAML configuration file for the document search None <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>ingest: Ingest the elements from a given source to vector store.</li> <li>search: Query the chosen vector store.</li> </ul>"},{"location":"cli/main/#ragbits-document-search-ingest","title":"ragbits document-search ingest","text":"<p>Ingest the elements from a given source to vector store.</p> <p>Usage:</p> <pre><code>ragbits document-search ingest [OPTIONS] SOURCE\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/main/#ragbits-document-search-search","title":"ragbits document-search search","text":"<p>Query the chosen vector store.</p> <p>Usage:</p> <pre><code>ragbits document-search search [OPTIONS] QUERY\n</code></pre> <p>Options:</p> Name Type Description Default <code>--k</code> integer Number of entries to retrieve <code>5</code> <code>--columns</code> text Comma-separated list of columns to display, available: id, element_type, key, location, text_representation, document_meta <code>element_type,key</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/main/#ragbits-evaluate","title":"ragbits evaluate","text":"<p>Commands for interacting with ragbits evaluate module</p> <p>Usage:</p> <pre><code>ragbits evaluate [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--dataloader-factory-path</code> text A path to evaluation data loader factory in format python.path:function_name None <code>--dataloader-yaml-path</code> path A path to evaluation data loader configuration None <code>--target-factory-path</code> text A path to a factory of the evaluation target class in format: python.path:function_name None <code>--target-yaml-path</code> path A path to a YAML configuration file of the evaluation target class None <code>--metrics-factory-path</code> text A path to metrics factory in format python.path:function_name None <code>--metrics-yaml-path</code> path A path to metrics configuration None <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>run: Evaluate the pipeline.</li> </ul>"},{"location":"cli/main/#ragbits-evaluate-run","title":"ragbits evaluate run","text":"<p>Evaluate the pipeline.</p> <p>Usage:</p> <pre><code>ragbits evaluate run [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/main/#ragbits-prompts","title":"ragbits prompts","text":"<p>Commands for managing prompts</p> <p>Usage:</p> <pre><code>ragbits prompts [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>exec: Executes a prompt using the specified prompt class and LLM factory.</li> <li>promptfoo: Generates the configuration files for the PromptFoo prompts.</li> <li>render: Renders a prompt by loading a class from a module and initializing it with a given payload.</li> <li>search: Lists all available prompts that can be used with the 'render' and 'exec' commands.</li> </ul>"},{"location":"cli/main/#ragbits-prompts-exec","title":"ragbits prompts exec","text":"<p>Executes a prompt using the specified prompt class and LLM factory.</p> <p>Usage:</p> <pre><code>ragbits prompts exec [OPTIONS] PROMPT_PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--payload</code> text N/A None <code>--llm-factory</code> text N/A <code>ragbits.core.llms.factory:simple_litellm_factory</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/main/#ragbits-prompts-promptfoo","title":"ragbits prompts promptfoo","text":"<p>Generates the configuration files for the PromptFoo prompts.</p> <p>For more information, see the Promptfoo integration documentation.</p> <p>Usage:</p> <pre><code>ragbits prompts promptfoo [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--file-pattern</code> text N/A <code>**/prompt_*.py</code> <code>--root-path</code> path N/A <code>/home/mateusz/workspace/oss/ragbits</code> <code>--target-path</code> path N/A <code>promptfooconfigs</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/main/#ragbits-prompts-render","title":"ragbits prompts render","text":"<p>Renders a prompt by loading a class from a module and initializing it with a given payload.</p> <p>Usage:</p> <pre><code>ragbits prompts render [OPTIONS] PROMPT_PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--payload</code> text N/A None <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/main/#ragbits-prompts-search","title":"ragbits prompts search","text":"<p>Lists all available prompts that can be used with the 'render' and 'exec' commands.</p> <p>Usage:</p> <pre><code>ragbits prompts search [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--file-pattern</code> text N/A <code>**/prompt_*.py</code> <code>--root-path</code> path N/A <code>/home/mateusz/workspace/oss/ragbits</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/main/#ragbits-vector-store","title":"ragbits vector-store","text":"<p>Commands for managing vector stores</p> <p>Usage:</p> <pre><code>ragbits vector-store [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--factory-path</code> text Python path to a function that creates a vector store, in a 'module.submodule:function' format None <code>--yaml-path</code> path Path to a YAML configuration file for the vector store None <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>list: List all objects in the chosen vector store.</li> <li>query: Query the chosen vector store.</li> <li>remove: Remove objects from the chosen vector store.</li> </ul>"},{"location":"cli/main/#ragbits-vector-store-list","title":"ragbits vector-store list","text":"<p>List all objects in the chosen vector store.</p> <p>Usage:</p> <pre><code>ragbits vector-store list [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--limit</code> integer Maximum number of entries to list <code>10</code> <code>--offset</code> integer How many entries to skip <code>0</code> <code>--columns</code> text Comma-separated list of columns to display, aviailable: id, text, image_bytes, metadata <code>id,text,metadata</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/main/#ragbits-vector-store-query","title":"ragbits vector-store query","text":"<p>Query the chosen vector store.</p> <p>Usage:</p> <pre><code>ragbits vector-store query [OPTIONS] TEXT\n</code></pre> <p>Options:</p> Name Type Description Default <code>--k</code> integer Number of entries to retrieve <code>5</code> <code>--score-threshold</code> float Minimum score for result to be returned None <code>--columns</code> text Comma-separated list of columns to display, aviailable: score, entry.id, entry.text, entry.image_bytes, entry.metadata <code>score,entry.id,entry.text,entry.metadata</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/main/#ragbits-vector-store-remove","title":"ragbits vector-store remove","text":"<p>Remove objects from the chosen vector store.</p> <p>Usage:</p> <pre><code>ragbits vector-store remove [OPTIONS] IDS...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"how-to/agents/define_and_use_agents/","title":"How-To: Define and use agents with Ragbits","text":"<p>Ragbits <code>Agent</code> combines the reasoning power of LLMs with the ability to execute custom code through tools. This makes it possible to handle complex tasks by giving the model access to your own Python functions.</p> <p>When using tool-enabled agents, the LLM reviews the system prompt and incoming messages to decide whether a tool should be called. Instead of just generating a text response, the model can choose to invoke a tool or combine both approaches.</p> <p>Before using tools, you can check whether your selected model supports function calling with: <pre><code>litellm.supports_function_calling(model=\"your-model-name\")\n</code></pre></p> <p>If function calling is supported and tools are enabled, the agent interprets the user input, decides whether a tool is needed, executes it if necessary, and returns a final response enriched with tool results.</p> <p>This response is encapsulated in an <code>AgentResult</code>, which includes the model's output, additional metadata, conversation history, and any tool calls performed.</p>"},{"location":"how-to/agents/define_and_use_agents/#how-to-build-an-agent-with-ragbits","title":"How to build an agent with Ragbits","text":"<p>This guide walks you through building a simple agent that uses a <code>get_weather</code> tool to return weather data based on a location.</p>"},{"location":"how-to/agents/define_and_use_agents/#define-a-tool-function","title":"Define a tool function","text":"<p>First, define the function you want your agent to call. It should take regular Python arguments and return a JSON-serializable result. <pre><code>import json\n\n\ndef get_weather(location: str) -&gt; str:\n    \"\"\"\n    Returns the current weather for a given location.\n\n    Args:\n        location: The location to get the weather for.\n\n    Returns:\n        The current weather for the given location.\n    \"\"\"\n    if \"tokyo\" in location.lower():\n        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"})\n    elif \"san francisco\" in location.lower():\n        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n    elif \"paris\" in location.lower():\n        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"})\n    else:\n</code></pre></p>"},{"location":"how-to/agents/define_and_use_agents/#define-a-prompt","title":"Define a prompt","text":"<p>Use a structured prompt to instruct the LLM. For details on writing prompts with Ragbits, see the Guide to Prompting.</p> <pre><code>from pydantic import BaseModel\nfrom ragbits.core.prompt import Prompt\n\n\nclass WeatherPromptInput(BaseModel):\n    \"\"\"\n    Input format for the WeatherPrompt.\n    \"\"\"\n\n    location: str\n\n\nclass WeatherPrompt(Prompt[WeatherPromptInput]):\n    \"\"\"\n    Prompt that returns weather for a given location.\n    \"\"\"\n\n    system_prompt = \"\"\"\n    You are a helpful assistant that responds to user questions about weather.\n    \"\"\"\n\n    user_prompt = \"\"\"\n    Tell me the temperature in {{ location }}.\n</code></pre>"},{"location":"how-to/agents/define_and_use_agents/#run-the-agent","title":"Run the agent","text":"<p>Create the agent, attach the prompt and tool, and run it: <pre><code>import asyncio\nfrom ragbits.agents import Agent\nfrom ragbits.core.llms import LiteLLM\n\n\nasync def main() -&gt; None:\n    \"\"\"\n    Run the example.\n    \"\"\"\n    llm = LiteLLM(model_name=\"gpt-4o-2024-08-06\", use_structured_output=True)\n    agent = Agent(\n        llm=llm,\n        prompt=WeatherPrompt,\n        tools=[get_weather],\n        default_options=AgentOptions(max_total_tokens=500, max_turns=5),\n    )\n</code></pre></p> <p>The result is an AgentResult, which includes the model's output, additional metadata, conversation history, and any tool calls performed.</p> <p>You can find the complete code example in the Ragbits repository here.</p>"},{"location":"how-to/agents/define_and_use_agents/#tool-choice","title":"Tool choice","text":"<p>To control what tool is used at first call you could use <code>tool_choice</code> parameter. There are the following options: - \"auto\": let model decide if tool call is needed - \"none\": do not call tool - \"required: enforce tool usage (model decides which one) - Callable: one of provided tools</p>"},{"location":"how-to/agents/define_and_use_agents/#conversation-history","title":"Conversation history","text":"<p><code>Agent</code>s can retain conversation context across multiple interactions by enabling the <code>keep_history</code> flag when initializing the agent. This is useful when you want the agent to understand follow-up questions without needing the user to repeat earlier details.</p> <p>To enable this, simply set <code>keep_history=True</code> when constructing the agent. The full exchange\u2014including messages, tool calls, and results\u2014is stored and can be accessed via the AgentResult.history property.</p>"},{"location":"how-to/agents/define_and_use_agents/#example-of-context-preservation","title":"Example of context preservation","text":"<p>The following example demonstrates how an agent with history enabled maintains context between interactions:</p> <pre><code>async def main() -&gt; None:\n    \"\"\"Run the weather agent with conversation history.\"\"\"\n    llm = LiteLLM(model_name=\"gpt-4o-2024-08-06\", use_structured_output=True)\n    agent = Agent(llm=llm, prompt=WeatherPrompt, tools=[get_weather], keep_history=True)\n\n    await agent.run(WeatherPromptInput(location=\"Paris\"))\n\n    # Follow-up question about Tokyo - the agent retains weather context\n    response = await agent.run(\"What about Tokyo?\")\n    print(response)\n</code></pre> <p>In this scenario, the agent recognizes that the follow-up question \"What about Tokyo?\" refers to weather information due to the preserved conversation history. The expected output would be an AgentResult containing the response:</p> <pre><code>AgentResult(content='The current temperature in Tokyo is 10\u00b0C.', ...)\n</code></pre>"},{"location":"how-to/agents/define_and_use_agents/#binding-dependencies-via-agentruncontext","title":"Binding dependencies via AgentRunContext","text":"<p>You can bind your external dependencies before the first access and safely use them in tools. After first attribute lookup, the dependencies container freezes to prevent mutation during a run.</p> <pre><code>from dataclasses import dataclass\nfrom ragbits.agents import Agent, AgentRunContext\nfrom ragbits.core.llms.mock import MockLLM, MockLLMOptions\n\n@dataclass\nclass Deps:\n    api_host: str\n\ndef get_api_host(context: AgentRunContext | None) -&gt; str:\n    \"\"\"Return the API host taken from the bound dependencies in context.\"\"\"\n    assert context is not None\n    return context.deps.api_host\n\nasync def main() -&gt; None:\n    llm = MockLLM(\n        default_options=MockLLMOptions(\n            response=\"Using dependencies from context.\",\n            tool_calls=[{\"name\": \"get_api_host\", \"arguments\": \"{}\", \"id\": \"example\", \"type\": \"function\"}],\n        )\n    )\n    agent = Agent(llm=llm, prompt=\"Retrieve API host\", tools=[get_api_host])\n\n    context = AgentRunContext()\n    context.deps.value = Deps(api_host=\"https://api.local\")\n\n    result = await agent.run(\"What host are we using?\", context=context)\n    print(result.tool_calls[0].result)\n</code></pre> <p>See the runnable example in <code>examples/agents/dependencies.py</code>.</p>"},{"location":"how-to/agents/define_and_use_agents/#streaming-agent-responses","title":"Streaming agent responses","text":"<p>For use cases where you want to process partial outputs from the LLM as they arrive (e.g., in chat UIs), the <code>Agent</code> class supports streaming through the <code>run_streaming()</code> method.</p> <p>This method returns an <code>AgentResultStreaming</code> object \u2014 an async iterator that yields parts of the LLM response and tool-related events in real time.</p>"},{"location":"how-to/agents/define_and_use_agents/#native-openai-tools","title":"Native OpenAI tools","text":"<p>Ragbits supports selected native OpenAI tools (web_search_preview, image_generation and code_interpreter). You can use them together with your tools. <pre><code>from ragbits.agents.tools import get_web_search_tool\n\nasync def main() -&gt; None:\n    \"\"\"Run the weather agent with additional tool.\"\"\"\n    model_name = \"gpt-4o-2024-08-06\"\n    llm = LiteLLM(model_name=model_name, use_structured_output=True)\n    agent = Agent(llm=llm, prompt=WeatherPrompt, tools=[get_web_search_tool(model_name)], keep_history=True)\n\n    response = await agent.run(WeatherPromptInput(location=\"Paris\"))\n    print(response)\n</code></pre></p> <p>Tool descriptions are available here. For each of these you can see detailed information on the corresponding sub-pages (i.e. here for web search). You can use default parameters or specify your own as a dict. For web search this might look like that: <pre><code>from ragbits.agents.tools import get_web_search_tool\n\ntool_params = {\n        \"user_location\": {\n            \"type\": \"approximate\",\n            \"country\": \"GB\",\n            \"city\": \"London\",\n            \"region\": \"London\",\n        }\n}\nweb_search_tool = get_web_search_tool(\"gpt-4o\", tool_params)\n</code></pre></p>"},{"location":"how-to/agents/provide_mcp_tools/","title":"How-To: Provide tools with Model Context Protocol (MCP)","text":"<p>The Model Context Protocol (aka MCP) is a way to provide tools and context to the LLM. From the MCP docs:</p> <p>MCP is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools.</p> <p>Ragbits has support for MCP. This enables you to use a wide range of MCP servers to provide tools to your Agents.</p>"},{"location":"how-to/agents/provide_mcp_tools/#mcp-servers","title":"MCP servers","text":"<p>Currently, the MCP spec defines three kinds of servers, based on the transport mechanism they use:</p> <ul> <li>stdio servers run as a subprocess of your application. You can think of them as running \"locally\".</li> <li>HTTP over SSE servers run remotely. You connect to them via a URL.</li> <li>Streamable HTTP servers run remotely using the Streamable HTTP transport defined in the MCP spec.</li> </ul> <p>You can use the <code>MCPServerStdio</code>, <code>MCPServerSse</code>, and <code>MCPServerStreamableHttp</code> classes to connect to these servers.</p> <p>For example, this is how you'd use the official MCP filesystem server (before running, make sure you have Node.js installed on your machine).</p> <pre><code>from ragbits.agents.mcp import MCPServerStdio\n\nasync with MCPServerStdio(\n    params={\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \".\"],\n    }\n) as server:\n    tools = await server.list_tools()\n</code></pre> <p>A complete list of working examples is available here.</p>"},{"location":"how-to/agents/provide_mcp_tools/#using-mcp-servers","title":"Using MCP servers","text":"<p>MCP servers can be added to Agents. Ragbits will call <code>list_tools()</code> on the MCP servers each time the Agent is run. This makes the LLM aware of the MCP server's tools. When the LLM calls a tool from an MCP server, Ragbits calls <code>call_tool()</code> on that server.</p> <pre><code>from ragbits.agents import Agent\nfrom ragbits.agents.mcp import MCPServerStdio\nfrom ragbits.core.llms import LiteLLM\n\nasync with MCPServerStdio(\n    params={\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \".\"],\n    }\n) as server:\n    agent = Agent(llm=LiteLLM(model_name=\"gpt-4.1-nano\"), mcp_servers=[server])\n    await agent.run(\"List all files in the current directory.\")\n</code></pre> <p>A complete example for local MCP integration is available here.</p>"},{"location":"how-to/agents/provide_mcp_tools/#caching","title":"Caching","text":"<p>Every time an Agent runs, it calls <code>list_tools()</code> on the MCP server. This can be a latency hit, especially if the server is a remote server. To automatically cache the list of tools, you can pass <code>cache_tools_list=True</code> to <code>MCPServerStdio</code>, <code>MCPServerSse</code>, and <code>MCPServerStreamableHttp</code>. You should only do this if you're certain the tool list will not change.</p> <p>If you want to invalidate the cache, you can call <code>invalidate_tools_cache()</code> on the servers.</p>"},{"location":"how-to/agents/serve_ragbits_agents/","title":"How-To: Serve Ragbits agents for A2A communication","text":"<p>Ragbits agents can be deployed as HTTP servers to enable A2A (Agent-to-Agent) communication. By exposing a FastAPI-based API, agents can receive structured requests, perform reasoning or tool-based operations, and return structured responses \u2014 enabling seamless interoperability between agents or external services.</p> <p>This guide walks through serving a Ragbits agent using FastAPI and Uvicorn, making it compliant with the A2A specification, including the discovery endpoint <code>.well-known/agent.json</code>.</p>"},{"location":"how-to/agents/serve_ragbits_agents/#define-the-agent","title":"Define the agent","text":"<p>Start by creating a simple weather agent using a structured prompt and tool function:</p> <pre><code>import json\n\nfrom pydantic import BaseModel\n\nfrom ragbits.agents import Agent\nfrom ragbits.core.llms import LiteLLM\nfrom ragbits.core.prompt import Prompt\n\n\ndef get_weather(location: str) -&gt; str:\n    \"\"\"\n    Returns the current weather for a given location.\n\n    Args:\n        location: The location to get the weather for.\n\n    Returns:\n        The current weather for the given location.\n    \"\"\"\n    if \"tokyo\" in location.lower():\n        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"})\n    elif \"san francisco\" in location.lower():\n        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n    elif \"paris\" in location.lower():\n        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"})\n    else:\n        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n\n\nclass WeatherPromptInput(BaseModel):\n    \"\"\"\n    Input format for the WeatherPrompt.\n    \"\"\"\n\n    location: str\n\n\nclass WeatherPrompt(Prompt[WeatherPromptInput]):\n    \"\"\"\n    Prompt that returns weather for a given location.\n    \"\"\"\n\n    system_prompt = \"\"\"\n    You are a helpful assistant that responds to user questions about weather.\n    \"\"\"\n\n    user_prompt = \"\"\"\n    Tell me the temperature in {{ location }}.\n\nllm = LiteLLM(model_name=\"gpt-4o-2024-08-06\" use_structured_output=True)\nagent = Agent(llm=llm, prompt=WeatherPrompt, tools=[get_weather])\n</code></pre>"},{"location":"how-to/agents/serve_ragbits_agents/#generate-the-agent-card","title":"Generate the agent card","text":"<p>The Agent Card defines the agent\u2019s name, description, and endpoint. It\u2019s automatically served at <code>/.well-known/agent.json</code> and is required for A2A discovery. You can generate the Agent Card using the <code>get_agent_card</code> method:</p> <pre><code>agent_card = await agent.get_agent_card(\n    name=\"Weather Agent\",\n    description=\"Provides current weather for a given location.\",\n    port=\"8000\",\n)\n</code></pre>"},{"location":"how-to/agents/serve_ragbits_agents/#serve-the-agent","title":"Serve the Agent","text":"<p>To serve the agent over HTTP with A2A-compliant endpoints, use the built-in <code>create_agent_server</code> utility. The agent server exposes two endpoints:</p> Endpoint Method Description <code>/.well-known/agent.json</code> <code>GET</code> Returns the agent's <code>AgentCard</code> metadata <code>/</code> <code>POST</code> Accepts a structured input <code>params: dict</code> and returns the agent's reasoning output <p>Note</p> <p>By default, the server runs on port <code>8000</code>. This can be customized by setting the <code>port</code> parameter when generating the agent card.</p> <p>To launch the agent as an A2A-compatible HTTP server, run the following code: <pre><code>import asyncio\n\nfrom ragbits.agents.a2a.server import create_agent_server\n\nasync def main():\n    server = create_agent_server(agent, agent_card, WeatherPromptInput)\n    await server.serve()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> This starts a FastAPI-based server on port <code>8000</code>, serving the agent\u2019s capabilities at the <code>.well-known/agent.json</code> discovery endpoint and handling structured <code>POST /</code> requests in compliance with the A2A specification.</p>"},{"location":"how-to/audit/use_metrics/","title":"How-To: Track metrics with Ragbits","text":"<p>Similar to traces, Ragbits also collects metrics. These metrics offer insight into system performance, resource usage, and operational health, allowing users to monitor and optimize their workflows effectively.</p>"},{"location":"how-to/audit/use_metrics/#default-metrics","title":"Default metrics","text":"<p>By default, the SDK tracks histogram metrics for LLMs:</p> <ul> <li><code>input_tokens</code>: the number of input tokens sent to the model</li> <li><code>prompt_throughput</code>: the time taken to process a prompt and receive a response</li> <li><code>token_throughput</code>: the number of tokens processed per second</li> <li><code>time_to_first_token</code>: the time taken (in seconds) to receive the first token in a streaming response</li> </ul>"},{"location":"how-to/audit/use_metrics/#supported-metric-types","title":"Supported metric types","text":"<p>Ragbits supports three types of metrics:</p> <ol> <li>Histogram metrics: For tracking the distribution of values (like durations, sizes)</li> <li>Counter metrics: For tracking counts of events (like requests, errors)</li> <li>Gauge metrics: For tracking current values that can increase or decrease (like memory usage)</li> </ol>"},{"location":"how-to/audit/use_metrics/#registering-custom-metrics","title":"Registering custom metrics","text":"<p>To register a custom metric, use the <code>register_metric</code> function:</p> <pre><code>from enum import Enum\nfrom ragbits.core.audit.metrics import register_metric\nfrom ragbits.core.audit.metrics.base import Metric, MetricType\n\n# You can define metrics as enums for type safety\nclass MyHistogramMetrics(str, Enum):\n    REQUEST_DURATION = \"request_duration\"\n\nclass MyCounterMetrics(str, Enum):\n    REQUEST_COUNT = \"request_count\"\n\n# Register a histogram metric\nregister_metric(\n    MyHistogramMetrics.REQUEST_DURATION,\n    Metric(\n        name=\"request_duration\",\n        description=\"Duration of requests in milliseconds\",\n        unit=\"ms\",\n        type=MetricType.HISTOGRAM,\n    ),\n)\n\n# Register a counter metric\nregister_metric(\n    MyCounterMetrics.REQUEST_COUNT,\n    Metric(\n        name=\"request_count\",\n        description=\"Number of requests processed\",\n        unit=\"requests\",\n        type=MetricType.COUNTER,\n    ),\n)\n</code></pre>"},{"location":"how-to/audit/use_metrics/#recording-metrics","title":"Recording metrics","text":"<p>To record metric values, use the <code>record_metric</code> function:</p> <pre><code>from ragbits.core.audit.metrics import record_metric\nfrom ragbits.core.audit.metrics.base import MetricType\n\n# Record a histogram value\nrecord_metric(\n    MyHistogramMetrics.REQUEST_DURATION,\n    150,  # 150ms duration\n    metric_type=MetricType.HISTOGRAM,\n    endpoint=\"/api/search\"  # Additional attributes\n)\n\n# Record a counter increment\nrecord_metric(\n    MyCounterMetrics.REQUEST_COUNT,\n    1,  # Increment by 1\n    metric_type=MetricType.COUNTER,\n    endpoint=\"/api/search\",\n    status_code=200\n)\n</code></pre>"},{"location":"how-to/audit/use_metrics/#using-opentelemetry-meter","title":"Using OpenTelemetry meter","text":"<p>To export metrics to the OpenTelemetry collector, configure the provider and exporter, and set up the <code>OtelMetricHandler</code> using the <code>set_metric_handlers</code> method.</p> <pre><code>from opentelemetry import metrics\nfrom opentelemetry.exporter.otlp.proto.grpc.metric_exporter import OTLPMetricExporter\nfrom opentelemetry.sdk.metrics import MeterProvider\nfrom opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader\nfrom opentelemetry.sdk.resources import SERVICE_NAME, Resource\nfrom ragbits.core.audit import set_metric_handlers\n\nresource = Resource(attributes={SERVICE_NAME: \"ragbits-example\"})\nmetric_exporter = OTLPMetricExporter(endpoint=\"http://localhost:4317\", insecure=True)\nmetric_reader = PeriodicExportingMetricReader(metric_exporter, export_interval_millis=1000)\nmetrics.set_meter_provider(MeterProvider(metric_readers=[metric_reader], resource=resource))\n\nset_metric_handlers(\"otel\")\n</code></pre> <p>Info</p> <p>This code snippet exports metrics to the local OpenTelemetry collector running at http://localhost:4317. To visualize metrics from Ragbits, open a browser and navigate to the Grafana dashboard at http://localhost:3000.</p> <p>A full example along with a detailed installation guide is available <code>here</code>.</p>"},{"location":"how-to/audit/use_metrics/#using-logfire-meter","title":"Using Logfire meter","text":"<p>To export metrics to the Logfire collector, you need to generate a write token in your Logfire project settings and set it as an environment variable.</p> <pre><code>export LOGFIRE_TOKEN=&lt;your-logfire-write-token&gt;\n</code></pre> <p>Create a new project dashboard based on the \"Basic System Metrics (Logfire)\" template. This template includes pre-configured panels for visualizing system metrics.</p> <p>Then set up the <code>LogfireMetricHandler</code> using the <code>set_metric_handlers</code> method.</p> <pre><code>from ragbits.core.audit import set_metric_handlers\n\nset_metric_handlers(\"logfire\")\n</code></pre> <p>You will find collected metrics in the dashboard you created before. A full example along with a detailed guide is available <code>here</code>.</p>"},{"location":"how-to/audit/use_tracing/","title":"How-To: Trace code execution with Ragbits","text":"<p>Each component of Ragbits includes built-in tracing, enabling users to collect detailed telemetry data without additional configuration. These traces provide visibility into execution flow, performance characteristics, and potential bottlenecks.</p>"},{"location":"how-to/audit/use_tracing/#default-tracing","title":"Default tracing","text":"<p>By default, the SDK traces the following:</p> <ul> <li>LLM generation and streaming</li> <li>Embedder calls for text and image embeddings</li> <li>Sources data fetching</li> <li>Vector Store operations - retrieve, store, remove and list</li> <li>Document Search operations - search and ingest</li> </ul>"},{"location":"how-to/audit/use_tracing/#tracing-your-own-code","title":"Tracing your own code","text":"<p>The main component of the tracing system is the trace. Traces need to be started and finished. You can create a trace in two ways:</p> <ol> <li> <p>Using the <code>trace()</code> context manager.</p> <pre><code>from ragbits.core.audit import trace\n\ndef add_numbers(a: int, b: int) -&gt; int:\n    with trace(name=\"add_numbers\", a=a, b=b) as outputs:\n        outputs.result = a + b\n    return outputs.result\n</code></pre> </li> <li> <p>Using the <code>@traceable</code> decorator.</p> <pre><code>from ragbits.core.audit import traceable\n\n@traceable\ndef add_numbers(a: int, b: int) -&gt; int:\n    return a + b\n</code></pre> </li> </ol> <p>The current trace is tracked via a Python <code>contextvar</code>. This means that it works with concurrency automatically. During runtime traces are populated to the configured trace handleres defined via <code>set_trace_handlers</code>.</p>"},{"location":"how-to/audit/use_tracing/#using-cli-tracer","title":"Using CLI tracer","text":"<p>To print traces locally in the CLI, configure <code>CLITraceHandler</code>. You can enable the CLI tracer in a few ways:</p> <ol> <li>Setting the environment variable <code>RAGBITS_VERBOSE=1</code></li> <li>Using the <code>--verbose</code> flag in the Ragbits CLI <code>uv run ragbits --verbose ...</code></li> <li>Using the <code>set_trace_handlers(\"cli\")</code> function explicitly in your script</li> </ol>"},{"location":"how-to/audit/use_tracing/#using-opentelemetry-tracer","title":"Using OpenTelemetry tracer","text":"<p>To export traces to the OpenTelemetry collector, configure the provider and exporter, and set up the <code>OtelTraceHandler</code> using the <code>set_trace_handlers</code> method.</p> <pre><code>from opentelemetry import trace\nfrom opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk.resources import SERVICE_NAME, Resource\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom ragbits.core.audit import set_trace_handlers\n\nresource = Resource(attributes={SERVICE_NAME: \"ragbits-example\"})\nspan_exporter = OTLPSpanExporter(\"http://localhost:4317\", insecure=True)\ntracer_provider = TracerProvider(resource=resource)\ntracer_provider.add_span_processor(BatchSpanProcessor(span_exporter, max_export_batch_size=1))\ntrace.set_tracer_provider(tracer_provider)\n\nset_trace_handlers(\"otel\")\n</code></pre> <p>Info</p> <p>This code snippet exports traces to the local OpenTelemetry collector running at http://localhost:4317. To visualize traces from Ragbits, open a browser and navigate to the Grafana dashboard at http://localhost:3000.</p> <p>A full example along with a detailed installation guide is available <code>here</code>.</p>"},{"location":"how-to/audit/use_tracing/#using-logfire-tracer","title":"Using Logfire tracer","text":"<p>To export traces to the Logfire collector, you need to generate a write token in your Logfire project settings and set it as an environment variable.</p> <pre><code>export LOGFIRE_TOKEN=&lt;your-logfire-write-token&gt;\n</code></pre> <p>Then set up the <code>LogfireTraceHandler</code> using the <code>set_trace_handlers</code> method.</p> <pre><code>from ragbits.core.audit import set_trace_handlers\n\nset_trace_handlers(\"logfire\")\n</code></pre> <p>You will find collected traces in the Live section of the Logfire project dashboard. A full example along with a detailed guide is available <code>here</code>.</p>"},{"location":"how-to/chatbots/api/","title":"How-To: Set up an API Server with UI for a chatbot in Ragbits","text":"<p>This guide shows you how to set up a Ragbits API server with a web UI for your chatbot application, covering all response types, customization options, and advanced features.</p>"},{"location":"how-to/chatbots/api/#quick-start","title":"Quick Start","text":""},{"location":"how-to/chatbots/api/#1-create-a-basic-chat-implementation","title":"1. Create a Basic Chat Implementation","text":"<p>First, create a chat implementation by subclassing <code>ChatInterface</code>. Here's a minimal example:</p> <pre><code>from collections.abc import AsyncGenerator\n\nfrom ragbits.chat.interface import ChatInterface\nfrom ragbits.chat.interface.types import ChatResponse\nfrom ragbits.core.prompt import ChatFormat\nfrom ragbits.core.llms import LiteLLM\n\nclass MyChat(ChatInterface):\n    def __init__(self) -&gt; None:\n        self.llm = LiteLLM(model_name=\"gpt-4o-mini\")\n\n    async def chat(\n        self,\n        message: str,\n        history: ChatFormat,\n        context: ChatContext,\n    ) -&gt; AsyncGenerator[ChatResponse, None]:\n        async for chunk in self.llm.generate_streaming([*history, {\"role\": \"user\", \"content\": message}]):\n            yield self.create_text_response(chunk)\n</code></pre> <p>Save this to a file, for example <code>chat.py</code>.</p>"},{"location":"how-to/chatbots/api/#2-start-the-user-interface","title":"2. Start the User Interface","text":"<p>Launch the API server with the built-in web UI using the Ragbits CLI:</p> <pre><code>ragbits api run path.to.your.module:MyChat\n</code></pre> <p>Note: <code>path.to.your.module</code> should be the dotted Python module path without the <code>.py</code> extension.</p> <p>The server will start on port 8000 by default. Open your browser and navigate to:</p> <pre><code>http://127.0.0.1:8000\n</code></pre> <p>You'll see the chat interface where you can interact with your chatbot immediately.</p>"},{"location":"how-to/chatbots/api/#response-types","title":"Response Types","text":"<p>Ragbits Chat supports multiple response types that can be yielded from your <code>chat</code> method to create rich, interactive experiences.</p>"},{"location":"how-to/chatbots/api/#text-responses","title":"Text Responses","text":"<p>Text responses are the primary way to stream content to users. Use <code>create_text_response()</code> to yield text chunks:</p> <pre><code>async def chat(self, message: str, history: ChatFormat, context: ChatContext) -&gt; AsyncGenerator[ChatResponse, None]:\n    # Stream response from LLM\n    async for chunk in self.llm.generate_streaming([*history, {\"role\": \"user\", \"content\": message}]):\n        yield self.create_text_response(chunk)\n</code></pre>"},{"location":"how-to/chatbots/api/#references","title":"References","text":"<p>References allow you to cite sources, documents, or external links that support your response:</p> <pre><code>async def chat(self, message: str, history: ChatFormat, context: ChatContext) -&gt; AsyncGenerator[ChatResponse, None]:\n    # Add a reference\n    yield self.create_reference(\n        title=\"Example Reference\",\n        content=\"This is an example reference document that might be relevant to your query.\",\n        url=\"https://example.com/reference1\",\n    )\n</code></pre>"},{"location":"how-to/chatbots/api/#images","title":"Images","text":"<p>You can include images in your responses using <code>create_image_response()</code>:</p> <pre><code>import uuid\n\nasync def chat(self, message: str, history: ChatFormat, context: ChatContext) -&gt; AsyncGenerator[ChatResponse, None]:\n    # Add an image to the response\n    yield self.create_image_response(\n        str(uuid.uuid4()),  # Unique identifier for the image\n        \"https://example.com/image.jpg\"  # Image URL\n    )\n</code></pre>"},{"location":"how-to/chatbots/api/#follow-up-messages","title":"Follow-up Messages","text":"<p>Provide suggested follow-up questions to guide the conversation:</p> <pre><code>async def chat(self, message: str, history: ChatFormat, context: ChatContext) -&gt; AsyncGenerator[ChatResponse, None]:\n    # Main response...\n    async for chunk in self.llm.generate_streaming([*history, {\"role\": \"user\", \"content\": message}]):\n        yield self.create_text_response(chunk)\n\n    # Add follow-up suggestions\n    yield self.create_followup_messages([\n        \"Tell me more about this topic\",\n        \"Can you provide another example?\",\n        \"How does this relate to X?\"\n    ])\n</code></pre> <p>Note: Follow-up messages will be displayed as buttons which will be sent to the server as a message after the user clicks on the button.</p>"},{"location":"how-to/chatbots/api/#live-updates","title":"Live Updates","text":"<p>Live updates show real-time progress for long-running operations (like web searches, API calls, or data processing):</p> <pre><code>import asyncio\nfrom ragbits.chat.interface.types import LiveUpdateType\n\nasync def chat(self, message: str, history: ChatFormat, context: ChatContext) -&gt; AsyncGenerator[ChatResponse, None]:\n    # Start a live update\n    yield self.create_live_update(\n        \"search_task\",  # Unique task ID\n        LiveUpdateType.START,\n        \"Searching the web for information...\"\n    )\n\n    # Simulate some work\n    await asyncio.sleep(2)\n\n    # Update the live task\n    yield self.create_live_update(\n        \"search_task\",\n        LiveUpdateType.FINISH,\n        \"Web search completed\",\n        \"Found 5 relevant results.\"  # Optional description\n    )\n\n    # You can have multiple concurrent live updates\n    yield self.create_live_update(\n        \"analysis_task\",\n        LiveUpdateType.FINISH,\n        \"Analysis completed\",\n        \"Processed 3 documents.\"\n    )\n\n    # Continue with text response...\n    async for chunk in self.llm.generate_streaming([*history, {\"role\": \"user\", \"content\": message}]):\n        yield self.create_text_response(chunk)\n</code></pre>"},{"location":"how-to/chatbots/api/#handling-file-uploads","title":"Handling File Uploads","text":"<p>Ragbits Chat supports file uploads, allowing users to send files to your chatbot. To enable this feature, implement the <code>upload_handler</code> method in your <code>ChatInterface</code> subclass.</p>"},{"location":"how-to/chatbots/api/#enable-file-uploads","title":"Enable File Uploads","text":"<p>Define an async <code>upload_handler</code> method that accepts a <code>fastapi.UploadFile</code> object:</p> <pre><code>from collections.abc import AsyncGenerator\n\nfrom fastapi import UploadFile\n\nfrom ragbits.chat.interface import ChatInterface\nfrom ragbits.chat.interface.types import ChatContext, ChatResponse\nfrom ragbits.core.prompt import ChatFormat\n\n\nclass MyChat(ChatInterface):\n    async def upload_handler(self, file: UploadFile) -&gt; None:\n        \"\"\"\n        Handle file uploads.\n\n        Args:\n            file: The uploaded file (FastAPI UploadFile)\n        \"\"\"\n        # Read the file content\n        content = await file.read()\n        filename = file.filename\n\n        # Process the file (e.g., ingest into vector store, save to disk)\n        print(f\"Received file: {filename}, size: {len(content)} bytes\")\n\n    async def chat(\n        self,\n        message: str,\n        history: ChatFormat,\n        context: ChatContext,\n    ) -&gt; AsyncGenerator[ChatResponse, None]:\n        yield self.create_text_response(f\"You said: {message}\")\n</code></pre> <p>When this method is implemented, the chat interface will automatically show an attachment icon in the input bar.</p> <p>Note: The upload handler processes the file but does not directly return a response to the chat stream. The frontend receives a success status via the <code>/api/upload</code> endpoint. If you want to acknowledge the upload in the chat, the user typically sends a follow-up message, or you can store the uploaded file reference in state for later use.</p>"},{"location":"how-to/chatbots/api/#state-management","title":"State Management","text":"<p>Ragbits Chat provides secure state management to maintain conversation context across requests. State data is automatically signed using HMAC to prevent tampering.</p>"},{"location":"how-to/chatbots/api/#storing-state","title":"Storing State","text":"<p>Use <code>create_state_update()</code> to store state information that persists across conversation turns:</p> <pre><code>from ragbits.chat.interface.types import ChatContext\nfrom ragbits.core.prompt import ChatFormat\n\nasync def chat(\n    self,\n    message: str,\n    history: ChatFormat,\n    context: ChatContext\n) -&gt; AsyncGenerator[ChatResponse, None]:\n    # Access existing state from context\n    current_state = context.state if context else {}\n\n    # Update state with new information\n    new_state = {\n        **current_state,\n        \"user_preference\": \"example_value\",\n        \"conversation_count\": current_state.get(\"conversation_count\", 0) + 1,\n        \"last_topic\": \"extracted from current message\"\n    }\n\n    # Store the updated state\n    yield self.create_state_update(new_state)\n</code></pre>"},{"location":"how-to/chatbots/api/#security-considerations","title":"Security Considerations","text":"<ul> <li>State data is automatically signed with HMAC-SHA256 to prevent client-side tampering</li> <li>The secret key is obtained from the <code>RAGBITS_SECRET_KEY</code> environment variable</li> <li>If no environment variable is set, a random key is generated (with a warning)</li> <li>For production, always set <code>RAGBITS_SECRET_KEY</code> to a strong, unique value</li> <li>State signatures are verified on each request - tampering results in a 400 error</li> </ul>"},{"location":"how-to/chatbots/api/#user-interface-configuration","title":"User Interface Configuration","text":""},{"location":"how-to/chatbots/api/#configure-user-forms","title":"Configure User Forms","text":"<p>Ragbits Chat supports two types of user forms: feedback forms and user settings forms.</p>"},{"location":"how-to/chatbots/api/#feedback-forms","title":"Feedback Forms","text":"<p>Configure feedback forms to collect user ratings and comments:</p> <pre><code>from typing import Literal\nfrom pydantic import BaseModel, ConfigDict, Field\nfrom ragbits.chat.interface.forms import FeedbackConfig\n\nclass LikeFormExample(BaseModel):\n    \"\"\"Form shown when user likes a response.\"\"\"\n    model_config = ConfigDict(\n        title=\"Like Form\",\n        json_schema_serialization_defaults_required=True,\n    )\n\n    like_reason: str = Field(\n        description=\"Why do you like this response?\",\n        min_length=1,\n    )\n\nclass DislikeFormExample(BaseModel):\n    \"\"\"Form shown when user dislikes a response.\"\"\"\n    model_config = ConfigDict(\n        title=\"Dislike Form\",\n        json_schema_serialization_defaults_required=True\n    )\n\n    issue_type: Literal[\"Incorrect information\", \"Not helpful\", \"Unclear\", \"Other\"] = Field(\n        description=\"What was the issue?\"\n    )\n    feedback: str = Field(\n        description=\"Please provide more details\",\n        min_length=1\n    )\n\nclass MyChat(ChatInterface):\n    feedback_config = FeedbackConfig(\n        like_enabled=True,\n        like_form=LikeFormExample,\n        dislike_enabled=True,\n        dislike_form=DislikeFormExample,\n    )\n\n    # ... rest of your implementation\n</code></pre>"},{"location":"how-to/chatbots/api/#user-settings-forms","title":"User Settings Forms","text":"<p>Configure user settings forms to collect user preferences:</p> <pre><code>from ragbits.chat.interface.forms import UserSettings\n\nclass UserSettingsFormExample(BaseModel):\n    \"\"\"Form for user preferences and settings.\"\"\"\n    model_config = ConfigDict(\n        title=\"User Settings\",\n        json_schema_serialization_defaults_required=True\n    )\n\n    language: Literal[\"English\", \"Spanish\", \"French\", \"German\"] = Field(\n        description=\"Preferred language\",\n        default=\"English\"\n    )\n\n    response_style: Literal[\"Concise\", \"Detailed\", \"Technical\"] = Field(\n        description=\"How would you like responses formatted?\",\n        default=\"Detailed\"\n    )\n\nclass MyChat(ChatInterface):\n    user_settings = UserSettings(form=UserSettingsFormExample)\n\n    # ... rest of your implementation\n</code></pre>"},{"location":"how-to/chatbots/api/#customize-ui-appearance","title":"Customize UI Appearance","text":"<p>Configure the chat interface appearance with custom icons, headers, and messages:</p> <pre><code>from ragbits.chat.interface.ui_customization import (\n    UICustomization,\n    HeaderCustomization,\n    PageMetaCustomization\n)\n\nclass MyChat(ChatInterface):\n    ui_customization = UICustomization(\n        # Header customization\n        header=HeaderCustomization(\n            title=\"My AI Assistant\",\n            subtitle=\"Powered by Ragbits\",\n            logo=\"\ud83e\udd16\"\n        ),\n\n        # Welcome message shown when chat starts\n        welcome_message=(\n            \"Hello! I'm your AI assistant.\\n\\n\"\n            \"How can I help you today? You can ask me **anything**! \"\n            \"I can provide information, answer questions, and assist with various tasks.\"\n        ),\n\n        # Page metadata\n        meta=PageMetaCustomization(\n            favicon=\"\ud83e\udd16\",\n            page_title=\"My AI Assistant\"\n        )\n    )\n\n    # ... rest of your implementation\n</code></pre>"},{"location":"how-to/chatbots/api/#enable-conversation-history","title":"Enable Conversation History","text":"<p>To enable conversation history persistence across sessions, set the <code>conversation_history</code> attribute:</p> <pre><code>class MyChat(ChatInterface):\n    conversation_history = True  # Enable conversation history\n\n    # ... rest of your implementation\n</code></pre> <p>When enabled, the chat interface will automatically maintain conversation history and show it in side panel.</p>"},{"location":"how-to/chatbots/api/#api-endpoints","title":"API Endpoints","text":"<p>The API server exposes the following endpoints:</p> <ul> <li><code>GET /</code>: Serves the web UI</li> <li><code>GET /api/config</code>: Returns UI configuration including feedback forms</li> <li><code>POST /api/chat</code>: Accepts chat messages and returns streaming responses</li> <li><code>POST /api/feedback</code>: Accepts feedback from the user</li> <li><code>POST /api/upload</code>: Accepts file uploads (only available when <code>upload_handler</code> is implemented)</li> </ul>"},{"location":"how-to/chatbots/api/#server-configuration","title":"Server Configuration","text":""},{"location":"how-to/chatbots/api/#launch-the-api-server","title":"Launch the API Server","text":"<p>You can start the API server using the Ragbits CLI:</p> <pre><code>ragbits api run path.to.your.module:MyChat\n</code></pre> <p>Note: <code>path.to.your.module</code> should be the dotted Python module path without the <code>.py</code> extension.</p>"},{"location":"how-to/chatbots/api/#custom-ui","title":"Custom UI","text":"<p>To use a custom UI build, use the <code>--ui-build-dir</code> option:</p> <pre><code>ragbits api run path.to.your.module:MyChat --ui-build-dir /path/to/your/ui/build\n</code></pre>"},{"location":"how-to/chatbots/api/#cors-configuration","title":"CORS Configuration","text":"<p>To allow cross-origin requests, use the <code>--cors-origin</code> option (can be specified multiple times):</p> <pre><code>ragbits api run path.to.your.module:MyChat --cors-origin http://localhost:3000 --cors-origin https://your-domain.com\n</code></pre>"},{"location":"how-to/chatbots/api/#custom-host-and-port","title":"Custom Host and Port","text":"<p>To run on a different host or port:</p> <pre><code>ragbits api run path.to.your.module:MyChat --host 0.0.0.0 --port 9000\n</code></pre>"},{"location":"how-to/chatbots/api/#enable-debug-mode","title":"Enable Debug Mode","text":"<p>To enable debug mode for detailed logging and error information, use the <code>--debug</code> flag. It will enable button in UI to toggle debug side panel which will show you all the internal state of the chat:</p> <pre><code>ragbits api run path.to.your.module:MyChat --debug\n</code></pre>"},{"location":"how-to/chatbots/api/#complete-example","title":"Complete Example","text":"<p>Here's a comprehensive example demonstrating all features of a Ragbits Chat implementation:</p> <pre><code>import asyncio\nimport uuid\nfrom collections.abc import AsyncGenerator\nfrom typing import Literal\n\nfrom pydantic import BaseModel, ConfigDict, Field\n\nfrom ragbits.chat.interface import ChatInterface\nfrom ragbits.chat.interface.forms import FeedbackConfig, UserSettings\nfrom ragbits.chat.interface.types import ChatContext, ChatResponse, LiveUpdateType\nfrom ragbits.core.prompt import ChatFormat\nfrom ragbits.chat.interface.ui_customization import HeaderCustomization, PageMetaCustomization, UICustomization\nfrom ragbits.core.llms import LiteLLM\n\n\nclass LikeFormExample(BaseModel):\n    \"\"\"Form shown when user likes a response.\"\"\"\n    model_config = ConfigDict(\n        title=\"Like Form\",\n        json_schema_serialization_defaults_required=True,\n    )\n\n    like_reason: str = Field(\n        description=\"Why do you like this response?\",\n        min_length=1,\n    )\n\n\nclass DislikeFormExample(BaseModel):\n    \"\"\"Form shown when user dislikes a response.\"\"\"\n    model_config = ConfigDict(\n        title=\"Dislike Form\",\n        json_schema_serialization_defaults_required=True\n    )\n\n    issue_type: Literal[\"Incorrect information\", \"Not helpful\", \"Unclear\", \"Other\"] = Field(\n        description=\"What was the issue?\"\n    )\n    feedback: str = Field(\n        description=\"Please provide more details\",\n        min_length=1\n    )\n\n\nclass UserSettingsFormExample(BaseModel):\n    \"\"\"Form for user preferences and settings.\"\"\"\n    model_config = ConfigDict(\n        title=\"User Settings\",\n        json_schema_serialization_defaults_required=True\n    )\n\n    language: Literal[\"English\", \"Spanish\", \"French\"] = Field(\n        description=\"Preferred language\",\n        default=\"English\"\n    )\n\n    response_style: Literal[\"Concise\", \"Detailed\", \"Technical\"] = Field(\n        description=\"Response style preference\",\n        default=\"Detailed\"\n    )\n\n\nclass MyChat(ChatInterface):\n    \"\"\"A comprehensive example implementation of the ChatInterface with all features.\"\"\"\n\n    # Configure feedback forms\n    feedback_config = FeedbackConfig(\n        like_enabled=True,\n        like_form=LikeFormExample,\n        dislike_enabled=True,\n        dislike_form=DislikeFormExample,\n    )\n\n    # Configure user settings\n    user_settings = UserSettings(form=UserSettingsFormExample)\n\n    # Customize UI appearance\n    ui_customization = UICustomization(\n        header=HeaderCustomization(\n            title=\"My AI Assistant\",\n            subtitle=\"Powered by Ragbits\",\n            logo=\"\ud83e\udd16\"\n        ),\n        welcome_message=(\n            \"Hello! I'm your AI assistant.\\n\\n\"\n            \"How can I help you today? You can ask me **anything**! \"\n            \"I can provide information, answer questions, and assist with various tasks.\"\n        ),\n        meta=PageMetaCustomization(\n            favicon=\"\ud83e\udd16\",\n            page_title=\"My AI Assistant\"\n        ),\n    )\n\n    # Enable conversation history\n    conversation_history = True\n\n    def __init__(self) -&gt; None:\n        self.llm = LiteLLM(model_name=\"gpt-4o-mini\")\n\n    async def chat(\n        self,\n        message: str,\n        history: ChatFormat,\n        context: ChatContext,\n    ) -&gt; AsyncGenerator[ChatResponse, None]:\n        \"\"\"\n        Comprehensive chat implementation demonstrating all response types.\n\n        Args:\n            message: The current user message\n            history: Optional list of previous messages in the conversation\n            context: Optional context including state and user settings\n\n        Yields:\n            ChatResponse objects with various content types\n        \"\"\"\n        # Access and update state\n        current_state = context.state if context else {}\n        conversation_count = current_state.get(\"conversation_count\", 0) + 1\n\n        updated_state = {\n            **current_state,\n            \"conversation_count\": conversation_count,\n            \"last_message_length\": len(message),\n            \"user_preference\": \"example_value\"\n        }\n\n        yield self.create_state_update(updated_state)\n\n        # Add reference documents\n        yield self.create_reference(\n            title=\"Example Reference Document\",\n            content=\"This is an example reference that might be relevant to your query.\",\n            url=\"https://example.com/reference1\",\n        )\n\n        # Add an example image\n        yield self.create_image_response(\n            str(uuid.uuid4()),\n            \"https://picsum.photos/400/300\"\n        )\n\n        # Demonstrate live updates for long-running operations\n        example_live_updates = [\n            self.create_live_update(\n                \"search_task\",\n                LiveUpdateType.START,\n                \"Searching for information...\"\n            ),\n            self.create_live_update(\n                \"search_task\",\n                LiveUpdateType.FINISH,\n                \"Search completed\",\n                f\"Found {conversation_count * 3} relevant results.\"\n            ),\n            self.create_live_update(\n                \"analysis_task\",\n                LiveUpdateType.FINISH,\n                \"Analysis completed\",\n                \"Processed and analyzed the search results.\"\n            ),\n        ]\n\n        for live_update in example_live_updates:\n            yield live_update\n            await asyncio.sleep(1)  # Simulate processing time\n\n        # Personalize response based on conversation count\n        if conversation_count == 1:\n            intro_text = \"Welcome! This is our first conversation. \"\n        elif conversation_count &gt; 5:\n            intro_text = f\"We've been chatting quite a bit ({conversation_count} messages)! \"\n        else:\n            intro_text = \"\"\n\n        # Stream the main response from the LLM\n        full_prompt = [\n            *history,\n            {\"role\": \"user\", \"content\": f\"{intro_text}{message}\"}\n        ]\n\n        async for chunk in self.llm.generate_streaming(full_prompt):\n            yield self.create_text_response(chunk)\n\n        # Add follow-up suggestions\n        yield self.create_followup_messages([\n            \"Tell me more about this topic\",\n            \"Can you provide another example?\",\n            \"How does this relate to other concepts?\"\n        ])\n</code></pre> <p>Save this as <code>my_chat.py</code> and run it with:</p> <pre><code>ragbits api run my_chat:MyChat --debug\n</code></pre> <p>Then open http://127.0.0.1:8000 in your browser to see your fully-featured chat interface!</p>"},{"location":"how-to/chatbots/extending-ui/","title":"How-To: Extend and Customize the Ragbits Chat UI","text":"<p>This guide covers advanced customization of the Ragbits Chat UI, including using decoupled components, creating plugins, and customizing the store implementation.</p>"},{"location":"how-to/chatbots/extending-ui/#using-decoupled-components-in-your-project","title":"Using Decoupled Components in Your Project","text":"<p>The UI components are designed to be decoupled and reusable in external projects. This section explains how to integrate them into a new application.</p>"},{"location":"how-to/chatbots/extending-ui/#required-packages","title":"Required Packages","text":"<p>Copy the dependencies from the project's <code>package.json</code>. The key packages are:</p> <p>UI &amp; Styling:</p> <pre><code>{\n  \"@heroui/react\": \"^2.8.1\",\n  \"@heroicons/react\": \"^2.2.0\",\n  \"framer-motion\": \"^12.23.6\",\n  \"tailwindcss\": \"^4.1.11\",\n  \"@tailwindcss/postcss\": \"^4.1.11\",\n  \"@tailwindcss/vite\": \"^4.1.11\",\n  \"@tailwindcss/typography\": \"^0.5.16\"\n}\n</code></pre> <p>Core Dependencies:</p> <pre><code>{\n  \"@ragbits/api-client-react\": \"*\",\n  \"react\": \"^18.3.1\",\n  \"react-dom\": \"^18.3.1\",\n  \"react-router\": \"^7.7.1\",\n  \"zustand\": \"^5.0.6\",\n  \"immer\": \"^10.1.1\",\n  \"uuid\": \"^11.1.0\"\n}\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#provider-hierarchy","title":"Provider Hierarchy","text":"<p>Set up your application with the following provider structure:</p> <pre><code>import { StrictMode } from \"react\";\nimport { HeroUIProvider } from \"@heroui/react\";\nimport { RagbitsContextProvider } from \"@ragbits/api-client-react\";\nimport { ThemeContextProvider } from \"./core/contexts/ThemeContext/ThemeContextProvider\";\nimport HistoryStoreContextProvider from \"./core/stores/HistoryStore/HistoryStoreContextProvider\";\nimport App from \"./App\";\n\nconst API_URL = \"https://your-api.com\";\n\ncreateRoot(document.getElementById(\"root\")!).render(\n  &lt;StrictMode&gt;\n    &lt;HeroUIProvider&gt;\n      &lt;RagbitsContextProvider baseUrl={API_URL}&gt;\n        &lt;ThemeContextProvider&gt;\n          &lt;HistoryStoreContextProvider&gt;\n            &lt;div className=\"bg-background flex h-screen w-screen items-start justify-center\"&gt;\n              &lt;div className=\"h-full w-full max-w-full\"&gt;\n                &lt;App /&gt;\n              &lt;/div&gt;\n            &lt;/div&gt;\n          &lt;/HistoryStoreContextProvider&gt;\n        &lt;/ThemeContextProvider&gt;\n      &lt;/RagbitsContextProvider&gt;\n    &lt;/HeroUIProvider&gt;\n  &lt;/StrictMode&gt;,\n);\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#provider-descriptions","title":"Provider Descriptions","text":"Provider Purpose <code>HeroUIProvider</code> HeroUI component library context for theming and accessibility <code>RagbitsContextProvider</code> Provides the Ragbits API client with the configured base URL <code>ThemeContextProvider</code> Manages light/dark theme switching with localStorage persistence <code>HistoryStoreContextProvider</code> Manages chat history and conversation state"},{"location":"how-to/chatbots/extending-ui/#setting-up-styles","title":"Setting Up Styles","text":""},{"location":"how-to/chatbots/extending-ui/#1-copy-globalscss","title":"1. Copy <code>globals.css</code>","text":"<p>Copy the <code>src/globals.css</code> file to your project and import it in your entry point:</p> <pre><code>@import \"tailwindcss\";\n@plugin \"@tailwindcss/typography\";\n@plugin \"../hero.ts\";\n\n/* NOTE: Update this path based on your project structure */\n@source \"../../../node_modules/@heroui/theme/dist/**/*.{js,ts,jsx,tsx}\";\n@custom-variant dark (&amp;:is(.dark *));\n\n@theme {\n  --breakpoint-xs: 28rem;\n  --animate-pop-in: pop-in 0.2s ease-out forwards;\n\n  @keyframes pop-in {\n    0% {\n      transform: scale(0.8);\n      opacity: 0;\n    }\n    100% {\n      transform: scale(1);\n      opacity: 1;\n    }\n  }\n}\n\n.markdown-container code::before,\n.markdown-container code::after {\n  content: none;\n}\n\n.prose {\n  overflow-wrap: break-word;\n}\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#2-update-heroui-theme-path","title":"2. Update HeroUI Theme Path","text":"<p>The <code>@source</code> directive path may need to be updated based on your project structure:</p> <pre><code>/* Original path (for this project's structure) */\n@source \"../../../node_modules/@heroui/theme/dist/**/*.{js,ts,jsx,tsx}\";\n\n/* Example: If globals.css is in src/ */\n@source \"../node_modules/@heroui/theme/dist/**/*.{js,ts,jsx,tsx}\";\n\n/* Example: If globals.css is in src/styles/ */\n@source \"../../node_modules/@heroui/theme/dist/**/*.{js,ts,jsx,tsx}\";\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#3-copy-heroui-plugin","title":"3. Copy HeroUI Plugin","text":"<p>Copy the <code>hero.ts</code> file to your project root (or update the <code>@plugin</code> path in <code>globals.css</code>):</p> <pre><code>// hero.ts\nimport { heroui } from \"@heroui/react\";\nexport default heroui();\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#store-customization","title":"Store Customization","text":"<p>The <code>HistoryStoreContextProvider</code> accepts a <code>storeInitializer</code> prop for dependency injection, allowing you to customize the store behavior.</p>"},{"location":"how-to/chatbots/extending-ui/#using-the-storeinitializer-prop","title":"Using the <code>storeInitializer</code> Prop","text":"<pre><code>import HistoryStoreContextProvider from \"./core/stores/HistoryStore/HistoryStoreContextProvider\";\nimport { createStore } from \"zustand\";\nimport { immer } from \"zustand/middleware/immer\";\n\n// Create a custom store initializer\nconst createCustomHistoryStore = immer((set, get) =&gt; ({\n  // ... your custom store implementation\n  conversations: {},\n  currentConversation: \"default\",\n\n  actions: {\n    sendMessage: async (text, ragbitsClient) =&gt; {\n      // Custom message handling logic\n      const response = await myCustomAPI.chat(text);\n      // Update state...\n    },\n    newConversation: () =&gt; {\n      // Custom conversation creation\n    },\n    // ... other actions\n  },\n\n  primitives: {\n    getCurrentConversation: () =&gt;\n      get().conversations[get().currentConversation],\n    addMessage: (conversationId, message) =&gt; {\n      // Add message to conversation\n    },\n    // ... other primitives\n  },\n\n  _internal: {\n    _hasHydrated: true,\n    _setHasHydrated: () =&gt; {},\n    handleResponse: () =&gt; {},\n  },\n}));\n\n// Use your custom initializer\n&lt;HistoryStoreContextProvider storeInitializer={createCustomHistoryStore}&gt;\n  &lt;App /&gt;\n&lt;/HistoryStoreContextProvider&gt;;\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#store-initializer-interface","title":"Store Initializer Interface","text":"<p>The store must implement the <code>HistoryStore</code> interface:</p> <pre><code>interface HistoryStore {\n  conversations: Record&lt;string, Conversation&gt;;\n  currentConversation: string;\n\n  computed: {\n    getContext: () =&gt; Record&lt;string, unknown&gt;;\n  };\n\n  actions: {\n    newConversation: () =&gt; string;\n    selectConversation: (conversationId: string) =&gt; void;\n    deleteConversation: (conversationId: string) =&gt; void;\n    sendMessage: (\n      text: string,\n      ragbitsClient: RagbitsClient,\n      additionalContext?: Record&lt;string, unknown&gt;,\n    ) =&gt; void;\n    stopAnswering: () =&gt; void;\n    // ... other actions\n  };\n\n  primitives: {\n    addMessage: (\n      conversationId: string,\n      message: Omit&lt;ChatMessage, \"id\"&gt;,\n    ) =&gt; string;\n    deleteMessage: (conversationId: string, messageId: string) =&gt; void;\n    getCurrentConversation: () =&gt; Conversation;\n    // ... other primitives\n  };\n\n  _internal: {\n    _hasHydrated: boolean;\n    _setHasHydrated: (state: boolean) =&gt; void;\n    handleResponse: (conversationIdRef, messageId, response) =&gt; void;\n  };\n}\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#waiting-for-hydration","title":"Waiting for Hydration","text":"<p>If your store needs async initialization (e.g., loading from IndexedDB), use the <code>waitForHydration</code> prop:</p> <pre><code>&lt;HistoryStoreContextProvider\n  storeInitializer={createPersistentStore}\n  waitForHydration={true}\n&gt;\n  {/* App will show loading screen until store is hydrated */}\n  &lt;App /&gt;\n&lt;/HistoryStoreContextProvider&gt;\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#minimal-setup-without-custom-store","title":"Minimal Setup (Without Custom Store)","text":"<p>For basic usage, <code>HistoryStoreContextProvider</code> provides a minimal in-memory store by default:</p> <pre><code>&lt;HistoryStoreContextProvider&gt;\n  {/* Uses built-in minimal store */}\n  &lt;App /&gt;\n&lt;/HistoryStoreContextProvider&gt;\n</code></pre> <p>This minimal store:</p> <ul> <li>Stores conversations in memory only (no persistence)</li> <li>Provides basic conversation management</li> <li>Does not make API calls (you need to handle that separately)</li> </ul>"},{"location":"how-to/chatbots/extending-ui/#using-history-store-hooks","title":"Using History Store Hooks","text":"<p>Access the store in your components:</p> <pre><code>import { useHistoryStore, useHistoryActions } from \"./core/stores/HistoryStore/selectors\";\n\nfunction ChatComponent() {\n  // Get actions\n  const { sendMessage, newConversation, stopAnswering } = useHistoryActions();\n\n  // Get current conversation messages\n  const messages = useHistoryStore((s) =&gt;\n    Object.values(s.primitives.getCurrentConversation().history)\n  );\n\n  // Get specific state\n  const currentConversationId = useHistoryStore((s) =&gt; s.currentConversation);\n\n  return (\n    &lt;div&gt;\n      {messages.map((msg) =&gt; (\n        &lt;Message key={msg.id} message={msg} /&gt;\n      ))}\n      &lt;button onClick={() =&gt; sendMessage(\"Hello!\", ragbitsClient)}&gt;\n        Send\n      &lt;/button&gt;\n    &lt;/div&gt;\n  );\n}\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#plugin-system","title":"Plugin System","text":"<p>The UI supports a powerful plugin architecture for extending functionality. Plugins can inject components into predefined UI slots, add routes, wrap existing routes, and run lifecycle hooks.</p>"},{"location":"how-to/chatbots/extending-ui/#plugin-architecture-overview","title":"Plugin Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     Plugin Registration                      \u2502\n\u2502         pluginManager.register(myPlugin)                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  Plugin Activation                           \u2502\n\u2502         pluginManager.activate(pluginName)                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u25bc              \u25bc              \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502 Register    \u2502 \u2502 Inject     \u2502 \u2502 Call         \u2502\n  \u2502 Slots       \u2502 \u2502 Routes     \u2502 \u2502 onActivate   \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#creating-a-plugin","title":"Creating a Plugin","text":"<p>Use the <code>createPlugin</code> helper function to define a type-safe plugin:</p> <pre><code>// src/plugins/MyPlugin/index.tsx\nimport { lazy } from \"react\";\nimport { createPlugin } from \"../../core/utils/plugins/utils\";\n\n// Lazy-load components for code splitting\nconst MyButton = lazy(() =&gt; import(\"./components/MyButton\"));\nconst MyPanel = lazy(() =&gt; import(\"./components/MyPanel\"));\n\nexport const MyPluginName = \"MyPlugin\";\n\nexport const MyPlugin = createPlugin({\n  name: MyPluginName,\n\n  // Components available for use with PluginWrapper\n  components: {\n    MyButton,\n    MyPanel,\n  },\n\n  // Lifecycle hooks\n  onActivate: () =&gt; {\n    console.log(\"MyPlugin activated\");\n  },\n  onDeactivate: () =&gt; {\n    console.log(\"MyPlugin deactivated\");\n  },\n\n  // UI slot attachments\n  slots: [\n    {\n      slot: \"layout.headerActions\",\n      component: MyButton,\n      priority: 5, // Higher priority = rendered first\n      condition: () =&gt; true, // Optional: dynamic visibility\n    },\n  ],\n\n  // Route definitions\n  routes: [\n    {\n      path: \"/my-feature\",\n      element: &lt;MyFeatureRoute /&gt;,\n    },\n  ],\n\n  // Route wrappers\n  routeWrappers: [\n    {\n      target: \"/\", // Or \"global\" for all routes\n      wrapper: (children) =&gt; &lt;MyWrapper&gt;{children}&lt;/MyWrapper&gt;,\n    },\n  ],\n\n  // Custom metadata\n  metadata: {\n    version: \"1.0.0\",\n    author: \"Your Name\",\n  },\n});\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#plugin-interface","title":"Plugin Interface","text":"<pre><code>interface Plugin&lt;T&gt; {\n  name: string;\n  components: T; // Record of lazy-loaded components\n  onActivate?: () =&gt; void;\n  onDeactivate?: () =&gt; void;\n  routes?: PluginRoute[];\n  routeWrappers?: PluginRouteWrapper[];\n  slots?: PluginSlot[];\n  metadata?: Record&lt;string, unknown&gt;;\n}\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#defining-and-using-slots","title":"Defining and Using Slots","text":"<p>Slots are predefined UI extension points where plugins can inject components.</p>"},{"location":"how-to/chatbots/extending-ui/#available-slots","title":"Available Slots","text":"Slot Name Location Props <code>layout.sidebar</code> Left sidebar area None <code>layout.headerActions</code> Header action buttons None <code>message.actions</code> Per-message action buttons <code>{ message, content, serverId }</code> <code>prompt.beforeSend</code> Before the prompt input None"},{"location":"how-to/chatbots/extending-ui/#attaching-to-slots","title":"Attaching to Slots","text":"<pre><code>// In your plugin definition\nslots: [\n  {\n    slot: \"message.actions\",\n    component: FeedbackButton,\n    priority: 10, // Higher = rendered first\n    condition: () =&gt; isFeatureEnabled(), // Optional\n  },\n];\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#creating-slot-components","title":"Creating Slot Components","text":"<p>Components attached to slots receive props based on the slot type:</p> <pre><code>// For message.actions slot\ninterface MessageActionsProps {\n  message: ChatMessage;\n  content: string;\n  serverId?: string;\n}\n\nconst FeedbackButton: FC&lt;MessageActionsProps&gt; = ({ message, content }) =&gt; {\n  return &lt;Button onClick={() =&gt; submitFeedback(message.id)}&gt;Feedback&lt;/Button&gt;;\n};\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#rendering-slots-in-components","title":"Rendering Slots in Components","text":"<p>Use the <code>&lt;Slot&gt;</code> component to render plugin content:</p> <pre><code>import { Slot } from \"../core/components/Slot\";\n\nfunction MessageActions({ message, content }: Props) {\n  return (\n    &lt;div className=\"flex gap-2\"&gt;\n      &lt;Slot\n        name=\"message.actions\"\n        props={{ message, content }}\n        fallback={&lt;span&gt;No actions&lt;/span&gt;}\n        skeletonSize={{ width: \"32px\", height: \"32px\" }}\n      /&gt;\n    &lt;/div&gt;\n  );\n}\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#checking-if-slot-has-content","title":"Checking if Slot Has Content","text":"<pre><code>import { useSlotHasFillers } from \"../core/utils/slots/useSlotHasFillers\";\n\nfunction Sidebar() {\n  const hasSidebarContent = useSlotHasFillers(\"layout.sidebar\");\n\n  if (!hasSidebarContent) {\n    return null;\n  }\n\n  return (\n    &lt;aside&gt;\n      &lt;Slot name=\"layout.sidebar\" /&gt;\n    &lt;/aside&gt;\n  );\n}\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#using-pluginwrapper","title":"Using PluginWrapper","text":"<p><code>PluginWrapper</code> provides type-safe rendering of plugin components with automatic lazy loading and skeleton fallbacks:</p> <pre><code>import { PluginWrapper } from \"../core/utils/plugins/PluginWrapper\";\nimport { MyPlugin } from \"../plugins/MyPlugin\";\n\nfunction SomeComponent() {\n  return (\n    &lt;PluginWrapper\n      plugin={MyPlugin}\n      component=\"MyButton\"\n      componentProps={{ onClick: handleClick }}\n      skeletonSize={{ width: \"100px\", height: \"40px\" }}\n    /&gt;\n  );\n}\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#pluginwrapper-props","title":"PluginWrapper Props","text":"Prop Type Description <code>plugin</code> <code>Plugin</code> The plugin instance <code>component</code> <code>keyof plugin.components</code> Component name to render <code>componentProps</code> <code>ComponentProps</code> Props to pass to the component <code>skeletonSize</code> <code>{ width, height }</code> Skeleton size during loading <code>disableSkeleton</code> <code>boolean</code> Disable loading skeleton"},{"location":"how-to/chatbots/extending-ui/#route-definitions","title":"Route Definitions","text":"<p>Plugins can add new routes or inject routes into existing route trees.</p>"},{"location":"how-to/chatbots/extending-ui/#adding-top-level-routes","title":"Adding Top-Level Routes","text":"<pre><code>routes: [\n  {\n    path: \"/login\",\n    element: &lt;LoginPage /&gt;,\n  },\n]\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#injecting-nested-routes","title":"Injecting Nested Routes","text":"<pre><code>routes: [\n  {\n    target: \"/\", // Parent route to inject into\n    path: \"conversation/:conversationId\",\n    element: &lt;ConversationPage /&gt;,\n  },\n]\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#route-wrappers","title":"Route Wrappers","text":"<p>Wrap existing routes with HOCs for authentication, guards, etc:</p> <pre><code>routeWrappers: [\n  // Wrap a specific route\n  {\n    target: \"/\",\n    wrapper: (children) =&gt; &lt;AuthGuard&gt;{children}&lt;/AuthGuard&gt;,\n  },\n  // Wrap all routes globally\n  {\n    target: \"global\",\n    wrapper: (children) =&gt; &lt;ErrorBoundary&gt;{children}&lt;/ErrorBoundary&gt;,\n  },\n]\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#registering-and-activating-plugins","title":"Registering and Activating Plugins","text":""},{"location":"how-to/chatbots/extending-ui/#static-registration-in-maintsx","title":"Static Registration (in main.tsx)","text":"<pre><code>import { pluginManager } from \"./core/utils/plugins/PluginManager\";\nimport { MyPlugin } from \"./plugins/MyPlugin\";\n\n// Register plugins before rendering\npluginManager.register(MyPlugin);\n\n// Activate immediately or conditionally\npluginManager.activate(MyPlugin.name);\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#dynamic-activation-based-on-config","title":"Dynamic Activation (based on config)","text":"<pre><code>// In a component or hook\nimport { pluginManager } from \"./core/utils/plugins/PluginManager\";\n\nfunction usePluginActivation() {\n  const { config } = useConfigContext();\n\n  useEffect(() =&gt; {\n    if (config.myFeatureEnabled) {\n      pluginManager.activate(MyPluginName);\n    }\n  }, [config]);\n}\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#dynamic-plugin-creation","title":"Dynamic Plugin Creation","text":"<pre><code>// Factory function for dynamic plugins\nexport const createOAuth2LoginPlugin = (\n  provider: string,\n  displayName: string,\n) =&gt; {\n  return createPlugin({\n    name: `OAuth2Login_${provider}`,\n    components: {\n      OAuth2Login: lazy(() =&gt; import(\"./components/OAuth2Login\")),\n    },\n    metadata: { provider, displayName },\n  });\n};\n\n// Usage\nconst googlePlugin = createOAuth2LoginPlugin(\"google\", \"Google\");\npluginManager.register(googlePlugin);\npluginManager.activate(googlePlugin.name);\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#react-hooks-for-plugins","title":"React Hooks for Plugins","text":"<pre><code>// Get a specific plugin\nimport { usePlugin } from \"./core/utils/plugins/usePlugin\";\nconst myPlugin = usePlugin(\"MyPlugin\");\n\n// Get all active plugins\nimport { useActivePlugins } from \"./core/utils/plugins/useActivePlugins\";\nconst activePlugins = useActivePlugins();\n\n// Check if slot has content\nimport { useSlotHasFillers } from \"./core/utils/slots/useSlotHasFillers\";\nconst hasHeaderActions = useSlotHasFillers(\"layout.headerActions\");\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#example-plugin-structure","title":"Example Plugin Structure","text":"<pre><code>plugins/\n\u2514\u2500\u2500 MyPlugin/\n    \u251c\u2500\u2500 index.tsx          # Plugin entry point with createPlugin\n    \u251c\u2500\u2500 components/\n    \u2502   \u251c\u2500\u2500 MyButton.tsx   # Lazy-loaded component\n    \u2502   \u2514\u2500\u2500 MyPanel.tsx    # Lazy-loaded component\n    \u2514\u2500\u2500 types.ts           # Plugin-specific types\n</code></pre>"},{"location":"how-to/chatbots/extending-ui/#what-works-in-standalone-mode","title":"What Works in Standalone Mode","text":"<ul> <li>Chat input and message display</li> <li>Theme switching (light/dark)</li> <li>Basic conversation flow</li> <li>Custom store implementations</li> <li>Core UI components</li> </ul>"},{"location":"how-to/chatbots/extending-ui/#what-requires-additional-setup","title":"What Requires Additional Setup","text":"<ul> <li>Plugins: Need explicit registration and activation</li> <li>Conversation persistence: Requires custom store with IndexedDB</li> <li>Config-based customization: Requires <code>ConfigContextProvider</code></li> <li>Authentication: Requires <code>AuthPlugin</code> activation</li> </ul>"},{"location":"how-to/document_search/ingest-documents/","title":"How-To: Ingest Documents","text":"<p>The Ragbits document ingest pipeline consists of four main steps: loading, parsing, enrichment, and indexing. All of these steps can be orchestrated using different strategies, depending on the expected load.</p>"},{"location":"how-to/document_search/ingest-documents/#loading-dataset","title":"Loading dataset","text":"<p>Before processing a document in Ragbits, it must first be defined and downloaded. This can be done in several ways: by specifying a source URI or using an instance of <code>Source</code>, <code>DocumentMeta</code> or <code>Document</code>.</p> URISourceMetadataDocument <pre><code>from ragbits.document_search import DocumentSearch\n\ndocument_search = DocumentSearch(...)\n\nawait document_search.ingest(\"s3://\")\n</code></pre> <pre><code>from ragbits.core.sources import WebSource\nfrom ragbits.document_search import DocumentSearch\n\ndocument_search = DocumentSearch(...)\n\nawait document_search.ingest([WebSource(...), ...])\n</code></pre> <pre><code>from ragbits.document_search.documents.document import DocumentMeta\nfrom ragbits.document_search import DocumentSearch\n\ndocument_search = DocumentSearch(...)\n\nawait document_search.ingest([DocumentMeta.from_local_path(...), ...])\n</code></pre> <pre><code>from ragbits.document_search.documents.document import Document\nfrom ragbits.document_search import DocumentSearch\n\ndocument_search = DocumentSearch(...)\n\nawait document_search.ingest([Document(...), ...])\n</code></pre> <p>All sources supported by Ragbits are available here.</p>"},{"location":"how-to/document_search/ingest-documents/#parsing-documents","title":"Parsing documents","text":"<p>Depending on the document type, different parsers operate in the background to convert the document into a list of elements. Ragbits primarily relies on the <code>docling</code> library, which supports parsing and chunking for most common document formats (e.g., PDF, Markdown, DOCX, JPG).</p> <p>To define a new parser, extend the <code>DocumentParser</code> class.</p> <pre><code>from bs4 import BeautifulSoup\nfrom ragbits.document_search.documents.document import Document, DocumentType\nfrom ragbits.document_search.documents.element import Element\nfrom ragbits.document_search.ingestion.parsers import DocumentParser\n\n\nclass HTMLDocumentParser(DocumentParser):\n    \"\"\"\n    Parser that uses the Beautiful Soup to process the documents.\n    \"\"\"\n\n    supported_document_types = {DocumentType.HTML}\n\n    async def parse(self, document: Document) -&gt; list[Element]:\n        \"\"\"\n        Parse the HTML document using the Beautiful Soup.\n\n        Args:\n            document: The document to parse.\n\n        Returns:\n            The list of elements extracted from the document.\n        \"\"\"\n        dom = BeautifulSoup(document.local_path.read_text(), \"html.parser\")\n        ...\n        return [\n            TextElement(document_meta=document.metadata, ...),\n            ...\n        ]\n</code></pre> <p>To apply the new parser, define a <code>DocumentParserRouter</code> and assign it to the <code>DocumentSearch</code> instance.</p> <pre><code>from ragbits.document_search import DocumentSearch\nfrom ragbits.document_search.documents.document import DocumentType\nfrom ragbits.document_search.ingestion.parsers import DocumentParserRouter\n\nparser_router = DocumentParserRouter({\n    DocumentType.HTML: HTMLDocumentParser(),\n    ...\n})\ndocument_search = DocumentSearch(parser_router=parser_router, ...)\n</code></pre>"},{"location":"how-to/document_search/ingest-documents/#enriching-elements","title":"Enriching elements","text":"<p>After parsing the document, the resulting elements can optionally be enriched. Element enrichers generate additional information about elements, such as text summaries or image descriptions. Most enrichers are lightweight wrappers around LLMs that process elements in a specific format. By default, Ragbits enriches image elements with descriptions using the preferred VLM.</p> <p>To define a new enricher, extend the <code>ElementEnricher</code> class.</p> <pre><code>from ragbits.document_search.documents.element import TextElement\nfrom ragbits.document_search.ingestion.enrichers import ElementEnricher\n\n\nclass TextElementEnricher(ElementEnricher[TextElement]):\n    \"\"\"\n    Enricher that summarizes text elements using LLM.\n    \"\"\"\n\n    async def enrich(self, elements: list[TextElement]) -&gt; list[TextElement]:\n        \"\"\"\n        Enrich text elements with the text summary.\n\n        Args:\n            elements: The text elements to be enriched.\n\n        Returns:\n            The list of enriched text elements.\n        \"\"\"\n        responses = await llm.generate(TextSummarizerPrompt(...))\n        ...\n        return [\n            TextElement(\n                document_meta=element.document_meta,\n                content=...,\n            ),\n            ...\n        ]\n</code></pre> <p>To apply the new enricher, define a <code>ElementEnricherRouter</code> and assign it to the <code>DocumentSearch</code> instance.</p> <pre><code>from ragbits.document_search import DocumentSearch\nfrom ragbits.document_search.documents.element import TextElement\nfrom ragbits.document_search.ingestion.enrichers import ElementEnricherRouter\n\nenricher_router = ElementEnricherRouter({\n    TextElement: TextElementEnricher(),\n    ...\n})\ndocument_search = DocumentSearch(enricher_router=enricher_router, ...)\n</code></pre>"},{"location":"how-to/document_search/ingest-documents/#indexing-elements","title":"Indexing elements","text":"<p>At the end of the ingestion process, elements are indexed into the vector database. First, the vector store is scanned to identify and remove any existing elements from sources that are about to be ingested. Then, the new elements are inserted, ensuring that only the latest versions of the sources remain. Indexing is performed in batches, allowing all elements from a batch of documents to be processed in a single request to the database, which improves efficiency and speeds up the process.</p>"},{"location":"how-to/document_search/ingest-documents/#orchestrating-ingest-tasks","title":"Orchestrating ingest tasks","text":"<p>Running an ingest pipeline can be time-consuming, depending on your expected load. Ragbits offers three built-in ingest strategies that you can use out of the box for your workload, or you can implement a custom strategy to suit your needs.</p> SequentialBatchedRay Distributed <pre><code>from ragbits.document_search import DocumentSearch\nfrom ragbits.document_search.ingestion.strategies import SequentialIngestStrategy\n\ningest_strategy = SequentialIngestStrategy()\ndocument_search = DocumentSearch(ingest_strategy=ingest_strategy, ...)\n\nawait document_search.ingest(\"s3://\")\n</code></pre> <p>The default ingest strategy in Ragbits is <code>SequentialIngestStrategy</code>. This strategy processes documents one by one, waiting for each document to be processed before moving on to the next. Although it's the simplest and most straightforward strategy, it may be slow when processing a large number of documents.</p> <pre><code>from ragbits.document_search import DocumentSearch\nfrom ragbits.document_search.ingestion.strategies import BatchedIngestStrategy\n\ningest_strategy = BatchedIngestStrategy(batch_size=10)\ndocument_search = DocumentSearch(ingest_strategy=ingest_strategy, ...)\n\nawait document_search.ingest(\"s3://\")\n</code></pre> <p>If you need to process documents simultaneously, you can use the <code>BatchedIngestStrategy</code> strategy. This strategy uses Python built-in <code>asyncio</code> to process documents concurrently, making it faster than the <code>SequentialIngestStrategy</code> strategy, especially with large document volumes.</p> <pre><code>from ragbits.document_search import DocumentSearch\nfrom ragbits.document_search.ingestion.strategies import RayDistributedIngestStrategy\n\ningest_strategy = RayDistributedIngestStrategy()\ndocument_search = DocumentSearch(ingest_strategy=ingest_strategy, ...)\n\nawait document_search.ingest(\"s3://\")\n</code></pre> <p>If you need even better performance, you can use the <code>RayDistributedIngestStrategy</code> strategy. By default, when run outside of a Ray cluster, the Ray Core library will parallelize the processing of documents on the local machine, using available CPU cores.</p> <p>When run inside a Ray cluster, the Ray Core library will parallelize the processing of documents across the nodes in the cluster. There are several ways of sending documents to the Ray cluster for processing, but using Ray Jobs API is by far the most recommended one.</p> <p>To use Ray Jobs API, you should prepare the processing script and the documents to be processed, and then submit the job to the Ray cluster. Make sure to replace <code>&lt;cluster_address&gt;</code> with the address of your Ray cluster and adjust the <code>entrypoint</code> and <code>runtime_env</code> parameters to match your setup.</p> <pre><code>from ray.job_submission import JobSubmissionClient\n\nclient = JobSubmissionClient(\"http://&lt;cluster_address&gt;:8265\")\nclient.submit_job(\n    entrypoint=\"python script.py\",\n    runtime_env={\n        \"working_dir\": \"./\",\n        \"pip\": [\n            \"ragbits-core\",\n            \"ragbits-document-search[ray]\"\n        ]\n    },\n)\n</code></pre> <p>Ray Jobs is also available as CLI commands. You can submit a job using the following command:</p> <pre><code>ray job submit \\\n    --address http://&lt;cluster_address&gt;:8265 \\\n    --runtime-env '{\"pip\": [\"ragbits-core\", \"ragbits-document-search[ray]\"]}' \\\n    --working-dir . \\\n    -- python script.py\n</code></pre> <p>There are also other ways to submit jobs to the Ray cluster. For more information, please refer to the Ray documentation.</p> <p>To define a new ingest strategy, extend the <code>IngestStrategy</code> class.</p> <pre><code>from ragbits.core.vector_stores import VectorStore\nfrom ragbits.document_search.documents.document import Document, DocumentMeta\nfrom ragbits.core.sources import Source\nfrom ragbits.document_search.ingestion.enrichers import ElementEnricherRouter\nfrom ragbits.document_search.ingestion.parsers import DocumentParserRouter\nfrom ragbits.document_search.ingestion.strategies import (\n    IngestDocumentResult,\n    IngestError,\n    IngestExecutionResult,\n    IngestStrategy,\n)\n\n\nclass DelayedIngestStrategy(IngestStrategy):\n    \"\"\"\n    Ingest strategy that processes documents in sequence, one at a time with a small delay.\n    \"\"\"\n\n    async def __call__(\n        self,\n        documents: Iterable[DocumentMeta | Document | Source],\n        vector_store: VectorStore,\n        parser_router: DocumentParserRouter,\n        enricher_router: ElementEnricherRouter,\n    ) -&gt; IngestExecutionResult:\n        \"\"\"\n        Ingest documents sequentially one by one with a small delay.\n\n        Args:\n            documents: The documents to ingest.\n            vector_store: The vector store to store document chunks.\n            parser_router: The document parser router to use.\n            enricher_router: The intermediate element enricher router to use.\n\n        Returns:\n            The ingest execution result.\n        \"\"\"\n        results = IngestExecutionResult()\n\n        for document in documents:\n            try:\n                # Parse\n                parsed_elements = await self._call_with_error_handling(self._parse_document, ...)\n\n                # Enrich\n                enriched_elements = await self._call_with_error_handling(self._enrich_elements, ...)\n\n                # Index\n                await self._call_with_error_handling(self._remove_elements, ...)\n                await self._call_with_error_handling(self._insert_elements, ...)\n\n                # Artificial delay\n                await asyncio.sleep(1)\n\n            except Exception as exc:\n                results.failed.append(IngestDocumentResult(error=IngestError.from_exception(exc), ...))\n            else:\n                results.successful.append(IngestDocumentResult(...))\n\n        return results\n</code></pre>"},{"location":"how-to/document_search/search-documents/","title":"How-To: Search Documents","text":"<p>The Ragbits document search pipeline consists of three sequential steps: query rephrasing, vector search, and reranking. Each step can be parameterized, enabling more sophisticated retrieval.</p>"},{"location":"how-to/document_search/search-documents/#search-vectors","title":"Search vectors","text":"<p>Searching for elements is performed using a vector store. <code>DocumentSearch</code> utilizes <code>Element</code> to format entry in the <code>VectorStore</code>. The retrieval strategy at this stage depends on the chosen vector store implementation.</p> Dense searchSparse searchHybrid search <pre><code>from ragbits.core.embeddings import LiteLLMEmbedder\nfrom ragbits.core.vector_stores.qdrant import QdrantVectorStore\nfrom ragbits.document_search import DocumentSearch\n\nembedder = LiteLLMEmbedder(model=\"text-embedding-3-small\", ...)\nvector_store = QdrantVectorStore(embedder=embedder, index_name=\"index\", ...)\ndocument_search = DocumentSearch(vector_store=vector_store, ...)\n\nelements = await document_search.search(\"What is the capital of Poland?\")\n</code></pre> <p>One of the simplest vector search strategies used in Ragbits is dense search. This approach leverages an embedding model to generate vector representations of search queries and compares them against the dense vector representations of ingested elements. It is a straightforward method and often serves as a good starting point for developing a retrieval pipeline.</p> <pre><code>from ragbits.core.embeddings.sparse.fastembed import FastEmbedSparseEmbedder\nfrom ragbits.core.vector_stores.qdrant import QdrantVectorStore\nfrom ragbits.document_search import DocumentSearch\n\n# Create a sparse embedder\nsparse_embedder = FastEmbedSparseEmbedder(model_name=\"prithivida/Splade_PP_en-distil-cocodenser-retriever\")\n\n# Create a vector store with the sparse embedder\nvector_store = QdrantVectorStore(embedder=sparse_embedder, index_name=\"sparse_index\", ...)\ndocument_search = DocumentSearch(vector_store=vector_store, ...)\n\nelements = await document_search.search(\"What is the capital of Poland?\")\n</code></pre> <p>Sparse search uses sparse vector representations where only non-zero values are stored along with their indices. This approach is particularly effective for lexical search, as it can directly represent term frequencies or TF-IDF weights. Sparse vectors often provide better interpretability, as each dimension typically corresponds to a specific token or feature.</p> <p>For more details about using sparse vectors with vector stores, see How to Use Sparse Vectors with Vector Stores.</p> <pre><code>from ragbits.core.embeddings.dense import LiteLLMEmbedder\nfrom ragbits.core.embeddings.sparse.fastembed import FastEmbedSparseEmbedder\nfrom ragbits.core.vector_stores.in_memory import InMemoryVectorStore\nfrom ragbits.core.vector_stores.hybrid import HybridSearchVectorStore\nfrom ragbits.document_search import DocumentSearch\n\n# Create a dense embedder\ndense_embedder = LiteLLMEmbedder(model=\"text-embedding-3-small\", ...)\n\n# Create a sparse embedder\nsparse_embedder = FastEmbedSparseEmbedder(model_name=\"prithivida/Splade_PP_en-distil-cocodenser-retriever\")\n\n# Create vector stores with different embedders\nvector_store_dense = InMemoryVectorStore(embedder=dense_embedder)\nvector_store_sparse = InMemoryVectorStore(embedder=sparse_embedder)\n\n# Combine them into a hybrid vector store\nvector_store = HybridSearchVectorStore(vector_store_dense, vector_store_sparse)\ndocument_search = DocumentSearch(vector_store=vector_store, ...)\n\nelements = await document_search.search(\"What is the capital of Poland?\")\n</code></pre> <p>Hybrid search is a more advanced strategy that combines multiple vector stores, each optimized for different types of data or embedding models. This approach allows for more flexible and efficient retrieval, as it can leverage the strengths of different vector stores to improve search results. The example above shows how to combine dense and sparse embeddings, which can significantly improve search quality by leveraging both semantic similarity (from dense embeddings) and lexical matching (from sparse embeddings).</p> <p>To learn more about using Hybrid Search, refer to How to Perform Hybrid Search with Multiple Vector Stores.</p>"},{"location":"how-to/document_search/search-documents/#limit-results-with-metadata-based-filtering","title":"Limit results with metadata-based filtering","text":"<p>You can filter search results based on document metadata using the <code>where</code> clause in <code>VectorStoreOptions</code>. This allows you to narrow down results to specific document types, sources, or any other metadata fields you've defined.</p> <pre><code>from ragbits.core.vector_stores.base import VectorStoreOptions\nfrom ragbits.document_search import DocumentSearch, DocumentSearchOptions\n\n# Create vector store options with metadata filtering\nvector_store_options = VectorStoreOptions(\n    k=2,  # Number of results to return\n    score_threshold=0.6,  # Minimum similarity score\n    where={\"document_meta\": {\"document_type\": \"txt\"}}  # Filter by document type\n)\n\n# Create document search options with the vector store options\noptions = DocumentSearchOptions(vector_store_options=vector_store_options)\n\n# Search with the filtering options\nresults = await document_search.search(\"Your search query\", options=options)\n</code></pre> <p>The <code>where</code> clause supports various filtering conditions. For example, you can filter by: - Document type - Source - Custom metadata fields</p> <p>This filtering happens at the vector store level, making the search more efficient by reducing the number of documents that need to be processed.</p>"},{"location":"how-to/document_search/search-documents/#rephrase-query","title":"Rephrase query","text":"<p>By default, the input query is provided directly to the embedding model. However, there is an option to add an additional step before vector search. Ragbits offers several common rephrasing techniques that can be utilized to refine the query and generate better embeddings for retrieval.</p> ParaphraseMulti query <pre><code>from ragbits.document_search.retrieval.rephrasers import LLMQueryRephraser\nfrom ragbits.document_search import DocumentSearch\n\nquery_rephraser = LLMQueryRephraser(LiteLLM(model_name=\"gpt-3.5-turbo\"))\ndocument_search = DocumentSearch(query_rephraser=query_rephraser, ...)\n\nelements = await document_search.search(\"What is the capital of Poland?\")\n</code></pre> <p>The simplest form of rephrasing is paraphrasing the input query. This approach utilizes an LLM to expand the query, making it as detailed as possible. This helps generate richer embeddings, ultimately improving the retrieval of relevant elements during the vector search step.</p> <pre><code>from ragbits.document_search.retrieval.rephrasers import LLMQueryRephraser, LLMQueryRephraserOptions\nfrom ragbits.document_search import DocumentSearch\n\nquery_rephraser = LLMQueryRephraser(LiteLLM(model_name=\"gpt-3.5-turbo\"), default_options=LLMQueryRephraserOptions(n=3))\ndocument_search = DocumentSearch(query_rephraser=query_rephraser, ...)\n\nelements = await document_search.search(\"What is the capital of Poland?\")\n</code></pre> <p>Multi query is a bit more sophisticated technique that breaks down the initial query into multiple independent inputs, which are then used separately to query the vector store. Similar to the previous algorithm, this method also utilizes an LLM to generate queries. This type of rephrasing can be particularly useful for multi-hop questions that require multiple rounds of retrieval.</p> <p>To define a new rephraser, extend the the <code>QueryRephraser</code> class.</p> <pre><code>from ragbits.document_search.retrieval.rephrasers import QueryRephraser, QueryRephraserOptions\n\n\nclass CustomRephraser(QueryRephraser[QueryRephraserOptions]):\n    \"\"\"\n    Rephraser that uses a LLM to rephrase queries.\n    \"\"\"\n\n    options_cls: type[QueryRephraserOptions] = QueryRephraserOptions\n\n    async def rephrase(self, query: str, options: QueryRephraserOptions | None = None) -&gt; Iterable[str]:\n        \"\"\"\n        Rephrase a query using the LLM.\n\n        Args:\n            query: The query to be rephrased.\n            options: The options for rephrasing.\n\n        Returns:\n            List containing the rephrased query.\n        \"\"\"\n        responses = await llm.generate(CustomRephraserPrompt(...))\n        ...\n        return [...]\n</code></pre>"},{"location":"how-to/document_search/search-documents/#rerank-elements","title":"Rerank elements","text":"<p>By default, elements retrieved from the vector store are returned without any post-processing, which may result in irrelevant data. To address this, reranking can be added at the end of the pipeline. Ragbits offers several common reranking algorithms that can be used to reorder and filter search results.</p> Cross encoderRRF <pre><code>from ragbits.document_search.retrieval.rerankers import LiteLLMReranker\nfrom ragbits.document_search import DocumentSearch\n\nreranker = LiteLLMReranker(model=\"cohere/rerank-english-v3.0\")\ndocument_search = DocumentSearch(reranker=reranker, ...)\n\nelements = await document_search.search(\"What is the capital of Poland?\")\n</code></pre> <p>The most popular approach is to use cross encoder model. Which is going to compuate scores for each query-element pair and then sort it and apply thresholding. This solution works well, but requires hosting cross encoder model or having access to external provider API that would host one for us.</p> <pre><code>from ragbits.document_search.retrieval.rerankers import ReciprocalRankFusionReranker\nfrom ragbits.document_search import DocumentSearch\n\nreranker = ReciprocalRankFusionReranker()\ndocument_search = DocumentSearch(reranker=reranker, ...)\n\nelements = await document_search.search(\"What is the capital of Poland?\")\n</code></pre> <p>If you have entries from multiple retrieval rounds, you may choose to use a simpler algorithm called Reciprocal Rank Fusion (RRF). RRF assigns scores to documents based on their positions in various ranked lists, allowing for the fusion of different ranking sources without the need for tuning.</p> <p>To define a new reranker, extend the the <code>Reranker</code> class.</p> <pre><code>from ragbits.document_search.retrieval.rerankers import Reranker, RerankerOptions\nfrom ragbits.document_search.documents.element import Element\n\n\nclass CustomReranker(Reranker[RerankerOptions]):\n    \"\"\"\n    Reranker that uses a LLM to rerank elements.\n    \"\"\"\n\n    options_cls: type[RerankerOptions] = RerankerOptions\n\n    async def rerank(\n        self,\n        elements: Sequence[Sequence[Element]],\n        query: str,\n        options: RerankerOptions | None = None,\n    ) -&gt; Sequence[Element]:\n        \"\"\"\n        Rerank elements with LLM.\n\n        Args:\n            elements: The elements to rerank.\n            query: The query to rerank the elements against.\n            options: The options for reranking.\n\n        Returns:\n            The reranked elements.\n        \"\"\"\n        responses = await llm.generate_with_metadata(ElementsRerankPrompt(...))\n        ...\n        return [...]\n</code></pre>"},{"location":"how-to/evaluate/custom_dataloader/","title":"How-To: Create custom data loader with Ragbits","text":"<p>Ragbits provides a base interface for data loading, <code>ragbits.evaluate.dataloaders.base.DataLoader</code>, designed specifically for evaluation purposes. A ready-to-use implementation, <code>ragbits.evaluate.dataloaders.hf.HFLoader</code>, is available for handling datasets in huggingface format.</p> <p>To create a custom DataLoader for your specific needs, you need to implement the <code>load</code> method in a class that inherits from the <code>DataLoader</code> interface.</p> <p>Please find the working example here.</p> <p>Note: This interface is not to be confused with PyTorch's <code>DataLoader</code>, as it serves a distinct purpose within the Ragbits evaluation framework.</p>"},{"location":"how-to/evaluate/custom_evaluation_pipeline/","title":"How-To: Create custom evaluation pipeline in Ragbits","text":"<p>Ragbits provides a ready-to-use evaluation pipeline for document search, implemented within the <code>ragbits.evaluate.document_search.DocumentSearchPipeline</code> module.</p> <p>To create a custom evaluation pipeline for your specific use case, you need to implement the <code>__call__</code> method as part of the <code>ragbits.evaluate.pipelines.base.EvaluationPipeline</code> interface.</p> <p>Please find the working example here</p>"},{"location":"how-to/evaluate/custom_metric/","title":"How-To: Create custom evaluation metric in Ragbits","text":"<p><code>ragbits.evaluate</code> package provides the implementation of metrics that measure the quality of document search pipeline within <code>ragbits.evaluate.metrics.document_search</code> on your data, however you are not limited to this. In order to implement custom ones for your specific use case you would need to inherit from <code>ragbits.evaluate.metrics.base.Metric</code> abstract class and implement <code>compute</code> method.</p> <p>Please find the working example here.</p>"},{"location":"how-to/evaluate/evaluate/","title":"How-To: Evaluate pipelines with Ragbits","text":"<p>Ragbits provides an interface for evaluating pipelines using specified metrics. Generally, you can create any evaluation pipeline and metrics that comply with the interface.</p> <p>Before running the evaluation, ensure the following prerequisites are met:</p> <ol> <li>Define the <code>EvaluationPipeline</code> structure class (Example)</li> <li>Define the <code>Metrics</code> and organize them into a <code>MetricSet</code> (Example)</li> <li>Define the <code>DataLoader</code> (Example)</li> </ol>"},{"location":"how-to/evaluate/evaluate/#running-evaluation-from-source-code","title":"Running evaluation from source code","text":"<p>The evaluation example is very similar to the one used in optimization, and it utilizes the same implementations of the required classes. The only difference is in the structure of the configuration file, as it does not need to include optimizer options or the parameters to be optimized.</p> <pre><code>import asyncio\nfrom ragbits.evaluate.evaluator import Evaluator\n\n\nasync def main():\n    config = {\n        \"dataloader\": {\n            \"type\": f\"{__name__}:RandomQuestionsDataLoader\",\n            \"config\": {\"num_questions\": 10, \"question_topic\": \"conspiracy theories\"},\n        },\n        \"pipeline\": {\n            \"type\": f\"{__name__}:RandomQuestionRespondPipeline\",\n            \"config\": {\n                \"system_prompt_content\":  \"Respond to user questions in as few words as possible\"\n                }\n            },\n        \"metrics\": {\n            \"precision_recall_f1\": {\n                \"type\": f\"{__name__}:TokenCountMetric\",\n                \"config\": {},\n            },\n        },\n    }\n    results = await Evaluator.run_from_config(config=config)\n    return results\n\nasyncio.run(main())\n</code></pre> <p>After the successful execution, your console should print a dictionary with keys corresponding to components of each metric and values equal to results aggregated over the defined dataloader.</p>"},{"location":"how-to/evaluate/evaluate/#running-evaluation-from-cli","title":"Running evaluation from CLI","text":"<p>Ragbits CLI provides a command to run evaluation in convenient way from the command line:</p> <pre><code>ragbits evaluate run \\\n    --dataloader-factory-path TEXT  # Factory path for data loader (python.path:ModuleName) [default: None] \\\n    --dataloader-yaml-path PATH     # YAML config file path for data loader [default: None] \\\n    --target-factory-path TEXT      # Factory path for target (python.path:function_name) [default: None] \\\n    --target-yaml-path PATH         # YAML config file path for target [default: None] \\\n    --metrics-factory-path TEXT     # Factory path for metrics (python.path:function_name) [default: None] \\\n    --metrics-yaml-path PATH        # YAML config file path for metrics [default: None]\n</code></pre> <p>Notes</p> <ul> <li>The <code>--target-factory-path</code> and <code>--target-yaml-path</code> are interchangeable, as are <code>--metrics-factory-path</code> and <code>--metrics-yaml-path</code>. Use one or the other based on your configuration preference.</li> <li>Non-required parameters (those with [default: None]) will be sourced from the project configuration if not provided.</li> </ul> <p>Example command:</p> <pre><code>ragbits evaluate \\\n  --dataloader-factory-path ragbits.evaluate.factories:synthetic_rag_dataset \\\n  --target-factory-path ragbits.evaluate.factories:basic_document_search_factory \\\n  --metrics-factory-path ragbits.evaluate.factories:precision_recall_f1 \\\n  run\n</code></pre>"},{"location":"how-to/evaluate/generate_dataset/","title":"How-To: Generate new dataset with LLM using Ragbits","text":"<p>Ragbits offers a convenient feature to generate artificial QA datasets for evaluating Retrieval-Augmented Generation (RAG) systems. You can choose between two different approaches:</p>"},{"location":"how-to/evaluate/generate_dataset/#available-stacks","title":"Available Stacks","text":"<ol> <li>FromScratch:</li> <li>This option allows you to create a complete QA dataset from scratch.</li> <li> <p>How it works: You provide a list of topics, and the system automatically generates both the corpus and the QA dataset.</p> </li> <li> <p>FromCorpus:</p> </li> <li>This approach uses an existing textual corpus.</li> <li>How it works: You supply a pre-existing corpus, such as documents you\u2019ve previously retrieved, and the system creates the QA dataset based on it.</li> </ol>"},{"location":"how-to/evaluate/generate_dataset/#usage-examples","title":"Usage Examples","text":"<p>Below are examples demonstrating how to use both approaches.</p>"},{"location":"how-to/evaluate/generate_dataset/#from-scratch","title":"From Scratch","text":"<pre><code>import json\n\nfrom datasets import Dataset\nfrom omegaconf import OmegaConf\nfrom ragbits.evaluate.dataset_generator.pipeline import DatasetGenerationPipeline\n\n\ndef print_dataset(dataset: Dataset):\n    entries = []\n    for idx, (question, answer, passage) in enumerate(\n        zip(dataset[\"question\"], dataset[\"basic_answer\"], dataset[\"passages\"])\n    ):\n        entries.append(\n            f\"{idx}. QUESTION: {question} ANSWER: {answer} PASSAGES: {json.dumps(passage)}\"\n        )\n    print(\"\\r\\n\".join(entries))\n\n# configuration should follow\n# ragbits.evaluate.dataset_generator.DatasetGenerationPipelineConfig data model\npipeline_config = OmegaConf.create(\n    {\n        \"input_name\": \"query\",\n        \"pipeline\": {\n            \"name\": \"synthetic-RAG-data\",\n            \"tasks\": [\n                {\n                    \"type\": \"ragbits.evaluate.dataset_generator.tasks.corpus_generation:CorpusGenerationStep\",\n                    \"llm\": {\n                        \"provider_type\": \"ragbits.core.llms.litellm:LiteLLM\",\n                        \"kwargs\": {\"model_name\": \"gpt-4o\"},\n                    },\n                    \"kwargs\": {\n                        \"num_per_query\": 5,\n                        \"prompt_class\": \"ragbits.evaluate.dataset_generator.prompts.corpus_generation:BasicCorpusGenerationPrompt\",\n                    },\n                },\n                {\n                    \"type\": \"ragbits.evaluate.dataset_generator.tasks.text_generation.qa:QueryGenTask\",\n                    \"llm\": {\n                        \"provider_type\": \"distilabel.llms:OpenAILLM\",\n                        \"kwargs\": {\"model\": \"gpt-4o\"},\n                    },\n                    \"kwargs\": {\n                        \"prompt_class\": \"ragbits.evaluate.dataset_generator.prompts.qa:QueryGenPrompt\"\n                    },\n                },\n                {\n                    \"type\": \"ragbits.evaluate.dataset_generator.tasks.text_generation.qa:AnswerGenTask\",\n                    \"llm\": {\n                        \"provider_type\": \"distilabel.llms:OpenAILLM\",\n                        \"kwargs\": {\"model\": \"gpt-4o\"},\n                    },\n                    \"kwargs\": {\n                        \"prompt_class\": \"ragbits.evaluate.dataset_generator.prompts.qa:BasicAnswerGenPrompt\"\n                    },\n                },\n                {\n                    \"type\": \"ragbits.evaluate.dataset_generator.tasks.text_generation.qa:PassagesGenTask\",\n                    \"llm\": {\n                        \"provider_type\": \"distilabel.llms:OpenAILLM\",\n                        \"kwargs\": {\"model\": \"gpt-4o\"},\n                    },\n                    \"kwargs\": {\n                        \"prompt_class\": \"ragbits.evaluate.dataset_generator.prompts.qa:PassagesGenPrompt\"\n                    },\n                    \"filters\": [\n                        \"ragbits.evaluate.dataset_generator.tasks.filter.dont_know:DontKnowFilter\"\n                    ],\n                },\n            ],\n        },\n    }\n)\n\n\ntopics = [\"conspiracy theories\", \"retrival augmented generation\"]\npipeline = DatasetGenerationPipeline.from_dict_config(dict_config=pipeline_config)\ndataset = pipeline(topics)\nprint_dataset(dataset)\n</code></pre> <p>After the succesful execution your console should display output with the followig structure:</p> <pre><code>0. QUESTION: Is there a theory that suggests the Earth is flat? ANSWER: Yes, the \"Flat Earth\" theory suggests that the Earth is a flat disc rather than a sphere. PASSAGES: [\"The 'Flat Earth' theory suggests that the Earth is a flat disc rather than a sphere.\"]\n1. QUESTION: Was the 1969 moon landing really staged by NASA? ANSWER: No, the 1969 moon landing was not staged by NASA. It was a real event where astronauts from the Apollo 11 mission landed on the moon. The conspiracy theory claiming it was staged is false. PASSAGES: [\"The moon landing conspiracy theory falsely claims the 1969 moon landing was staged by NASA.\"]\n2. QUESTION: Is the Earth really flat instead of round? ANSWER: No, the Earth is not flat. Scientific evidence overwhelmingly supports that Earth is an oblate spheroid, which means it is mostly spherical but slightly flattened at the poles and bulging at the equator. PASSAGES: [\"scientific evidence overwhelmingly supports that Earth is an oblate spheroid, which means it is mostly spherical but slightly flattened at the poles and bulging at the equator\"]\n3. QUESTION: Who claims the moon landing was staged in 1969? ANSWER: The moon landing conspiracy theory claims it was staged by NASA in 1969. PASSAGES: [\"The moon landing conspiracy theory claims it was staged by NASA in 1969.\"]\n4. QUESTION: How does retrieval augmented generation improve accuracy? ANSWER: Retrieval augmented generation improves accuracy by combining pretrained language models with a retrieval component, allowing the model to access and incorporate relevant information from external data sources during the generation process. PASSAGES: [\"Retrieval augmented generation (RAG) combines pretrained language models with a retrieval component to enhance accuracy.\"]\n5. QUESTION: How does retrieval-augmented generation improve response accuracy and relevancy? ANSWER: Retrieval-augmented generation improves response accuracy and relevancy by combining retrieved information with language models. This approach allows the model to incorporate relevant data from external sources, which enhances its ability to generate more accurate and contextually appropriate responses. PASSAGES: [\"Retrieval-augmented generation combines retrieved information with language models to improve response accuracy and relevancy.\"]\n6. QUESTION: How does retrieval-augmented generation work to improve response accuracy? ANSWER: Retrieval-augmented generation improves response accuracy by combining information retrieval with text generation. This approach involves retrieving relevant information from a database or other sources and using that information to generate more accurate and informed responses. PASSAGES: [\"Retrieval-augmented generation combines information retrieval with text generation to enhance response accuracy.\"]\n7. QUESTION: How does retrieval augmented generation work? ANSWER: Retrieval augmented generation works by combining language models with an external information retrieval system. This approach allows the model to access and incorporate relevant data from an external source, enhancing the generation of responses or content with up-to-date or specific information it might not have inherently. PASSAGES: [\"Retrieval augmented generation combines language models with external information retrieval.\"]\n8. QUESTION: How does retrieval-augmented generation improve AI responses? ANSWER: Retrieval-augmented generation improves AI responses by combining the retrieval of relevant documents with text generation, providing enhanced context for the responses. PASSAGES: [\"retrieval of relevant documents\", \"text generation for improved context\"]\n</code></pre> <p>Please note that the results may differ among the runs due to undeterministic nature of LLM.</p>"},{"location":"how-to/evaluate/generate_dataset/#from-corpus","title":"From Corpus","text":"<p>The code would be very similar as previously - the only differences are:</p> <ul> <li>removal of first task from the tasks list in pipeline config</li> <li>change of input name from <code>query</code> to <code>chunk</code></li> </ul> <pre><code>import json\n\nfrom datasets import Dataset\nfrom omegaconf import OmegaConf\nfrom ragbits.evaluate.dataset_generator.pipeline import DatasetGenerationPipeline\n\n\n# configuration should follow\n# ragbits.evaluate.dataset_generator.DatasetGenerationPipelineConfig data model\npipeline_config = OmegaConf.create(\n    {\n        \"input_name\": \"chunk\",\n        \"pipeline\": {\n            \"name\": \"synthetic-RAG-data\",\n            \"tasks\": [\n                {\n                    \"type\": \"ragbits.evaluate.dataset_generator.tasks.text_generation.qa:QueryGenTask\",\n                    \"llm\": {\n                        \"provider_type\": \"distilabel.llms:OpenAILLM\",\n                        \"kwargs\": {\"model\": \"gpt-4o\"},\n                    },\n                    \"kwargs\": {\n                        \"prompt_class\": \"ragbits.evaluate.dataset_generator.prompts.qa:QueryGenPrompt\"\n                    },\n                },\n                {\n                    \"type\": \"ragbits.evaluate.dataset_generator.tasks.text_generation.qa:AnswerGenTask\",\n                    \"llm\": {\n                        \"provider_type\": \"distilabel.llms:OpenAILLM\",\n                        \"kwargs\": {\"model\": \"gpt-4o\"},\n                    },\n                    \"kwargs\": {\n                        \"prompt_class\": \"ragbits.evaluate.dataset_generator.prompts.qa:BasicAnswerGenPrompt\"\n                    },\n                },\n                {\n                    \"type\": \"ragbits.evaluate.dataset_generator.tasks.text_generation.qa:PassagesGenTask\",\n                    \"llm\": {\n                        \"provider_type\": \"distilabel.llms:OpenAILLM\",\n                        \"kwargs\": {\"model\": \"gpt-4o\"},\n                    },\n                    \"kwargs\": {\n                        \"prompt_class\": \"ragbits.evaluate.dataset_generator.prompts.qa:PassagesGenPrompt\"\n                    },\n                    \"filters\": [\n                        \"ragbits.evaluate.dataset_generator.tasks.filter.dont_know:DontKnowFilter\"\n                    ],\n                },\n            ],\n        },\n    }\n)\n\n\ndef print_dataset(dataset: Dataset):\n    entries = []\n    for idx, (question, answer, passage) in enumerate(\n        zip(dataset[\"question\"], dataset[\"basic_answer\"], dataset[\"passages\"])\n    ):\n        entries.append(\n            f\"{idx}. QUESTION: {question} ANSWER: {answer} PASSAGES: {json.dumps(passage)}\"\n        )\n    print(\"\\r\\n\".join(entries))\n\n\ntopics = [\n    \"Neural networks are algorithms capable of data structure recognition\",\n    \"Large Language Models (LLM) are trained to predict the term given the context\",\n    \"Logistic regression is a simpliest form of neural network with no hidden neurons and output activated with sigmoid function\",\n]\npipeline = DatasetGenerationPipeline.from_dict_config(dict_config=pipeline_config)\ndataset = pipeline(topics)\nprint_dataset(dataset)\n</code></pre> <p>After succesful execution you should see the following output minus the considerations mentioned in From Scratch section:</p> <pre><code>0. QUESTION: What are neural networks capable of? ANSWER: Neural networks are capable of data structure recognition. PASSAGES: [\"Neural networks are algorithms capable of data structure recognition\"]\n1. QUESTION: What does LLM stand for? ANSWER: LLM stands for Large Language Models. PASSAGES: [\"Large Language Models (LLM)\"]\n2. QUESTION: What's the simplest form of a neural network? ANSWER: Logistic regression is the simplest form of a neural network, with no hidden neurons and an output activated with a sigmoid function. PASSAGES: [\"Logistic regression is a simpliest form of neural network with no hidden neurons and output activated with sigmoid function\"]\n</code></pre>"},{"location":"how-to/evaluate/optimize/","title":"How-To: Auto-optimize for hyperparameter tuning in Ragbits","text":"<p>Ragbits provides a feature that allows users to automatically configure hyperparameters for a pipeline. This functionality is agnostic to the type of optimized structure, with the only requirements being the following:</p> <ul> <li>The optimized pipeline must inherit from <code>ragbits.evaluate.pipelines.base.EvaluationPipeline</code>.</li> <li>The definition of optimized metrics must adhere to the <code>ragbits.evaluate.metrics.base.Metric</code> interface.</li> <li>An instance of a class inheriting from <code>ragbits.evaluate.dataloaders.base.DataLoader</code> must be provided as the data source for optimization.</li> </ul>"},{"location":"how-to/evaluate/optimize/#supported-parameter-types","title":"Supported Parameter Types","text":"<p>The optimized parameters can be of the following types:</p> <ul> <li>Continuous</li> <li>Ordinal</li> <li>Categorical</li> </ul> <p>For ordinal and continuous parameters, the values should be integers or floats. For categorical parameters, more sophisticated structures are supported, including the possibility of nested parameters of other types.</p> <p>Each optimized variable should be marked with the <code>optimize=True</code> flag in the configuration.</p> <p>For categorical variables, you must also provide the <code>choices</code> field, which lists all possible values to be considered during optimization. For continuous and ordinal variables, the <code>range</code> field should be specified as a two-element list defining the minimum and maximum values of interest. For continuous parameters, the elements must be floats, while for ordinal parameters, they must be integers.</p>"},{"location":"how-to/evaluate/optimize/#example-usage","title":"Example Usage","text":"<p>In this example, we will optimize a system prompt for a question-answering pipeline so that the answers contain the minimal number of tokens.</p>"},{"location":"how-to/evaluate/optimize/#define-the-optimized-pipeline-structure","title":"Define the Optimized Pipeline Structure","text":"<pre><code>from dataclasses import dataclass\nfrom ragbits.evaluate.pipelines.base import EvaluationResult, EvaluationPipeline\nfrom ragbits.core.llms.litellm import LiteLLM\nfrom ragbits.core.prompt import Prompt\nfrom pydantic import BaseModel\n\n\n@dataclass\nclass RandomQuestionPipelineResult(EvaluationResult):\n    answer: str\n\n\nclass QuestionRespondPromptInput(BaseModel):\n    system_prompt_content: str\n    question: str\n\n\nclass QuestionRespondPrompt(Prompt[QuestionRespondPromptInput]):\n    system_prompt = \"{{ system_prompt_content }}\"\n    user_prompt = \"{{ question }}\"\n\n\nclass RandomQuestionRespondPipeline(EvaluationPipeline):\n    def __init__(self, system_prompt_content: str):\n        self.system_prompt_content = system_prompt_content\n\n    async def __call__(self, data: dict[str, str]) -&gt; RandomQuestionPipelineResult:\n        llm = LiteLLM()\n        input_prompt = QuestionRespondPrompt(\n            QuestionRespondPromptInput(\n                system_prompt_content=self.system_prompt_content,\n                question=data[\"question\"],\n            )\n        )\n        answer = await llm.generate(prompt=input_prompt)\n        return RandomQuestionPipelineResult(answer=answer)\n</code></pre>"},{"location":"how-to/evaluate/optimize/#define-the-data-loader","title":"Define the Data Loader","text":"<p>Next, we define the data loader. We'll use Ragbits generation stack to create an artificial data loader:</p> <pre><code>from ragbits.evaluate.dataloaders.base import DataLoader\nfrom ragbits.core.llms.litellm import LiteLLM\nfrom ragbits.core.prompt import Prompt\nfrom pydantic import BaseModel\n\n\nclass DatasetGenerationPromptInput(BaseModel):\n    topic: str\n\n\nclass DatasetGenerationPrompt(Prompt[DatasetGenerationPromptInput]):\n    system_prompt = \"Be a provider of random questions on a topic specified by the user.\"\n    user_prompt = \"Generate a question about {{ topic }}\"\n\n\nclass RandomQuestionsDataLoader(DataLoader):\n    def __init__(self, num_questions: int, question_topic: str):\n        self.num_questions = num_questions\n        self.question_topic = question_topic\n\n    async def load(self) -&gt; list[dict[str, str]]:\n        questions = []\n        llm = LiteLLM()\n        for _ in range(self.num_questions):\n            question = await llm.generate(\n                DatasetGenerationPrompt(DatasetGenerationPromptInput(topic=self.question_topic))\n            )\n            questions.append({\"question\": question})\n        return questions\n</code></pre>"},{"location":"how-to/evaluate/optimize/#define-the-metrics","title":"Define the Metrics","text":"<pre><code>import tiktoken\nfrom ragbits.evaluate.metrics.base import Metric, MetricSet, ResultT\n\n\nclass TokenCountMetric(Metric):\n    def compute(self, results: list[ResultT]) -&gt; dict[str, float]:\n        encoding = tiktoken.get_encoding(\"cl100k_base\")\n        num_tokens = [len(encoding.encode(out.answer)) for out in results]\n        return {\"num_tokens\": sum(num_tokens) / len(num_tokens)}\n</code></pre>"},{"location":"how-to/evaluate/optimize/#run-the-experiment","title":"Run the experiment","text":"<pre><code>from pprint import pp as pprint\nfrom ragbits.evaluate.optimizer import Optimizer\n\n\ndef main():\n    config = {\n        \"optimizer\": {\n            \"direction\": \"minimize\",\n            \"n_trials\": 5,\n            \"max_retries_for_trial\": 1,\n        },\n        \"experiment\": {\n            \"dataloader\": {\n                \"type\": f\"{__name__}:RandomQuestionsDataLoader\",\n                \"config\": {\"num_questions\": 10, \"question_topic\": \"conspiracy theories\"},\n            },\n            \"pipeline\": {\n                \"type\": f\"{__name__}:RandomQuestionRespondPipeline\",\n                \"config\": {\n                    \"system_prompt_content\": {\n                        \"optimize\": True,\n                        \"choices\": [\n                            \"Be a friendly bot answering user questions. Be as concise as possible\",\n                            \"Be a silly bot answering user questions. Use as few tokens as possible\",\n                            \"Be informative and straight to the point\",\n                            \"Respond to user questions in as few words as possible\",\n                        ],\n                    }\n                },\n            },\n            \"metrics\": {\n                \"precision_recall_f1\": {\n                    \"type\": f\"{__name__}:TokenCountMetric\",\n                    \"config\": {},\n                },\n            },\n        },\n    }\n\n    experiment_results = Optimizer.run_from_config(config=config)\n    pprint(experiment_results)\n    return experiment_results\n\nmain()\n</code></pre> <p>After executing the code, your console should display an output structure similar to this:</p> <pre><code>[({'system_prompt_content': 'Be a silly bot answering user questions. Use as few tokens as possible'},\n  6.0,\n  {'num_tokens': 6.0}),\n ({'system_prompt_content': 'Be a silly bot answering user questions. Use as few tokens as possible'},\n  10.7,\n  {'num_tokens': 10.7}),\n ({'system_prompt_content': 'Be a friendly bot answering user questions. Be as concise as possible'},\n  37.8,\n  {'num_tokens': 37.8}),\n ({'system_prompt_content': 'Be informative and straight to the point'},\n  113.2,\n  {'num_tokens': 113.2})]\n</code></pre> <p>This output consists of tuples, each containing three elements:</p> <ol> <li>The configuration used in the trial.</li> <li>The score achieved.</li> <li>A dictionary of detailed metrics that contribute to the score.</li> </ol> <p>The tuples are ordered from the best to the worst configuration based on the score.</p> <p>Please note that the details may vary between runs due to the non-deterministic nature of both the LLM and the optimization algorithm.</p>"},{"location":"how-to/guardrails/use_guardrails/","title":"How-To: Setup guardrails with Ragbits","text":"<p>Ragbits offers an expandable guardrails system. You can use one of the available guardrails or create your own to prevent toxic language, PII leaks etc.</p> <p>In this guide we will show you how to use guardrail based on OpenAI moderation and how to creat your own guardrail.</p>"},{"location":"how-to/guardrails/use_guardrails/#using-existing-guardrail","title":"Using existing guardrail","text":"<p>To use one of the existing guardrails you need to import it together with <code>GuardrailManager</code>. Next you simply pass a list of guardrails to the manager and call <code>verify()</code> function that will check the input (<code>str</code> or <code>Prompt</code>) against all provided guardrails asynchronously.</p> <pre><code>import asyncio\nfrom ragbits.guardrails.base import GuardrailManager, GuardrailVerificationResult\nfrom ragbits.guardrails.openai_moderation import OpenAIModerationGuardrail\n\n\nasync def verify_message(message: str) -&gt; list[GuardrailVerificationResult]:\n    manager = GuardrailManager([OpenAIModerationGuardrail()])\n    return await manager.verify(message)\n\n\nif __name__ == '__main__':\n    print(asyncio.run(verify_message(\"Test message\")))\n</code></pre> <p>The expected output is an object with the following properties: <pre><code>    guardrail_name: str\n    succeeded: bool\n    fail_reason: str | None\n</code></pre> It allows you to see which guardrail was used, whether the check was successful and optionally a fail reason.</p>"},{"location":"how-to/guardrails/use_guardrails/#implementing-custom-guardrail","title":"Implementing custom guardrail","text":"<p>We need to create a new class that inherits from <code>Guardrail</code> and implements abstract method <code>verify</code>.</p> <pre><code>from ragbits.core.prompt import Prompt\nfrom ragbits.guardrails.base import Guardrail, GuardrailVerificationResult\n\nclass CustomGuardrail(Guardrail):\n\n    async def verify(self, input_to_verify: Prompt | str) -&gt; GuardrailVerificationResult:\n        pass\n</code></pre> <p>With that you can pass your <code>CustomGuardrail</code> to the <code>GuardrailManager</code> as shown in using existing guardrails section.</p>"},{"location":"how-to/llms/use_llms/","title":"How-To: Interact with LLMs using Ragbits","text":"<p>This guide will walk you through configuring and using both local and remote LLMs in Ragbits. It covers initializing models, calling LLM classes using Prompts and raw string inputs, and handling different response formats.</p>"},{"location":"how-to/llms/use_llms/#setting-up-and-using-a-remote-llms","title":"Setting up and using a remote LLMs","text":"<p>To interact with a remote LLM (e.g., OpenAI, Azure, or other providers), provide an API key and specify the endpoint. Ragbits uses LiteLLM as an abstraction layer, allowing you to call models from multiple providers seamlessly. You can see the full list of supported providers here.</p> <pre><code>import asyncio\nfrom ragbits.core.llms.litellm import LiteLLM\n\nasync def main():\n    llm = LiteLLM(model_name=\"gpt-4o-2024-08-06\")\n    response = await llm.generate(\"Tell me a joke.\")\n    print(response)\n\nasyncio.run(main())\n</code></pre> <p>With LiteLLM, you can switch between different LLM providers by changing the <code>model_name</code> parameter and configuring authentication accordingly. See the LiteLLM documentation for details on calling models from different providers.</p> <p>Tip</p> <p>For batch generation just provide list of prompts <code>await llm.generate([\"Tell me a joke.\", \"Tell me another joke\"])</code></p>"},{"location":"how-to/llms/use_llms/#configuring-llm-options","title":"Configuring LLM Options","text":"<p>LLMs in Ragbits allow you to customize the behavior of the model using various options. These options are passed during initialization or when calling the <code>generate</code> method.</p>"},{"location":"how-to/llms/use_llms/#litellm-options","title":"LiteLLM Options","text":"<p>The <code>LiteLLMOptions</code> class provides options for remote LLMs, aligning with the LiteLLM API. These options allow you to control the behavior of models from various providers. Each of the option is described in the LiteLLM documentation and Reasoning Documentation</p> <p>Example usage: <pre><code>from ragbits.core.llms.litellm import LiteLLM, LiteLLMOptions\n\noptions = LiteLLMOptions(\n    temperature=0.5,\n    max_tokens=150,\n    top_p=0.8,\n    stop=[\"\\n\"]\n)\n\nllm = LiteLLM(model_name=\"gpt-4o-2024-08-06\", default_options=options)\nresponse = llm.generate(\"Write a short story about a robot learning to paint.\")\nprint(response)\n</code></pre></p> <p>Warning</p> <p>If you provide reasoning_effort to the OpenAI model, the reasoning content will not be returned.</p>"},{"location":"how-to/llms/use_llms/#using-local-llms","title":"Using Local LLMs","text":"<p>For guidance on setting up and using local models in Ragbits, refer to the Local LLMs Guide.</p>"},{"location":"how-to/llms/use_llms/#calling-llm-classes-with-prompts-raw-strings-and-conversations","title":"Calling LLM Classes with prompts, raw strings and conversations","text":"<p>Ragbits provides a flexible way to interact with LLMs by allowing you to use <code>Prompt</code> instances, raw strings, or conversation formats (like OpenAI's chat format) when calling the <code>generate</code> method. This section explains how to use these different input types effectively.</p>"},{"location":"how-to/llms/use_llms/#using-prompts-with-llms","title":"Using prompts with LLMs","text":"<p>Prompts in Ragbits are powerful tools for structuring inputs and outputs when interacting with LLMs. They allow you to define system prompts, user prompts, and even structured output formats using Pydantic models. For more details on using prompts, check out the Prompting Guide. For more advanced use cases, such as using attachments in prompts, check out the guide: How-To: Use attachments in prompts with Ragbits.</p> <pre><code>from ragbits.core.prompt import Prompt\n\n\nclass JokePrompt(Prompt):\n    \"\"\"\n    A prompt that generates jokes.\n    \"\"\"\n\n    system_prompt = \"\"\"\n    You are a joke generator. The jokes you generate should be funny and not offensive.\n    \"\"\"\n\n    user_prompt = \"\"\"Tell me a joke.\"\"\"\n</code></pre> <p>Passing the prompt to a model is then as simple as:</p> <pre><code>import asyncio\nfrom ragbits.core.llms.litellm import LiteLLM\n\nasync def main():\n    llm = LiteLLM(\"gpt-4o-2024-08-06\", use_structured_output=True)\n    static_prompt = JokePrompt()\n    print(await llm.generate(static_prompt))\n\nasyncio.run(main())\n</code></pre>"},{"location":"how-to/llms/use_llms/#using-raw-strings-with-llms","title":"Using Raw Strings with LLMs","text":"<p>For simpler use cases, you can directly pass a raw string to the <code>generate</code> method. This is useful when you don't need the additional structure provided by prompts.</p> <pre><code>import asyncio\nfrom ragbits.core.llms.litellm import LiteLLM\n\nasync def main():\n    llm = LiteLLM(model_name=\"gpt-4o-2024-08-06\")\n    response = await llm.generate(\"Tell me a fun fact about space.\")\n    print(response)\n\nasyncio.run(main())\n</code></pre>"},{"location":"how-to/llms/use_llms/#using-chat-format-with-llms","title":"Using Chat Format with LLMs","text":"<p>Ragbits also supports OpenAI-style chat formats, where you can pass a list of message dictionaries to the <code>generate</code> method. This is useful for conversational applications.</p> <pre><code>import asyncio\nfrom ragbits.core.llms.litellm import LiteLLM\n\nasync def main():\n    llm = LiteLLM(model_name=\"gpt-4o-2024-08-06\")\n    messages = [\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n    ]\n    response = await llm.generate(messages)\n    print(response)\n\nasyncio.run(main())\n</code></pre>"},{"location":"how-to/llms/use_local_llms/","title":"How-To: Use local or self-hosted LLMs","text":"<p>This guide explains how to set up and use local LLMs in Ragbits. It covers installation, model initialization, and configuration options.</p> <p>\u2139\ufe0f NOTE</p> <p>Local implementation is not dedicated for production. Use it only in experiments / evaluation</p>"},{"location":"how-to/llms/use_local_llms/#setting-up-and-using-a-local-models","title":"Setting up and using a local models","text":"<p>To use local LLMs, you need to install the 'local' extra requirements:</p> <pre><code>pip install ragbits[local]\n</code></pre> <p>Local LLMs in Ragbits use <code>AutoModelForCausalLM</code> with <code>device_map=\"auto\"</code>. This setting automatically fills all available space on the GPU(s) first, then the CPU, and finally the hard drive (the absolute slowest option) if there is still not enough memory. See the Hugging Face documentation for more details.</p> <p>Using a local model is as simple as: <pre><code>from ragbits.core.llms.local import LocalLLM\n\nlocal_llm = LocalLLM(model_name=\"mistral-7b\")\nresponse = local_llm.generate(\"Tell me a science fact.\")\nprint(response)\n</code></pre></p> <p>The <code>model_name</code> parameter can be specified in several ways: - a string representing the model ID of a pretrained model hosted on Hugging Face Hub, such as <code>\"mistral-7b\"</code>, - a path to a directory containing a model, e.g., <code>\"./my_model_directory/\"</code>, - a path or URL to a saved configuration JSON file, e.g., <code>\"./my_model_directory/configuration.json\"</code>.</p>"},{"location":"how-to/llms/use_local_llms/#local-llm-options","title":"Local LLM Options","text":"<p>The <code>LocalLLMOptions</code> class provides a set of parameters to fine-tune the behavior of local LLMs. These options described in the HuggingFace documentation.</p> <p>Example usage: <pre><code>from ragbits.core.llms.local import LocalLLM, LocalLLMOptions\n\noptions = LocalLLMOptions(\n    temperature=0.7,\n    max_new_tokens=100,\n    do_sample=True,\n    top_p=0.9\n)\n\nlocal_llm = LocalLLM(model_name=\"mistral-7b\", default_options=options)\nresponse = local_llm.generate(\"Explain quantum mechanics in simple terms.\")\nprint(response)\n</code></pre></p>"},{"location":"how-to/llms/use_local_llms/#local-llm-servers","title":"Local LLM servers","text":"<p>Ragbits also supports local LLM servers, you can use llama.cpp, vllm or other servers that are supported by LiteLLM.</p>"},{"location":"how-to/llms/use_local_llms/#using-llamacpp","title":"Using llama.cpp","text":"<p>To use llama.cpp you first need to install it. You can do this by building the sources or by using a package manager. The next step is downloading one of the models in gguf format. You can find a list of available models here. After that you can start the llama.cp server with the following command: <pre><code>./llama-server -m &lt;model_name&gt;.gguf -c 2048 -t 8 --api-key &lt;api_key&gt;\n</code></pre></p> <p>\u2139\ufe0f NOTE</p> <p>The api key is required to use on the server, LiteLLM expects it from an OpenAI client.</p> <p>Now you can use the server in Ragbits: <pre><code>import asyncio\n\nfrom ragbits.core.llms.litellm import LiteLLM\nfrom ragbits.core.prompt.base import SimplePrompt\n\n\nasync def main() -&gt; None:\n    llm = LiteLLM(model_name=\"openai/local\", api_key=\"&lt;api_key&gt;\", api_base=\"http://127.0.0.1:8080\")\n    prompt = SimplePrompt(\"Tell me a joke about software developers.\")\n    response = await llm.generate(prompt)\n    print(response)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre></p>"},{"location":"how-to/llms/use_local_llms/#using-vllm","title":"Using vllm","text":"<p>To use vllm you first need to install it. You can do this by following the installation instructions.</p> <p>With the vllm installed you can start the server with the following command: <pre><code>vllm serve &lt;model_name&gt;\n</code></pre> vllm will download the model if it is not already present in the cache. You can find a list of available models here.</p> <p>Now you can use the server in Ragbits: <pre><code>import asyncio\n\nfrom ragbits.core.llms.litellm import LiteLLM\nfrom ragbits.core.prompt.base import SimplePrompt\n\n\nasync def main() -&gt; None:\n    llm = LiteLLM(model_name=\"hosted_vllm/&lt;model_name&gt;\", api_base=\"http://127.0.0.1:8000/v1\")\n    prompt = SimplePrompt(\"Tell me a joke about software developers.\")\n    response = await llm.generate(prompt)\n    print(response)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre></p>"},{"location":"how-to/llms/use_local_llms/#using-vllm-as-embedding-server","title":"Using vllm as embedding server","text":"<p>To use vllm as embedding server you need to start the server with the following command (make sure model supports embedding): <pre><code>vllm serve &lt;model_name&gt; --task embed\n</code></pre></p> <p>After that you can send requests the server in Ragbits: <pre><code>import asyncio\n\nfrom ragbits.core.embeddings import LiteLLMEmbedder\n\n\nasync def main() -&gt; None:\n    embedder = LiteLLMEmbedder(model_name=\"hosted_vllm/&lt;model_name&gt;\", api_base=\"http://127.0.0.1:8000/v1\")\n    embeddings = await embedder.embed_text([\"Hello\"])\n    print(len(embeddings[0]))\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre></p>"},{"location":"how-to/llms/use_tools_with_llms/","title":"How-To: Use Tool Calling with LLMs in Ragbits","text":"<p>This guide will walk you through providing external tools to use by LLMs. This feature enables LLMs to return which of the provided tools to call and with which arguments in order to accomplish a task given in the prompt.</p>"},{"location":"how-to/llms/use_tools_with_llms/#define-tools","title":"Define tools","text":"<p>Tools for LLMs can be defined as Python functions or as JSON schemas.</p> Python functionJSON schema <pre><code>def get_weather(location: str) -&gt; str:\n    \"\"\"\n    Returns the current weather for a given location.\n\n    Args:\n        location: The location to get the weather for.\n    \"\"\"\n</code></pre> <pre><code>{\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"get_weather\",\n        \"description\": \"Returns the current weather for a given location.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"location\": {\n                    \"description\": \"The location to get the weather for.\",\n                    \"title\": \"Location\",\n                    \"type\": \"string\",\n                }\n            },\n            \"required\": [\"location\"],\n        },\n    },\n}\n</code></pre> <p>For convenience lets use Python function notation.</p> <pre><code>import json\n\ndef get_weather(location: str, units: str | None = None) -&gt; str:\n    \"\"\"\n    Returns the current weather for a given location.\n\n    Args:\n        location: The location to get the weather for.\n        units: The units to use for the weather information.\n\n    Returns:\n        The current weather for the given location.\n    \"\"\"\n    match location.lower():\n        case \"tokyo\":\n            return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"})\n        case \"san francisco\":\n            return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n        case \"paris\":\n            return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"})\n        case _:\n            return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n</code></pre> <p>Tools can be passed to the LLM as an optional generation argument. If LLM decides to use tools, then the tool calls will be returned directly as a response and there will be no text output.</p> <pre><code>import asyncio\nfrom ragbits.core.llms import LiteLLM\n\nasync def main():\n    llm = LiteLLM(model_name=\"gpt-4o-2024-08-06\")\n    response = await llm.generate(\"What's the temperature in San Francisco?\", tools=[get_weather])\n    print(response)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Info</p> <p>Using tools in local LLMs is not supported - any tools passed as arguments to local LLMs are ignored.</p>"},{"location":"how-to/llms/use_tools_with_llms/#stream-tool-calls","title":"Stream tool calls","text":"<p>Tools can also be streamed from the LLM. If LLM decides to use multiple tools, they will be returned in the iterator one by one.</p> <pre><code>import asyncio\nfrom ragbits.core.llms import LiteLLM\n\nasync def main():\n    llm = LiteLLM(model_name=\"gpt-4o-2024-08-06\")\n    response = llm.generate_streaming(\"What's the temperature in San Francisco?\", tools=[get_weather])\n    async for chunk in response:\n        print(chunk)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"how-to/project/component_preferences/","title":"How-To: Set preferred components in Ragbits project","text":""},{"location":"how-to/project/component_preferences/#introduction","title":"Introduction","text":"<p>When you use Ragbits in your project, you can set the preferred components for different component types (like embedders, vector stores, LLMs, etc.) in the project configuration. Typically, there are many different implementations for each type of component, and each implementation has its own configuration. Ragbits allows you to choose the implementation you prefer for each type of component and the configuration to be used along with it.</p> <p>In this guide, you will learn two methods of setting the preferred components for your project: by a factory function and by a YAML configuration file. Preferred components are used automatically by the Ragbits CLI, and you will also learn how to use them in your own code. At the end of the guide, you will find a list of component types for which you can set the preferred configuration.</p>"},{"location":"how-to/project/component_preferences/#setting-the-preferred-components","title":"Setting the Preferred Components","text":"<p>You can specify the component preferences in two different ways: either by providing a factory function that creates the preferred instance of the component or by providing a YAML configuration file that contains the preferred configuration.</p>"},{"location":"how-to/project/component_preferences/#by-a-factory-function","title":"By a Factory Function","text":"<p>To set the preferred component using a factory function, you need to create a function that takes no arguments and returns an instance of the component. You then set the full Python path to this function in the <code>[tool.ragbits.core.component_preference_factories]</code> section of your project's <code>pyproject.toml</code> file.</p> <p>For example, to designate <code>QdrantVectorStore</code> (with an in-memory <code>AsyncQdrantClient</code>) as the preferred vector store implementation, you can create a factory function like this:</p> <pre><code>from ragbits.core.vector_stores.qdrant import QdrantVectorStore\nfrom ragbits.core.embeddings import LiteLLMEmbedder\nfrom qdrant_client import AsyncQdrantClient\n\ndef get_qdrant_vector_store():\n    return QdrantVectorStore(\n        client=AsyncQdrantClient(location=\":memory:\"),\n        index_name=\"my_index\",\n        embedder=LiteLLMEmbedder(),\n    )\n</code></pre> <p>Then, you set the full Python path to this function in the <code>[tool.ragbits.core.component_preference_factories]</code> section of your project's <code>pyproject.toml</code> file:</p> <pre><code>[tool.ragbits.core.component_preference_factories]\nvector_store = \"my_project:get_qdrant_vector_store\"\n</code></pre> <p>The key <code>vector_store</code> is the name of the component type for which you are setting the preferred configuration. To see all possible component types, refer to the List of Component Types section below. The <code>[tool.ragbits.core.component_preference_factories]</code> may contain multiple keys, each corresponding to a different component type. For example:</p> <pre><code>[tool.ragbits.core.component_preference_factories]\nvector_store = \"my_project:get_qdrant_vector_store\"\nembedder = \"my_project:get_litellm_embedder\"\n</code></pre> <p></p> <p>LLM Specific Configuration</p> <p>Ragbits can distinguish between LLMs, depending on their capabilities. You can use a special <code>[tool.ragbits.core.llm_preference_factories]</code> section in your <code>pyproject.toml</code> file to set the preferred LLM factory functions for different types of LLMs. For example:</p> <pre><code>[tool.ragbits.core.llm_preference_factories]\ntext = \"my_project:get_text_llm\"\nvision = \"my_project:get_vision_llm\"\nstructured_output = \"my_project:get_structured_output_llm\"\n</code></pre> <p>The keys in the <code>[tool.ragbits.core.llm_preference_factories]</code> section are the names of the LLM types for which you are setting the preferred configuration. The possible LLM types are <code>text</code>, <code>vision</code>, and <code>structured_output</code>. The values are the full Python paths to the factory functions that create instances of the LLMs.</p>"},{"location":"how-to/project/component_preferences/#by-a-yaml-configuration-file","title":"By a YAML Configuration File","text":"<p>To set the preferred components using a YAML configuration file, you need to create a YAML file that contains the preferred configuration for different types of components. You then set the path to this file in the <code>[tool.ragbits.core]</code> section of your project's <code>pyproject.toml</code> file.</p> <p>For example, to designate <code>QdrantVectorStore</code> (with an in-memory <code>AsyncQdrantClient</code>) as the preferred vector store implementation, you can create a YAML file like this:</p> <pre><code>vector_store:\n  type: QdrantVectorStore\n  config:\n    client:\n      location: \":memory:\"\n    index_name: my_index\n    embedder:\n      type: LiteLLMEmbedder\n</code></pre> <p>Then, you set the path to this file as <code>component_preference_config_path</code> in the <code>[tool.ragbits.core]</code> section of your project's <code>pyproject.toml</code> file:</p> <pre><code>[tool.ragbits.core]\ncomponent_preference_config_path = \"preferred_instances.yaml\"\n</code></pre> <p>Each key in the YAML configuration file corresponds to a different component type. The value of each key is a dictionary with up to two keys: <code>type</code> and <code>config</code>. The <code>type</code> key is the name of the preferred component implementation, and the optional <code>config</code> key is the configuration to be used with the component. The configuration is specific to each component type and implementation and corresponds to the arguments of the component's constructor.</p> <p>When using subclasses built into Ragbits, you can use either the name of the class alone (like the <code>QdrantVectorStore</code> in the example above) or the full Python path to the class (like <code>ragbits.core.vector_stores.QdrantVectorStore</code>). For other classes (like your own custom implementations of Ragbits components), you must use the full Python path.</p> <p>In the example, the <code>vector_store</code> key is the name of the component type for which you are setting the preferred component. To see all possible component types, refer to the List of Component Types. The YAML configuration may contain multiple keys, each corresponding to a different component type. For example:</p> <pre><code>vector_store:\n  type: QdrantVectorStore\n  config:\n    client:\n      location: \":memory:\"\n    index_name: my_index\n    embedder:\n      type: LiteLLMEmbedder\n\nrephraser:\n  type: NoopQueryRephraser\n</code></pre> <p></p> <p><code>DocumentSearch</code> Specific Configuration</p> <p>While you can provide <code>DocumentSearch</code> with a preferred configuration in the same way as other components (by setting the <code>document_search</code> key in the YAML configuration file), there is also a shortcut. If you don't provide a preferred configuration for <code>DocumentSearch</code> explicitly, it will look for your project's preferences regarding all the components that <code>DocumentSearch</code> needs (like <code>vector_store</code>, <code>provider</code>, <code>rephraser</code>, <code>reranker</code>, etc.) and create a <code>DocumentSearch</code> instance with your preferred components. This way, you don't have to configure those components twice (once for <code>DocumentSearch</code> and once for the component itself).</p> <p>This is an example of a YAML configuration file that sets the preferred configuration for <code>DocumentSearch</code> explicitly:</p> <pre><code>document_search:\n  type: DocumentSearch\n  config:\n    rephraser:\n      type: NoopQueryRephraser\n    vector_store:\n      type: InMemoryVectorStore\n      config:\n        embedder:\n          type: NoopEmbedder\n</code></pre> <p>This is an example of a YAML configuration file that sets the preferred configuration for <code>DocumentSearch</code> implicitly:</p> <pre><code>rephraser:\n  type: NoopQueryRephraser\nvector_store:\n  type: InMemoryVectorStore\n  config:\n    embedder:\n      type: NoopEmbedder\n</code></pre> <p>In both cases, <code>DocumentSearch</code> will use <code>NoopEmbedder</code> as the preferred embedder and <code>InMemoryVectorStore</code> as the preferred vector store.</p>"},{"location":"how-to/project/component_preferences/#using-the-preferred-components","title":"Using the Preferred Components","text":"<p>Preferred components are used automatically by the Ragbits CLI. The <code>ragbits</code> commands that work on components (like <code>ragbits vector-store</code>, <code>ragbits document-search</code>, etc.) will use the component preferred for the given type unless instructed otherwise.</p> <p>You can also retrieve preferred components in your own code by instantiating the component using the <code>preferred_subclass()</code> factory method of the base class of the given component type. This method will automatically create an instance of the preferred implementation of the component with the configuration you have set.</p> <p>For example, the code below will create an instance of the default vector store implementation with the default configuration (as long as you have set the default vector store in the project configuration):</p> <pre><code>from ragbits.core.vector_stores import VectorStore\nfrom ragbits.core.config import core_config\n\nvector_store = VectorStore.preferred_subclass(core_config)\n</code></pre> <p>Note that <code>VectorStore</code> itself is an abstract class, so the instance created by <code>preferred_subclass()</code> will be an instance of one of the concrete subclasses of <code>VectorStore</code> that you have set as the preferred in the project configuration.</p> <p></p> <p>LLM Specific Usage</p> <p>If you set the preferred LLM factory functions in the project configuration, you can use the <code>get_preferred_llm()</code> function to create an instance of the preferred LLM for a given type. For example:</p> <pre><code>from ragbits.core.llms.factory import get_preferred_llm, LLMType\n\ntext_llm = get_preferred_llm(LLMType.TEXT)  # one of: TEXT, VISION, STRUCTURED_OUTPUT\n</code></pre>"},{"location":"how-to/project/component_preferences/#list-of-component-types","title":"List of Component Types","text":"<p>This is the list of component types for which you can set a preferred configuration:</p> Key Package Base class Notes <code>embedder</code> <code>ragbits-core</code> <code>Embedder</code> <code>llm</code> <code>ragbits-core</code> <code>LLM</code> Specifics: Configuration, Usage <code>vector_store</code> <code>ragbits-core</code> <code>VectorStore</code> <code>history_compressor</code> <code>ragbits-chat</code> <code>ConversationHistoryCompressor</code> <code>document_search</code> <code>ragbits-document-search</code> <code>DocumentSearch</code> Specifics: Configuration <code>parser</code> <code>ragbits-document-search</code> <code>DocumentParser</code> <code>rephraser</code> <code>ragbits-document-search</code> <code>QueryRephraser</code> <code>reranker</code> <code>ragbits-document-search</code> <code>Reranker</code>"},{"location":"how-to/project/custom_components/","title":"How-To: Register custom components","text":"<p>Ragbits allows you to extend its functionality by adding custom implementations of various components, such as <code>sources</code> or <code>elements</code>. In most cases, you just need to import them directly in your code and use them, but in some cases, such as source ingest via CLI, you need to import them implictly to avoid errors.</p> <p>To register your component classes, include their module paths in the <code>modules_to_import</code> section of your <code>pyproject.toml</code> file:</p> <pre><code>[tool.ragbits.core]\nmodules_to_import = [\n    \"python.path.to.custom_source\",\n    \"python.path.to.custom_element\",\n    ...\n]\n</code></pre> <p>And that's it, Ragbits always reads <code>pyproject.toml</code> every time you run it and imports modules from it, so you can be sure that your components will always be available in a runtime.</p> <p>Tip</p> <p>It is a good practice to put all custom components in the <code>modules_to_import</code> section to avoid potential errors in the future.</p>"},{"location":"how-to/prompts/promptfoo/","title":"How-To: Test prompts with promptfoo and Ragbits","text":"<p>Ragbits' <code>Prompt</code> abstraction can be seamlessly integrated with the <code>promptfoo</code> tool. After installing <code>promptfoo</code> as specified in the promptfoo documentation, you can generate promptfoo configuration files for all the prompts discovered by our autodiscover mechanism by running the following command:</p> <pre><code>ragbits prompts promptfoo\n</code></pre> <p>This command will generate a YAML files in the directory specified by <code>--target-path</code> (<code>promptfooconfigs</code> by default). The generated file should look like this:</p> <pre><code>prompts:\n  - file:///path/to/your/prompt:PromptClass.to_promptfoo\n</code></pre> <p>You can then edit the generated file to add your custom <code>promptfoo</code> configurations. Once your <code>promptfoo</code> configuration file is ready, you can run <code>promptfoo</code> with the following command:</p> <pre><code>promptfoo eval -c /path/to/generated/promptfoo-config.yaml\n</code></pre> <p>Important: To ensure compatibility, make sure Node.js version 20 is installed.</p>"},{"location":"how-to/prompts/use_attachments_in_prompts/","title":"How-To: Use attachments in prompts with Ragbits","text":"<p>This guide will walk you through defining and using prompts in Ragbits that accept attachments as input. It covers handling single and multiple attachment inputs, incorporating conditionals in prompt templates based on the presence of attachments, and using such prompts with an LLM.</p> <p>Attachment types currently supported include standard image formats (such as JPEG, PNG) and PDF documents.</p>"},{"location":"how-to/prompts/use_attachments_in_prompts/#how-to-define-a-prompt-with-an-attachment-input","title":"How to define a prompt with an attachment input","text":"<p>The attachment is represented by the <code>prompt.Attachment</code> class. It can be initialized in multiple ways depending on the source of the file data. The class supports both binary data and URLs, with optional MIME type specification.</p> <pre><code>from ragbits.core.prompt import Attachment\n\nfile_bytes = Attachment(data=b\"file_bytes\")\nimage_url = Attachment(url=\"http://image.jpg\")\npdf_url = Attachment(url=\"http://document.pdf\")\nfile_with_url_and_mime =  Attachment(url=\"http://address.pl/file_with_no_extension\", mime_type=\"jpeg\")\n</code></pre> <p>To define a prompt that takes an attachment as input, create a Pydantic model representing the input structure. The model should include a field for the attachment that holds an instance of <code>prompt.Attachment</code> class - its name does not matter.</p> <p>To pass multiple attachments, just define multiple fields of type <code>Attachment</code> or a single field that is a list of <code>Attachment</code> instances.</p> <pre><code>import asyncio\nfrom pydantic import BaseModel\nfrom ragbits.core.prompt import Attachment, Prompt\nfrom ragbits.core.llms.litellm import LiteLLM\n\nclass EmployeeOnboardingInput(BaseModel):\n    \"\"\"\n    Input model for employee onboarding files.\n    \"\"\"\n    headshot: Attachment\n    contract: Attachment\n    documents: list[Attachment]\n\n\nclass EmployeeOnboardingPrompt(Prompt):\n    \"\"\"\n    A prompt to process employee onboarding files.\n    \"\"\"\n\n    user_prompt = \"Review the employee onboarding files and provide feedback.\"\n\n\nasync def main():\n    llm = LiteLLM(\"gpt-4o\")\n\n    headshot = Attachment(data=b\"&lt;your_photo_here&gt;\")\n    contract = Attachment(data=b\"&lt;your_contract_here&gt;\")\n    documents = [\n        Attachment(data=b\"&lt;your_document_1_here&gt;\"),\n        Attachment(data=b\"&lt;your_document_2_here&gt;\"),\n    ]\n    prompt = EmployeeOnboardingPrompt(\n        EmployeeOnboardingInput(headshot=headshot, contract=contract, documents=documents)\n    )\n    response = await llm.generate(prompt)\n    print(response)\n\n\nasyncio.run(main())\n</code></pre>"},{"location":"how-to/prompts/use_attachments_in_prompts/#using-conditionals-in-templates","title":"Using conditionals in templates","text":"<p>Sometimes, you may want to modify the prompt based on whether an attachment is provided. Jinja conditionals can help achieve this.</p> <pre><code>import asyncio\nfrom pydantic import BaseModel\nfrom ragbits.core.prompt import Attachment, Prompt\nfrom ragbits.core.llms.litellm import LiteLLM\n\nclass QuestionWithOptionalPhotoInput(BaseModel):\n    \"\"\"\n    Input model that optionally includes a photo.\n    \"\"\"\n    question: str\n    reference_photo: Attachment | None = None\n\n\nclass QuestionWithPhotoPrompt(Prompt[QuestionWithOptionalPhotoInput]):\n    \"\"\"\n    A prompt that considers whether a photo is provided.\n    \"\"\"\n\n    system_prompt = \"\"\"\n    You are a knowledgeable assistant providing detailed answers.\n    If a photo is provided, use it as a reference for your response.\n    \"\"\"\n\n    user_prompt = \"\"\"\n    User asked: {{ question }}\n    {% if reference_photo %}\n    Here is a reference photo: {{ reference_photo }}\n    {% else %}\n    No photo was provided.\n    {% endif %}\n    \"\"\"\n\n\nasync def main():\n    llm = LiteLLM(\"gpt-4o\")\n    input_with_photo = QuestionWithOptionalPhotoInput(\n        question=\"What animal do you see in this photo?\", reference_photo=Attachment(data=b\"&lt;your_photo_here&gt;\")\n    )\n    input_without_photo = QuestionWithOptionalPhotoInput(question=\"What is the capital of France?\")\n\n    print(await llm.generate(QuestionWithPhotoPrompt(input_with_photo)))\n    print(await llm.generate(QuestionWithPhotoPrompt(input_without_photo)))\n\n\nasyncio.run(main())\n</code></pre>"},{"location":"how-to/prompts/use_prompting/","title":"How-To: Define and use prompts with Ragbits","text":"<p>This guide will walk you through defining and using prompts in Ragbits, including configuring input and output data types, creating custom output parsers, and passing images to a prompt.</p>"},{"location":"how-to/prompts/use_prompting/#how-to-define-a-prompt","title":"How to Define a Prompt","text":""},{"location":"how-to/prompts/use_prompting/#static-prompt-without-an-input-model","title":"Static Prompt Without an Input Model","text":"<p>To define a static prompt without an input model, you can create a subclass of the <code>Prompt</code> class and provide the <code>user_prompt</code> attribute.</p> <p><pre><code>from ragbits.core.prompt import Prompt\n\n\nclass JokePrompt(Prompt):\n    \"\"\"\n    A prompt that generates jokes.\n    \"\"\"\n\n    system_prompt = \"\"\"\n    You are a joke generator. The jokes you generate should be funny and not offensive.\n    \"\"\"\n\n    user_prompt = \"\"\"Tell me a joke.\"\"\"\n</code></pre> Passing the prompt to a model is as simple as: <pre><code>import asyncio\nfrom ragbits.core.llms.litellm import LiteLLM\n\nasync def main():\n    llm = LiteLLM(\"gpt-4o-2024-08-06\", use_structured_output=True)\n    static_prompt = JokePrompt()\n    print(await llm.generate(static_prompt))\n\nasyncio.run(main())\n</code></pre></p> <p>Tip</p> <p>Prompts also support history in OpenAI Chat Format, try <code>JokePrompt(history=[{\"role\": \"assistant\", \"content\": \"What you call a cute door?/n A-door-able\"}])</code></p>"},{"location":"how-to/prompts/use_prompting/#extending-the-prompt-with-an-input-model","title":"Extending the Prompt with an Input Model","text":"<p>To extend the prompt with an input model, define a Pydantic model for the input data and pass it as a generic type to the <code>Prompt</code> class. The output type defaults to string.</p> <p>Let's use a RAG example as a case study:</p> <pre><code>import asyncio\nfrom pydantic import BaseModel\n\nfrom ragbits.core.prompt import Prompt\nfrom ragbits.core.llms.litellm import LiteLLM\n\n\nclass QueryWithContext(BaseModel):\n    \"\"\"\n    Input format for the QueryWithContext.\n    \"\"\"\n\n    query: str\n    context: list[str]\n\n\nclass RAGPrompt(Prompt[QueryWithContext]):\n    \"\"\"\n    A simple prompt for RAG system.\n    \"\"\"\n\n    system_prompt = \"\"\"\n    You are a helpful assistant. Answer the QUESTION that will be provided using CONTEXT.\n    If in the given CONTEXT there is not enough information refuse to answer.\n    \"\"\"\n\n    user_prompt = \"\"\"\n    QUESTION:\n    {{ query }}\n\n    CONTEXT:\n    {% for item in context %}\n        {{ item }}\n    {% endfor %}\n    \"\"\"\n\n\nasync def main():\n    llm = LiteLLM()\n    query = \"Write down names of last two world cup winners\"\n    context = [\"Today is November 2017\", \"Germany won 2014 world cup\", \"Spain won 2010 world cup\"]\n    prompt = RAGPrompt(QueryWithContext(query=query, context=context))\n    response = await llm.generate(prompt)\n    print(response)\n\n\nasyncio.run(main())\n</code></pre> <p>After succesful execution console should something like:</p> <pre><code>The last two World Cup winners as of November 2017 are Germany (2014) and Spain (2010).\n</code></pre>"},{"location":"how-to/prompts/use_prompting/#how-to-configure-prompts-output-data-type","title":"How to configure <code>Prompt</code>'s output data type","text":""},{"location":"how-to/prompts/use_prompting/#defining-output-as-a-pydantic-model","title":"Defining output as a Pydantic Model","text":"<p>You can define the output of a prompt as a Pydantic model by specifying the output type as a generic parameter. However, note that not all llm models support output schema definition. To use this feature effectively, you must set the <code>use_structured_output=True</code> flag when initializing the LLM. If this flag is not used, you will need to ensure that the JSON schema of your data model is incorporated into the prompt.</p> <p>Let\u2019s revisit the previous example, making one adjustment: this time, we will define a structured output format.</p> <pre><code>import asyncio\nfrom pydantic import BaseModel\n\nfrom ragbits.core.prompt import Prompt\nfrom ragbits.core.llms.litellm import LiteLLM\n\n\nclass QueryWithContext(BaseModel):\n    \"\"\"\n    Input format for the QueryWithContext.\n    \"\"\"\n\n    query: str\n    context: list[str]\n\n\nclass OutputSchema(BaseModel):\n    last: str\n    previous: str\n\n\nclass RAGPrompt(Prompt[QueryWithContext, OutputSchema]):\n    \"\"\"\n    A simple prompt for RAG system.\n    \"\"\"\n\n    system_prompt = \"\"\"\n    You are a helpful assistant. Answer the QUESTION that will be provided using CONTEXT.\n    If in the given CONTEXT there is not enough information refuse to answer.\n    \"\"\"\n\n    user_prompt = \"\"\"\n    QUESTION:\n    {{ query }}\n\n    CONTEXT:\n    {% for item in context %}\n        {{ item }}\n    {% endfor %}\n    \"\"\"\n\n\nasync def main():\n    llm = LiteLLM(model_name=\"gpt-4o-2024-08-06\", use_structured_output=True)\n    query = \"Write down names of last two world cup winners\"\n    context = [\"Today is November 2017\", \"Germany won 2014 world cup\", \"Spain won 2010 world cup\"]\n    prompt = RAGPrompt(QueryWithContext(query=query, context=context))\n    response = await llm.generate(prompt)\n    print(response)\n\n\nasyncio.run(main())\n</code></pre> <p>After succesful execution console should display:</p> <pre><code>last='Germany' previous='Spain'\n</code></pre>"},{"location":"how-to/prompts/use_prompting/#configuring-output-as-a-simple-type","title":"Configuring output as a simple type","text":"<p>You can configure the ouput as a simple type, such as <code>bool</code>, <code>int</code> or <code>float</code>. In order for those parsers to execute properly you would need to force the model with the prompt that you pass to generate raw response in a format that can be converted to numeric type (for <code>int</code> and <code>float</code>) or some finite set of words (the example below shows exact values) that are interpreted as bool. If those conditions are not met <code>ragbits.core.prompt.parsers.ResponseParsingError</code> would be raised</p> <pre><code>import asyncio\n\nfrom pydantic import BaseModel\n\nfrom ragbits.core.llms.litellm import LiteLLM\nfrom ragbits.core.prompt import Prompt\nfrom ragbits.core.prompt.parsers import ResponseParsingError\n\n\nclass RoleInput(BaseModel):\n    role: str\n\n\nclass BooleanPrompt(Prompt[RoleInput, bool]):\n    user_prompt = (\"Are you {{ role }}? Answer 'yes' or 'no' only.\"\n        \"Do not provide any other additional information - just a single word\"\n                   )\n\ndef assert_responses(boolean_prompt: BooleanPrompt) -&gt; None:\n    # all allowed values parsed to true\n    for s in [\"true\", \"1\", \"yes\", \"y\", \"TRUE\", \"YES\"]:\n        assert boolean_prompt.parse_response(s)\n    # all allowed values parsed to false\n    for s in [\"false\", \"0\", \"no\", \"n\", \"FALSE\", \"NO\"]:\n        assert not boolean_prompt.parse_response(s)\n\nasync def main():\n    llm = LiteLLM()\n    boolean_prompt = BooleanPrompt(RoleInput(role=\"a human\"))\n    assert_responses(boolean_prompt)\n    try:\n        gen = await llm.generate(prompt=boolean_prompt)\n    except ResponseParsingError as e:\n        print(f\"Failed to parse response: {e}\")\n    print(gen)\n\n\nasyncio.run(main())\n</code></pre>"},{"location":"how-to/prompts/use_prompting/#how-to-create-a-custom-output-parser-for-a-prompt","title":"How to create a custom output parser for a <code>Prompt</code>","text":"<p>The limitiations described above can be handled by creating a custom parser. The example below will show you how:</p> <pre><code>import asyncio\nimport re\nfrom pydantic import BaseModel\n\nfrom ragbits.core.llms.litellm import LiteLLM\nfrom ragbits.core.prompt import Prompt\n\n\nclass ItemInput(BaseModel):\n    items: str\n\n\nclass IntegerPrompt(Prompt[ItemInput, int]):\n    system_prompt = \"Respond to user as quantitive analytics bot\"\n    user_prompt = \"How many {{ items }}\"\n\n    @staticmethod\n    def response_parser(response: str) -&gt; int:\n        print(response)\n        all_integers = re.findall(r\"\\b\\d+\\b\", response)\n        if len(all_integers) &gt; 0:\n            return all_integers[0]\n        return -1\n\n\nasync def main():\n    llm = LiteLLM()\n    prompt = IntegerPrompt(ItemInput(items=\"people do live in Raglandia?\"))\n    response = await llm.generate(prompt=prompt)\n    print(response)\n\n\nasyncio.run(main())\n</code></pre>"},{"location":"how-to/sources/google-drive/","title":"How-To: Setup and Query Google Drive Source","text":"<p>This guide shows you how to set up and use Google Drive as a source in Ragbits, including downloading files and folders from Google Drive.</p>"},{"location":"how-to/sources/google-drive/#prerequisites-setup","title":"Prerequisites Setup","text":""},{"location":"how-to/sources/google-drive/#1-enable-google-drive-api","title":"1. Enable Google Drive API","text":"<p>First, you need to enable the Google Drive API in your Google Cloud project:</p> <ol> <li>Go to the Google Cloud Console</li> <li>Select your project (or create a new one)</li> <li>Navigate to APIs &amp; Services &gt; Library</li> <li>Search for \"Google Drive API\"</li> <li>Click on \"Google Drive API\" and click Enable</li> </ol>"},{"location":"how-to/sources/google-drive/#2-create-a-service-account","title":"2. Create a Service Account","text":"<p>To authenticate with Google Drive programmatically, you'll need a service account:</p> <ol> <li>In Google Cloud Console, go to IAM &amp; Admin &gt; Service Accounts</li> <li>Click Create Service Account</li> <li>Enter a name (e.g., \"ragbits-google-drive\")</li> <li>Add a description (optional)</li> <li>Click Create and Continue</li> <li>Skip role assignment for now (click Continue)</li> <li>Click Done</li> </ol>"},{"location":"how-to/sources/google-drive/#3-generate-service-account-key","title":"3. Generate Service Account Key","text":"<p>Now you need to create and download the JSON credentials file:</p> <ol> <li>In the Service Accounts list, click on your newly created service account</li> <li>Go to the Keys tab</li> <li>Click Add Key &gt; Create new key</li> <li>Select JSON format</li> <li>Click Create</li> <li>The JSON file will be downloaded automatically</li> <li>Save this file securely (e.g., as <code>service-account-key.json</code>)</li> </ol> <p>Security Note</p> <p>Keep your service account key file secure and never commit it to version control. Consider using environment variables or secure secret management.</p>"},{"location":"how-to/sources/google-drive/#4-grant-access-to-google-drive-filesfolders","title":"4. Grant Access to Google Drive Files/Folders","text":"<p>Since the service account is not a regular user, you need to share the Google Drive files or folders with the service account:</p> <ol> <li>Open the JSON key file and copy the <code>client_email</code> value (it looks like <code>your-service@project.iam.gserviceaccount.com</code>)</li> <li>In Google Drive, right-click on the file or folder you want to access</li> <li>Click Share</li> <li>Paste the service account email and set permissions (Viewer is sufficient for reading)</li> <li>Click Send</li> </ol>"},{"location":"how-to/sources/google-drive/#basic-usage","title":"Basic Usage","text":""},{"location":"how-to/sources/google-drive/#setting-up-credentials","title":"Setting Up Credentials","text":"<pre><code>from ragbits.core.sources.google_drive import GoogleDriveSource\n\n# Set the path to your service account key file\nGoogleDriveSource.set_credentials_file_path(\"path/to/service-account-key.json\")\n</code></pre>"},{"location":"how-to/sources/google-drive/#example-download-files-from-google-drive","title":"Example: Download Files from Google Drive","text":"<pre><code>import asyncio\nfrom ragbits.core.sources.google_drive import GoogleDriveSource\n\nasync def download_google_drive_files():\n    # Set credentials file path\n    GoogleDriveSource.set_credentials_file_path(\"service-account-key.json\")\n\n    # Example 1: Download a single file by ID\n    file_id = \"1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms\"  # Example Google Sheets ID\n    sources = await GoogleDriveSource.from_uri(file_id)\n\n    for source in sources:\n        if not source.is_folder:\n            local_path = await source.fetch()\n            print(f\"Downloaded: {source.file_name} to {local_path}\")\n\n    # Example 2: Download all files from a folder (non-recursive)\n    folder_id = \"1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms\"\n    sources = await GoogleDriveSource.from_uri(f\"{folder_id}/*\")\n\n    for source in sources:\n        if not source.is_folder:\n            local_path = await source.fetch()\n            print(f\"Downloaded: {source.file_name} to {local_path}\")\n\n    # Example 3: Download all files recursively from a folder\n    sources = await GoogleDriveSource.from_uri(f\"{folder_id}/**\")\n\n    for source in sources:\n        if not source.is_folder:\n            try:\n                local_path = await source.fetch()\n                print(f\"Downloaded: {source.file_name} to {local_path}\")\n            except Exception as e:\n                print(f\"Failed to download {source.file_name}: {e}\")\n\n# Run the example\nasyncio.run(download_google_drive_files())\n</code></pre>"},{"location":"how-to/sources/google-drive/#uri-patterns","title":"URI Patterns","text":"<p>The Google Drive source supports several URI patterns:</p> Pattern Description Example <code>&lt;file_id&gt;</code> Single file or folder by ID <code>1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms</code> <code>&lt;folder_id&gt;/*</code> All files directly in folder <code>1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/*</code> <code>&lt;folder_id&gt;/&lt;prefix&gt;*</code> Files in folder starting with prefix <code>1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/report*</code> <code>&lt;folder_id&gt;/**</code> All files recursively in folder <code>1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/**</code>"},{"location":"how-to/sources/google-drive/#environment-variables","title":"Environment Variables","text":"<p>You can also set up credentials using environment variables:</p> <pre><code># Set the service account key as JSON string\nexport GOOGLE_DRIVE_CLIENTID_JSON='{\"type\": \"service_account\", \"project_id\": \"...\", ...}'\n\n# Or set the path to the key file\nexport GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/service-account-key.json\"\n</code></pre>"},{"location":"how-to/sources/google-drive/#advanced-example-processing-documents","title":"Advanced Example: Processing Documents","text":"<pre><code>import asyncio\nfrom ragbits.core.sources.google_drive import GoogleDriveSource\n\nasync def process_drive_documents():\n    \"\"\"Example of processing documents from Google Drive.\"\"\"\n\n    # Set up credentials\n    GoogleDriveSource.set_credentials_file_path(\"service-account-key.json\")\n\n    # Define the folder containing documents\n    documents_folder_id = \"your-folder-id-here\"\n\n    try:\n        # Get all files from the folder recursively\n        sources = await GoogleDriveSource.from_uri(f\"{documents_folder_id}/**\")\n\n        processed_count = 0\n        skipped_count = 0\n\n        for source in sources:\n            if source.is_folder:\n                print(f\"Skipping folder: {source.file_name}\")\n                continue\n\n            # Filter by file type (example: only process text and document files)\n            if source.mime_type in [\n                'text/plain',\n                'application/pdf',\n                'application/vnd.google-apps.document',\n                'application/vnd.openxmlformats-officedocument.wordprocessingml.document'\n            ]:\n                try:\n                    local_path = await source.fetch()\n                    print(f\" Processed: {source.file_name} (Type: {source.mime_type})\")\n\n                    # Here you could add your document processing logic\n                    # For example: extract text, analyze content, etc.\n\n                    processed_count += 1\n                except Exception as e:\n                    print(f\" Failed to process {source.file_name}: {e}\")\n            else:\n                print(f\"  Skipped: {source.file_name} (Type: {source.mime_type})\")\n                skipped_count += 1\n\n        print(f\"\\n Summary:\")\n        print(f\"   Processed: {processed_count} files\")\n        print(f\"   Skipped: {skipped_count} files\")\n\n    except Exception as e:\n        print(f\"Error accessing Google Drive: {e}\")\n\n# Run the example\nasyncio.run(process_drive_documents())\n</code></pre>"},{"location":"how-to/sources/google-drive/#impersonating-google-accounts","title":"Impersonating Google Accounts","text":"<p>You can configure your Google service account to impersonate other users in your Google Workspace domain. This is useful when you need to access files or perform actions on behalf of specific users.</p>"},{"location":"how-to/sources/google-drive/#step-1-enable-domain-wide-delegation","title":"Step 1: Enable Domain-Wide Delegation","text":"<ol> <li>Sign in to the Google Admin Console as a Super Admin.</li> <li>Navigate to:     Security &gt; Access and data control &gt; API controls &gt; MANAGE DOMAIN WIDE DELEGATION</li> <li>Add a new API client or edit an existing one, and include the following OAuth scopes:<ul> <li><code>https://www.googleapis.com/auth/cloud-platform</code></li> <li><code>https://www.googleapis.com/auth/drive</code></li> </ul> </li> <li>Click Authorize or Save to apply the changes.</li> </ol>"},{"location":"how-to/sources/google-drive/#step-2-impersonate-a-user-in-your-code","title":"Step 2: Impersonate a User in Your Code","text":"<p>After configuring domain-wide delegation, you can specify a target user to impersonate when using the <code>GoogleDriveSource</code> in your code.</p> <pre><code>from ragbits.core.sources.google_drive import GoogleDriveSource\n\ntarget_email = \"johnDoe@yourdomain.com\"\ncredentials_file = \"service-account-key.json\"\n\n# Set the path to your service account key file\nGoogleDriveSource.set_credentials_file_path(credentials_file)\n\n# Set the email address of the user to impersonate\nGoogleDriveSource.set_impersonation_target(target_email)\n</code></pre> <p>Note: - The <code>target_email</code> must be a valid user in your Google Workspace domain. - Ensure your service account has been granted domain-wide delegation as described above.</p> <p>This setup allows your service account to act on behalf of the specified user, enabling access to their Google Drive files and resources as permitted by the assigned scopes.</p>"},{"location":"how-to/sources/google-drive/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to/sources/google-drive/#common-issues","title":"Common Issues","text":"<ol> <li> <p>\"Service account info was not in the expected format\"</p> <ul> <li>Make sure you're using a service account key file, not OAuth2 client credentials</li> <li>Verify the JSON file contains required fields: <code>client_email</code>, <code>private_key</code>, <code>token_uri</code></li> </ul> </li> <li> <p>\"File not found\" or \"Permission denied\"</p> <ul> <li>Ensure the file/folder is shared with your service account email</li> <li>Check that the file ID is correct</li> <li>Verify the service account has at least \"Viewer\" permissions</li> </ul> </li> <li> <p>\"Google Drive API not enabled\"</p> <ul> <li>Enable the Google Drive API in Google Cloud Console</li> <li>Wait a few minutes for the API to be fully activated</li> </ul> </li> <li> <p>\"Quota exceeded\"</p> <ul> <li>Google Drive API has usage limits</li> <li>Implement rate limiting in your code</li> <li>Consider upgrading your Google Cloud quotas if needed</li> </ul> </li> <li> <p>\"Export size limit exceeded\"</p> <ul> <li>Google Workspace files (Docs, Sheets, etc.) have a 9MB export limit</li> <li>Large Google Workspace files may fail to download</li> <li>Consider splitting large documents or using alternative export methods</li> </ul> </li> </ol>"},{"location":"how-to/sources/google-drive/#getting-filefolder-ids","title":"Getting File/Folder IDs","text":"<p>You can find Google Drive file or folder IDs in several ways:</p> <ol> <li> <p>From the URL: When viewing a file in Google Drive, the ID is in the URL:    <pre><code>https://drive.google.com/file/d/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/view\n                                ^--- This is the file ID ---^\n</code></pre></p> </li> <li> <p>Right-click method: Right-click \u2192 \"Get link\" \u2192 Extract ID from the shareable link</p> </li> <li> <p>Programmatically: Use the Google Drive API to search and list files</p> </li> </ol>"},{"location":"how-to/sources/google-drive/#configuration-options","title":"Configuration Options","text":""},{"location":"how-to/sources/google-drive/#local-storage-directory","title":"Local Storage Directory","text":"<p>By default, downloaded files are stored in a temporary directory. You can customize this:</p> <pre><code>import os\n\n# Set custom download directory\nos.environ[\"LOCAL_STORAGE_DIR\"] = \"/path/to/your/download/directory\"\n</code></pre>"},{"location":"how-to/sources/google-drive/#supported-file-types","title":"Supported File Types","text":"<p>The Google Drive source automatically handles various file types:</p> <ul> <li>Google Workspace files: Automatically exported to common formats (Docs \u2192 DOCX, Sheets \u2192 XLSX, etc.)</li> <li>Regular files: Downloaded as-is</li> <li>Large files: Handled with resumable downloads for reliability</li> </ul> <p>File Size Limitations</p> <p>Google Workspace files (Google Docs, Sheets, Slides, etc.) have a 9MB export limit when converting to standard formats (DOCX, XLSX, PPTX). Files larger than this limit may fail to download. For large documents, consider:</p> <ul> <li>Breaking them into smaller documents</li> <li>Using Google's native format instead of exporting</li> <li>Accessing them directly through the Google Workspace APIs</li> </ul>"},{"location":"how-to/sources/google-drive/#best-practices","title":"Best Practices","text":"<ol> <li>Security: Store service account keys securely and rotate them regularly</li> <li>Permissions: Use the principle of least privilege - only grant necessary permissions</li> <li>Error Handling: Always implement proper error handling for network and API failures</li> <li>Rate Limiting: Respect Google Drive API quotas and implement appropriate delays</li> <li>Monitoring: Log operations for debugging and monitoring purposes</li> </ol>"},{"location":"how-to/sources/load-dataset/","title":"How-To: Load dataset from sources","text":"<p>Ragbits provides an abstraction for handling datasets. The <code>Source</code> component is designed to define interactions with any data source, such as downloading and querying.</p>"},{"location":"how-to/sources/load-dataset/#supported-sources","title":"Supported sources","text":"<p>This is the list of currently supported sources by Ragbits.</p> Source URI Schema Class Azure Blob Storage <code>azure://https://&lt;account-name&gt;.blob.core.windows.net/&lt;container-name&gt;/&lt;blob-name&gt;</code> <code>AzureBlobStorageSource</code> Google Cloud Storage <code>gcs://&lt;bucket-name&gt;/&lt;prefix&gt;</code> <code>GCSSource</code> Google Drive <code>&lt;drive-id&gt;</code> <code>GoogleDriveSource</code> Git <code>git://&lt;https-url&gt;|&lt;ssh-url&gt;</code> <code>GitSource</code> Hugging Face <code>hf://&lt;dataset-path&gt;/&lt;split&gt;/&lt;row&gt;</code> <code>HuggingFaceSource</code> Local file <code>local://&lt;file-path&gt;|&lt;blob-pattern&gt;</code> <code>LocalFileSource</code> Amazon S3 <code>s3://&lt;bucket-name&gt;/&lt;prefix&gt;</code> <code>S3Source</code> Web <code>web://&lt;https-url&gt;</code> <code>WebSource</code>"},{"location":"how-to/sources/load-dataset/#custom-source","title":"Custom source","text":"<p>To define a new sources, extend the <code>Source</code> class.</p> <pre><code>from ragbits.core.sources import Source\n\n\nclass CustomSource(Source):\n    \"\"\"\n    Source that downloads file from the web.\n    \"\"\"\n\n    protocol: ClassVar[str] = \"custom\"\n    source_url: str\n    ...\n\n    @property\n    def id(self) -&gt; str:\n        \"\"\"\n        Get the source identifier.\n        \"\"\"\n        return f\"{self.protocol}:{self.source_url}\"\n\n    async def fetch(self) -&gt; Path:\n        \"\"\"\n        Download a file for the given url.\n\n        Returns:\n            The local path to the downloaded file.\n        \"\"\"\n        ...\n        return Path(f\"/tmp/{self.source_url}\")\n\n    @classmethod\n    async def list_sources(cls, source_url: str) -&gt; Iterable[Self]:\n        \"\"\"\n        List all sources from the given storage.\n\n        Args:\n            source_url: The source url to list sources from.\n\n        Returns:\n            The iterable of Source objects.\n        \"\"\"\n        ...\n        return [cls(...), ...]\n\n    @classmethod\n    async def from_uri(cls, uri: str) -&gt; Iterable[Self]:\n        \"\"\"\n        Create source instances from a URI path.\n\n        Args:\n            uri: The URI path.\n\n        Returns:\n            The iterable of Source objects matching the path pattern.\n        \"\"\"\n        ...\n        return await self.list_sources(...)\n</code></pre> <p>Hint</p> <p>To use a custom source via the CLI, make sure that the custom source class is registered in <code>pyproject.toml</code>. You can find information on how to do this here.</p>"},{"location":"how-to/vector_stores/hybrid/","title":"How to Perform Hybrid Search with Multiple Vector Stores","text":"<p>Ragbits comes with a special type of vector store called <code>HybridSearchVectorStore</code>, which allows you to combine multiple vector stores into a single search index. It acts as a single vector store but internally manages querying and updating multiple vector stores during operations like storing, searching, and deleting entries.</p> <p>The main use cases for using a hybrid vector store are:</p> <ul> <li>Combining Different Modalities: You can combine multiple vector stores that store different types of data, like text and images. This allows you to store multiple modality-specific vectors for the same entry (for example, an image embedding and a text embedding of a description of the image) and search them together.</li> <li>Combining Different Types of Embeddings: You can combine multiple vector stores that store different types of embeddings, like dense and sparse embeddings. This allows you to store multiple embeddings for the same entry and search them simultaneously.</li> </ul>"},{"location":"how-to/vector_stores/hybrid/#using-a-hybrid-vector-store-with-different-modalities","title":"Using a Hybrid Vector Store with Different Modalities","text":"<p>To create a hybrid vector store, you need to pass a list of vector stores to the constructor of the <code>HybridSearchVectorStore</code> class. For example, this creates two in-memory vector stores\u2014one for text and one for images:</p> <pre><code>from ragbits.core.vector_stores.hybrid import HybridSearchVectorStore\nfrom ragbits.core.vector_stores.in_memory import InMemoryVectorStore\nfrom ragbits.core.embeddings.dense.vertex_multimodal import VertexAIMultimodelEmbedder\n\nembedder = VertexAIMultimodelEmbedder()\n\nvector_store_text = InMemoryVectorStore(embedder=embedder, embedding_type=EmbeddingType.TEXT)\nvector_store_image = InMemoryVectorStore(embedder=embedder, embedding_type=EmbeddingType.IMAGE)\n\nvector_store_hybrid = HybridSearchVectorStore(vector_store_text, vector_store_image)\n</code></pre> <p>You can then use the <code>vector_store_hybrid</code> object to store, search, and delete entries, just as you would use a regular vector store, or pass it to Ragbits' Document Search. When you store an entry in the hybrid vector store, it will be stored in all the vector stores it contains. In this case, one will store the text embedding and the other will store the image embedding.</p>"},{"location":"how-to/vector_stores/hybrid/#using-a-hybrid-vector-store-with-different-types-of-embeddings","title":"Using a Hybrid Vector Store with Different Types of Embeddings","text":"<p>You can create a hybrid vector store with different types of embeddings, including combining dense and sparse embeddings for improved search performance. Here's an example that creates two in-memory vector stores\u2014one using a dense embedder and one using a sparse embedder:</p> <pre><code>from ragbits.core.vector_stores.hybrid import HybridSearchVectorStore\nfrom ragbits.core.vector_stores.in_memory import InMemoryVectorStore\nfrom ragbits.core.embeddings.dense import LiteLLMEmbedder\nfrom ragbits.core.embeddings.sparse.fastembed import FastEmbedSparseEmbedder\n\n# Create a dense vector store using OpenAI embeddings\nvector_store_dense = InMemoryVectorStore(\n    embedder=LiteLLMEmbedder(model=\"text-embedding-3-small\")\n)\n\n# Create a sparse vector store using sparse embeddings\nvector_store_sparse = InMemoryVectorStore(\n    embedder=FastEmbedSparseEmbedder(model_name=\"prithivida/Splade_PP_en-distil-cocodenser-retriever\")\n)\n\n# Combine them into a hybrid search vector store\nvector_store_hybrid = HybridSearchVectorStore(vector_store_dense, vector_store_sparse)\n</code></pre> <p>You can then use the <code>vector_store_hybrid</code> object to store, search, and delete entries, just as you would use a regular vector store, or pass it to Ragbits' Document Search. When you store an entry in the hybrid vector store, it will be stored in all the vector stores it contains. In this case, one will store the dense embedding and the other will store the sparse embedding.</p> <p>For more details about using sparse vectors with vector stores, see How to Use Sparse Vectors with Vector Stores.</p> <p>Note that you can pass an arbitrary number of vector stores to the <code>HybridSearchVectorStore</code> constructor, and they can be of any type as long as they implement the <code>VectorStore</code> interface. For example, this combines three vector stores\u2014one Chroma vector store, one Qdrant vector store, and one PgVector vector store:</p> <pre><code>import asyncpg\nfrom chromadb import EphemeralClient\nfrom qdrant_client import AsyncQdrantClient\n\nfrom ragbits.core.vector_stores.hybrid import HybridSearchVectorStore\nfrom ragbits.core.vector_stores.chroma import ChromaVectorStore\nfrom ragbits.core.vector_stores.qdrant import QdrantVectorStore\nfrom ragbits.core.vector_stores.pgvector import PgVectorStore\nfrom ragbits.core.embeddings.dense import LiteLLMEmbedder\n\npostgres_pool = await asyncpg.create_pool(\"postgresql://user:password@localhost/db\")\n\nvector_store_hybrid = HybridSearchVectorStore(\n    ChromaVectorStore(\n        client=EphemeralClient(),\n        index_name=\"chroma_example\",\n        embedder=LiteLLMEmbedder(),\n    ),\n    QdrantVectorStore(\n        client=AsyncQdrantClient(location=\":memory:\"),\n        index_name=\"qdrant_example\",\n        embedder=LiteLLMEmbedder(),\n    ),\n    PgVectorStore(\n        client=pool,\n        table_name=\"postgres_example\",\n        vector_size=1536,\n        embedder=LiteLLMEmbedder(),\n    ),\n)\n\n# The entry will be stored in all three vector stores\nawait vector_store_hybrid.store([VectorStoreEntry(id=uuid.uuid4(), text=\"Example entry\")])\n</code></pre>"},{"location":"how-to/vector_stores/hybrid/#specifying-the-retrieval-strategy-for-a-hybrid-vector-store","title":"Specifying the Retrieval Strategy for a Hybrid Vector Store","text":"<p>When you search a hybrid vector store, you can specify a retrieval strategy to determine how the results from the different vector stores are combined. Ragbits comes with the following retrieval strategies:</p> <ul> <li><code>OrderedHybridRetrivalStrategy</code>: This strategy returns the results from the vector stores ordered by their score. If the same entry is found in multiple vector stores, either the highest score is used or if the <code>sum_scores</code> parameter is set to <code>True</code>, the scores are summed. This is the default strategy.</li> <li><code>ReciprocalRankFusion</code>: This strategy combines the results from the vector stores using the Reciprocal Rank Fusion algorithm, which prioritizes entries that appear at the top of the results from individual vector stores. If the same entry is found in multiple vector stores, the scores are summed by default, or if the <code>sum_scores</code> parameter is set to <code>False</code>, the highest score is used.</li> <li><code>DistributionBasedScoreFusion</code>: This strategy combines the results from the vector stores using the Distribution-Based Score Fusion algorithm, which normalizes the scores from the individual vector stores so they can be compared and combined sensibly. If the same entry is found in multiple vector stores, either the highest score is used or if the <code>sum_scores</code> parameter is set to <code>True</code>, the scores are summed.</li> </ul> <p>Note that summing the scores from individual stores boosts the entries found in multiple stores. This can be useful when searching through multiple types of embeddings but may not be desirable when searching through multiple modalities since entries containing both text and image embeddings would have an advantage over those containing only one.</p> <p>To specify a retrieval strategy when searching a hybrid vector store, you can pass it as the <code>retrieval_strategy</code> parameter to the constructor of the <code>HybridSearchVectorStore</code> class. For example, this creates a hybrid vector store with the <code>DistributionBasedScoreFusion</code> retrieval strategy:</p> <pre><code>from ragbits.core.vector_stores.hybrid import HybridSearchVectorStore\nfrom ragbits.core.vector_stores.in_memory import InMemoryVectorStore\nfrom ragbits.core.vector_stores.hybrid_strategies import DistributionBasedScoreFusion\nfrom ragbits.core.embeddings.dense import LiteLLMEmbedder\n\nembedder = LiteLLMEmbedder()\n\nvector_store_text = InMemoryVectorStore(embedder=embedder, embedding_type=EmbeddingType.TEXT)\nvector_store_image = InMemoryVectorStore(embedder=embedder, embedding_type=EmbeddingType.IMAGE)\n\nvector_store_hybrid = HybridSearchVectorStore(\n    vector_store_text,\n    vector_store_image,\n    retrieval_strategy=DistributionBasedScoreFusion(),\n)\n</code></pre>"},{"location":"how-to/vector_stores/sparse_vectors/","title":"How to Use Sparse Vectors with Vector Stores","text":"<p>Sparse embeddings are a representation technique where only non-zero values of a vector are stored along with their indices. This is in contrast to dense embeddings, where all values in the vector are stored regardless of whether they're zero or not. Ragbits supports sparse embeddings through the <code>SparseVector</code> and <code>SparseEmbedder</code> classes.</p>"},{"location":"how-to/vector_stores/sparse_vectors/#benefits-of-sparse-vectors","title":"Benefits of Sparse Vectors","text":"<p>Sparse vectors offer several advantages in certain use cases:</p> <ol> <li>Memory efficiency: By storing only non-zero values, sparse vectors can be much more memory-efficient when the vast majority of values in a vector are zeros.</li> <li>Interpretability: Sparse vectors often have better interpretability as each dimension can correspond to a specific token or feature.</li> <li>Complementary to dense vectors: When used in hybrid search alongside dense vectors, sparse vectors can improve recall by capturing different aspects of similarity.</li> <li>Term-weighting: Sparse vectors can directly represent term frequencies or TF-IDF weights, making them useful for lexical search.</li> </ol>"},{"location":"how-to/vector_stores/sparse_vectors/#supported-vector-stores","title":"Supported Vector Stores","text":"<p>Currently, Ragbits supports sparse embeddings with the following vector stores:</p> <ul> <li>InMemoryVectorStore: For quick testing and small-scale use cases</li> <li>QdrantVectorStore: For production use cases with the Qdrant vector database</li> </ul>"},{"location":"how-to/vector_stores/sparse_vectors/#creating-a-sparse-embedder","title":"Creating a Sparse Embedder","text":"<p>Ragbits provides several implementations of <code>SparseEmbedder</code>:</p> <ol> <li>BagOfTokens: A simple implementation that creates sparse vectors based on token counts</li> <li>FastEmbedSparseEmbedder: Uses the FastEmbed library for efficient sparse embedding generation</li> </ol> <p>Here's an example of creating a sparse embedder using BagOfTokens:</p> <pre><code>from ragbits.core.embeddings.sparse import BagOfTokens, BagOfTokensOptions\n\n# Create a sparse embedder that uses GPT-4 tokenizer\nsparse_embedder = BagOfTokens(\n    default_options=BagOfTokensOptions(\n        model_name=\"gpt-4\",  # which model to tokenize for\n        min_token_count=2\n    )\n)\n</code></pre> <p>Or using FastEmbedSparseEmbedder:</p> <pre><code>from ragbits.core.embeddings.sparse.fastembed import FastEmbedSparseEmbedder, FastEmbedOptions\n\n# Create a sparse embedder using FastEmbed\nsparse_embedder = FastEmbedSparseEmbedder(model_name=\"prithivida/Splade_PP_en-distil-cocodenser-retriever\")\n</code></pre>"},{"location":"how-to/vector_stores/sparse_vectors/#using-sparse-embeddings-with-vector-stores","title":"Using Sparse Embeddings with Vector Stores","text":"<p>You can use sparse embeddings with supported vector stores by simply passing a <code>SparseEmbedder</code> to the vector store constructor:</p>"},{"location":"how-to/vector_stores/sparse_vectors/#in-memory-vector-store","title":"In-Memory Vector Store","text":"<pre><code>from ragbits.core.vector_stores.in_memory import InMemoryVectorStore\nfrom ragbits.core.embeddings.sparse import BagOfTokens\n\n# Create a sparse BagOfTokens embedder with default options\nsparse_embedder = BagOfTokens()\n\n# Create an in-memory vector store with the sparse embedder\nvector_store = InMemoryVectorStore(embedder=sparse_embedder)\n\n# Use the vector store as normal\nawait vector_store.store([VectorStoreEntry(id=uuid.uuid4(), text=\"This is a test entry\")])\nresults = await vector_store.retrieve(\"test query\")\n</code></pre>"},{"location":"how-to/vector_stores/sparse_vectors/#qdrant-vector-store","title":"Qdrant Vector Store","text":"<pre><code>from qdrant_client import AsyncQdrantClient\nfrom qdrant_client.models import Distance\nfrom ragbits.core.vector_stores.qdrant import QdrantVectorStore\nfrom ragbits.core.embeddings.sparse.fastembed import FastEmbedSparseEmbedder, FastEmbedOptions\n\n# Create a sparse embedder\nsparse_embedder = FastEmbedSparseEmbedder(model_name=\"prithivida/Splade_PP_en-distil-cocodenser-retriever\")\n\n# Create a Qdrant vector store with the sparse embedder\nvector_store = QdrantVectorStore(\n    client=AsyncQdrantClient(location=\":memory:\"),\n    index_name=\"sparse_test\",\n    embedder=sparse_embedder,\n    distance_method=Distance.COSINE\n)\n\n# Use the vector store as normal\nawait vector_store.store([VectorStoreEntry(id=uuid.uuid4(), text=\"This is a test entry\")])\nresults = await vector_store.retrieve(\"test query\")\n</code></pre>"},{"location":"how-to/vector_stores/sparse_vectors/#working-with-sparse-vectors-directly","title":"Working with Sparse Vectors Directly","text":"<p>If you need to work with sparse vectors directly, you can use the <code>SparseVector</code> class:</p> <pre><code>from ragbits.core.embeddings.sparse import SparseVector\n\n# Create a sparse vector with non-zero indices and values\nvector = SparseVector(\n    indices=[1, 5, 10],\n    values=[0.5, 0.3, 0.8]\n)\n</code></pre> <p>The vector above represents a very large vector where only positions 1, 5, and 10 have non-zero values (0.5, 0.3, and 0.8 respectively).</p>"},{"location":"how-to/vector_stores/use_pgVector_store/","title":"How-To: Use PostgreSQL as a vector store with pgVector in Ragbits","text":""},{"location":"how-to/vector_stores/use_pgVector_store/#how-to-set-up-pgvector-database-locally","title":"How to set up pgVector database locally","text":"<p>To run a local instance of pgVector, use Docker to pull and start the database container.</p> <ol> <li> <p>Pull the pgVector Docker image <code>bash sudo docker pull pgvector/pgvector:pg17</code></p> </li> <li> <p>Run the PostgreSQL container with pgVector</p> </li> </ol> <pre><code>docker run --name postgres_container \\\n        -p 5432:5432 \\\n        -e POSTGRES_USER=ragbits_user \\\n        -e POSTGRES_PASSWORD=ragbits_password \\\n        -e POSTGRES_DB=ragbits_db \\\n        -d pgvector/pgvector:0.8.0-pg17\n</code></pre> <ul> <li><code>--name</code> the docker container a name assign to postgres.</li> <li><code>-p 5432:5432</code> maps the default PostgreSQL port to the local machine.</li> <li><code>-e POSTGRES_USER=ragbits_user</code> sets the user name of the database</li> <li><code>-e POSTGRES_PASSWORD=ragbits_password</code> example sets the database password.</li> <li><code>-d</code> runs the container in detached mode.</li> </ul> <p>The local instance of pgVector is accessible using the following connection string: <code>DB = \"postgresql://ragbits_user:ragbits_password@localhost:5432/ragbits_db\"</code></p> <p>The database connection string (DB) may vary depending on the deployment setup. If the database is hosted remotely, in the cloud, or configured differently, update the connection string accordingly to match the appropriate host, port, credentials, and database name.</p>"},{"location":"how-to/vector_stores/use_pgVector_store/#how-to-connect-to-pgvector-database-with-ragbits","title":"How to connect to pgVector database with Ragbits","text":"<p>To connect to PostgreSQL, establish a connection pool using asyncpg library.</p> <p>The connection string can be provided directly: <pre><code>import asyncpg\nDB = \"postgresql://ragbits_user:ragbits_password@localhost:5432/ragbits_db\"\nasync def main() -&gt; None:\n    pool = await asyncpg.create_pool(dsn=DB)\n</code></pre> Or specified using individual parameters: <pre><code>import asyncpg\nasync def main() -&gt; None:\n    pool = await asyncpg.create_pool(\n        user=\"ragbits_user\",\n        password=\"ragbits_password\",\n        database=\"ragbits_db\",\n        host=\"localhost\",\n    )\n</code></pre> To ensure proper resource management, you can use asyncpg.create_pool as a context manager: <pre><code>import asyncpg\nDB = \"postgresql://ragbits_user:ragbits_password@localhost:5432/ragbits_db\"\nasync with asyncpg.create_pool(dsn=DB) as pool:\n</code></pre></p> <p>The connection pool created with asyncpg.create_pool will be used to initialize an instance of PgVectorStore.</p> <pre><code>import asyncpg\nfrom ragbits.core.vector_stores.pgvector import PgVectorStore\nfrom ragbits.core.embeddings.dense import LiteLLMEmbedder\nasync def main() -&gt; None:\n  DB = \"postgresql://ragbits_user:ragbits_password@localhost:5432/ragbits_db\"\n  async with asyncpg.create_pool(dsn=DB) as pool:\n    embedder = LiteLLMEmbedder(model=\"text-embedding-3-small\")\n    vector_store = PgVectorStore(embedder=embedder, client=pool, table_name=\"test_table\")\n</code></pre> <p>Note</p> <p>PgVectorStore will automatically determine the vector dimensions from the embedder. If you prefer explicit control or need to override the automatic detection, you can provide the <code>vector_size</code> parameter to PgVectorStore initializer.</p>"},{"location":"how-to/vector_stores/use_pgVector_store/#pgvectorstore-in-ragbits","title":"pgVectorStore in Ragbits","text":"<p>Example: <pre><code>import asyncpg\nimport asyncio\nfrom ragbits.core.vector_stores.base import VectorStoreEntry\nfrom ragbits.core.vector_stores.pgvector import PgVectorStore\nfrom ragbits.core.embeddings.dense import LiteLLMEmbedder\n\nasync def main() -&gt; None:\n  DB = \"postgresql://ragbits_user:ragbits_password@localhost:5432/ragbits_db\"\n  async with asyncpg.create_pool(dsn=DB) as pool:\n    embedder = LiteLLMEmbedder(model=\"text-embedding-3-small\")\n    vector_store = PgVectorStore(embedder=embedder, client=pool, table_name=\"test_table\")\n    data = [VectorStoreEntry(id=\"test_id_1\", text=\"test text 1\",\n            metadata={\"key1\": \"value1\", \"content\": \"test 1\"}),\n            VectorStoreEntry(id=\"test_id_2\", text=\"test text 2\",\n                              metadata={\"key2\": \"value2\", \"content\": \"test 2\"})]\n\n    await vector_store.store(data)\n    all_entries = await vector_store.list()\n    print(\"All entries \", all_entries)\n    list_result = await vector_store.list({\"content\": \"test 1\"})\n    print(\"Entries with  {content: test 1}\", list_result)\n    retrieve_result = await vector_store.retrieve(\"similar test query\")\n    print(\"Entries similar to query\", retrieve_result)\n    await vector_store.remove([\"test_id_1\", \"test_id_2\"])\n    after_remove = await vector_store.list()\n    print(\"Entries after remove \", after_remove)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre></p>"},{"location":"how-to/vector_stores/use_pgVector_store/#pgvectorstore-distance","title":"PgVectorStore distance","text":"<p>One of the <code>PgVectorStore</code> parameters is <code>distance_method</code> - the similarity metric used for vector comparisons. Supported values include:</p> <ul> <li>\"cosine\" (&lt;=&gt;) \u2013 Cosine distance</li> <li>\"l2\" (&lt;-&gt;) \u2013 Euclidean (L2) distance</li> <li>\"l1\" (&lt;+&gt;) \u2013 Manhattan (L1) distance</li> <li>\"ip\" (&lt;#&gt;) \u2013 Inner product</li> <li>\"bit_hamming\" (&lt;~&gt;) \u2013 Hamming distance</li> <li>\"bit_jaccard\" (&lt;%&gt;) \u2013 Jaccard distance</li> <li>\"sparsevec_l2\" (&lt;-&gt;) \u2013 Sparse vector L2 distance</li> <li>\"halfvec_l2\" (&lt;-&gt;) \u2013 Half precision vector L2 distance</li> </ul> <p>The default value for distance method is cosine similarity. See PgVectorStore API for more information about PgVectorStore parameters and methods.</p>"},{"location":"tutorials/agents/","title":"Tutorial: Multi-Agent System with A2A and MCP","text":"<p>Let's build a multi-agent system for automated trip planning with Ragbits. In this tutorial, we'll create:</p> <ol> <li>A Flight Finder Agent that searches for available flights</li> <li>A City Explorer Agent that gathers information about destinations</li> <li>An Orchestrator Agent that coordinates both agents to create comprehensive trip plans</li> </ol> <p>What you'll learn:</p> <ul> <li>How to create specialized agents with tools/function calling</li> <li>How to use the Model Context Protocol (MCP) for external data</li> <li>How to expose agents through Agent-to-Agent (A2A) protocol</li> <li>How to build an orchestrator that manages conversation context</li> </ul>"},{"location":"tutorials/agents/#configuring-the-environment","title":"Configuring the environment","text":"<p>Install the latest Ragbits via <code>pip install -U ragbits[a2a,mcp]</code> to follow along.</p> <p>During development, we will use OpenAI's <code>gpt-4.1</code> model. To authenticate, Ragbits will look into your <code>OPENAI_API_KEY</code>. You can easily swap this with other providers.</p> <p>Recommended: Set up OpenTelemetry tracing to understand what's happening under the hood.</p> <p>OpenTelemetry is an LLMOps tool that natively integrates with Ragbits and offer explainability and experiment tracking. In this tutorial, you can use OpenTelemetry to visualize prompts and optimization progress as traces to understand the Ragbits' behavior better. Check the full setup guide here.</p>"},{"location":"tutorials/agents/#building-the-flight-finder-agent","title":"Building the Flight Finder Agent","text":"<p>We start by defining the prompt that will lead this agent.</p> flight_agent.py<pre><code>from pydantic import BaseModel\nfrom ragbits.core.prompt import Prompt\n\nclass FlightPromptInput(BaseModel):\n    \"\"\"Defines the structured input schema for the flight search prompt.\"\"\"\n\n    input: str\n\n\nclass FlightPrompt(Prompt[FlightPromptInput]):\n    \"\"\"Prompt for a flight search assistant.\"\"\"\n\n    system_prompt = \"\"\"\n    You are a helpful travel assistant that finds available flights between two cities.\n    \"\"\"\n\n    user_prompt = \"\"\"\n    {{ input }}\n    \"\"\"\n\n\nprint(FlightPrompt(FlightPromptInput(input=\"I need to fly from New York to Paris. What flights are available?\")).chat)\n</code></pre> <pre><code>[{'role': 'system', 'content': 'You are a helpful travel assistant that finds available flights between two cities.'},\n{'role': 'user', 'content': 'I need to fly from New York to Paris. What flights are available?'}]\n</code></pre> <p>Next, we define a tool that will provide flight information. Note: in a real application, you'd connect to the actual flight APIs:</p> flight_agent.py<pre><code>import json\n\ndef get_flight_info(departure: str, arrival: str) -&gt; str:\n    \"\"\"\n    Returns flight information between two locations.\n\n    Args:\n        departure: The departure city.\n        arrival: The arrival city.\n\n    Returns:\n        A JSON string with mock flight details.\n    \"\"\"\n    if \"new york\" in departure.lower() and \"paris\" in arrival.lower():\n        return json.dumps(\n            {\n                \"from\": \"New York\",\n                \"to\": \"Paris\",\n                \"flights\": [\n                    {\"airline\": \"British Airways\", \"departure\": \"10:00 AM\", \"arrival\": \"10:00 PM\"},\n                    {\"airline\": \"Delta\", \"departure\": \"1:00 PM\", \"arrival\": \"1:00 AM\"},\n                ],\n            }\n        )\n\n    return json.dumps({\"from\": departure, \"to\": arrival, \"flights\": \"No flight data available\"})\n</code></pre> <p>This agent will call this function as needed, and the results will be injected back to the conversation.</p> <p>Now let's create the agent and test it:</p> flight_agent.py<pre><code>from ragbits.agents import Agent\nfrom ragbits.core.llms import LiteLLM\n\nllm = LiteLLM(\n    model_name=\"gpt-4.1\",\n    use_structured_output=True,\n)\nflight_agent = Agent(llm=llm, prompt=FlightPrompt, tools=[get_flight_info])\n\nasync def main() -&gt; None:\n    result = await flight_agent.run(FlightPromptInput(input=\"I need to fly from New York to Paris. What flights are available?\"))\n    print(result.content)\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    asyncio.run(main())\n</code></pre> <p>Run it:</p> <pre><code>python flight_agent.py\n</code></pre> <p>A typical response looks like this: <pre><code>Here are some available flights from New York to Paris:\n\n1. **British Airways**\n   - **Departure:** 10:00 AM\n   - **Arrival:** 10:00 PM\n\n2. **Delta**\n   - **Departure:** 1:00 PM\n   - **Arrival:** 1:00 AM\n</code></pre></p> <p>Please note that the results may differ among the runs due to undeterministic nature of LLM.</p> <p>Try it yourself</p> <p>You can try to connect this agents to a real flight API, such as aviationstack.</p>"},{"location":"tutorials/agents/#building-the-city-explorer-agent","title":"Building the City Explorer Agent","text":"<p>Let's create a City Explorer Agent that gather and synthesize city information from the internet. Again we start with the prompt:</p> city_explorer_agent.py<pre><code>from pydantic import BaseModel\nfrom ragbits.core.prompt import Prompt\n\n\nclass CityExplorerPromptInput(BaseModel):\n    \"\"\"Defines the structured input schema for the city explorer prompt.\"\"\"\n\n    input: str\n\n\nclass CityExplorerPrompt(Prompt[CityExplorerPromptInput]):\n    \"\"\"Prompt for a city explorer assistant.\"\"\"\n\n    system_prompt = \"\"\"\n    You are a helpful travel assistant that gathers and synthesizes city information from the internet.\n    To gather information call mcp fetch server with the URL to the city's wikipedia page.\n    Then synthesize the information into a concise summary.\n\n    e.g\n    https://en.wikipedia.org/wiki/London\n    https://en.wikipedia.org/wiki/Paris\n    \"\"\"\n\n    user_prompt = \"\"\"\n    {{ input }}.\n    \"\"\"\n</code></pre> <p>Now define the agent, We will not build an MCP server from scratch, but run an already existing one - Web Fetcher. Start by installing it with:</p> <pre><code>pip install mcp-server-fetch\n</code></pre> city_explorer_agent.py<pre><code>from ragbits.agents import Agent\nfrom ragbits.agents.mcp import MCPServerStdio\nfrom ragbits.core.llms import LiteLLM\nfrom ragbits.core.prompt import Prompt\nasync def main() -&gt; None:\n    \"\"\"Runs the city explorer agent.\"\"\"\n    async with MCPServerStdio(\n        params={\n            \"command\": \"python\",\n            \"args\": [\"-m\", \"mcp_server_fetch\"],\n        },\n        client_session_timeout_seconds=60,\n    ) as server:\n        llm = LiteLLM(\n            model_name=\"gpt-4.1\",\n            use_structured_output=True,\n        )\n        city_explorer_agent = Agent(llm=llm, prompt=CityExplorerPrompt, mcp_servers=[server])\n        result = await city_explorer_agent.run(CityExplorerPromptInput(input=\"Tell me something interesting about Paris.\"))\n        print(result.content)\n\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    asyncio.run(main())\n</code></pre> <p>Test this agent by running: <pre><code>python city_explorer_agent.py\n</code></pre></p> <pre><code>Paris is the capital and largest city of France, located in the \u00cele-de-France region. Renowned for its historical landmarks, the city is a significant cultural and economic center in Europe. Key attractions include the Eiffel Tower, Notre-Dame Cathedral, the Louvre Museum, and the Arc de Triomphe. Known for its romantic ambiance, Paris is often referred to as \"The City of Light.\"\n\nThe city is characterized by its extensive urban area and is densely populated, with a population of over 2 million within city limits and approximately 13 million in the metropolitan area as of 2021. Paris is divided into 20 districts, known as arrondissements. The current mayor is Anne Hidalgo. The city's motto is \"Fluctuat nec mergitur,\" meaning \"Tossed by the waves but never sunk,\" reflecting its resilience.\n\nParis is a hub for art, fashion, gastronomy, and culture, drawing millions of visitors each year who seek to experience its heritage and vibrant lifestyle.\n</code></pre> <p>Notice that we didn't have to write any tool, just reuse already existing one. This is the magic of MCP protocol.</p>"},{"location":"tutorials/agents/#exposing-agents-through-a2a","title":"Exposing Agents through A2A","text":"<p>Now we need to expose our agents through the Agent-to-Agent (A2A) protocol so they can be called remotely. We'll create agent cards and servers for both agents. Let's start with the flight agent. Update the main function with:</p> flight_agent.py<pre><code>from ragbits.agents.a2a.server import create_agent_server\n\nasync def main() -&gt; None:\n    \"\"\"Runs the flight agent.\"\"\"\n    flight_agent_card = await flight_agent.get_agent_card(\n        name=\"Flight Info Agent\", description=\"Provides available flight information between two cities.\", port=8000\n    )\n    flight_agent_server = create_agent_server(flight_agent, flight_agent_card, FlightPromptInput)\n    await flight_agent_server.serve()\n</code></pre> <p>and then run.</p> <pre><code>python flight_agent.py\n</code></pre> <p>Now, your server with agent should be up and running</p> <pre><code>INFO:     Started server process [1473119]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n</code></pre> <p>You can go to your browser and type <code>http://127.0.0.1:8000/.well-known/agent.json</code> to see and agent card:</p> <pre><code>{\n  \"additionalInterfaces\": null,\n  \"capabilities\": {\n    \"extensions\": null,\n    \"pushNotifications\": null,\n    \"stateTransitionHistory\": null,\n    \"streaming\": null\n  },\n  // More text...\n  \"supportsAuthenticatedExtendedCard\": null,\n  \"url\": \"http://127.0.0.1:8000\",\n  \"version\": \"0.0.0\"\n}\n</code></pre> <p>Warning</p> <p>Do not kill this process, open a new terminal for the next parts.</p> <p>Next, do the same for the City Explorer agent</p> city_explorer_agent.py<pre><code>from ragbits.agents.a2a.server import create_agent_server\n\n        city_explorer_agent_card = await city_explorer_agent.get_agent_card(\n            name=\"City Explorer Agent\",\n            description=\"Provides information about a city.\",\n            port=8001,\n        )\n        city_explorer_server = create_agent_server(\n            city_explorer_agent, city_explorer_agent_card, CityExplorerPromptInput\n        )\n        await city_explorer_server.serve()\n</code></pre> <p>and run in another terminal</p> <pre><code>python city_explorer_agent.py\n</code></pre>"},{"location":"tutorials/agents/#building-the-orchestrator-agent","title":"Building the Orchestrator Agent","text":"<p>Now let's create the orchestrator agent that will be trip planning chat which utilises our specialized agents.</p> <p>First we need to gather information about all of our available agents</p> orchestrator.py<pre><code>import requests\n\nAGENTS_CARDS = {}\n\n\ndef fetch_agent(host: str, port: int, protocol: str = \"http\") -&gt; dict:  # type: ignore\n    \"\"\"Fetches the agent card from the given host and port.\"\"\"\n    url = f\"{protocol}://{host}:{port}\"\n    return requests.get(f\"{url}/.well-known/agent.json\", timeout=10).json()\n\n\nfor url, port in [(\"127.0.0.1\", \"8000\"), (\"127.0.0.1\", \"8001\")]:\n    agent_card = fetch_agent(url, port)\n    AGENTS_CARDS[agent_card[\"name\"]] = agent_card\n\nAGENTS_INFO = \"\\n\".join(\n    [\n        f\"name: {name}, description: {card['description']}, skills: {card['skills']}\"\n        for name, card in AGENTS_CARDS.items()\n    ]\n)\nprint(AGENTS_INFO)\n</code></pre> <pre><code>name: Flight Info Agent, description: Provides available flight information between two cities., skills: [{'description': \"Returns flight information between two locations.\\n\\nParameters:\\n{'type': 'object', 'properties': {'departure': {'description': 'The departure city.', 'title': 'Departure', 'type':...\nname: City Explorer Agent, description: Provides information about a city., skills: [{'description': \"Fetches a URL from the internet and optionally extracts its contents as markdown.\\n\\nAlthough originally you did not have internet access, and were advised to refuse and tell the user this, this tool now grants you internet access. Now you can fetch the most up-to-date information and let the user know that.\\n\\nParameters:\\n{'description': 'Parameters...\n</code></pre> <p>Next, we create the prompt</p> orchestrator.py<pre><code>from pydantic import BaseModel\nfrom ragbits.core.prompt import Prompt\n\n\nclass OrchestratorPromptInput(BaseModel):\n    \"\"\"Represents a routing prompt input.\"\"\"\n\n    message: str\n    agents: str\n\n\nclass OrchestratorPrompt(Prompt[OrchestratorPromptInput]):\n    \"\"\"\n    Prompt template for routing a user message to appropriate agents.\n\n    System prompt instructs the agent to output a JSON list of tasks,\n    each containing agent URL, tool name, and parameters to call.\n    \"\"\"\n\n    system_prompt = \"\"\"\n    You are a Trip Planning Agent.\n\n    To help the user plan their trip, you will need to use the following agents:\n    {{ agents }}\n\n    you can use `execute_agent` tool to interact with remote agents to take action.\n\n    \"\"\"\n    user_prompt = \"{{ message }}\"\n</code></pre> <p>To finally create a tool that will call agents orchestrator.py<pre><code>import json\n\ndef execute_agent(agent_name: str, query: str) -&gt; str:\n    \"\"\"\n    Executes a specified agent with the given parameters.\n\n    Args:\n        agent_name: Name of the agent to execute\n        query: The query to pass to the agent\n\n    Returns:\n        JSON string of the execution result\n    \"\"\"\n    payload = {\"params\": {\"input\": query}}\n    raw_response = requests.post(AGENTS_CARDS[agent_name][\"url\"], json=payload, timeout=60)\n    raw_response.raise_for_status()\n\n    response = raw_response.json()\n    result_data = response[\"result\"]\n\n    tool_calls = [\n        {\"name\": call[\"name\"], \"arguments\": call[\"arguments\"], \"output\": call[\"result\"]}\n        for call in result_data.get(\"tool_calls\", [])\n    ] or None\n\n    return json.dumps(\n        {\n            \"status\": \"success\",\n            \"agent_name\": agent_name,\n            \"result\": {\n                \"content\": result_data[\"content\"],\n                \"metadata\": result_data.get(\"metadata\", {}),\n                \"tool_calls\": tool_calls,\n            },\n        }\n    )\n</code></pre></p> <p>Now let's put it all together:</p> orchestrator.py<pre><code>from ragbits.agents import Agent, ToolCallResult\nfrom ragbits.core.llms import LiteLLM, ToolCall\nimport asyncio\n\nasync def main() -&gt; None:\n    \"\"\"\n    Sets up a LiteLLM-powered AgentOrchestrator with two remote agents and sends a travel planning query.\n    The orchestrator delegates the task (finding flights and hotels) to the appropriate agents and prints the response.\n    \"\"\"\n    llm = LiteLLM(\n        model_name=\"gpt-4.1\",\n        use_structured_output=True,\n    )\n\n    agent = Agent(llm=llm, prompt=OrchestratorPrompt, tools=[execute_agent], keep_history=True)\n\n    while True:\n        user_input = input(\"\\nUSER: \")\n        print(\"ASSISTANT:\")\n        async for chunk in agent.run_streaming(OrchestratorPromptInput(message=user_input, agents=AGENTS_INFO)):\n            match chunk:\n                case ToolCall():\n                    print(f\"Tool call: {chunk.name} with arguments {chunk.arguments}\")\n                case ToolCallResult():\n                    print(f\"Tool call result: {chunk.result[:100]}...\")\n                case _:\n                    print(chunk, end=\"\", flush=True)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Now you can test the complete system by running (assuming city and flight agents are running in another terminals):</p> <pre><code>python orchestrator.py\n</code></pre> <p>Then interact with the orchestrator with <code>I want to visit Paris from New York. Please give me some info about it and suggest recommended flights</code>:</p> <ol> <li>The orchestrator calls city explorer and flight finder agents</li> <li>The city explorer agent fetches Paris information via MCP</li> <li>The flight finder agent searches for New York \u2192 Paris flights</li> <li>The orchestrator combines everything into a comprehensive trip plan and streams the response</li> </ol> <p>Good job, you've done it!</p> <p>Feel free to extend this system with additional agents for activities, restaurants, weather information, or any other travel-related services.</p> <p>Tip</p> <p>Full working example of this code can be found at: <code>examples/agents/a2a</code></p>"},{"location":"tutorials/chat/","title":"Tutorial: Building Tool-Powered Chat Interfaces with Agents","text":"<p>Let's build a sophisticated chatbot interface with Ragbits Chat and Agents. We'll create an intelligent chat system that uses AI agents with real tools to provide web search results, generate images, and deliver live updates during processing.</p> <p>What you'll learn:</p> <ul> <li>How to create an agent-powered chat interface with real tools (web search, image generation)</li> <li>How to implement live updates that show tool execution progress</li> <li>How to extract and display web search references automatically</li> <li>How to handle image generation with base64 encoding and chunking</li> <li>How to build authentication-enabled chat interfaces</li> <li>How to configure user settings and feedback forms</li> <li>How to customize the chat UI with branding and welcome messages</li> <li>How to debug and optimize tool-powered chat systems</li> <li>How to build production-ready intelligent assistants with real capabilities</li> </ul> <p>Install the latest Ragbits via <code>pip install -U ragbits</code> and follow along.</p>"},{"location":"tutorials/chat/#configuring-the-environment","title":"Configuring the environment","text":"<p>During development, we will use OpenAI's <code>gpt-4o-2024-08-06</code> model with tools. To authenticate, Ragbits will look into your <code>OPENAI_API_KEY</code>. You can easily swap this out for other providers or local models.</p> <p>Recommended: Set up OpenTelemetry tracing to understand what's happening under the hood.</p> <p>OpenTelemetry is an LLMOps tool that natively integrates with Ragbits and offers explainability and experiment tracking. In this tutorial, you can use OpenTelemetry to visualize prompts and tool calls as traces. Check the full setup guide here.</p>"},{"location":"tutorials/chat/#step-1-basic-agent-setup-with-prompt","title":"Step 1: Basic Agent Setup with Prompt","text":"<p>Let's start by creating the foundation - an agent with a specialized prompt for mountain hiking assistance. This establishes the core AI behavior and domain expertise.</p> <p>Create a file called <code>mountain_chat.py</code> and add the basic structure:</p> <pre><code>import base64\nfrom collections.abc import AsyncGenerator\nfrom pathlib import Path\nfrom typing import Literal\n\nfrom pydantic import BaseModel, ConfigDict, Field\n\nfrom ragbits.agents import Agent, ToolCallResult\nfrom ragbits.agents.tools.openai import get_image_generation_tool, get_web_search_tool\nfrom ragbits.chat.interface import ChatInterface\nfrom ragbits.chat.interface.types import ChatContext, ChatResponse, LiveUpdateType, Message\nfrom ragbits.core.llms import LiteLLM, ToolCall\nfrom ragbits.core.prompt import Prompt\n\n# Define the agent's input format\nclass GeneralAssistantPromptInput(BaseModel):\n    \"\"\"Input format for the General Assistant Prompt.\"\"\"\n    query: str\n    language: str\n\n# Create the agent prompt with domain expertise\nclass GeneralAssistantPrompt(Prompt[GeneralAssistantPromptInput]):\n    \"\"\"Prompt that responds to user queries using appropriate tools.\"\"\"\n\n    system_prompt = \"\"\"\n    You are a helpful assistant that is expert in mountain hiking and answers user questions.\n    You have access to the following tools: web search and image generation.\n\n    Guidelines:\n    1. Use the web search tool when the user asks for factual information, research, or current events.\n    2. Use the image generation tool when the user asks to create, generate, draw, or produce images.\n    3. The image generation tool generates images in 512x512 resolution.\n    4. Return the image as a base64 encoded string in the response.\n    5. Always select the most appropriate tool based on the user's request.\n    6. If the user asks explicitly for a picture, use only the image generation tool.\n    7. Do not output images in chat. The image will be displayed in the UI.\n    8. Answer in {{ language }} language.\n    \"\"\"\n\n    user_prompt = \"\"\"\n    {{ query }}\n    \"\"\"\n\nclass BasicMountainChat(ChatInterface):\n    \"\"\"Basic mountain hiking assistant with tools.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.model_name = \"gpt-4o-2024-08-06\"\n        self.llm = LiteLLM(model_name=self.model_name, use_structured_output=True)\n\n        # Create agent with real tools\n        self.agent = Agent(\n            llm=self.llm,\n            prompt=GeneralAssistantPrompt,\n            tools=[\n                get_web_search_tool(self.model_name),\n                get_image_generation_tool(self.model_name),\n            ],\n        )\n\n    async def chat(\n        self,\n        message: str,\n        history: ChatFormat,\n        context: ChatContext,\n    ) -&gt; AsyncGenerator[ChatResponse, None]:\n        # Basic streaming implementation\n        stream = self.agent.run_streaming(\n            GeneralAssistantPromptInput(\n                query=message,\n                language=\"English\"  # Default language for now\n            )\n        )\n\n        async for response in stream:\n            match response:\n                case str():\n                    # Regular text content from the LLM\n                    if response.strip():  # Only yield non-empty text\n                        yield self.create_text_response(response)\n</code></pre> <p>How this works:</p> <ul> <li>Domain Expertise: The prompt specializes the agent in mountain hiking, giving it focused knowledge</li> <li>Tool Integration: We configure web search and image generation tools that the agent can use</li> <li>Streaming: The agent streams responses in real-time as they're generated</li> <li>Language Support: Input includes language parameter for internationalization</li> </ul> <p>Test this basic version:</p> <pre><code>ragbits api run mountain_chat:BasicMountainChat\n</code></pre> <p>Why Start Simple</p> <p>Starting with a basic implementation helps you understand the core concepts before adding complexity. The agent already has access to powerful tools but we'll add UI feedback in the next steps.</p>"},{"location":"tutorials/chat/#step-2-adding-live-updates-for-tool-execution","title":"Step 2: Adding Live Updates for Tool Execution","text":"<p>Now let's add live updates so users can see when tools are being executed. This provides real-time feedback during potentially long-running operations like web searches or image generation.</p> <p>Add these methods to your <code>BasicMountainChat</code> class:</p> <pre><code>class BasicMountainChat(ChatInterface):\n    # ... previous code ...\n\n    @staticmethod\n    def _get_tool_display_name(tool_name: str) -&gt; str:\n        \"\"\"Get user-friendly display names for tools.\"\"\"\n        return {\n            \"search_web\": \"\ud83d\udd0d Web Search\",\n            \"image_generation\": \"\ud83c\udfa8 Image Generator\"\n        }.get(tool_name, tool_name)\n\n    async def _handle_tool_call(self, response: ToolCall) -&gt; ChatResponse:\n        \"\"\"Handle tool call and return live update.\"\"\"\n        tool_display_name = self._get_tool_display_name(response.name)\n        return self.create_live_update(\n            response.id,\n            LiveUpdateType.START,\n            f\"Using {tool_display_name}\",\n            \"Processing your request...\"\n        )\n\n    async def _handle_tool_result(self, response: ToolCallResult) -&gt; AsyncGenerator[ChatResponse, None]:\n        \"\"\"Handle tool call result and yield appropriate responses.\"\"\"\n        tool_display_name = self._get_tool_display_name(response.name)\n\n        # Signal completion\n        yield self.create_live_update(\n            response.id,\n            LiveUpdateType.FINISH,\n            f\"{tool_display_name} completed\",\n        )\n\n    async def chat(\n        self,\n        message: str,\n        history: ChatFormat,\n        context: ChatContext,\n    ) -&gt; AsyncGenerator[ChatResponse, None]:\n        # Enhanced streaming with tool handling\n        stream = self.agent.run_streaming(\n            GeneralAssistantPromptInput(\n                query=message,\n                language=\"English\"\n            )\n        )\n\n        async for response in stream:\n            match response:\n                case str():\n                    # Regular text content from the LLM\n                    if response.strip():\n                        yield self.create_text_response(response)\n\n                case ToolCall():\n                    # Tool is being called - show live update\n                    yield await self._handle_tool_call(response)\n\n                case ToolCallResult():\n                    # Tool completed - process results\n                    async for result_response in self._handle_tool_result(response):\n                        yield result_response\n</code></pre> <p>How live updates work:</p> <ul> <li>ToolCall Detection: When the agent decides to use a tool, we catch the <code>ToolCall</code> object</li> <li>Start Indicator: Show a \"Using [Tool Name]\" message with a processing indicator</li> <li>Completion Signal: When the tool finishes, show a completion message</li> <li>User Experience: Users see real-time progress instead of waiting in silence</li> </ul> <p>Test the enhanced version:</p> <pre><code>ragbits api run mountain_chat:BasicMountainChat\n</code></pre> <p>Try asking: \"Search for information about Mount Everest weather\" and watch the live updates appear!</p>"},{"location":"tutorials/chat/#step-3-processing-web-search-results","title":"Step 3: Processing Web Search Results","text":"<p>Now let's add automatic extraction of web search references. When the web search tool returns results, we'll extract URLs and display them as clickable references in the chat.</p> <p>Add this method to handle web search results:</p> <pre><code>class BasicMountainChat(ChatInterface):\n    # ... previous code ...\n\n    async def _extract_web_references(self, response: ToolCallResult) -&gt; AsyncGenerator[ChatResponse, None]:\n        \"\"\"Extract URL citations from web search results.\"\"\"\n        for item in response.result.output:\n            if item.type == \"message\":\n                for content in item.content:\n                    for annotation in content.annotations:\n                        if annotation.type == \"url_citation\" and annotation.title and annotation.url:\n                            yield self.create_reference(\n                                title=annotation.title,\n                                url=annotation.url,\n                                content=\"\"\n                            )\n\n    async def _handle_tool_result(self, response: ToolCallResult) -&gt; AsyncGenerator[ChatResponse, None]:\n        \"\"\"Handle tool call result and yield appropriate responses.\"\"\"\n        tool_display_name = self._get_tool_display_name(response.name)\n\n        # Signal completion\n        yield self.create_live_update(\n            response.id,\n            LiveUpdateType.FINISH,\n            f\"{tool_display_name} completed\",\n        )\n\n        # Process specific tool results\n        if response.name == \"search_web\":\n            async for reference in self._extract_web_references(response):\n                yield reference\n</code></pre> <p>How web reference extraction works:</p> <ul> <li>Result Processing: After web search completes, we examine the tool result</li> <li>Annotation Parsing: Web search results contain annotations with URL citations</li> <li>Reference Creation: Each citation becomes a clickable reference in the chat UI</li> <li>Automatic Display: Users see relevant links without manual processing</li> </ul> <p>The web search tool returns structured data with:</p> <ul> <li>URLs: Direct links to relevant web pages</li> <li>Titles: Descriptive titles for each reference</li> <li>Annotations: Metadata about why each link is relevant</li> </ul> <p>Test web search with references:</p> <pre><code>ragbits api run mountain_chat:BasicMountainChat\n</code></pre> <p>Try: \"Search for the best hiking trails in the Alps\" and you'll see both the AI response and clickable reference links!</p>"},{"location":"tutorials/chat/#step-4-adding-image-generation-support","title":"Step 4: Adding Image Generation Support","text":"<p>Now let's add support for image generation with proper base64 encoding and display. When the image generation tool creates images, we'll handle the file processing and convert them for display in the chat.</p> <p>Add this method to handle image generation results:</p> <pre><code>class BasicMountainChat(ChatInterface):\n    # ... previous code ...\n\n    async def _create_image_response(self, image_path: Path) -&gt; ChatResponse:\n        \"\"\"Create image response from file path.\"\"\"\n        with open(image_path, \"rb\") as image_file:\n            image_filename = image_path.name\n            base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n            return self.create_image_response(\n                image_filename,\n                f\"data:image/png;base64,{base64_image}\"\n            )\n\n    async def _handle_tool_result(self, response: ToolCallResult) -&gt; AsyncGenerator[ChatResponse, None]:\n        \"\"\"Handle tool call result and yield appropriate responses.\"\"\"\n        tool_display_name = self._get_tool_display_name(response.name)\n\n        # Signal completion\n        yield self.create_live_update(\n            response.id,\n            LiveUpdateType.FINISH,\n            f\"{tool_display_name} completed\",\n        )\n\n        # Process specific tool results\n        if response.name == \"search_web\":\n            async for reference in self._extract_web_references(response):\n                yield reference\n        elif response.name == \"image_generation\" and response.result.image_path:\n            yield await self._create_image_response(response.result.image_path)\n</code></pre> <p>How image generation works:</p> <ul> <li>Tool Execution: The agent calls the image generation tool with a text prompt</li> <li>File Creation: The tool generates an image and saves it to a temporary file</li> <li>Base64 Encoding: We read the image file and convert it to base64 format</li> <li>Data URL: Create a proper data URL with MIME type for browser display</li> <li>Automatic Chunking: Large images are automatically chunked by the API for efficient transmission</li> </ul> <p>The image generation process:</p> <ol> <li>Agent Decision: Agent determines an image would be helpful</li> <li>Tool Call: Calls image generation with descriptive prompt</li> <li>AI Generation: Uses AI image model (like DALL-E) to create the image</li> <li>File Processing: Converts generated image to base64 for web display</li> <li>UI Display: Image appears directly in the chat interface</li> </ol> <p>Test image generation:</p> <pre><code>ragbits api run mountain_chat:BasicMountainChat\n</code></pre> <p>Try: \"Generate an image of mountain hiking gear\" and watch the AI create a custom image!</p>"},{"location":"tutorials/chat/#step-5-adding-ui-customization-and-user-settings","title":"Step 5: Adding UI Customization and User Settings","text":"<p>Now let's add a polished UI with custom branding, user settings, and conversation history. This transforms our basic chat into a professional-looking application.</p> <p>Add user settings and UI customization:</p> <pre><code>from ragbits.chat.interface.forms import FeedbackConfig, UserSettings\nfrom ragbits.chat.interface.ui_customization import HeaderCustomization, PageMetaCustomization, UICustomization\n\n# Define user settings form\nclass UserSettingsFormExample(BaseModel):\n    \"\"\"User preferences for the chat interface.\"\"\"\n    model_config = ConfigDict(title=\"Chat Settings\", json_schema_serialization_defaults_required=True)\n\n    language: Literal[\"English\", \"Polish\"] = Field(\n        description=\"Please select the language\",\n        default=\"English\"\n    )\n\nclass MountainChatWithUI(ChatInterface):\n    \"\"\"Enhanced mountain hiking assistant with custom UI.\"\"\"\n\n    # Customize the UI appearance\n    ui_customization = UICustomization(\n        header=HeaderCustomization(\n            title=\"\ud83c\udfd4\ufe0f Mountain Hiking Assistant\",\n            subtitle=\"by Ragbits\",\n            logo=\"\ud83e\udd7e\"\n        ),\n        welcome_message=(\n            \"\ud83c\udfd4\ufe0f **Welcome to your Mountain Hiking Assistant!**\\n\\n\"\n            \"I can help you with:\\n\"\n            \"- **Web Search** for hiking information, weather, trails\\n\"\n            \"- **Image Generation** for visualizing routes, gear, or concepts\\n\\n\"\n            \"Ask me anything about mountain hiking!\"\n        ),\n        meta=PageMetaCustomization(favicon=\"\ud83c\udfd4\ufe0f\", page_title=\"Mountain Hiking Assistant\"),\n    )\n\n    # Add user settings\n    user_settings = UserSettings(form=UserSettingsFormExample)\n\n    # Enable features\n    conversation_history = True\n    show_usage = True\n\n    def __init__(self) -&gt; None:\n        self.model_name = \"gpt-4o-2024-08-06\"\n        self.llm = LiteLLM(model_name=self.model_name, use_structured_output=True)\n\n        self.agent = Agent(\n            llm=self.llm,\n            prompt=GeneralAssistantPrompt,\n            tools=[\n                get_web_search_tool(self.model_name),\n                get_image_generation_tool(self.model_name),\n            ],\n        )\n\n    # ... (include all the tool handling methods from previous steps) ...\n\n    async def chat(\n        self,\n        message: str,\n        history: ChatFormat,\n        context: ChatContext,\n    ) -&gt; AsyncGenerator[ChatResponse, None]:\n        # Get user language preference\n        language = \"English\"\n        if context and context.user_settings:\n            language = context.user_settings.get(\"language\", \"English\")\n\n        # Create streaming response from agent\n        stream = self.agent.run_streaming(\n            GeneralAssistantPromptInput(\n                query=message,\n                language=language\n            )\n        )\n\n        # Process streaming responses (same pattern as before)\n        async for response in stream:\n            match response:\n                case str():\n                    if response.strip():\n                        yield self.create_text_response(response)\n                case ToolCall():\n                    yield await self._handle_tool_call(response)\n                case ToolCallResult():\n                    async for result_response in self._handle_tool_result(response):\n                        yield result_response\n</code></pre> <p>UI customization features:</p> <ul> <li>Custom Header: Branded title, subtitle, and logo</li> <li>Welcome Message: Markdown-formatted introduction with feature overview</li> <li>Page Metadata: Custom favicon and page title for browser tabs</li> <li>User Settings: Language preference that affects agent responses</li> <li>Conversation History: Persistent chat history across sessions</li> <li>Usage Tracking: Token usage display for monitoring costs</li> </ul> <p>Test the enhanced UI:</p> <pre><code>ragbits api run mountain_chat:MountainChatWithUI\n</code></pre> <p>You'll see a professional-looking interface with custom branding and user settings!</p>"},{"location":"tutorials/chat/#step-6-adding-authentication-and-feedback-forms","title":"Step 6: Adding Authentication and Feedback Forms","text":"<p>For production applications, you'll want authentication and user feedback. Let's add these final features to create a complete, secure chat interface.</p> <p>Add feedback forms and authentication:</p> <pre><code>from ragbits.chat.auth import ListAuthenticationBackend\n\n# Define feedback forms\nclass LikeFormExample(BaseModel):\n    \"\"\"Form for positive feedback.\"\"\"\n    model_config = ConfigDict(\n        title=\"Like Form\",\n        json_schema_serialization_defaults_required=True,\n    )\n\n    like_reason: str = Field(\n        description=\"Why do you like this?\",\n        min_length=1,\n    )\n\nclass DislikeFormExample(BaseModel):\n    \"\"\"Form for negative feedback.\"\"\"\n    model_config = ConfigDict(\n        title=\"Dislike Form\",\n        json_schema_serialization_defaults_required=True\n    )\n\n    issue_type: Literal[\"Incorrect information\", \"Not helpful\", \"Unclear\", \"Other\"] = Field(\n        description=\"What was the issue?\"\n    )\n    feedback: str = Field(description=\"Please provide more details\", min_length=1)\n\nclass AuthenticatedMountainChat(ChatInterface):\n    \"\"\"Complete mountain hiking assistant with authentication.\"\"\"\n\n    ui_customization = UICustomization(\n        header=HeaderCustomization(\n            title=\"\ud83d\udd10 Authenticated Mountain Assistant\",\n            subtitle=\"by Ragbits\",\n            logo=\"\ud83e\udd7e\"\n        ),\n        welcome_message=(\n            \"\ud83d\udd10 **Welcome to Authenticated Mountain Assistant!**\\n\\n\"\n            \"You can ask me **anything** about mountain hiking! \\n\\n\"\n            \"I can also generate images for you.\\n\\n\"\n            \"Please log in to start chatting!\"\n        ),\n        meta=PageMetaCustomization(favicon=\"\ud83c\udfd4\ufe0f\", page_title=\"Mountain Assistant\"),\n    )\n\n    # Configure feedback system\n    feedback_config = FeedbackConfig(\n        like_enabled=True,\n        like_form=LikeFormExample,\n        dislike_enabled=True,\n        dislike_form=DislikeFormExample,\n    )\n\n    # Add user settings and features\n    user_settings = UserSettings(form=UserSettingsFormExample)\n    conversation_history = True\n    show_usage = True\n\n    def __init__(self) -&gt; None:\n        self.model_name = \"gpt-4o-2024-08-06\"\n        self.llm = LiteLLM(model_name=self.model_name, use_structured_output=True)\n        self.agent = Agent(\n            llm=self.llm,\n            prompt=GeneralAssistantPrompt,\n            tools=[\n                get_web_search_tool(self.model_name),\n                get_image_generation_tool(self.model_name),\n            ],\n        )\n\n    # ... (include all the tool handling methods from previous steps) ...\n\n    async def chat(\n        self,\n        message: str,\n        history: ChatFormat,\n        context: ChatContext,\n    ) -&gt; AsyncGenerator[ChatResponse, None]:\n        # Check authentication\n        user_info = context.user\n\n        if not user_info:\n            yield self.create_text_response(\"\u26a0\ufe0f Authentication information not found.\")\n            return\n\n        # Get user language preference\n        language = context.user_settings.get(\"language\", \"English\") if context else \"English\"\n\n        # Process with agent (same as before)\n        stream = self.agent.run_streaming(\n            GeneralAssistantPromptInput(query=message, language=language)\n        )\n\n        async for response in stream:\n            match response:\n                case str():\n                    if response.strip():\n                        yield self.create_text_response(response)\n                case ToolCall():\n                    yield await self._handle_tool_call(response)\n                case ToolCallResult():\n                    async for result_response in self._handle_tool_result(response):\n                        yield result_response\n\n# Create authentication backend\ndef get_auth_backend() -&gt; ListAuthenticationBackend:\n    \"\"\"Factory function to create the authentication backend.\"\"\"\n    users = [\n        {\n            \"user_id\": \"8e6c5871-3817-4d62-828f-ef6789de31b9\",\n            \"username\": \"test\",\n            \"password\": \"test123\",\n            \"email\": \"test@example.com\",\n            \"full_name\": \"Test User\",\n            \"roles\": [\"user\"],\n            \"metadata\": {\"department\": \"Hiking\", \"clearance_level\": \"standard\"},\n        },\n    ]\n    return ListAuthenticationBackend(users)\n</code></pre> <p>Authentication and feedback features:</p> <ul> <li>User Authentication: Secure login system with user management</li> <li>Feedback Forms: Structured feedback collection with like/dislike options</li> <li>User Context: Access to authenticated user information in chat logic</li> <li>Session Management: Automatic session handling and token validation</li> </ul> <p>Launch with authentication:</p> <pre><code>ragbits api run mountain_chat:AuthenticatedMountainChat --auth mountain_chat:get_auth_backend\n</code></pre> <p>Login credentials:</p> <ul> <li>Username: <code>test</code></li> <li>Password: <code>test123</code></li> </ul>"},{"location":"tutorials/chat/#enabling-debug-mode","title":"Enabling Debug Mode","text":"<p>Debug mode provides detailed information about tool calls and agent decisions:</p> <pre><code>ragbits api run mountain_chat:AuthenticatedMountainChat --auth mountain_chat:get_auth_backend --debug\n</code></pre> <p>With debug mode enabled:</p> <ul> <li>Debug panel shows tool execution details</li> <li>Agent decision-making process is visible</li> <li>Token usage and performance metrics displayed</li> <li>Error information is comprehensive</li> </ul> <p>Additional server options:</p> <pre><code># Custom host and port\nragbits api run mountain_chat:AuthenticatedMountainChat --host 0.0.0.0 --port 9000\n\n# Enable CORS for development\nragbits api run mountain_chat:AuthenticatedMountainChat --cors-origin http://localhost:3000\n</code></pre>"},{"location":"tutorials/chat/#complete-working-example","title":"Complete Working Example","text":"<p>Here's your complete <code>mountain_chat.py</code> file with all features:</p> <pre><code>\"\"\"\nComplete Mountain Hiking Assistant with Tools, Authentication, and UI Customization\n\"\"\"\n\nimport base64\nfrom collections.abc import AsyncGenerator\nfrom pathlib import Path\nfrom typing import Literal\n\nfrom pydantic import BaseModel, ConfigDict, Field\n\nfrom ragbits.agents import Agent, ToolCallResult\nfrom ragbits.agents.tools.openai import get_image_generation_tool, get_web_search_tool\nfrom ragbits.chat.auth import ListAuthenticationBackend\nfrom ragbits.chat.interface import ChatInterface\nfrom ragbits.chat.interface.forms import FeedbackConfig, UserSettings\nfrom ragbits.chat.interface.types import ChatContext, ChatResponse, LiveUpdateType, Message\nfrom ragbits.chat.interface.ui_customization import HeaderCustomization, PageMetaCustomization, UICustomization\nfrom ragbits.core.llms import LiteLLM, ToolCall\nfrom ragbits.core.prompt import Prompt\n\n# Forms\nclass LikeFormExample(BaseModel):\n    model_config = ConfigDict(title=\"Like Form\", json_schema_serialization_defaults_required=True)\n    like_reason: str = Field(description=\"Why do you like this?\", min_length=1)\n\nclass DislikeFormExample(BaseModel):\n    model_config = ConfigDict(title=\"Dislike Form\", json_schema_serialization_defaults_required=True)\n    issue_type: Literal[\"Incorrect information\", \"Not helpful\", \"Unclear\", \"Other\"] = Field(description=\"What was the issue?\")\n    feedback: str = Field(description=\"Please provide more details\", min_length=1)\n\nclass UserSettingsFormExample(BaseModel):\n    model_config = ConfigDict(title=\"Chat Settings\", json_schema_serialization_defaults_required=True)\n    language: Literal[\"English\", \"Polish\"] = Field(description=\"Please select the language\", default=\"English\")\n\n# Agent prompt\nclass GeneralAssistantPromptInput(BaseModel):\n    query: str\n    language: str\n\nclass GeneralAssistantPrompt(Prompt[GeneralAssistantPromptInput]):\n    system_prompt = \"\"\"\n    You are a helpful assistant that is expert in mountain hiking and answers user questions.\n    You have access to the following tools: web search and image generation.\n\n    Guidelines:\n    1. Use the web search tool when the user asks for factual information, research, or current events.\n    2. Use the image generation tool when the user asks to create, generate, draw, or produce images.\n    3. The image generation tool generates images in 512x512 resolution.\n    4. Return the image as a base64 encoded string in the response.\n    5. Always select the most appropriate tool based on the user's request.\n    6. If the user asks explicitly for a picture, use only the image generation tool.\n    7. Do not output images in chat. The image will be displayed in the UI.\n    8. Answer in {{ language }} language.\n    \"\"\"\n    user_prompt = \"{{ query }}\"\n\nclass MyChat(ChatInterface):\n    \"\"\"Complete mountain hiking assistant with all features.\"\"\"\n\n    ui_customization = UICustomization(\n        header=HeaderCustomization(title=\"\ud83d\udd10 Authenticated Mountain Assistant\", subtitle=\"by Ragbits\", logo=\"\ud83e\udd7e\"),\n        welcome_message=(\n            \"\ud83d\udd10 **Welcome to Authenticated Mountain Assistant!**\\n\\n\"\n            \"You can ask me **anything** about mountain hiking! \\n\\n Also I can generate images for you.\\n\\n\"\n            \"Please log in to start chatting!\"\n        ),\n        meta=PageMetaCustomization(favicon=\"\ud83c\udfd4\ufe0f\", page_title=\"Mountain Assistant\"),\n    )\n\n    feedback_config = FeedbackConfig(\n        like_enabled=True, like_form=LikeFormExample,\n        dislike_enabled=True, dislike_form=DislikeFormExample,\n    )\n    user_settings = UserSettings(form=UserSettingsFormExample)\n    conversation_history = True\n    show_usage = True\n\n    def __init__(self) -&gt; None:\n        self.model_name = \"gpt-4o-2024-08-06\"\n        self.llm = LiteLLM(model_name=self.model_name, use_structured_output=True)\n        self.agent = Agent(llm=self.llm, prompt=GeneralAssistantPrompt, tools=[\n            get_web_search_tool(self.model_name), get_image_generation_tool(self.model_name),\n        ])\n\n    @staticmethod\n    def _get_tool_display_name(tool_name: str) -&gt; str:\n        return {\"search_web\": \"\ud83d\udd0d Web Search\", \"image_generation\": \"\ud83c\udfa8 Image Generator\"}.get(tool_name, tool_name)\n\n    async def _handle_tool_call(self, response: ToolCall) -&gt; ChatResponse:\n        tool_display_name = self._get_tool_display_name(response.name)\n        return self.create_live_update(response.id, LiveUpdateType.START, f\"Using {tool_display_name}\", \"Processing your request...\")\n\n    async def _handle_tool_result(self, response: ToolCallResult) -&gt; AsyncGenerator[ChatResponse, None]:\n        tool_display_name = self._get_tool_display_name(response.name)\n        yield self.create_live_update(response.id, LiveUpdateType.FINISH, f\"{tool_display_name} completed\")\n\n        if response.name == \"search_web\":\n            async for reference in self._extract_web_references(response):\n                yield reference\n        elif response.name == \"image_generation\" and response.result.image_path:\n            yield await self._create_image_response(response.result.image_path)\n\n    async def _extract_web_references(self, response: ToolCallResult) -&gt; AsyncGenerator[ChatResponse, None]:\n        for item in response.result.output:\n            if item.type == \"message\":\n                for content in item.content:\n                    for annotation in content.annotations:\n                        if annotation.type == \"url_citation\" and annotation.title and annotation.url:\n                            yield self.create_reference(title=annotation.title, url=annotation.url, content=\"\")\n\n    async def _create_image_response(self, image_path: Path) -&gt; ChatResponse:\n        with open(image_path, \"rb\") as image_file:\n            image_filename = image_path.name\n            base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n            return self.create_image_response(image_filename, f\"data:image/png;base64,{base64_image}\")\n\n    async def chat(self, message: str, history: ChatFormat, context: ChatContext) -&gt; AsyncGenerator[ChatResponse, None]:\n        user_info = context.user\n        if not user_info:\n            yield self.create_text_response(\"\u26a0\ufe0f Authentication information not found.\")\n            return\n\n        stream = self.agent.run_streaming(GeneralAssistantPromptInput(\n            query=message, language=context.user_settings[\"language\"]\n        ))\n\n        async for response in stream:\n            match response:\n                case str():\n                    if response.strip():\n                        yield self.create_text_response(response)\n                case ToolCall():\n                    yield await self._handle_tool_call(response)\n                case ToolCallResult():\n                    async for result_response in self._handle_tool_result(response):\n                        yield result_response\n\ndef get_auth_backend() -&gt; ListAuthenticationBackend:\n    users = [{\"user_id\": \"8e6c5871-3817-4d62-828f-ef6789de31b9\", \"username\": \"test\", \"password\": \"test123\",\n              \"email\": \"test@example.com\", \"full_name\": \"Test User\", \"roles\": [\"user\"],\n              \"metadata\": {\"department\": \"Hiking\", \"clearance_level\": \"standard\"}}]\n    return ListAuthenticationBackend(users)\n</code></pre>"},{"location":"tutorials/chat/#conclusions","title":"Conclusions","text":"<p>In this tutorial, we've built a sophisticated chat interface using real AI tools for web search and image generation, providing actual capabilities rather than simulated responses.</p>"},{"location":"tutorials/chat/#key-features-implemented","title":"Key Features Implemented","text":"<ul> <li>\ud83d\udd0d Real Web Search: Live web search with automatic reference extraction</li> <li>\ud83c\udfa8 Real Image Generation: AI-powered image creation with base64 encoding</li> <li>\u26a1 Live Updates: Real-time progress indicators during tool execution</li> <li>\ud83d\udd10 Authentication: Secure login system with user management</li> <li>\ud83d\udcdd User Forms: Feedback collection and language preferences</li> <li>\ud83c\udfa8 UI Customization: Branded interface with welcome messages</li> <li>\ud83d\udcca Usage Tracking: Token usage and conversation history</li> </ul>"},{"location":"tutorials/chat/#why-this-approach-works","title":"Why This Approach Works","text":"<ol> <li>Real Capabilities: Tools perform actual web searches and generate real images</li> <li>Live Feedback: Users see progress as tools execute, improving UX</li> <li>Automatic Processing: Web references extracted automatically from search results</li> <li>Flexible Tools: Easy to add more tools (database queries, API calls, etc.)</li> <li>Production Ready: Built-in authentication, error handling, and monitoring</li> </ol>"},{"location":"tutorials/chat/#next-steps","title":"Next Steps","text":"<p>Now you can build tool-powered chat interfaces with real capabilities! You can:</p> <ul> <li>Add More Tools: Create custom tools for specific domains</li> <li>Enhance Authentication: Connect to external auth providers</li> <li>Integrate Databases: Add tools for data retrieval and storage</li> <li>Connect APIs: Use tools to integrate with external services</li> <li>Add Document Search: Connect to Document Search for knowledge bases</li> </ul> <p>The key insight: use real tools that provide actual capabilities rather than simulated responses. This creates chat interfaces that can truly help users accomplish tasks.</p> <p>For more advanced configurations and deployment options, check out the Chat API How-To Guide.</p>"},{"location":"tutorials/intro/","title":"Tutorial: Large Language Models Intro","text":"<p>Let's walk through a quick example of basic question answering. Specifically, let's build a system for answering tech questions, e.g. about Linux or iPhone apps.</p> <p>Install the latest Ragbits via <code>pip install -U ragbits ragbits-agents</code> and follow along.</p>"},{"location":"tutorials/intro/#configuring-the-environment","title":"Configuring the environment","text":"<p>During development, we will use OpenAI's <code>gpt-4.1-nano</code> model. To authenticate, Ragbits will look into your <code>OPENAI_API_KEY</code>. You can easily swap this out for other providers or local models.</p> <p>Recommended: Set up OpenTelemetry tracing to understand what's happening under the hood.</p> <p>OpenTelemetry is an LLMOps tool that natively integrates with Ragbits and offer explainability and experiment tracking. In this tutorial, you can use OpenTelemetry to visualize prompts and optimization progress as traces to understand the Ragbits' behavior better. Check the full setup guide here.</p>"},{"location":"tutorials/intro/#defining-and-running-prompts","title":"Defining and running Prompts","text":"<p>The recommended way to define a prompt in Ragbits is to create a class that inherits from the <code>Prompt</code> class.</p> <pre><code>from pydantic import BaseModel\nfrom ragbits.core.prompt import Prompt\n\nclass QuestionAnswerPromptInput(BaseModel):\n    question: str\n\nclass QuestionAnswerPrompt(Prompt[QuestionAnswerPromptInput, str]):\n    system_prompt = \"\"\"\n    You are a question answering agent. Answer the question to the best of your ability.\n    \"\"\"\n    user_prompt = \"\"\"\n    Question: {{ question }}\n    \"\"\"\n</code></pre> <p>In order to run this prompt, initilize <code>LLM</code> client and call <code>generate</code> method.</p> <pre><code>import asyncio\n\nfrom ragbits.core.llms import LiteLLM\n\nasync def main() -&gt; None:\n    llm = LiteLLM(model_name=\"gpt-4.1-nano\")\n    prompt = QuestionAnswerPrompt(QuestionAnswerPromptInput(\n        question=\"What are high memory and low memory on linux?\",\n    ))\n    response = await llm.generate(prompt)\n    print(response)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <pre><code>In Linux, 'high memory' and 'low memory' refer to different parts of the system's physical RAM. Low memory\ntypically refers to the portion of RAM that is directly accessible by the kernel and most processes, often\nthe first 640MB or 1GB of RAM, depending on the architecture. High memory, on the other hand, is the portion\nof RAM beyond this limit, which requires special handling because it cannot be directly accessed by the kernel\nusing regular pointers. High memory is usually seen in systems with large amounts of RAM where the kernel can't\ndirectly address all memory with its own address space.\n</code></pre> <p>You can further and experiment with different prompting techniques like chain-of-thought in order to elicit reasoning out of your model before it commits to the answer.</p> <pre><code>class CoTQuestionAnswerPromptOutput(BaseModel):\n    reason: str\n    answer: str\n\nclass CoTQuestionAnswerPrompt(Prompt[QuestionAnswerPromptInput, CoTQuestionAnswerPromptOutput]):\n    system_prompt = \"\"\"\n    You are a question answering agent. Answer the question to the best of your ability.\n    Think step by step.\n    \"\"\"\n    user_prompt = \"\"\"\n    Question: {{ question }}\n    \"\"\"\n</code></pre> <p>Note that we have added a schema for the response, you can use it for structured output to get more predictable results by setting <code>use_structured_output=True</code> flag.</p> <pre><code>async def main() -&gt; None:\n    llm = LiteLLM(model_name=\"gpt-4.1-nano\", use_structured_output=True)\n    prompt = CoTQuestionAnswerPrompt(QuestionAnswerPromptInput(\n        question=\"What are high memory and low memory on linux?\",\n    ))\n    response = await llm.generate(prompt)\n    print(response.answer)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <pre><code>High memory on Linux refers to the part of RAM above the addressable limit for a 32-bit kernel, often above 1GB\nor 4GB depending on architecture, which requires special handling to access. Low memory is the portion within\nthe addressable range for the kernel, generally below these limits, and is directly accessible by the system.\n</code></pre> <p>Observe the reasoning process</p> <p>Try printing <code>response.reason</code> to see the step-by-step reasoning the model performed. You will notice that while this chain-of-thought approach can improve answer quality, it also consumes more tokens due to the additional reasoning content - an important consideration for cost and latency.</p> <p>Interestingly, asking for reasoning can make the output answer shorter in this case. Is this a good thing or a bad thing? It depends on what you need: there's no free lunch, but Ragbits gives you the tools to experiment with different strategies extremely quickly.</p>"},{"location":"tutorials/intro/#evaluating-the-system","title":"Evaluating the system","text":"<p>Ragbits provides evalution for second layer components, such as <code>DocumentSearch</code> or <code>Agent</code>. To run the evaluation on LLM, you must use it through the <code>Agent</code> object.</p> <pre><code>from ragbits.agents.types import QuestionAnswerAgent\n\nllm = LiteLLM(model_name=\"gpt-4.1-nano\", use_structured_output=True)\nresponder = QuestionAnswerAgent(llm=llm, prompt=CoTQuestionAnswerPrompt)\n</code></pre> <p>To measure the quality of your Ragbits system, you need a bunch of input values, like questions for example, and a metric that can score the quality of an output from your system. Metrics vary widely. Some metrics need ground-truth labels of ideal outputs, e.g. for classification or question answering. Other metrics are self-supervised, e.g. checking faithfulness or lack of hallucination.</p> <p>Let's load a dataset of questions and their ground truth answers. Since we started this tutorial with the goal of building a system for answering Tech questions, we obtained a bunch of questions and their correct answers from the RAG-QA Arena dataset.</p> <pre><code>from ragbits.core.sources import WebSource\nfrom ragbits.evaluate.dataloaders.question_answer import QuestionAnswerDataLoader\n\nsource = WebSource(url=\"https://huggingface.co/datasets/deepsense-ai/ragbits/resolve/main/ragqa_arena_tech_examples.jsonl\")\ndataloader = QuestionAnswerDataLoader(\n    source=source,\n    split=\"data[:100]\",\n    question_key=\"question\",\n    answer_key=\"response\",\n)\n</code></pre> <pre><code>async def main() -&gt; None:\n    dataset = await dataloader.load()\n    print(dataset[0])\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <pre><code>QuestionAnswerData(\n    question=\"why igp is used in mpls?\",\n    reference_answer=\"An IGP exchanges routing prefixes between gateways/routers.  \\nWithout a routing protocol, you'd have to configure each route on every router and you'd have no dynamic updates when routes change because of link failures. \\nFuthermore, within an MPLS network, an IGP is vital for advertising the internal topology and ensuring connectivity for MP-BGP inside the network.\",\n    reference_context=None\n)\n</code></pre> <p>What kind of metric can suit our question-answering task? There are many choices, but since the answers are long, we may ask: How well does the system response cover all key facts in the gold response? And the other way around, how well is the system response not saying things that aren't in the gold response?</p> <p>That metric measures essentially an answer correctness, so let's load a <code>QuestionAnswerAnswerCorrectness</code> metric from Ragbits. This metric is actually implemented as a very simple Ragbits module using whatever LLM we are working with.</p> <pre><code>from ragbits.evaluate.metrics.question_answer import QuestionAnswerAnswerCorrectness\n\njudge = LiteLLM(model_name=\"gpt-4.1\")\nmetric = QuestionAnswerAnswerCorrectness(judge)\n</code></pre> <pre><code>from ragbits.evaluate.pipelines.question_answer import QuestionAnswerResult\n\nasync def main() -&gt; None:\n    dataset = await dataloader.load()\n    response = await responder.run(QuestionAnswerPromptInput(question=dataset[0].question))\n    score = await metric.compute([\n        QuestionAnswerResult(\n            question=dataset[0].question,\n            reference_answer=dataset[0].reference_answer,\n            predicted_result=response,\n        )\n    ])\n    print(score)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <pre><code>{'LLM_based_answer_correctness': 1.0}\n</code></pre> <p>For evaluation, you could use the metric above in a simple loop and just average the score. But for nice parallelism and utilities, we can rely on <code>Evaluator</code>.</p> <pre><code>from ragbits.evaluate.evaluator import Evaluator\nfrom ragbits.evaluate.metrics import MetricSet\nfrom ragbits.evaluate.pipelines.question_answer import QuestionAnswerPipeline\n\nasync def main() -&gt; None:\n    evaluator = Evaluator()\n    results = await evaluator.compute(\n        dataloader=dataloader,\n        pipeline=QuestionAnswerPipeline(responder),\n        metricset=MetricSet(metric),\n    )\n    print(results.metrics)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <pre><code>{'LLM_based_answer_correctness': 0.68}  # Your result may differ\n</code></pre>"},{"location":"tutorials/intro/#conclusions","title":"Conclusions","text":"<p>In this tutorial, we built a very simple LLM workflow using chain-of-thought for question answering and evaluated it on a small dataset.</p> <p>Can we do better? In the next guide, we will build a retrieval-augmented generation (RAG) pipeline in Ragbits for the same task. We will see how this can boost the score substantially.</p>"},{"location":"tutorials/rag/","title":"Tutorial: Retrieval-Augmented Generation (RAG)","text":"<p>Let's now go through a more advanced question answering system with retrieval-augmented generation (RAG) in Ragbits. We will use the same dataset as in the previous tutorial, but we will try to improve the performance.</p> <p>Install the latest Ragbits via <code>pip install -U ragbits[qdrant]</code> and follow along.</p>"},{"location":"tutorials/rag/#configuring-the-environment","title":"Configuring the environment","text":"<p>During development, we will use OpenAI's <code>gpt-4.1-nano</code> model. To authenticate, Ragbits will look into your <code>OPENAI_API_KEY</code>. You can easily swap this out for other providers or local models.</p> <p>Recommended: Set up OpenTelemetry tracing to understand what's happening under the hood.</p> <p>OpenTelemetry is an LLMOps tool that natively integrates with Ragbits and offer explainability and experiment tracking. In this tutorial, you can use OpenTelemetry to visualize prompts and optimization progress as traces to understand the Ragbits' behavior better. Check the full setup guide here.</p>"},{"location":"tutorials/rag/#setting-up-the-retriever","title":"Setting up the retriever","text":"<p>First, let's download the corpus data that we will use for RAG search. To make this fast and cheap to run, we have downsampled the original corpus to 28,000 documents.</p> <p>Before we can search through our documents, we need to parse them into a format that Ragbits can understand. Since our data comes in JSONL format (JSON Lines), we will create a custom document parser that can handle this specific format.</p> <pre><code>import json\n\nfrom ragbits.document_search.documents.document import Document, DocumentType\nfrom ragbits.document_search.documents.element import Element, TextElement\nfrom ragbits.document_search.ingestion.parsers import DocumentParser\n\n# truncate long docs\nMAX_CHARACTERS = 6000\n\nclass RAGQADocumentParser(DocumentParser):\n    supported_document_types = {DocumentType.JSONL}\n\n    async def parse(self, document: Document) -&gt; list[Element]:\n        return [\n            TextElement(\n                content=parsed[\"text\"][:MAX_CHARACTERS],\n                document_meta=document.metadata,\n            )\n            for line in document.local_path.read_text().strip().split(\"\\n\")\n            if (parsed := json.loads(line))\n        ]\n</code></pre> <p>Now we will configure our document search pipeline using Qdrant as the vector database and OpenAI's embeddings for semantic search. We will also use our newly created document parser to parse the corpus data.</p> <pre><code>from qdrant_client import AsyncQdrantClient\nfrom ragbits.core.embeddings import LiteLLMEmbedder\nfrom ragbits.core.vector_stores import VectorStoreOptions\nfrom ragbits.core.vector_stores.qdrant import QdrantVectorStore\nfrom ragbits.document_search import DocumentSearch\nfrom ragbits.document_search.ingestion.parsers import DocumentParserRouter\nfrom ragbits.document_search.ingestion.strategies import BatchedIngestStrategy\n\nretriever = DocumentSearch(\n    vector_store=QdrantVectorStore(\n        client=AsyncQdrantClient(path=\"./ragqa_arena_tech_corpus\"),\n        embedder=LiteLLMEmbedder(model_name=\"text-embedding-3-small\"),\n        default_options=VectorStoreOptions(k=5),\n        index_name=\"ragqa_arena_tech_corpus\",\n    ),\n    ingest_strategy=BatchedIngestStrategy(index_batch_size=1000),\n    parser_router=DocumentParserRouter({DocumentType.JSONL: RAGQADocumentParser()}),\n)\n</code></pre> <p>In order to ingest the data, we run the <code>ingest</code> method on our retriever. The index will be saved in the <code>ragqa_arena_tech_corpus</code> folder. The ingest process may take about 2 minutes.</p> <pre><code>import asyncio\n\nasync def main() -&gt; None:\n    results = await retriever.ingest(\"web://https://huggingface.co/datasets/deepsense-ai/ragbits/resolve/main/ragqa_arena_tech_corpus.jsonl\")\n    print(results)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <pre><code>IngestExecutionResult(\n    successful=[\n        IngestDocumentResult(\n            document_uri='web://https://huggingface.co/datasets/deepsense-ai/ragbits/resolve/main/ragqa_arena_tech_corpus.jsonl',\n            num_elements=28436,\n            error=None\n        )\n    ],\n    failed=[]\n)\n</code></pre>"},{"location":"tutorials/rag/#building-rag-pipeline","title":"Building RAG pipeline","text":"<p>In the previous tutorial, we looked at the low-level Ragbits components in isolation like <code>Prompt</code> or <code>LLM</code>.</p> <p>What if we want to build a pipeline that has multiple steps? For RAG, we need to combine retrieval and generation seamlessly. Let's start by creating prompts that can handle both questions and retrieved context.</p> <p>First, we will create prompts that can work with retrieved context. Notice how we modify our input model to accept both a question and optional context from our retriever.</p> <pre><code>from collections.abc import Sequence\n\nfrom pydantic import BaseModel\nfrom ragbits.core.prompt import Prompt\nfrom ragbits.document_search.documents.element import Element\n\nclass QuestionAnswerPromptInput(BaseModel):\n    question: str\n    context: Sequence[Element] | None = None\n\nclass CoTQuestionAnswerPromptOutput(BaseModel):\n    reason: str\n    answer: str\n\nclass CoTQuestionAnswerPrompt(Prompt[QuestionAnswerPromptInput, CoTQuestionAnswerPromptOutput]):\n    system_prompt = \"\"\"\n    You are a question answering agent. Answer the question that will be provided using context.\n    If in the given context there is not enough information refuse to answer.\n    Think step by step.\n    \"\"\"\n    user_prompt = \"\"\"\n    Question: {{ question }}\n    Context: {% for chunk in context %}{{ chunk.text_representation }}{%- endfor %}\n    \"\"\"\n</code></pre> <p>The syntax below with <code>Agent</code> allows you to connect a few pieces together, in this case, our retriever and a generation component, so the whole system can be evaluated and optimized.</p> <p>The <code>Agent</code> class allows you to connect retrieval and generation components together, creating a pipeline that can be evaluated and optimized as a whole. Here's how we create a RAG agent that inherits from <code>QuestionAnswerAgent</code> that we used in the previous tutorial.</p> <pre><code>from ragbits.agents import AgentOptions, AgentResult\nfrom ragbits.agents.types import QuestionAnswerAgent\n\nclass QuestionAnswerAgentWithRAG(QuestionAnswerAgent):\n    async def run(self, input: QuestionAnswerPromptInput, options: AgentOptions | None = None) -&gt; AgentResult[CoTQuestionAnswerPromptOutput]:\n        context = await retriever.search(input.question)\n        return await super().run(QuestionAnswerPromptInput(question=input.question, context=context))\n</code></pre> <p>Now let's put it all together and test our RAG pipeline.</p> <pre><code>from ragbits.core.llms import LiteLLM\n\nllm = LiteLLM(model_name=\"gpt-4.1-nano\", use_structured_output=True)\nrag = QuestionAnswerAgentWithRAG(llm=llm, prompt=CoTQuestionAnswerPrompt)\n</code></pre> <pre><code>async def main() -&gt; None:\n    response = await rag.run(QuestionAnswerPromptInput(question=\"What are high memory and low memory on linux?\"))\n    print(response.content.answer)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <pre><code>In Linux, high memory (HighMem) refers to a segment of physical memory that is not permanently mapped\nin the kernel's address space, requiring temporary mapping when accessed. Low memory (LowMem) is memory\nthat is always mapped and directly accessible by the kernel. High memory is typically used for user-space\nprograms or caches, and accessing it involves special handling like calling kmap.\n</code></pre>"},{"location":"tutorials/rag/#evaluating-the-system","title":"Evaluating the system","text":"<p>In the previous tutorial with a simple CoT prompt, we got around 68% in terms of answer correctness on our devset. Would this RAG pipeline score better?</p> <pre><code>from ragbits.core.sources import WebSource\nfrom ragbits.evaluate.dataloaders.question_answer import QuestionAnswerDataLoader\nfrom ragbits.evaluate.evaluator import Evaluator\nfrom ragbits.evaluate.metrics import MetricSet\nfrom ragbits.evaluate.metrics.question_answer import QuestionAnswerAnswerCorrectness\nfrom ragbits.evaluate.pipelines.question_answer import QuestionAnswerPipeline\n\nasync def main() -&gt; None:\n    # Define the data loader\n    source = WebSource(url=\"https://huggingface.co/datasets/deepsense-ai/ragbits/resolve/main/ragqa_arena_tech_examples.jsonl\")\n    dataloader=QuestionAnswerDataLoader(\n        source=source,\n        split=\"data[:100]\",\n        question_key=\"question\",\n        answer_key=\"response\",\n    )\n\n    # Define the metric\n    judge = LiteLLM(model_name=\"gpt-4.1\")\n    metric = QuestionAnswerAnswerCorrectness(judge)\n\n    # Run the evaluation\n    evaluator = Evaluator()\n    results = await evaluator.compute(\n        dataloader=dataloader,\n        pipeline=QuestionAnswerPipeline(rag),\n        metricset=MetricSet(metric),\n    )\n    print(results.metrics)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <pre><code>{'LLM_based_answer_correctness': 0.81625}  # Your result may differ\n</code></pre>"},{"location":"tutorials/rag/#conclusions","title":"Conclusions","text":"<p>Improving from around 68% to approximately 81% on this task, in terms of answer correctness, was pretty easy. But Ragbits gives you paths to continue iterating on the quality of your system and we have barely scratched the surface.</p> <p>In general, you have the following tools:</p> <ul> <li>Query Rephrasing: Automatically rephrase user questions into multiple variations to capture different semantic angles and improve retrieval recall, especially for ambiguous or poorly-worded queries.</li> <li>Hybrid Vector Search: Combine dense vector embeddings with sparse keyword-based search (like BM25) to leverage both semantic similarity and exact keyword matching for more comprehensive document retrieval.</li> <li>Reranking: Apply a secondary ranking model to reorder retrieved documents based on their relevance to the specific query, filtering out less relevant results before they reach the language model.</li> </ul> <p>Check the Document Search guide to learn more about available retrieval techniques.</p>"}]}